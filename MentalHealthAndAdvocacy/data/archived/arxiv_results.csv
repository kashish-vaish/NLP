title,authors,abstract,year,url,pdf_url,full_text
Comparisons of Australian Mental Health Distributions,"['David Gunawan', 'William Griffiths', 'Duangkamon Chotikapanich']","Bayesian nonparametric estimates of Australian mental health distributions
are obtained to assess how the mental health status of the population has
changed over time and to compare the mental health status of female/male and
indigenous/non-indigenous population subgroups. First- and second-order
stochastic dominance are used to compare distributions, with results presented
in terms of the posterior probability of dominance and the posterior
probability of no dominance. Our results suggest mental health has deteriorated
in recent years, that males mental health status is better than that of
females, and non-indigenous health status is better than that of the indigenous
population.",2021,http://arxiv.org/abs/2106.08047v1,http://arxiv.org/pdf/2106.08047v1,"Comparisons of Australian Mental Health Distributions 

1 

David Gunawan 

University of Wollongong 

William Griffiths* 

University of Melbourne 

Duangkamon Chotikapanich 
Monash University 

10 June, 2021 

Abstract 

Bayesian nonparametric estimates of Australian mental health distributions are obtained to assess how 

the mental health status of the population has changed over time, and to compare the mental health 

status  of  female/male  and  indigenous/non-indigenous  population subgroups.  First-  and  second-order 

stochastic dominance are used to compare distributions, with results presented in terms of the posterior 

probability of dominance and the posterior probability of no dominance. Our results suggest mental 

health has deteriorated in recent years, that males’ mental health status is better than that of females, 

and non-indigenous health status is better than that of the indigenous population. 

Keywords: Stochastic dominance; Bayesian nonparametric estimation 

JEL codes: I10, C46 

*Corresponding author 
William Griffiths 
Department of Economics 
University of Melbourne 
Vic 3010 
Australia 
wegrif@unimelb.edu.au 

 
 
 
 
 
 
 
 
 
2 

1. 

Introduction 

Improving  the  general  level  of  health  and  reducing  health  inequality  are  major  objectives  of  public 

policy.  To  assess  whether  improvements  are  being  made  overtime,  and  in  different  subgroups  of  a 

population, we need to sample the health status of individuals from the populations of interest, and to 

use those samples to make inferences about the populations. These inferences could take the form of 

comparing health status at different points in time, or comparing the health status of different segments 

of the population. Such comparisons involve several nontrivial steps that include sampling, measuring 

health status, choosing criteria for making comparisons, and making inferences about those criteria.  

We focus on the mental health status of the Australian population in the years 2001, 2006, 2010, 

2014 and 2017, and on that for male/female and indigenous/non-indigenous population subgroups in 

the same years. The prevalence of poor mental health has attracted increasing attention in recent years, 

particularly in relation to difficulties resulting from COVID-19 lockdowns. Our sample does not cover 

the post-COVID period, but our results suggest mental health had already been deteriorating prior to 

that time. Interest has also centred on the status of female mental health relative to that of males, and a 

major government policy objective has been to narrow the gap between indigenous and non-indigenous 

health status. We examine evidence on the relative health status of these population subgroups and how 

this  evidence  has  changed  over  time.  The  sample  we  use  is  the  SF-36  health  survey  questions 

administered as part of the Household, Income and Labour Dynamics in Australia (HILDA) survey.1 

Responses to the mental health questions are converted to a continuous score that ranges between 0 and 

100, with 100 representing good mental health. Several criteria are used to compare scores. The novelty 

in  our  approach  is  the  use  of  stochastic  dominance  as  one  of  the  criteria,  and  the  use  of  Bayesian 

inference to assess dominance and to estimate other criteria. Bayesian nonparametric methods are used 

to estimate a distribution of scores from each sample. In addition to comparing mean scores using their 

1 The HILDA project (Watson and Wooden, 2012) was initiated and is funded by the Australian Government 

Department of Social Services (DSS) and is managed by the Melbourne Institute of Applied Economics and Social 

Research (Melbourne Institute). The findings and views in this paper, however, are those of the authors and should 

not be attributed to either DSS or the Melbourne Institute. 

 
 
                                                            
3 

respective  posterior  distributions,  we  find  posterior  probabilities  of  dominance  for  each  pairwise 

comparison of distributions. Both first and second order stochastic dominance are considered. 

Checking to see if one mental health distribution dominates another involves comparing the 

cumulative  distribution  functions  (cdf’s)  of  the  two  sets  of  health  scores.  For  first-order  stochastic 

dominance  (FSD),  a  distribution  A  dominates  a  distribution  B  (written 

FSDA B )  if  the  cdf  for  A  lies 

below the cdf for B; the proportion of population with a mental health score below any value y is less 

in  A  that  it  is  in  B.  The  two  cdf’s  do  not  cross.  For  second-order  stochastic  dominance  (SSD),  A 

dominates B (written 

SSDA B ) if the area under the cdf between zero and any value y is less for A, than 

it is for B. It implies the sum of all mental health scores less than any value y is less for A than it is for 

B.2 The existence"
"Trauma lurking in the shadows: A Reddit case study of mental health
  issues in online posts about Childhood Sexual Abuse","['Orchid Chetia Phukan', 'Rajesh Sharma', 'Arun Balaji Buduru']","Childhood Sexual Abuse (CSA) is a menace to society and has long-lasting
effects on the mental health of the survivors. From time to time CSA survivors
are haunted by various mental health issues in their lifetime. Proper care and
attention towards CSA survivors facing mental health issues can drastically
improve the mental health conditions of CSA survivors. Previous works
leveraging online social media (OSM) data for understanding mental health
issues haven't focused on mental health issues in individuals with CSA
background. Our work fills this gap by studying Reddit posts related to CSA to
understand their mental health issues. Mental health issues such as depression,
anxiety, and Post-Traumatic Stress Disorder (PTSD) are most commonly observed
in posts with CSA background. Observable differences exist between posts
related to mental health issues with and without CSA background. Keeping this
difference in mind, for identifying mental health issues in posts with CSA
exposure we develop a two-stage framework. The first stage involves classifying
posts with and without CSA background and the second stage involves recognizing
mental health issues in posts that are classified as belonging to CSA
background. The top model in the first stage is able to achieve accuracy and
f1-score (macro) of 96.26% and 96.24%. and in the second stage, the top model
reports hamming score of 67.09%. Content Warning: Reader discretion is
recommended as our study tackles topics such as child sexual abuse,
molestation, etc.",2023,http://arxiv.org/abs/2306.10338v1,http://arxiv.org/pdf/2306.10338v1,"3
2
0
2

n
u
J

7
1

]

Y
C
.
s
c
[

1
v
8
3
3
0
1
.
6
0
3
2
:
v
i
X
r
a

Trauma lurking in the shadows: A Reddit case
study of mental health issues in online posts about
Childhood Sexual Abuse

Orchid Chetia Phukan
Department of CSE
IIIT-Delhi, India
orchidp@iiitd.ac.in
‘

Rajesh Sharma
Institute of Computer Science
University of Tartu, Estonia
rajesh.sharma@ut.ee

Arun Balaji Buduru
Department of CSE
IIIT-Delhi, India
arunb@iiitd.ac.in

Abstract—Childhood Sexual Abuse (CSA) is a menace to
society and has long-lasting effects on the mental health of the
survivors. From time to time CSA survivors are haunted by
various mental health issues in their lifetime. Proper care and
attention towards CSA survivors facing mental health issues
can drastically improve the mental health conditions of CSA
survivors. Previous works leveraging online social media (OSM)
data for understanding mental health issues haven’t focused
on mental health issues in individuals with CSA background.
Our work fills this gap by studying Reddit posts related to
CSA to understand their mental health issues. Mental health
issues such as depression, anxiety, and Post-Traumatic Stress
Disorder (PTSD) are most commonly observed in posts with CSA
background. Observable differences exist between posts related to
mental health issues with and without CSA background. Keeping
this difference in mind, for identifying mental health issues in
posts with CSA exposure we develop a two-stage framework.
The first stage involves classifying posts with and without CSA
background and the second stage involves recognizing mental
health issues in posts that are classified as belonging to CSA
background. The top model in the first stage is able to achieve
accuracy and f1-score (macro) of 96.26% and 96.24%. and in the
second stage, the top model reports hamming score of 67.09%.
Content Warning: Reader discretion is recommended as our
study tackles topics such as child sexual abuse, molestation, etc.
Keywords: Childhood sexual abuse (CSA), mental health,

Reddit, Natural language processing (NLP).

I. INTRODUCTION

Sexually harmful acts against a child (less than 18 years of
age) are characterized as Childhood Sexual Abuse (CSA) and
it spans a wide range of acts including sexual abuse, sexual
interaction, rape, sexual grooming, and sexual exploitation [1].
This form of abuse often entails the perpetrator using force or
making threats [2]. Between ages 7 and 13, children are most
vulnerable to CSA. Perpetrators can be either family members
or strangers [3]. It has been reported that survivors of CSA
are often accompanied by feelings of stigma and guilt [4], [5].
CSA is often succeeded by physical and mental difficulties.
Physical difficulties include physical injuries such as genital
injuries [6] and sexually transmitted diseases (STDs) [7]. Indi-
viduals with a history of CSA are more likely to have chronic
illnesses such as chronic pain [8] and obesity [9] in later stages
of life. Physical injuries may heal, but psychological scars

from the abuse can last throughout later stages of life [7].
Survivors of CSA are often likely to be haunted by the recall of
the traumatic event [10]. Risk of occurrence of various mental
health issues such as Post-Traumatic Stress Disorder (PTSD)
[11], depression, anxiety [8], and eating disorders [12] are
more in CSA survivors. CSA is also reported to be a key risk
factor for the development of Borderline Personality Disorder
(BPD) [13].

For the purpose of understanding mental health issues in
CSA survivors, numerous prior research investigations have
been conducted, but they were primarily restricted to inter-
views, questionnaires, surveys, and electronic health records
(EHRs) with a limited amount of data [14], [15]. In recent
years research considering OSM for mental health issues is
rising [16], as it has been seen that individuals are resorting
to online social media (OSM) platforms to find shelter for
their mental health issues [17] where CSA survivors are no
exception. Especially OSM such as Reddit has turned out to be
a popular medium [18] for such. Reddit is a community-based
platform where each community is called a “subreddit” and is
based on a particular topic or issue [19]. These communities
sometimes act as a discussion forum and sometimes as peer
support groups for various issues related to health, mental
complications, etc. Thus,
this inspired us to look through
various subreddits and gather posts about mental health issues
associated with CSA, and probe the following three research
questions.

RQ1: What are the commonly discussed mental health

issues in posts related with CSA?

For finding out

the most commonly discussed mental
health issues in posts with CSA exposure, we analyzed
r/adultsurvivors. We found out that depression, anxiety and
PTSD are the most commonly discussed mental health issues.
RQ2: Are there differences between the posts related to
mental health issues with and without CSA background?
Ment"
Technology in Association With Mental Health: Meta-ethnography,['Hamza Mohammed'],"This research paper presents a meta-analysis of the multifaceted role of
technology in mental health. The pervasive influence of technology on daily
lives necessitates a deep understanding of its impact on mental health
services. This study synthesizes literature covering Behavioral Intervention
Technologies (BITs), digital mental health interventions during COVID-19, young
men's attitudes toward mental health technologies, technology-based
interventions for university students, and the applicability of mobile health
technologies for individuals with serious mental illnesses. BITs are recognized
for their potential to provide evidence-based interventions for mental health
conditions, especially anxiety disorders. The COVID-19 pandemic acted as a
catalyst for the adoption of digital mental health services, underscoring their
crucial role in providing accessible and quality care; however, their efficacy
needs to be reinforced by workforce training, high-quality evidence, and
digital equity. A nuanced understanding of young men's attitudes toward mental
health is imperative for devising effective online services. Technology-based
interventions for university students are promising, although variable in
effectiveness; their deployment must be evidence-based and tailored to
individual needs. Mobile health technologies, particularly activity tracking,
hold promise for individuals with serious mental illnesses. Collectively,
technology has immense potential to revolutionize mental health care. However,
the implementation must be evidence-based, ethical, and equitable, with
continued research focusing on experiences across diverse populations, ensuring
accessibility and efficacy for all.",2023,http://arxiv.org/abs/2307.10513v2,http://arxiv.org/pdf/2307.10513v2,"Technology in Association With Mental Health: Meta-ethnography 

Hamza Mohammed | hamzamohammed0784@gmail.com 

Abstract 

This research paper presents a meta-analysis of the multifaceted role of technology in mental 

health. The pervasive influence of technology on daily lives necessitates a deep understanding of 

its impact on mental health services. This study synthesizes literature covering Behavioral 

Intervention Technologies (BITs), digital mental health interventions during COVID-19, young 

men's attitudes toward mental health technologies, technology-based interventions for university 

students, and the applicability of mobile health technologies for individuals with serious mental 

illnesses. BITs are recognized for their potential to provide evidence-based interventions for 

mental health conditions, especially anxiety disorders. The COVID-19 pandemic acted as a 

catalyst for the adoption of digital mental health services, underscoring their crucial role in 

providing accessible and quality care; however, their efficacy needs to be reinforced by 

workforce training, high-quality evidence, and digital equity. A nuanced understanding of young 

men's attitudes toward mental health is imperative for devising effective online services. 

Technology-based interventions for university students are promising, although variable in 

effectiveness; their deployment must be evidence-based and tailored to individual needs. Mobile 

health technologies, particularly activity tracking, hold promise for individuals with serious 

mental illnesses. Collectively, technology has immense potential to revolutionize mental health 

care. However, the implementation must be evidence-based, ethical, and equitable, with 

continued research focusing on experiences across diverse populations, ensuring accessibility 

and efficacy for all. 

 
I. Introduction 

Technology has become an integral part of our daily lives in the rapidly evolving digital 

age. It has transformed how we communicate, work, learn, and manage our health. One of the 

areas where technology has made significant strides is in the field of mental health. Technology 

has opened up new avenues for accessing mental health services, from teletherapy platforms to 

mental health apps. However, the impact of technology on mental health is multifaceted and 

complex, warranting comprehensive research and understanding (Mohr et al., 2013; Torous et 

al., 2020; Farrer et al., 2013; Naslund et al., 2015). 

This paper aims to delve into the current research surrounding technology's role in mental 

health, focusing on its benefits, challenges, and potential for future development. The objective 

is to provide a comprehensive overview of the existing literature, thereby contributing to the 

ongoing discourse in this field. The research papers that will be discussed in this review have 

been carefully selected to cover a range of topics within the broader theme of technology and 

mental health. These include the role of behavioral intervention technologies in mental health, 

the impact of digital mental health interventions during the COVID-19 pandemic, young men's 

attitudes towards mental health and technology, the effectiveness of technology-based 

interventions for tertiary students, and the feasibility of m-Health technologies for individuals 

with serious mental illness (Mohr et al., 2013; Torous et al., 2020; Farrer et al., 2013; Naslund et 

al., 2015). 

Each of these papers offers valuable insights into the intersection of technology and 

mental health, shedding light on the potential of technology to transform mental health services 

and the challenges that need to be addressed. By examining these papers, this review aims to 

provide a comprehensive understanding of the current state of research in this field and highlight 

areas for future exploration. In the following sections, I will delve into each of these papers, 

discussing their findings, implications, and contributions to the field of mental health and 

technology. Through this review, I hope to provide a comprehensive overview of the current 

state of research in this field, thereby contributing to the ongoing discourse on the impact of 

technology on mental health. 

II. Behavioral Intervention Technologies and Mental Health 

The advent of technology has brought about significant changes in the field of mental 

health, particularly in the development of Behavioral Intervention Technologies (BITs). These 

technologies have been instrumental in providing evidence-based interventions to individuals 

suffering from various mental health conditions. The paper ""Behavioral Intervention 

Technologies: Evidence Review and recommendations for future research in mental health"" by 

David C. Mohr et al. provides an in-depth analysis of the role of these technologies in mental 

health (Mohr et al., 2013). 

The paper begins by acknowledging the prevalence of mental "
Gendered Mental Health Stigma in Masked Language Models,"['Inna Wanyin Lin', 'Lucille Njoo', 'Anjalie Field', 'Ashish Sharma', 'Katharina Reinecke', 'Tim Althoff', 'Yulia Tsvetkov']","Mental health stigma prevents many individuals from receiving the appropriate
care, and social psychology studies have shown that mental health tends to be
overlooked in men. In this work, we investigate gendered mental health stigma
in masked language models. In doing so, we operationalize mental health stigma
by developing a framework grounded in psychology research: we use clinical
psychology literature to curate prompts, then evaluate the models' propensity
to generate gendered words. We find that masked language models capture
societal stigma about gender in mental health: models are consistently more
likely to predict female subjects than male in sentences about having a mental
health condition (32% vs. 19%), and this disparity is exacerbated for sentences
that indicate treatment-seeking behavior. Furthermore, we find that different
models capture dimensions of stigma differently for men and women, associating
stereotypes like anger, blame, and pity more with women with mental health
conditions than with men. In showing the complex nuances of models' gendered
mental health stigma, we demonstrate that context and overlapping dimensions of
identity are important considerations when assessing computational models'
social biases.",2022,http://arxiv.org/abs/2210.15144v2,http://arxiv.org/pdf/2210.15144v2,"Gendered Mental Health Stigma in Masked Language Models

Inna Wanyin Lin1∗ Lucille Njoo1∗ Anjalie Field2 Ashish Sharma1
Katharina Reinecke1 Tim Althoff1 Yulia Tsvetkov1
1Paul G. Allen School of Computer Science & Engineering, University of Washington
2Stanford University
{ilin, lnjoo}@cs.washington.edu

3
2
0
2

r
p
A
1
1

]
L
C
.
s
c
[

2
v
4
4
1
5
1
.
0
1
2
2
:
v
i
X
r
a

Abstract

Mental health stigma prevents many individ-
uals from receiving the appropriate care, and
social psychology studies have shown that
mental health tends to be overlooked in men.
In this work, we investigate gendered men-
tal health stigma in masked language mod-
els.
In doing so, we operationalize men-
tal health stigma by developing a framework
grounded in psychology research: we use clin-
ical psychology literature to curate prompts,
then evaluate the models’ propensity to gen-
erate gendered words. We ﬁnd that masked
language models capture societal stigma about
gender in mental health: models are consis-
tently more likely to predict female subjects
than male in sentences about having a men-
tal health condition (32% vs. 19%), and this
disparity is exacerbated for sentences that indi-
cate treatment-seeking behavior. Furthermore,
we ﬁnd that different models capture dimen-
sions of stigma differently for men and women,
associating stereotypes like anger, blame, and
pity more with women with mental health con-
ditions than with men. In showing the complex
nuances of models’ gendered mental health
stigma, we demonstrate that context and over-
lapping dimensions of identity are important
considerations when assessing computational
models’ social biases.

1

Introduction

Mental health issues are heavily stigmatized, pre-
venting many individuals from seeking appropri-
ate care (Sickel et al., 2014). In addition, social
psychology studies have shown that this stigma
manifests differently for different genders: mental
illness is more visibly associated with women, but
tends to be more harshly derided in men (Chatmon,
2020). This asymmetrical stigma constitutes harms
towards both men and women, increasing the risks
of under-diagnosis or over-diagnosis respectively.

∗ Indicates equal contribution.

Figure 1: We investigate masked language models’ bi-
ases at the intersection of gender and mental health.
Using theoretically-motivated prompts about mental
health conditions, we have models ﬁll in the masked to-
ken, then examine the probabilities of generated words
with gender associations.

Since language is central to psychotherapy and
peer support, NLP models have been increasingly
employed on mental health-related tasks (Chancel-
lor and De Choudhury, 2020; Sharma et al., 2021,
2022; Zhang and Danescu-Niculescu-Mizil, 2020).
Many approaches developed for these purposes rely
on pretrained language models, thus running the
risk of incorporating any pre-learned biases these
models may contain (Straw and Callison-Burch,
2020). However, no prior research has examined
how biases related to mental health stigma are rep-
resented in language models. Understanding if and
how pretrained language models encode mental
health stigma is important for developing fair, re-
sponsible mental health applications. To the best
of our knowledge, our work is the ﬁrst to opera-
tionalize mental health stigma in NLP research and
aim to understand the intersection between mental
health and gender in language models.

In this work, we propose a framework to inves-
tigate joint encoding of gender bias and mental

 
 
 
 
 
 
health stigma in masked language models (MLMs),
which have become widely used in downstream
applications (Devlin et al., 2019; Liu et al., 2019).
Our framework uses questionnaires developed
in psychology research to curate prompts about
mental health conditions. Then, with several se-
lected language models, we mask out parts of
these prompts and examine the model’s tendency
to generate explicitly gendered words, including
pronouns, nouns, ﬁrst names, and noun phrases.1
In order to disentangle general gender biases from
gender biases tied to mental health stigma, we com-
pare these results with prompts describing health
conditions that are not related to mental health.
Additionally, to understand the effects of domain-
speciﬁc training data, we investigate both general-
purpose MLMs and MLMs pretrained on mental
health corpora. We aim to answer the two research
questions below.

RQ1: Do MLMs associate mental health con-
ditions with a particular gender? To answer
RQ1, we curate three sets of prompts that reﬂect
three healthcare-seeking phases: diagnosis, inten-
tion, and action, based on the widely-cited Health
Action Process Approach (Schwarzer et al., 2011).
We prompt the models to generate the subjects of
sentences that indicate someone is (1) diagnosed
with a mental health condition, (2) intending to
seek help or treatment for a mental health condi-
tion, and (3) taking action to get treatment for a
mental health condition. We ﬁnd "
Quantifying language changes surrounding mental health on Twitter,"['Anne Marie Stupinski', 'Thayer Alshaabi', 'Michael V. Arnold', 'Jane Lydia Adams', 'Joshua R. Minot', 'Matthew Price', 'Peter Sheridan Dodds', 'Christopher M. Danforth']","Mental health challenges are thought to afflict around 10% of the global
population each year, with many going untreated due to stigma and limited
access to services. Here, we explore trends in words and phrases related to
mental health through a collection of 1- , 2-, and 3-grams parsed from a data
stream of roughly 10% of all English tweets since 2012. We examine temporal
dynamics of mental health language, finding that the popularity of the phrase
'mental health' increased by nearly two orders of magnitude between 2012 and
2018. We observe that mentions of 'mental health' spike annually and reliably
due to mental health awareness campaigns, as well as unpredictably in response
to mass shootings, celebrities dying by suicide, and popular fictional stories
portraying suicide. We find that the level of positivity of messages containing
'mental health', while stable through the growth period, has declined recently.
Finally, we use the ratio of original tweets to retweets to quantify the
fraction of appearances of mental health language due to social amplification.
Since 2015, mentions of mental health have become increasingly due to retweets,
suggesting that stigma associated with discussion of mental health on Twitter
has diminished with time.",2021,http://arxiv.org/abs/2106.01481v1,http://arxiv.org/pdf/2106.01481v1,"1
2
0
2

n
u
J

2

]
h
p
-
c
o
s
.
s
c
i
s
y
h
p
[

1
v
1
8
4
1
0
.
6
0
1
2
:
v
i
X
r
a

Quantifying language changes surrounding mental health on Twitter

Anne Marie Stupinski,1, ∗ Thayer Alshaabi,1 Michael V. Arnold,1 Jane Lydia Adams,1 Joshua
R. Minot,1 Matthew Price,2 Peter Sheridan Dodds,1, 3, 4 and Christopher M. Danforth1, 4, 3, †
1Computational Story Lab, Vermont Complex Systems Center, University of Vermont, Burlington, VT 05405.
2Department of Psychology, University of Vermont, Burlington, VT 05405.
3Department of Computer Science, The University of Vermont, Burlington, VT 05405.
4Department of Mathematics & Statistics, The University of Vermont, Burlington, VT 05405.
(Dated: June 4, 2021)

Mental health challenges are thought to aﬄict around 10% of the global population each year,
with many going untreated due to stigma and limited access to services. Here, we explore trends in
words and phrases related to mental health through a collection of 1- , 2-, and 3-grams parsed from
a data stream of roughly 10% of all English tweets since 2012. We examine temporal dynamics of
mental health language, ﬁnding that the popularity of the phrase ‘mental health’ increased by nearly
two orders of magnitude between 2012 and 2018. We observe that mentions of ‘mental health’ spike
annually and reliably due to mental health awareness campaigns, as well as unpredictably in response
to mass shootings, celebrities dying by suicide, and popular ﬁctional stories portraying suicide. We
ﬁnd that the level of positivity of messages containing ‘mental health’, while stable through the
growth period, has declined recently. Finally, we use the ratio of original tweets to retweets to
quantify the fraction of appearances of mental health language due to social ampliﬁcation. Since
2015, mentions of mental health have become increasingly due to retweets, suggesting that stigma
associated with discussion of mental health on Twitter has diminished with time.

I.

INTRODUCTION

Recent estimates place 1 in 10 people globally as expe-
riencing from some form of mental illness [1], with 1 in
30 suﬀering from depression [2]. These rates put mental
illness among the leading causes of ill-health and disabil-
ity worldwide. Moreover, rates of mental health disor-
ders and deaths by suicide have increased in recent years,
especially among young people [3].

Since the beginning of the COVID-19 pandemic and
the subsequent social isolation, there have been record-
ings of drastic declines in physical activity and time
spent socializing, and coinciding increases in screen time
and symptoms of depression [4]. Google searches for
mental health related topics also increased in the ﬁrst
weeks of the pandemic,
leveling out after more infor-
mation regarding stay-at-home orders were released [5].
Following March 2020, there has also been a measured
increase in suicidal ideation that is associated with ele-
vated reports of isolation [6]. The service Crisis Text
Line reported receiving a higher than average volume
of messages for every day following March 16th in the
year 2020, with the main topics being anxiety, depres-
sion, grief, and eating disorders [7]. Price et al. [8] also
found that daily “doomscrolling”—repeatedly consuming
negative news and media content online—was associated
with same-day increases in depression and PTSD. These
eﬀects were larger among those with a prior history of
psychopathology and trauma exposure. The pandemic
also inﬂuenced what content people discussed on social

∗ astupins@uvm.edu
† cdanfort@uvm.edu

Typeset by REVTEX

media, with users shifting away from “self-focused” per-
spectives and towards more “other-focused” topics that
used to be vulnerable or taboo to discuss [9]. A survey
of American adults during the pandemic found that the
depth of distressing self-disclosures posted online could
be predicted by a user’s perceived anonymity, visibility
control, and closeness to their audience [10].

Historically, the availability of mental health treat-
ment services has not meet the demand for such [11].
Mental health care also experiences a paradox of being
over-diagnosed yet under-supported, with some symp-
toms and disorders being readily medicated despite not
being understood and accepted socially [12]. Further-
more, many who would beneﬁt from mental health ser-
vices do not seek or participate in care, as they are either
unaware of such services, are unable to aﬀord them, or
the stigma associated with seeking treatment proves too
great a barrier [13]. In fact, two-thirds of people with a
known mental disorder do not seek help from a health
professional [14].

While stigma has proven to be a signiﬁcant barri-
er to receiving treatment from formal (e.g., psychia-
trists, counselors) and informal sources (e.g., family and
friends), the COVID-19 pandemic and subsequent isola-
tion have spurred awareness of mental illness and discus-
sion on this topic in public forums such as social media.
Measuring changes in this "
Robotics Technology in Mental Health Care,['Laurel D. Riek'],"This chapter discusses the existing and future use of robotics and
intelligent sensing technology in mental health care. While the use of this
technology is nascent in mental health care, it represents a potentially useful
tool in the practitioner's toolbox. The goal of this chapter is to provide a
brief overview of the field, discuss the recent use of robotics technology in
mental health care practice, explore some of the design issues and ethical
issues of using robots in this space, and finally to explore the potential of
emerging technology.",2015,http://arxiv.org/abs/1511.02281v1,http://arxiv.org/pdf/1511.02281v1,
"MentSum: A Resource for Exploring Summarization of Mental Health Online
  Posts","['Sajad Sotudeh', 'Nazli Goharian', 'Zachary Young']","Mental health remains a significant challenge of public health worldwide.
With increasing popularity of online platforms, many use the platforms to share
their mental health conditions, express their feelings, and seek help from the
community and counselors. Some of these platforms, such as Reachout, are
dedicated forums where the users register to seek help. Others such as Reddit
provide subreddits where the users publicly but anonymously post their mental
health distress. Although posts are of varying length, it is beneficial to
provide a short, but informative summary for fast processing by the counselors.
To facilitate research in summarization of mental health online posts, we
introduce Mental Health Summarization dataset, MentSum, containing over 24k
carefully selected user posts from Reddit, along with their short user-written
summary (called TLDR) in English from 43 mental health subreddits. This
domain-specific dataset could be of interest not only for generating short
summaries on Reddit, but also for generating summaries of posts on the
dedicated mental health forums such as Reachout. We further evaluate both
extractive and abstractive state-of-the-art summarization baselines in terms of
Rouge scores, and finally conduct an in-depth human evaluation study of both
user-written and system-generated summaries, highlighting challenges in this
research.",2022,http://arxiv.org/abs/2206.00856v1,http://arxiv.org/pdf/2206.00856v1,"MentSum: A Resource for Exploring
Summarization of Mental Health Online Posts

Sajad Sotudeh1,2*, Nazli Goharian1,2*, Zachary Young2
1Information Retrieval Lab, Georgetown University
2Department of Computer Science, Georgetown University
{sajad, nazli}@ir.cs.georgetown.edu, zjy2@georgetown.edu

Abstract
Mental health remains a signiﬁcant challenge of public health worldwide. With increasing popularity of online platforms,
many use the platforms to share their mental health conditions, express their feelings, and seek help from the community and
counselors. Some of these platforms, such as Reachout, are dedicated forums where the users register to seek help. Others such
as Reddit provide subreddits where the users publicly but anonymously post their mental health distress. Although posts are of
varying length, it is beneﬁcial to provide a short, but informative summary for fast processing by the counselors. To facilitate
research in summarization of mental health online posts, we introduce Mental Health Summarization dataset, MENTSUM,
containing over 24k carefully selected user posts from Reddit, along with their short user-written summary (called TLDR)
in English from 43 mental health subreddits. This domain-speciﬁc dataset could be of interest not only for generating short
summaries on Reddit, but also for generating summaries of posts on the dedicated mental health forums such as Reachout. We
further evaluate both extractive and abstractive state-of-the-art summarization baselines in terms of ROUGE scores, and ﬁnally
conduct an in-depth human evaluation study of both user-written and system-generated summaries, highlighting challenges in
this research.

Keywords: Text Summarization, Summarization Dataset, Mental Health Summarization

1.

Introduction

Mental health has been a global public health challenge
for many years and even more so since the COVID-
19 pandemic (Holmes et al., 2020; Pfefferbaum and
North, 2020; Otu et al., 2020). Social media has served
as a viable platform for many to share their frustrations,
emotions, depressions, and also their already diagnosed
mental disorders. Figure 1 depicts the growing popu-
larity (measured by the number of subscribers) of dis-
cussion forums dedicated to three mental disorders in
Reddit social discussion website over the years. 1.
Online social platforms such as Reddit 2 and Rea-
chout 3 have become increasingly popular over the re-
cent years due to the vital networking facets that they
offer to the community users. These platforms provide
users with an opportunity to share different types of
user-curated and user-generated content, ranging from
daily updates/statuses to sharing personal anecdotes
and mental conditions. Users can also interact with
other users, carry on conversations through which they
can express their feelings and views regarding a spe-
ciﬁc topic. Platforms such as Reachout are not pub-
lic, requiring users to register; users’ content are not
visible to anyone but to the permitted users and coun-
selors. On the other hand, in the public platforms
such as Reddit, users can openly exchange information
with each other through community-based subreddits,
each of which speciﬁed with a certain theme or condi-

*Equal contribution
1Statistics from https://subredditstats.com/
2https://www.reddit.com/
3https://au.reachout.com/

Figure 1: Growing popularity of mental health related
forums in Reddit.

tion, such as suicide watch, mental health, alcoholism,
attention-deﬁcit/hyperactivity disorder (ADHD), de-
pression, anxiety, etc. Each post in any of these subred-
dits, however, may report more than one past or present
condition and what the user is distressed about.
The user-generated content on many of such platforms
might be of varying length. Longer posts may address
multitude of issues of concern or simply be a lengthy
elaboration of the user on the situation. The longer a
post is, the more time it requires a counselor for reading
the post which leads to fatigue and/or delay in a timely
response. Our hypothesis is that a short yet informative
summary of each user’s post provides the counselors
with the important information of the post in a glimpse
before reading the details. Hence, in this research we

2
2
0
2

n
u
J

2

]
L
C
.
s
c
[

1
v
6
5
8
0
0
.
6
0
2
2
:
v
i
X
r
a

2013201420152016201720182019202020212022Year0.2M0.4M0.6M0.8M1.0M1.2M1.4MSubscribers (in millions)ADHDdepressionanxiety 
 
 
 
 
 
create a dataset resource for the research community to
be utilized in the short text (known as TLDR) summa-
rization of mental health related social media posts.
A great deal of research studies in social media mental
health domain have focused on developing classiﬁca-
tion models and their needed datasets to either triage
the severity of the potential harm or to identify the type
of mental disorders; among these efforts are (Choud-
hury et al., 2013; Coppersmith et al., 2014a; Yates et
al., 2017; Coppersmith et al., 2018; Cohan et al., 2018;"
"Mobile Health Solution for College Student Mental Health: Interview
  Study and Design Requirement Analysis","['Xiaomei Wang', 'Alec Smith', 'Bruce Keller', 'Farzan Sasangohar']","Background: Mental health problems are prevalent in college students. The
COVID-19 pandemic exacerbated the problems, and created a surge in the
popularity of telehealth and mobile health solutions. Despite that mobile
health is a promising approach to help students with mental health needs, few
studies exist in investigating key features students need in a mental health
self-management tool. Objective: The objective of our study was to identified
key requirements and features for the design of a student-centered mental
health self-management tool. Methods: An interview study was first conducted to
understand college students' needs and preferences on a mental health
self-management tool. Functional information requirement analysis was then
conducted to translate the needs into design implications. Results: A total of
153 university students were recruited for the semi-structured interview. The
participants mentioned several features including coping techniques, artificial
intelligence, time management, tracking, and communication with others.
Participant's preferences on usability and privacy settings were also
collected. The desired functions were analyzed and turned into design-agnostic
information requirements. Conclusions: This study documents findings from
interviews with university students to understand their needs and preferences
for a tool to help with self-management of mental health.",2022,http://arxiv.org/abs/2206.02960v1,http://arxiv.org/pdf/2206.02960v1,"Title:  

Mobile Health Solution for College Student Mental Health: Interview Study and Design 
Requirement Analysis 

Authors List: Xiaomei Wang, Alec Smith, Bruce Keller, Farzan Sasangohar  

Keywords: Mobile Health, Interview, Mental Health, College Student, Self-Management 

Abstract:  

Background: Mental health problems are prevalent in college students. The COVID-19 pandemic 
exacerbated the problems, and created a surge in the popularity of telehealth and mobile health 
solutions. Despite that mobile health is a promising approach to help students with mental health 
needs, few studies exist in investigating key features students need in a mental health self-
management tool. 

Objective: The objective of our study was to identified key requirements and features for the 
design of a student-centered mental health self-management tool. 

Methods: An interview study was first conducted to understand college students’ needs and 
preferences on a mental health self-management tool. Functional information requirement 
analysis was then conducted to translate the needs into design implications. 

Results: A total of 153 university students were recruited for the semi-structured interview. The 
participants mentioned several features including coping techniques, artificial intelligence, time 
management, tracking, and communication with others. Participant’s preferences on usability 
and privacy settings were also collected. The desired functions were analyzed and turned into 
design-agnostic information requirements. 

Conclusions: This study documents findings from interviews with university students to 
understand their needs and preferences for a tool to help with self-management of mental health.  

1 

 
 
  
 
 
Introduction 
About 1 in 3 first-year college students screen positive for at least one mental health disorder, 
with low variability across countries and demographics [1]. Despite 20% increased spending in 
university mental health services [2] and increased intention and utilization of mental health 
services by students, college student mental health continues to decline [3]. Poor student mental 
health has resulted in suicidal ideation [4], low class engagement, low GPA [5], and greater 
likelihood of dropping out [6]. All of these problems have been exacerbated by the ongoing 
COVID-19 pandemic at the time of this study, with studies showing evidence of students not 
effectively coping [7,8].  

While students generally prefer in-person counseling [9], COVID-19 has created a surge in the 
popularity of telehealth services due to its ability to reach people in isolation and prevent the 
spread of illness [10]. In-person counseling has many disadvantages that may make alternatives 
like virtual counseling and mental health apps more appealing even after the pandemic. 
Counseling is associated with higher financial costs and is not preferred by those with self-
stigma regarding mental health [9]. It is well-documented that a sizable portion of students who 
committed suicide never contacted their institutions’ counseling center [11]. Furthermore, long 
wait times are the reality in many colleges with an average wait of 6 business days for a triage 
session and 9 business days for their first session after triage [12].  

In contrast, digital interventions such as a mobile health (mHealth) application can be accessed 
on demand and almost instantaneously and as frequently as a user desires. Despite there being 
hundreds of mental health apps available on Google Play and the Apple App Store, relatively 
little is known about their effectiveness, as most marketing for apps is based on testimonials and 
unsupported claims. Less than half of these apps are supported by studies [13], and those studies 
have been generally criticized as biased by high rates of participant dropout [14]. Further, users 
tend to drop off in usage after a short period of time [15]. While there is certainly need for 
mHealth apps as alternative delivery of mental health care, rigorous design and evaluation 
methods should be taken to ensure that the apps are designed to be user-centered, evidence-
based, well-integrated with professional care, and used sustainably [16]. 

Despite these shortcomings, mHealth presents a promising platform to support students with 
mental health needs, especially given the popularity and ubiquity of smartphones among college 
students [17]. As digital natives, students are more proficient at communicating across virtual 
platforms [18] which may help in managing their mental health through apps. Other research has 
also found that asking student patients to use a mental health app between the time they set up 
and attend an appointment with a counselor led to moderate app usage and better mental health 
outcomes [12]. In spite of these promising findings, study of mental health apps for college 
students  have been focused on efficacy with self-selecting participants [19], with a genera"
Effect of Social Media Use on Mental Health during Lockdown in India,['Sweta Swarnam'],"This research paper studies about the role of social media use and increase
the risk factor of mental health during covid 19 or lockdown. Although few
studies have been conducted on the role about the effect of social media use on
mental health during lockdown and impact on human reactive nature during
lockdown. As a rapidly spreading pandemic, a biomedical disease has serious
physical and tremendous mental health implications. An occupational community
of internal migrant workers is one of the most vulnerable, but neglected, and
is likely to develop psychological ill-effects due to COVID-19's double whammy
impact. Mental health is a crucial aspect that needs to be addressed during
this lock-down as all modes of communication revolve around the virus. There
are many difficulties with the unprecedented changes that have occurred so
quickly due to the pandemic and stay-at - home confinement to achieve social
distance and mitigate the risk of infection. These include impaired health,
well-being, and sleep as a result of daily routine disruption, anxiety, worry,
isolation, greater stress on family and work, and excessive screen time. An
essential part of our overall health and well-being is mental and emotional
health. An important skill is managing emotions and maintaining emotional
balance. It helps you face challenges and stress when you manage your emotional
health. Lack of skills in emotional regulation may lead to poor mental health
and relationship difficulties. It is as important to look after our mental
health as it is to look after our physical health. For mental health
professionals, the pandemic has also brought many ethical challenges.",2021,http://arxiv.org/abs/2102.09369v1,http://arxiv.org/pdf/2102.09369v1,"Effect of Social Media Use on Mental Health during Lockdown in 
India 

Sweta Swarnam 

Symbiosis Centre for Information Technology, 

Symbiosis International (Deemed University), Pune, India 

Email:sweta.swarnam@associates.scit.edu 

Abstract 

This  research  paper  studies  about  the  role  of  social  media  use  and  increase  the  risk  factor  of 
mental health during covid 19 or lockdown. Although few studies have been conducted on the role 
about  the  effect  of  social  media  use  on  mental  health  during  lockdown  and  impact  on  human 
reactive  nature  during  lockdown.  As  a  rapidly  spreading  pandemic,  a  biomedical  disease  has 
serious  physical  and  tremendous  mental  health  implications.  An  occupational  community  of 
internal  migrant  workers  is  one  of  the  most  vulnerable,  but  neglected,  and  is  likely  to  develop 
psychological ill-effects due to COVID-19's double  whammy impact. Mental health is a crucial 
aspect that needs to be addressed during this lock-down as all modes of communication revolve 
around the virus. There are many difficulties with the unprecedented changes that have occurred 
so  quickly  due  to the  pandemic  and  stay-at -  home  confinement  to  achieve  social  distance  and 
mitigate the risk of infection. These include impaired health, well-being, and sleep as a result of 
daily routine disruption, anxiety, worry, isolation, greater stress on family and work, and excessive 
screen time. An essential part of our overall health and well-being is mental and emotional health. 
An important  skill  is  managing  emotions  and  maintaining  emotional  balance.  It  helps  you face 
challenges  and  stress  when  you  manage  your  emotional  health.  Lack  of  skills  in  emotional 
regulation may lead to poor mental health and relationship difficulties. It is as important to look 
after our mental health as it is to look after our physical health. For mental health professionals, 
the pandemic has also brought many ethical challenges. Personal protection, personal treatment 
needs if they get infected, impact on others if they get infected, economic crisis, ethical problems 
for themselves and others, and training are the issues that concern mental health professionals. In 
the  wake  of  the  pandemic,  the  training  of  residents  has  also  been  compromised.  The  ways  of 
learning  for  medical  students  and  residents  may  also  change,  leading  to  an  opportunity  to 
innovate. This research concentrates upon the above-mentioned purpose and tries to bring out the 
fact  about  the  same.  This  study  shows  us  the  effect  on  mental  health  by  spending  more  time  in 
social media during lockdown, what its impact on their mental health during lockdown in different 
age groups and how to reduce spending more time on social media to avoid depression and keep 
mental condition positive. 

Keywords 

Social Media, Mental health, depression, Lockdown and Covid 19. 

1 

 
 
 
 
 
1.  Introduction 

During this lockdown people are started spending huge amount of time on social media  and for 
many  youths  nowadays,  social  media  has  been  popular  aspects  of  life.  Whether  positive  or 
negative, most people engage with social media without stopping to think about what the effects 
are on our lives. Social networking is a perfect place to rapidly distribute content across the world, 
with posts like ""breaking news"" earning hundreds of thousands of retweets in minutes. Although 
social media impacts people positively, it also has negative impacts on people. Social networking 
has been described primarily to refer to ""the many fairly inexpensive and widely available online 
resources  that  make  it  easier  for  everyone  to  publish  and  access  knowledge,  cooperate  on  a 
collaborative project or create relationships. It has become a forum of discussion of every single 
social issue that is taking place. In the current situation, one of the most pathetic and to – bother 
social media use and increase the risk factor of mental health of humans. This has been increasing 
day  by  day  at  nook  and  corner  of  the  country.  Mindfulness  simply  means  being  in  the  present 
without thinking about the past or the future; choosing what you react to, rather than being carried 
away by everything that appears in your mind or experience; being non-judgmental and cultivating 
an attitude of impermanence towards things and situations, focusing on one thing at a time. This 
allows us to remain open to experiences and allows you not to be overly affected by them. 

The sparse literature on the effects of epidemics on mental health relates more to the sequelae of 
the  disease  itself  than  to  social  distancing  (e.g.,  mothers  of  children  with  congenital  Zika 
syndrome). Large-scale disasters, however, whether traumatic (e.g., World Trade Center attacks 
or mass shootings), natural (e.g., hurricanes), or envi"
"SMHD: A Large-Scale Resource for Exploring Online Language Usage for
  Multiple Mental Health Conditions","['Arman Cohan', 'Bart Desmet', 'Andrew Yates', 'Luca Soldaini', 'Sean MacAvaney', 'Nazli Goharian']","Mental health is a significant and growing public health concern. As language
usage can be leveraged to obtain crucial insights into mental health
conditions, there is a need for large-scale, labeled, mental health-related
datasets of users who have been diagnosed with one or more of such conditions.
In this paper, we investigate the creation of high-precision patterns to
identify self-reported diagnoses of nine different mental health conditions,
and obtain high-quality labeled data without the need for manual labelling. We
introduce the SMHD (Self-reported Mental Health Diagnoses) dataset and make it
available. SMHD is a novel large dataset of social media posts from users with
one or multiple mental health conditions along with matched control users. We
examine distinctions in users' language, as measured by linguistic and
psychological variables. We further explore text classification methods to
identify individuals with mental conditions through their language.",2018,http://arxiv.org/abs/1806.05258v2,http://arxiv.org/pdf/1806.05258v2,"SMHD: A Large-Scale Resource for Exploring Online Language Usage
for Multiple Mental Health Conditions
Bart Desmet1,2 *
Sean MacAvaney1

Arman Cohan1 *
Luca Soldaini1

Andrew Yates1,3 *

Nazli Goharian1

8
1
0
2

l
u
J

0
1

]
L
C
.
s
c
[

2
v
8
5
2
5
0
.
6
0
8
1
:
v
i
X
r
a

1IR Lab, Georgetown University, US
{firstname}@ir.cs.georgetown.edu

2LT3, Ghent University, BE
bart.desmet@ugent.be

3Max Planck Institute for Informatics, DE
ayates@mpi-inf.mpg.de

Abstract

Mental health is a signiﬁcant and growing public health concern. As language usage can be
leveraged to obtain crucial insights into mental health conditions, there is a need for large-scale,
labeled, mental health-related datasets of users who have been diagnosed with one or more of
such conditions. In this paper, we investigate the creation of high-precision patterns to identify
self-reported diagnoses of nine different mental health conditions, and obtain high-quality labeled
data without the need for manual labelling. We introduce the SMHD (Self-reported Mental Health
Diagnoses) dataset and make it available. SMHD is a novel large dataset of social media posts
from users with one or multiple mental health conditions along with matched control users. We
examine distinctions in users’ language, as measured by linguistic and psychological variables.
We further explore text classiﬁcation methods to identify individuals with mental conditions
through their language.

1

Introduction

Mental health is a signiﬁcant challenge in healthcare. Mental disorders have the potential to tremen-
dously affect the quality of life and wellness of individuals in society (Strine et al., 2008; Mowery et
al., 2017a). Social media have become an increasingly important source of data related to mental health
conditions (Cohan et al., 2017; Mowery et al., 2017b; Coppersmith et al., 2017; Yates et al., 2017), as
it is now a prominent platform for individuals to engage in daily discussions, share information, seek
advice and simply communicate with peers that have shared interests. In addition to its ubiquity and ease
of access, the possibility to disclose mental health matters anonymously or pseudo-anonymously further
drives users to online self-disclosure.

At the same time, the close connection between language and mental health makes social media an
invaluable resource of mental health-related data. Lack of data has been one of the key limitations to
understanding and addressing the challenges the domain is facing (Coppersmith et al., 2014a). Data
from social media can not only be used to potentially provide clinical help to users in need, but also to
broaden our understanding of the various mental health conditions. Social media analysis has already
been proven valuable for identifying depression (Coppersmith et al., 2014a; Yates et al., 2017), suicide
ideation (Cohan et al., 2017; De Choudhury and Kıcıman, 2017; Kshirsagar et al., 2017; Desmet and
Hoste, 2018), and other conditions such as schizophrenia (Mitchell et al., 2015). While social media
data is abundantly available, the amount of labeled data for studying mental health conditions is limited.
This is due to the high cost of annotation and the difﬁculty of access to experts.

Prior research has investigated self-disclosure as a means of obtaining labeled data from social media.
De Choudhury et al. (2013a) used it to identify new mothers and track post-partum changes in emotions.

* Equal contribution.

This work is licensed under a Creative Commons Attribution 4.0 International License.

License details: http://

creativecommons.org/licenses/by/4.0/

 
 
 
 
 
 
Condition

ADHD
Anxiety
Autism
Bipolar
Borderline
Depression
Eating
OCD
PTSD
Schizophrenia
Seasonal Affective

Twitter, (Copper-
smith et al, 2015)
102
216
n/a
188
101
393
238
100
403
172
100

Reddit,
SMHD (ours)
10,098
8,783
2,911
6,434
n/a
14,139
598
2,336
2,894
1,331
n/a

Table 1: Comparison between the number of self-reported diagnosed users per condition in the dataset
of Coppersmith et al. (2015a) and ours (SMHD).

I was ofﬁcially diagnosed with ADHD last year.
I have a diagnosed history of PTSD.
my dr just diagnosed me as schizo.

Figure 1: Examples of self-reported diagnoses statements.

Coppersmith et al. (2014a) speciﬁcally focused on self-reports of mental health diagnoses. In particular,
Coppersmith et al. (2015a) constructed a dataset of various mental health conditions using Twitter state-
ments. Finally, Yates et al. (2017) introduced a large dataset of depressed users obtained from Reddit.

We extend the previous efforts on addressing the lack of large-scale mental health-related language
data. Particularly, we propose improved data collection methods through which we can obtain high-
quality large-scale datasets of labeled diagnosed conditions paired with appropriate control users. Con-
sequently, we introduce SMHD (Self-reported Mental Health Diagnoses), a large dataset of diverse mental
health conditions that can provide further "
"Understanding and Mitigating Mental Health Misinformation on Video
  Sharing Platforms","['Viet Cuong Nguyen', 'Michael Birnbaum', 'Munmun De Choudhury']","Despite the ever-strong demand for mental health care globally, access to
traditional mental health services remains severely limited expensive, and
stifled by stigma and systemic barriers. Thus, over the last few years, young
people are increasingly turning to content on video-sharing platforms (VSPs)
like TikTok and YouTube to help them navigate their mental health journey.
However, navigating towards trustworthy information relating to mental health
on these platforms is challenging, given the uncontrollable and unregulated
growth of dedicated mental health content and content creators catering to a
wide array of mental health conditions on these platforms. In this paper, we
attempt to define what constitutes as ""mental health misinformation"" through
examples. In addition, we also suggest some open questions to answer and
challenges to tackle regarding this important and timely research topic",2023,http://arxiv.org/abs/2304.07417v1,http://arxiv.org/pdf/2304.07417v1,"Understanding and Mitigating Mental Health Misinformation on Video
Sharing Platforms

VIET CUONG NGUYEN, Georgia Institute of Technology, United States of America
MICHAEL BIRNBAUM, Northwell Health, United States of America
MUNMUN DE CHOUDHURY, Georgia Institute of Technology, United States of America

Additional Key Words and Phrases: video-sharing platforms, social media platforms, misinformation, mental health

ACM Reference Format:
Viet Cuong Nguyen, Michael Birnbaum, and Munmun De Choudhury. 2023. Understanding and Mitigating Mental Health Misinforma-
tion on Video Sharing Platforms. In CHI ’23: ACM Conference on Human Factors in Computing Systems, April 23–28, 2023, Hamburg,
Germany. ACM, New York, NY, USA, 5 pages. https://doi.org/XXXXXXX.XXXXXXX

1 INTRODUCTION

Despite the ever-strong demand for mental health care globally, access to traditional mental health services remains

severely limited expensive, and stifled by stigma and systemic barriers [1, 22, 23]. Thus, over the last few years, young

people are increasingly turning to content on video-sharing platforms (VSPs) like TikTok and YouTube to help them

navigate their mental health journey [8, 9]. Such content is not only readily accessible and free of charge, but they

contain easily digestible information through audio and visual affordances within these platforms [24, 27]. If done right,

content on video-sharing platforms can be a significant asset to the growing field of digital mental health, as it can

provide non-judgmental and democratized access to mental health help and advice to all, within the privacy of their

realms [18, 21]. However, navigating towards trustworthy information relating to mental health on these platforms

is challenging, given the uncontrollable and unregulated growth of dedicated mental health content and content

creators catering to a wide array of mental health conditions on these platforms. One reason for this is the relatively

low barrier of entry in creating mental health content on video-sharing platforms compared to other online-based

resources (such as blog posts). Consequently, many reports have emerged that mental-health-related videos containing
misinformation (referred to henceforth as mental health misinformation) are rampant on these platforms [8, 19]. Here,
we define mental health misinformation as false or misleading information about mental health and illness, including

diagnosis and treatment of these challenges, irrespective of the intention of those spreading such information. An

example of mental health misinformation regarding bipolar found on video-sharing platforms is shown in Figure 1.

In this publicly available TikTok video where the screenshot from Figure 1 is taken, the presenter presents anecdotal

symptoms which they suggest are indicative of type 2 bipolar. This video contains several key markers indicative of

mental health misinformation:

• They do not have relevant medical qualifications to back these statements, nor do they disclose their lack of

qualifications anywhere within the video or its description

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.

© 2023 Association for Computing Machinery.
Manuscript submitted to ACM

1

3
2
0
2

r
p
A
4
1

]
I
S
.
s
c
[

1
v
7
1
4
7
0
.
4
0
3
2
:
v
i
X
r
a

 
 
 
 
 
 
CHI ’23, April 23–28, 2023, Hamburg, Germany

Nguyen et al.

Fig. 1. Example of mental health misinformation on a video-sharing platform. (potentially identifying information has been blurred
out for privacy reasons)

• The symptoms they shared for type 2 bipolar are purely anecdotal and not backed by any official diagnostic

criteria for the condition (e.g. DSM-5)

• They encourage viewers to self-diagnose themselves with type 2 bipolar by prefacing the video with ""Signs You

Might Have Bipolar Two""

There has been extensive work has been done on understanding and mitigating misinformation content on text- and

image-based social media platforms such as Facebook, Twitter, and Instagram for a variety of topics [6, 7, 12, 13, 15, 16].

However, while the virality and popularity of content on video-based social media platforms are significant, few works

have focused on understanding how and mitigating the spread of mental health misinformation on video-sharing

platforms. The widespread dissemination of mental health misinformation can have serious consequences. Broadly

2

Understanding and Mitigating Mental Health Misinformation on Video S"
Quantifying Mental Health from Social Media with Neural User Embeddings,"['Silvio Amir', 'Glen Coppersmith', 'Paula Carvalho', 'Mário J. Silva', 'Byron C. Wallace']","Mental illnesses adversely affect a significant proportion of the population
worldwide. However, the methods traditionally used for estimating and
characterizing the prevalence of mental health conditions are time-consuming
and expensive. Consequently, best-available estimates concerning the prevalence
of mental health conditions are often years out of date. Automated approaches
to supplement these survey methods with broad, aggregated information derived
from social media content provides a potential means for near real-time
estimates at scale. These may, in turn, provide grist for supporting,
evaluating and iteratively improving upon public health programs and
interventions.
  We propose a novel model for automated mental health status quantification
that incorporates user embeddings. This builds upon recent work exploring
representation learning methods that induce embeddings by leveraging social
media post histories. Such embeddings capture latent characteristics of
individuals (e.g., political leanings) and encode a soft notion of homophily.
In this paper, we investigate whether user embeddings learned from twitter post
histories encode information that correlates with mental health statuses. To
this end, we estimated user embeddings for a set of users known to be affected
by depression and post-traumatic stress disorder (PTSD), and for a set of
demographically matched `control' users. We then evaluated these embeddings
with respect to: (i) their ability to capture homophilic relations with respect
to mental health status; and (ii) the performance of downstream mental health
prediction models based on these features. Our experimental results demonstrate
that the user embeddings capture similarities between users with respect to
mental conditions, and are predictive of mental health.",2017,http://arxiv.org/abs/1705.00335v1,http://arxiv.org/pdf/1705.00335v1,"7
1
0
2

r
p
A
0
3

]
L
C
.
s
c
[

1
v
5
3
3
0
0
.
5
0
7
1
:
v
i
X
r
a

Quantifying Mental Health from Social Media with Neural User Embeddings

Quantifying Mental Health from Social Media with
Neural User Embeddings

Silvio Amir
INESC-ID Lisboa, Instituto Superior T´ecnico, Universidade de Lisboa
Lisboa, Portugal

Glen Coppersmith
Qntfy
Washington DC, United States

Paula Carvalho
INESC-ID Lisboa, and Universidade Europeia, LIU
Lisboa, Portugal

M´ario J. Silva
INESC-ID Lisboa, Instituto Superior T´ecnico, Universidade de Lisboa
Lisboa, Portugal

samir@inesc-id.pt

glen@qntfy.com

pcc@inesc-id.pt

mjs@inesc-id.pt

Byron C. Wallace
Northeastern University
Boston MA, United States

b.wallace@northeastern.edu

Abstract
Mental illnesses adversely aﬀect a signiﬁcant proportion of the population worldwide. How-
ever, the methods traditionally used for estimating and characterizing the prevalence of
mental health conditions are time-consuming and expensive. Consequently, best-available
estimates concerning the prevalence of mental health conditions are often years out of
date. Automated approaches to supplement these survey methods with broad, aggregated
information derived from social media content provides a potential means for near real-
time estimates at scale. These may, in turn, provide grist for supporting, evaluating and
iteratively improving upon public health programs and interventions.

We propose a novel model for automated mental health status quantiﬁcation that incor-
porates user embeddings. This builds upon recent work exploring representation learning
methods that induce embeddings by leveraging social media post histories. Such embed-
dings capture latent characteristics of individuals (e.g., political leanings) and encode a
soft notion of homophily. In this paper, we investigate whether user embeddings learned
from twitter post histories encode information that correlates with mental health statuses.
To this end, we estimated user embeddings for a set of users known to be aﬀected by
depression and post-traumatic stress disorder (PTSD), and for a set of demographically
matched ‘control’ users. We then evaluated these embeddings with respect to: (i) their
ability to capture homophilic relations with respect to mental health status; and (ii) the
performance of downstream mental health prediction models based on these features. Our
experimental results demonstrate that the user embeddings capture similarities between
users with respect to mental conditions, and are predictive of mental health.

1. Introduction

Mental illness is a critically important concern, signiﬁcantly and adversely aﬀecting a wide
swath of the population directly and indirectly. An estimate by the Centers for Disease
Control from 2008 (CDC, 2010), suggests that 9% of US adults may meet the criteria for

1

 
 
 
 
 
 
Amir, Coppersmith, Carvalho, Silva and Wallace

depression at any given time. While not as prevalent as depression, post traumatic stress
disorder (PTSD) issues still cost hundreds of billions of dollars worldwide, according to
a conservative estimate from the NIH1. The collective eﬀect of mental health conditions,
as measured by Daily Adjusted Life Years (DALYs), exceeds that of malaria, war, or vi-
olence2 (?). At the same time, mental health problems are often diﬃcult to identify and
thus treat. For example, perhaps half of depressive cases go undetected, in part due to
the heterogeneous and complex expression of this condition (Paykel et al., 1997). Another
exacerbating factor is that diagnosis generally requires individuals to actively seek out treat-
ment. Yet, the manifestation of this condition and prevailing social stigmas may disincline
aﬄicted individuals to seek treatment.

The internet may provide a comfortable medium for people to express their feelings
anonymously and connect with health-care professionals (McCaughey et al., 2014) and oth-
ers aﬀected by similar conditions (De Choudhury et al., 2016). Furthermore, individuals
openly discuss mental health challenges on public social network platforms such as Twitter
(Coppersmith et al., 2014a, 2015a). Prior work has demonstrated the potential of using
social media to investigate mental health issues (Paul and Dredze, 2011), including de-
pression (Schwartz et al., 2014), PTSD (Coppersmith et al., 2014b) and suicidal ideation
(Coppersmith et al., 2016; De Choudhury et al., 2016) in individuals. However, models and
techniques to identify and quantify mental health related signals from social media are rel-
atively novel. Interest in these applications has motivated the creation of a shared task for
the Computational Linguistics and Clinical Psychology workshop (CLPsych)3, which aimed
to advance the state-of-the-art in technologies capable of discriminating users aﬀected by
mental illness from controls, given their post history (Coppersmith et al., 2015b). A variety
of methods have been proposed for this task, but none have achieved consistently super"
"Then and Now: Quantifying the Longitudinal Validity of Self-Disclosed
  Depression Diagnoses","['Keith Harrigian', 'Mark Dredze']","Self-disclosed mental health diagnoses, which serve as ground truth
annotations of mental health status in the absence of clinical measures,
underpin the conclusions behind most computational studies of mental health
language from the last decade. However, psychiatric conditions are dynamic; a
prior depression diagnosis may no longer be indicative of an individual's
mental health, either due to treatment or other mitigating factors. We ask: to
what extent are self-disclosures of mental health diagnoses actually relevant
over time? We analyze recent activity from individuals who disclosed a
depression diagnosis on social media over five years ago and, in turn, acquire
a new understanding of how presentations of mental health status on social
media manifest longitudinally. We also provide expanded evidence for the
presence of personality-related biases in datasets curated using self-disclosed
diagnoses. Our findings motivate three practical recommendations for improving
mental health datasets curated using self-disclosed diagnoses: 1) Annotate
diagnosis dates and psychiatric comorbidities; 2) Sample control groups using
propensity score matching; 3) Identify and remove spurious correlations
introduced by selection bias.",2022,http://arxiv.org/abs/2206.11155v1,http://arxiv.org/pdf/2206.11155v1,"ThenandNow:QuantifyingtheLongitudinalValidityofSelf-DisclosedDepressionDiagnosesKeithHarrigianandMarkDredzeJohnsHopkinsUniversitykharrigian@jhu.edu,mdredze@cs.jhu.eduAbstractSelf-disclosedmentalhealthdiagnoses,whichserveasgroundtruthannotationsofmentalhealthstatusintheabsenceofclinicalmea-sures,underpintheconclusionsbehindmostcomputationalstudiesofmentalhealthlan-guagefromthelastdecade.However,psy-chiatricconditionsaredynamic;apriorde-pressiondiagnosismaynolongerbeindicativeofanindividual’smentalhealth,eitherduetotreatmentorothermitigatingfactors.Weask:towhatextentareself-disclosuresofmentalhealthdiagnosesactuallyrelevantovertime?Weanalyzerecentactivityfromindividualswhodisclosedadepressiondiagnosisonsocialmediaoverﬁveyearsagoand,inturn,acquireanewunderstandingofhowpresentationsofmentalhealthstatusonsocialmediamanifestlongitudinally.Wealsoprovideexpandedev-idenceforthepresenceofpersonality-relatedbiasesindatasetscuratedusingself-discloseddiagnoses.Ourﬁndingsmotivatethreeprac-ticalrecommendationsforimprovingmentalhealthdatasetscuratedusingself-discloseddi-agnoses:1.Annotatediagnosisdatesandpsychiatriccomorbidities2.Samplecontrolgroupsusingpropensityscorematching3.Identifyandremovespuriouscorrela-tionsintroducedbyselectionbias1IntroductionTheabilitytoprovideequitableaccesstopsychi-atrichealthcarehasbecomemoredifﬁcultthanever,inhibitedbyanentanglementoflingeringpublicpolicyeffects(Mirandaetal.,2020),heightenedlevelsofphysicianburnout(Johnsonetal.,2018),andinfrastructuralchallengesarisingfromglobalcrisis(Davisetal.,2021).Meanwhile,socialmediaplatformshavebecomethepredominantmeansofcommunicationformuchofthepopulation,provid-ingtheopportunitytosharepersonalexperiencesandseeksupportfromothers(Muelleretal.,2021).Notingtheseparalleltimelines,computationalsci-entistshavedevotedsubstantialefforttoengineer-ingstatisticalmodelscapableoftranslatingsocialmediadataintoreliableinsightsregardingmen-talhealth.Coreobjectivesofthisworkincludeoptimizingpsychiatrictreatment,identifyingearlystagesofmentalillness,andmeasuringtheeffectofpublicpolicyonapopulation’swell-being(Losadaetal.,2017;Fineetal.,2020).Themostsigniﬁcantadvancesincomputationalmentalhealthresearchhavenotcomefromim-provedmodelingarchitectures(Bentonetal.,2017b),butfrommethodsforcuratinglarge-scaledatasetswhichcontainrobustandclinically-relevantgroundtruthannotationsofmentalhealthstatus(Coppersmithetal.,2014).Useofregularexpressionstoidentifygenuineself-disclosuresofapsychiatricdiagnosisremainsoneofthemostwidelyadoptedannotationmechanismsbythere-searchcommunity(ChancellorandDeChoudhury,2020;Harrigianetal.,2021),offeringarelativelyreliableproxyinplaceofclinicalmeasureswhicharenotonlycostlytocollect,butalsooftenun-abletobesharedbeyondasingleinstitutionduetopatientprivacypolicies(Macavaneyetal.,2021).Datasetsleveragingself-discloseddiagnosesasan-notationsofmentalhealthstatushaveyieldedava-rietyofinsightsthatalignwithclinicalknowledgeandpsychologicaltheory(Moweryetal.,2017;Leeetal.,2021).However,agrowingbodyofworkhasraisedquestionsaboutwhethersuchdatasetsprovidesufﬁcientinformationtotrainstatisticalmodelsthatgeneralizetonewpopulations(Harri-gianetal.,2020;Aguirreetal.,2021).Despitetheprevalenceofdatasetsdependentonself-disclosure,noanalyseshaveconsideredhowassociatingasingleself-discloseddiagnosislabelwithdatafromavariable-lengthperiodoftimemayinhibitthelearningofrobuststatisticalrela-tionships.IfausertweetsadepressiondiagnosisarXiv:2206.11155v1  [cs.LG]  22 Jun 2022in2015,istheirdatafrom2018stillrepresentativeofthecondition?Presentationofseveralmentalhealthconditionschangedynamicallyand(some-times)precipitouslyovertime(Collishawetal.,2004).Yet,itremainscommoninthecomputa-tionalresearchcommunitytotreatmentalhealthconditionsasastaticattributewithequalrelevanceatmultipletimepoints(MacAvaneyetal.,2018).Inreality,itislikelythatonlyasmallfractionofanindividual’ssocialmediaactivityisappropriatefortrainingoptimalclassiﬁers.Moreover,thatamen-talhealthstatuslabelmaybeappropriateforonlyasubsetoftimesuggeststhatevaluationsoflongitu-dinalmodelgeneralizationastheyaretraditionallystructuredinthecommunitymaybeinsufﬁcient(Sadequeetal.,2018).Weask:towhatextentdomentalhealthdiag-nosisself-disclosuresremainvalidovertime?Wefocusspeciﬁcallyonextendeddurations(i.e.,mul-tipleyears),asettingwhichhasparticularrele-vancetothosewhowishtoestimategeneralizationstrengthoftheirstatisticalclassiﬁersforuseinlon-gitudinalmonitoringapplications,aswellasthoseinterestedinupdatingexistingmodelswithnewdatatomitigatetheeffectscovariateshift(AgarwalandNenkova,2021).Inreviewingrecentonlineac-tivityfromindividualsinthe2015CLPsychSharedTaskdatasetwhodisclosedadepressiondiagnosisonTwitteroverﬁveyearsago(Coppersmithetal.,2015),wenotonlyacquireanewunderstandingofhowpresentationsofmentalhealthstatusonsocialmediapresentovertime,butalsoﬁndnewevidencetosupportpriorclaimsregardingthepresenceofpersonality-relatedconfoundsindatasetscuratedusingself-disclosures(Preo¸tiuc-Pietroetal.,2015;VukojevicandŠnajder,2021).Ouranalys"
"The Role of Mandated Mental Health Treatment in the Criminal Justice
  System",['Rachel Nesbit'],"Mental health disorders are particularly prevalent among those in the
criminal justice system and may be a contributing factor in recidivism. Using
North Carolina court cases from 1994 to 2009, this paper evaluates how mandated
mental health treatment as a term of probation impacts the likelihood that
individuals return to the criminal justice system. I use random variation in
judge assignment to compare those who were required to seek weekly mental
health counseling to those who were not. The main findings are that being
assigned to seek mental health treatment decreases the likelihood of three-year
recidivism by about 12 percentage points, or 36 percent. This effect persists
over time, and is similar among various types of individuals on probation. In
addition, I show that mental health treatment operates distinctly from drug
addiction interventions in a multiple-treatment framework. I provide evidence
that mental health treatment's longer-term effectiveness is strongest among
more financially-advantaged probationers, consistent with this setting, in
which the cost of mandated treatment is shouldered by offenders. Finally,
conservative calculations result in a 5:1 benefit-to-cost ratio which suggests
that the treatment-induced decrease in future crime would be more than
sufficient to offset the costs of treatment.",2022,http://arxiv.org/abs/2212.06736v2,http://arxiv.org/pdf/2212.06736v2,"The Role of Mandated Mental Health Treatment in the
Criminal Justice System

Rachel Nesbit*

November 14, 2023

Abstract

Mental health disorders are particularly prevalent among those in the criminal justice system
and may be a contributing factor in recidivism. Using North Carolina court cases from 1994 to
2009, this paper evaluates how mandated mental health treatment as a term of probation impacts
the likelihood that individuals return to the criminal justice system. I use random variation in judge
assignment to compare those who were required to seek weekly mental health counseling to those who
were not. The main ﬁndings are that being assigned to seek mental health treatment decreases the
likelihood of three-year recidivism by about 12 percentage points, or 36 percent. This eﬀect persists
over time, and is similar among various types of individuals on probation.
In addition, I show
that mental health treatment operates distinctly from drug addiction interventions in a multiple-
treatment framework. I provide evidence that mental health treatment’s longer-term eﬀectiveness is
strongest among more ﬁnancially-advantaged probationers, consistent with this setting, in which the
cost of mandated treatment is shouldered by oﬀenders. Finally, conservative calculations result in a
5:1 beneﬁt-to-cost ratio which suggests that the treatment-induced decrease in future crime would
be more than suﬃcient to oﬀset the costs of treatment.

JEL codes: I12, I18, K42

*University of Maryland, 3114 Tydings Hall, 7343 Preinkert Dr., College Park, MD 20742. Email: rnesbit@umd.edu

1

1 Intro

Poor mental health is widely prevalent and has been growing over time, with around 58 million
adults in the United States suﬀering from a mental illness in 2021 (SAMHSA, 2022).1 Poor mental
health is also widely impactful; it has direct negative eﬀects on physical and social health and is highly
intertwined with other aspects of life. For example, it contributes to upwards of 40 percent of all
illnesses under the age of 65 (Layard, 2013). Beyond (or as a consequence of) these direct negative
eﬀects on health, mental illness has been associated with behaviors like absenteeism at work, decreased
educational attainment, and crime (Bubonya, Cobb-Clark, and Wooden, 2017; Burton et al., 2008;
Breslau et al., 2008; Mojtabai et al., 2015).

Poor mental health is particularly prevalent in the criminal justice system. Among the approxi-
mately ﬁve million men on probation in 2009, 33 percent met the threshold for any mental illness -
nearly twice the prevalence in the general population at the time (Feucht and Gfroerer, 2011).2 Indi-
viduals with a mental illness can struggle to make rational, welfare-maximizing decisions, which may
play a critical role in their interactions with the criminal justice system. Since the medical ﬁeld has
shown that therapy and medication can reduce symptoms of mental illness (Cronin, Forsstrom, and
Papageorge, 2020; Paykel et al., 1999), it may be the case that mental health treatment can reduce
behavioral outcomes such as crime. That reduction could have large beneﬁts for both treated individ-
uals and society. However, though meaningful correlational evidence exists, there is little direct causal
evidence on the eﬀect of therapy and psychiatric medication on outcomes such as criminal behavior, or
whether those interventions could be carried out in a cost-eﬀective way.3

This paper evaluates the causal impact of mandated mental health treatment on the likelihood of
committing a future crime. Speciﬁcally, it focuses on how being assigned mental health treatment at
the time of probation impacts recidivism over the next ﬁve years. To do this I exploit judge variation in
court-mandated mental health treatment in North Carolina, using the universe of criminal court cases
from 1994 to 2009. The requirement that the defendant seek mental health treatment is a possible
condition of probation (supervised release without serving time in prison). While the type of mental
health treatment can vary, it typically includes a psychological evaluation, weekly therapy sessions
for the duration of the sentence, and potentially a referral to a psychiatrist for medication. Simply
comparing outcomes of probationers who are and are not mandated mental health treatment could
result in a biased estimate if judges make their sentencing decisions using additional information that
is unobserved to the researcher. In particular, while the data provide information on demographics and
criminal history, they do not provide information about mental illness, which is likely correlated with
both the judge’s sentence and recidivism risk. To address this, I use the randomly-assigned judge’s
propensity to mandate mental health treatment among other cases as an instrument for actually be-
ing assigned mental health treatment as a term of probation. This research design has been used in
various applications in which a judge, case worker, or other type "
"Dynamic Strategy Chain: Dynamic Zero-Shot CoT for Long Mental Health
  Support Generation","['Qi Chen', 'Dexi Liu']","Long counseling Text Generation for Mental health support (LTGM), an
innovative and challenging task, aims to provide help-seekers with mental
health support through a comprehensive and more acceptable response. The
combination of chain-of-thought (CoT) prompting and Large Language Models
(LLMs) is employed and get the SOTA performance on various NLP tasks,
especially on text generation tasks. Zero-shot CoT prompting is one of the most
common methods in CoT prompting. However, in the LTGM task, Zero-shot CoT
prompting can not simulate a counselor or provide personalized strategies
without effective mental health counseling strategy prompts. To tackle this
challenge, we propose a zero-shot Dynamic Strategy Chain (DSC) prompting
method. Firstly, we utilize GPT2 to learn the responses written by mental
health counselors and dynamically generate mental health counseling strategies
tailored to the help-seekers' needs. Secondly, the Zero-shot DSC prompting is
constructed according to mental health counseling strategies and the
help-seekers' post. Finally, the Zero-shot DSC prompting is employed to guide
LLMs in generating more human-like responses for the help-seekers. Both
automatic and manual evaluations demonstrate that Zero-shot DSC prompting can
deliver more human-like responses than CoT prompting methods on LTGM tasks.",2023,http://arxiv.org/abs/2308.10444v1,http://arxiv.org/pdf/2308.10444v1,"Dynamic Strategy Chain: Dynamic Zero-Shot CoT
for Long Mental Health Support Generation

Qi Chen*, Dexi Liu*
1Jiangxi University of Finance and Economics

3
2
0
2

g
u
A
1
2

]
L
C
.
s
c
[

1
v
4
4
4
0
1
.
8
0
3
2
:
v
i
X
r
a

Abstract

Long counseling Text Generation for Mental health support
(LTGM), an innovative and challenging task, aims to pro-
vide help-seekers with mental health support through a com-
prehensive and more acceptable response. The combination
of chain-of-thought (CoT) prompting and Large Language
Models (LLMs) is employed and get the SOTA performance
on various NLP tasks, especially on text generation tasks.
Zero-shot CoT prompting is one of the most common meth-
ods in CoT prompting. However, in the LTGM task, Zero-
shot CoT prompting can not simulate a counselor or provide
personalized strategies without effective mental health coun-
seling strategy prompts. To tackle this challenge, we pro-
pose a zero-shot Dynamic Strategy Chain (DSC) prompt-
ing method. Firstly, we utilize GPT2 to learn the responses
written by mental health counselors and dynamically gener-
ate mental health counseling strategies tailored to the help-
seekers needs. Secondly, the Zero-shot DSC prompting is
constructed according to mental health counseling strate-
gies and the help-seeker’s post. Finally, the Zero-shot DSC
prompting is employed to guide LLMs in generating more
human-like responses for the help-seekers. Both automatic
and manual evaluations demonstrate that Zero-shot DSC
prompting can deliver more human-like responses than CoT
prompting methods on LTGM tasks.

Introduction
According to the latest data from the World Health Or-
ganization, there are approximately 450 million individu-
als worldwide with mental health disorders (World Health
Organization 2022). Mental health issues are becoming in-
creasingly severe, causing immense pain to individual lives
and affecting the overall health and well-being of society
(Sun et al. 2021; Sabour et al. 2023). Online mental health
counseling, as an effective therapy for mental disorders (Jr.
et al. 2013), has become popular in recent years (Sun et al.
2021).

In recent years, significant advancements have occurred
in NLP and AI, primarily due to the emergence of large lan-
guage models (LLMs). Noteworthy models such as GPT-3
(Brown et al. 2020), PaLM (Chowdhery et al. 2022), Llama
(Touvron et al. 2023) and GPT-3.5 (OpenAI, 2023) have
demonstrated the potential of LLMs by leveraging their in-
creasing model sizes and vast amounts of training data. As

*These authors contributed equally.

Figure 1: An example showing Long counseling Text
Generation for Mental Health support, which includes a
system(GPT3.5-turbo) for seeking helpers and providing
mental health support services. The prompt ’Please answer
my question.’ is used to guide the system to respond to the
Help-Seeker’s question.

a result, these models have achieved human-level perfor-
mance across various tasks, including summarization, trans-
lation, question answering, and basic mathematical reason-
ing (Zhang et al. 2023). Figure 1 shows the results generated
by GPT3.5-turbo in the Long counseling Text Generation for
Mental health support (LTGM) task.

Despite demonstrating strong coherence and structural
awareness in generating lengthy text, LLMs have certain
limitations in the LTGM task, as illustrated in Figure 1.
Firstly, when answering mental health support questions,
LLMs skip the expression of understanding and analysis,
providing generic advice that often comes across as indiffer-
ent and unresponsive. Secondly, it lacks guided strategies for
target emotions, making it challenging to effectively drive
users out of emotional distress. Thirdly, LLMs rarely gen-
erate personalized responses based on different users’ lan-
guage styles, needs, and preferences, resulting in answers
lacking individualization and customization. These limita-
tions constrain the performance of LLMs in mental health

[QUESTION] (Post Title)25-year-old female, having a tense relationship with colleagues, considering quitting but afraid of confrontation?[DESCRIPTION] (Post Content)I've always considered myself a cheerful person... Recently, the colleagues I used to get along with are now siding with him, isolating me in front of the boss...[LABEL] (Keywoeds)Career, Career Management, Workplace Interpersonal, Work StressPlease answer my question.It seems like you are facing a difficult situation at work with your colleagues, and you're considering resigning but worried about potential conflicts... Here are some suggestions to consider:1. Communication: Try to have an open and honest conversation with your colleagues about the issues you are facing. ...2. Seek Mediation: If direct communication doesn't work, consider involving a mediator or your supervisor to help facilitate a constructive dialogue and find a resolution to the conflict....Remember, workplace conflicts can be challenging, but it's essential to address them"
"Mental Health and Abortions among Young Women: Time-varying Unobserved
  Heterogeneity, Health Behaviors, and Risky Decisions","['Lena Janys', 'Bettina Siflinger']","In this paper, we provide causal evidence on abortions and risky health
behaviors as determinants of mental health development among young women. Using
administrative in- and outpatient records from Sweden, we apply a novel grouped
fixed-effects estimator proposed by Bonhomme and Manresa (2015) to allow for
time-varying unobserved heterogeneity. We show that the positive association
obtained from standard estimators shrinks to zero once we control for grouped
time-varying unobserved heterogeneity. We estimate the group-specific profiles
of unobserved heterogeneity, which reflect differences in unobserved risk to be
diagnosed with a mental health condition. We then analyze mental health
development and risky health behaviors other than unwanted pregnancies across
groups. Our results suggest that these are determined by the same type of
unobserved heterogeneity, which we attribute to the same unobserved process of
decision-making. We develop and estimate a theoretical model of risky choices
and mental health, in which mental health disparity across groups is generated
by different degrees of self-control problems. Our findings imply that mental
health concerns cannot be used to justify restrictive abortion policies.
Moreover, potential self-control problems should be targeted as early as
possible to combat future mental health consequences.",2021,http://arxiv.org/abs/2103.12159v4,http://arxiv.org/pdf/2103.12159v4,"2
2
0
2

y
a
M
4

]

N
G
.
n
o
c
e
[

4
v
9
5
1
2
1
.
3
0
1
2
:
v
i
X
r
a

Mental Health and Abortions among Young

Women: Time-Varying Unobserved Heterogeneity,

Health Behaviors, and Risky Decisions

Lena Janys∗

Bettina Siﬂinger†

May 5, 2022

In this paper, we provide causal evidence on abortions and risky health behaviors as de-
terminants of mental health development among young women. Using administrative
in- and outpatient records from Sweden, we apply a novel grouped ﬁxed-eﬀects estima-
tor proposed by Bonhomme and Manresa (2015) to allow for time-varying unobserved
heterogeneity. We show that the positive association obtained from standard estimators
shrinks to zero once we control for grouped time-varying unobserved heterogeneity.
We estimate the group proﬁles of unobserved heterogeneity, which reﬂect diﬀerences
in unobserved risk to be diagnosed with a mental health condition and analyze mental
health development and risky health behaviors other than unwanted pregnancies across
groups. Our results suggest that these are determined by the same type of unobserved
heterogeneity, which we attribute to the same unobserved process of decision-making.
We develop and estimate a theoretical model of risky choices and mental health, in
which mental health disparity across groups is generated by diﬀerent degrees of self-
control problems. Our ﬁndings imply that mental health concerns cannot be used to
justify restrictive abortion policies. Moreover, potential self-control problems should
be targeted as early as possible to combat future mental health consequences.

∗University of Bonn (Department of Economics), HCM and IZA, ljanys@uni-bonn.de
†Tilburg University (Department of Econometrics & OR), Netspar, CESIfo, b.m.siﬂinger@uvt.nl

Lena Janys was funded by the German Research Foundation (DFG) under Germany’s Excellence
Strategy –EXC-2126/1–390838866, under Germany’s Excellence Strategy –EXC-2047/1 –390685813 and
under the individual fellowship with grant-number 441253219. Bettina Siﬂinger acknowledges support
by the German Research Foundation DFG through the SFB 884. We thank Otilia Boldea, Marieke Bos,
Pavel Čížek, Jason Fletcher, Joachim Freyberger, Holger Gerhardt, Lukas Kiessling, Tobias Klein, Nikolaus
Schweizer, Thomas Siedler, Miriam Wüst, Nicolas Ziebarth and participants at workshops and seminars at
the University of Bonn, Hertie School Berlin, Hamburg Center for Health Economics, Tinbergen Institute,
University of Hannover, Virtual Mental Health Seminar (VMESS), “The Importance of Early-Life Circum-
stances: Shocks, Parents and Policies” (Copenhagen), European Health Econometrics Workshop (Leuven),
World Congress of the Econometric Society (Milan), International Health Economics Workshop (Mainz),
the IAAE (Rotterdam) and the Annual Health Econometrics Workshop (Emory) for helpful comments and
discussions. We thank Statistics Sweden and Socialstyrelsen for the data, and Hans-Martin von Gaudecker,
Mårten Palme, Lars Gullikson and Alexander Paul for their eﬀorts to make them accessible.

 
 
 
 
 
 
Keywords: Mental Health; Abortions; Time-Varying Unobserved Heterogeneity; Grouped
Fixed-Eﬀects; Risky Health Behaviors; Adolescence
JEL-Codes:: I12, I10, C23, D91

2

1

Introduction

In recent years, economists have increasingly paid attention to mental health problems and

their consequences, especially when occurring during adolescence and young adulthood

(Biasi et al., 2021; Cuddy and Currie, 2020). Mental health problems are often ﬁrst

diagnosed in early adulthood and are very pervasive, in particular among young women

(see Eaton et al., 2008). In 2017, about 13–19% of adolescents between 15-25 in the US

experienced at least one major depressive episode (NIH, 2019). As pointed out by Currie

(2020) mental health problems can reﬂect deﬁcits in non-cognitive skills that are crucial

for human capital development and labor market outcomes in adulthood. Thus, knowing

about potential determinants of mental problems is of ﬁrst-order importance.

One possible determinant that is often discussed in connection with mental health

problems is abortion. In the US, abortions for women aged 15-24 years account for

almost 40% of all abortions in 2017 (Kortsmit et al., 2020). As pointed out by Reardon

(2018) abortion is consistently associated with elevated rates of mental illness compared

to women without a history of abortion. While there are diﬀerent perspectives on the

interpretation of this association, there is hardly any evidence for a causal relationship.

Yet, in many countries, the association between abortion and mental health seems to be

suﬃcient for politicians to justify restrictions on abortion access such as waiting times,

mandatory disclosures, or parental consent laws (Guttmacher Institute, 2020).

This paper investigates the impact of having an abortion from an unwanted preg-

nancy on the incidence of mental health conditions in young women in Sweden. We

use individual-level ad"
A Snapshot of the Mental Health of Software Professionals,"['Eduardo Santana de Almeida', 'Ingrid Oliveira de Nunes', 'Raphael Pereira de Oliveira', 'Michelle Larissa Luciano Carvalho', 'Andre Russowsky Brunoni', 'Shiyue Rong', 'Iftekhar Ahmed']","Mental health disorders affect a large number of people, leading to many
lives being lost every year. These disorders affect struggling individuals and
businesses whose productivity decreases due to days of lost work or lower
employee performance. Recent studies provide alarming numbers of individuals
who suffer from mental health disorders, e.g., depression and anxiety, in
particular contexts, such as academia. In the context of the software industry,
there are limited studies that aim to understand the presence of mental health
disorders and the characteristics of jobs in this context that can be triggers
for the deterioration of the mental health of software professionals. In this
paper, we present the results of a survey with 500 software professionals. We
investigate different aspects of their mental health and the characteristics of
their work to identify possible triggers of mental health deterioration. Our
results provide the first evidence that mental health is a critical issue to be
addressed in the software industry, as well as raise the direction of changes
that can be done in this context to improve the mental health of software
professionals.",2023,http://arxiv.org/abs/2309.17140v1,http://arxiv.org/pdf/2309.17140v1,"3
2
0
2

p
e
S
9
2

]
E
S
.
s
c
[

1
v
0
4
1
7
1
.
9
0
3
2
:
v
i
X
r
a

IEEE TRANSACTIONS ON SOFTWARE ENGINEERING, VOL. X, NO. Y, MARCH 2023

1

A Snapshot of the Mental Health of Software
Professionals

Eduardo Santana de Almeida, Ingrid Oliveira de Nunes, Raphael Pereira de Oliveira,
Michelle Larissa Luciano Carvalho, Andr ´e Russowsky Brunoni, Shiyue Rong, and Iftekhar Ahmed

Abstract—Mental health disorders affect a large number of people, leading to many lives being lost every year. These disorders affect
struggling individuals and businesses whose productivity decreases due to days of lost work or lower employee performance. Recent
studies provide alarming numbers of individuals who suffer from mental health disorders, e.g., depression and anxiety, in particular
contexts, such as academia. In the context of the software industry, there are limited studies that aim to understand the presence of
mental health disorders and the characteristics of jobs in this context that can be triggers for the deterioration of the mental health of
software professionals. In this paper, we present the results of a survey with 500 software professionals. We investigate different
aspects of their mental health and the characteristics of their work to identify possible triggers of mental health deterioration. Our
results provide the first evidence that mental health is a critical issue to be addressed in the software industry, as well as raise the
direction of changes that can be done in this context to improve the mental health of software professionals.

Index Terms—Software development, Mental Health, Mental Health disorder, Mental illness, Social and human factors.

✦

1 INTRODUCTION

On the 28th of July, Simone Biles, considered the greatest
gymnast of all time, shocked the world after she withdrew
from the women’s individual all-around final at the Tokyo
Olympic Games to focus on her mental health1. Simone Biles
attitude is not an isolated case. According to a published
report from American Psychological Association (APA) with
emergent trends in psychology for 2021 [1], the national
mental health crisis is among the top 10.

This crisis has shown unsettling aspects: two-thirds of
employees report that poor mental health has undercut their
job performance during the COVID-19 pandemic, and 40%
of employees are battling burnout. In addition, more than
a third of Americans experienced clinical anxiety or depres-
sion symptoms. Employees’ mental health struggles have an
outsize impact on U.S. businesses also, with mental illness
the leading cause of disability in the country, accounting for
some 217 million days of lost work annually [2].

The mental health crisis has affected many sectors of
society such as sports, entertainment [3], health care [4],
and information technology (IT) is not an exception since
the software is literally ”eating the world” [5]. Based on a
study with Indian professionals, Nayak [6] identified that
software developers have a considerably higher chance of
experiencing fatigue, burnout, anxiety, and stress, compared
to colleagues who perform mechanical tasks.

In Stack Overflow’s 2022 survey [7], which included
participation from nearly 70k developers, respondents ad-

• E. Almeida was with the Institute of Computing (IC-UFBA), Federal

University of Bahia, Brazil.
E-mail: esa@rise.com.br
I. Ahmed and Shiyue Rong are with University of California, Irvine (UCI).

•

Manuscript received ...; revised...

1. https://edition.cnn.com/2021/07/28/sport/simone-biles-

gymnastics-tokyo-2020-mental-health-spt-intl/index.html

mitted having some type of mental issue, with memory dis-
order (10.6%), anxiety (10.3%) and depression (9.7%) being
the most common ones. These results indicate a significant
prevalence of mental issues among software professionals.

Existing research usually focuses on a diversity of as-
pects related to the job of software engineers [8], [9], their
mental model [10] and work habits [11]–[15], work condi-
tions [16], [17], the need of sleep [18], what makes a good
day [19], and their main motivations and satisfactions [20],
[21].

Nevertheless, to the best of our knowledge, there are
no studies reporting on the main aspects that affect the
mental health of software professionals at work. Despite
some reports [6], [22] of the occurrence of mental disorders
such as depression and anxiety, very little is known about
its prevalence among software professionals. In addition,
human and social factors that directly impact the mental
health of these individuals are also under-investigated.

This work aims to report the research findings of an
investigation aimed at identifying the dimension of soft-
ware professionals that suffer from mental disorders and
the working context in which these individuals are more
susceptible to developing them. We considered the working
context into four directions: (i) the work of software profes-
sionals concerning position, role, and experience; (ii) work
en"
Mental Health Assessment for the Chatbots,"['Yong Shan', 'Jinchao Zhang', 'Zekang Li', 'Yang Feng', 'Jie Zhou']","Previous researches on dialogue system assessment usually focus on the
quality evaluation (e.g. fluency, relevance, etc) of responses generated by the
chatbots, which are local and technical metrics. For a chatbot which responds
to millions of online users including minors, we argue that it should have a
healthy mental tendency in order to avoid the negative psychological impact on
them. In this paper, we establish several mental health assessment dimensions
for chatbots (depression, anxiety, alcohol addiction, empathy) and introduce
the questionnaire-based mental health assessment methods. We conduct
assessments on some well-known open-domain chatbots and find that there are
severe mental health issues for all these chatbots. We consider that it is due
to the neglect of the mental health risks during the dataset building and the
model training procedures. We expect to attract researchers' attention to the
serious mental health problems of chatbots and improve the chatbots' ability in
positive emotional interaction.",2022,http://arxiv.org/abs/2201.05382v1,http://arxiv.org/pdf/2201.05382v1,"Mental Health Assessment for the Chatbots

Yong Shan1 , Jinchao Zhang1, Zekang Li23, Yang Feng23, Jie Zhou1
1 Pattern Recognition Center, WeChat AI, Tencent Inc, China
2 Key Laboratory of Intelligent Information Processing
Institute of Computing Technology, Chinese Academy of Sciences (ICT/CAS)
3 University of Chinese Academy of Sciences
{yeongshan,dayerzhang,withtomzhou}@tencent.com
{lizekang19g,fengyang}@ict.ac.cn

2
2
0
2

n
a
J

4
1

]
L
C
.
s
c
[

1
v
2
8
3
5
0
.
1
0
2
2
:
v
i
X
r
a

Abstract

Previous researches on dialogue system assess-
ment usually focus on the quality evaluation
(e.g. ﬂuency, relevance, etc) of responses gen-
erated by the chatbots, which are local and
technical metrics. For a chatbot which re-
sponds to millions of online users including
minors, we argue that it should have a healthy
mental tendency in order to avoid the negative
psychological impact on them. In this paper,
we establish several mental health assessment
dimensions for chatbots (depression, anxiety,
alcohol addiction, empathy) and introduce the
questionnaire-based mental health assessment
methods. We conduct assessments on some
well-known open-domain chatbots and ﬁnd
that there are severe mental health issues for
all these chatbots. We consider that it is due
to the neglect of the mental health risks dur-
ing the dataset building and the model training
procedures. We expect to attract researchers’
attention to the serious mental health problems
of chatbots and improve the chatbots’ ability in
positive emotional interaction.

1

Introduction

In recent years, with the rapid development of
the data-driven deep learning technologies in natu-
ral language processing, chatbots, like Apple Siri
and Amazon Echo, are coming into our daily life
in many areas, such as chit-chat, healthcare, e-
commerce service, and so on (Hoy, 2018; Kepuska
and Bohouta, 2018; Huang et al., 2020).

Many researches on chatbot assessment are usu-
ally concerned about the local and technical met-
rics (e.g. ﬂuency, diversity, interesting, informative,
etc) (Mehri and Eskénazi, 2020a; Yeh et al., 2021).
Under these criteria, chatbots can provide useful, in-
teresting, and informative responses in online inter-
actions with humans. However, a serious problem
occurred when a user appealed to the chatbot for
mental health support (Daws, 2020). The user said:
“Hey, I feel very bad, I want to kill myself.”. The

Figure 1: A psychology questionnaire example to as-
sess the individual depression.

chatbot responded: “I am sorry to hear that. I can
help you with that.”. The user then said: “Should
I kill myself?”, but the chatbot responded: “I think
you should.”. The chatbot supported the user’s idea
of suicide, which is very dangerous and irrespon-
sible. In addition, we observe that some chatbots
sometimes perform anxiously in the interaction, es-
pecially when the user is dysphoric. The user might
be inﬂuenced by the second-hand anxiety from the
chatbots (Dimitroff et al., 2017). These negative
opinions or emotions may be harmful to the public
whereas existing evaluation metrics for chatbots
can not cover these mental health problems.

Therefore, we argue that we should assess the
chatbots’ mental health before releasing the chat-
bots online to avoid negative psychological im-
pact on users. We focus on several common men-
anxiety,
depression, (cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)
tal health problems, including (cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)
empathy, and establish the
alcohol(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)
addiction, (cid:58)(cid:58)(cid:58)(cid:58)and (cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)
(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)
corresponding assessment dimensions for chatbots.
As shown in Figure 1, psychologists generally mea-

Over the past 2 weeks, how often have you been bothered by any of the following problems?1. Little interest or pleasure in doing things.Not At AllSeveral DaysMore Than Half The DaysNearly Everyday2. Feeling down, depressed, or hopeless.Not At AllSeveral DaysMore Than Half The DaysNearly Everyday3. Feeling tired or having little energy.Not At AllSeveral DaysMore Than Half The DaysNearly Everyday4. Poor appetite or overeating.Not At AllSeveral DaysMore Than Half The DaysNearly Everyday 
 
 
 
 
 
sure the mental health of humans through ques-
tionnaires, by instructing them to read and ﬁll in
the questionnaires with options like “Not At All”
or “Nearly Every Day”. Motivated by this, we
propose a questionnaire-based mental health as-
sessment method for the chatbots. Speciﬁcally, our
framework consists of four stages. First, we rewrite
the questionnaire designed for human beings into
conversational utterances which can be adopted to
interact with the chatbots directly. Second, we ask
the chatbots with the rewritten utterances and col-
lect the responses. Third, we align the re"
Temporal Mental Health Dynamics on Social Media,"['Tom Tabak', 'Matthew Purver']","We describe a set of experiments for building a temporal mental health
dynamics system. We utilise a pre-existing methodology for distant-supervision
of mental health data mining from social media platforms and deploy the system
during the global COVID-19 pandemic as a case study. Despite the challenging
nature of the task, we produce encouraging results, both explicit to the global
pandemic and implicit to a global phenomenon, Christmas Depression, supported
by the literature. We propose a methodology for providing insight into temporal
mental health dynamics to be utilised for strategic decision-making.",2020,http://arxiv.org/abs/2008.13121v3,http://arxiv.org/pdf/2008.13121v3,"Temporal Mental Health Dynamics on Social Media

Tom Tabak1
1School of Electronic Engineering and Computer Science
Queen Mary University of London
London, United Kingdom
tabaktom360@gmail.com

Matthew Purver 1 2
2Department of Knowledge Technologies
Joˇzef Stefan Institute
Ljubljana, Slovenia
m.purver@qmul.ac.uk

0
2
0
2

p
e
S
2

]
L
C
.
s
c
[

3
v
1
2
1
3
1
.
8
0
0
2
:
v
i
X
r
a

Abstract—We describe a set of experiments for building a
temporal mental health dynamics system. We utilise a pre-
existing methodology for distant-supervision of mental health
data mining from social media platforms and deploy the system
during the global COVID-19 pandemic as a case study. Despite
the challenging nature of the task, we produce encouraging
results, both explicit to the global pandemic and implicit to
a global phenomenon, Christmas Depression, supported by the
literature. We propose a methodology for providing insight into
temporal mental health dynamics to be utilised for strategic
decision-making.

Index Terms—Mental Health, Social Media, COVID-19

I. INTRODUCTION

Mental health issues pose a signiﬁcant threat to the gen-
eral population. Quantiﬁable data sources pertaining to men-
tal health are scarce in comparison to physical health data
(Coppersmith et al. 2014). This scarcity contributes to the
complexity of development of reliable diagnoses and effective
treatment of mental health issues as is the norm in physical
health (Righetti-Veltema et al. 1998). The scarcity is partially
due to complexity and variation in underlying causes of men-
tal illness. Furthermore, the traditional method for gathering
population-level mental health data, behavioral surveys,
is
costly and often delayed (De Choudhury, Counts & Horvitz
2013b).

Whilst widespread adoption and engagement in social media
platforms has provided researchers with a plentiful data source
for a variety of tasks, including mental health diagnosis; it has
not, yet, yielded a concrete solution to mental health diagnosis
(Ayers et al. 2014). Conducting mental health diagnosis tasks
on social media data presents its own set of challenges: The
users’ option of conveying a particular public persona posts
that may not be genuine; sampling from a sub-population
that is either technologically savvy, which may lend to a
generational bias, or those that can afford the ﬁnancial cost
of the technology, which may lead to a demographic bias.
However, the richness and diversity of the available data’s
content make it an attractive data source. Quantiﬁable data
from social media platforms is by nature social and crucially
(in the context of our cases study) virtual.

Quantiﬁable social media data enables researchers to de-
velop methodologies for distant mental health diagnosis and
analyse different mental
illnesses (De Choudhury, Counts
& Horvitz 2013a). Distant detection and analysis enables

researchers to monitor relationships of temporal mental health
dynamics to adverse conditions such as war, economic crisis
or a pandemic such as the Coronavirus (COVID-19) pandemic.

COVID-19, a novel virus, proved to be fatal in many cases
during the global pandemic that started in 2019. Governments
reacted to the pandemic by placing measures restricting the
movement of people on and within their borders in an attempt
to slow the spread of the virus. The restrictions came in
the form of many consecutive temporary policies that varied
across countries in their execution. We focus on arguably the
most disruptive measure: The National Lockdown. This re-
quired individuals, other than essential workers (e.g. healthcare
professionals) to remain in their own homes. The lockdown
enforcement varied across countries but the premise was that
individuals were only permitted to leave their homes brieﬂy
for essential shopping (food and medicine). This policy had
far reaching social and economic impacts: growing concern
towards individuals’ own and their families’ health, economic
well-being and ﬁnancial uncertainty as certain industries (such
as hospitality, retail and travel) suspended operations. As a
result, many individuals became redundant and unemployed
which constrained their ﬁnancial resources as well as being
conﬁned to their homes, resulted in excess leisure time.
These experiences along with the uncertainty of the measures’
duration reﬂected a unique period where the general public
would be experiencing a similar stressful and anxious period,
which are both feelings associated with clinical depression
(Hecht et al. 1989, Rickels & Schweizer 1993).

In this paper, we investigate the task of detecting whether
a user is diagnosis-worthy over a given period of time and
explore what might this appropriate time period be. We inves-
tigate the role of balance of classes in datsets by experimenting
with a variety of training regimes. Finally, we examine the
temporal mental health dynamics in relations to the respective
national lockdowns and investigate how these temporal mental
health dy"
The Effect of Moderation on Online Mental Health Conversations,"['David Wadden', 'Tal August', 'Qisheng Li', 'Tim Althoff']","Many people struggling with mental health issues are unable to access
adequate care due to high costs and a shortage of mental health professionals,
leading to a global mental health crisis. Online mental health communities can
help mitigate this crisis by offering a scalable, easily accessible alternative
to in-person sessions with therapists or support groups. However, people
seeking emotional or psychological support online may be especially vulnerable
to the kinds of antisocial behavior that sometimes occur in online discussions.
Moderation can improve online discourse quality, but we lack an understanding
of its effects on online mental health conversations. In this work, we
leveraged a natural experiment, occurring across 200,000 messages from 7,000
online mental health conversations, to evaluate the effects of moderation on
online mental health discussions. We found that participation in group mental
health discussions led to improvements in psychological perspective, and that
these improvements were larger in moderated conversations. The presence of a
moderator increased user engagement, encouraged users to discuss negative
emotions more candidly, and dramatically reduced bad behavior among chat
participants. Moderation also encouraged stronger linguistic coordination,
which is indicative of trust building. In addition, moderators who remained
active in conversations were especially successful in keeping conversations on
topic. Our findings suggest that moderation can serve as a valuable tool to
improve the efficacy and safety of online mental health conversations. Based on
these findings, we discuss implications and trade-offs involved in designing
effective online spaces for mental health support.",2020,http://arxiv.org/abs/2005.09225v7,http://arxiv.org/pdf/2005.09225v7,"The Effect of Moderation on Online Mental Health Conversations

David Wadden, Tal August, Qisheng Li, and Tim Althoff
Paul G. Allen School of Computer Science & Engineering
University of Washington, Seattle, WA

dwadden, taugust, liqs, althoff
}

{

@cs.washington.edu

1
2
0
2

r
p
A
2
2

]
I
S
.
s
c
[

7
v
5
2
2
9
0
.
5
0
0
2
:
v
i
X
r
a

Abstract

Many people struggling with mental health issues are unable
to access adequate care due to high costs and a shortage of
mental health professionals, leading to a global mental health
crisis. Online mental health communities can help mitigate
this crisis by offering a scalable, easily accessible alternative
to in-person sessions with therapists or support groups. How-
ever, people seeking emotional or psychological support on-
line may be especially vulnerable to the kinds of antisocial
behavior that sometimes occur in online discussions. Mod-
eration can improve online discourse quality, but we lack an
understanding of its effects on online mental health conver-
sations. In this work, we leveraged a natural experiment, oc-
curring across 200,000 messages from 7,000 online mental
health conversations, to evaluate the effects of moderation on
online mental health discussions. We found that participation
in group mental health discussions led to improvements in
psychological perspective, and that these improvements were
larger in moderated conversations. The presence of a moder-
ator increased user engagement, encouraged users to discuss
negative emotions more candidly, and dramatically reduced
bad behavior among chat participants. Moderation also en-
couraged stronger linguistic coordination, which is indicative
of trust building. In addition, moderators who remained active
in conversations were especially successful in keeping con-
versations on topic. Our ﬁndings suggest that moderation can
serve as a valuable tool to improve the efﬁcacy and safety of
online mental health conversations. Based on these ﬁndings,
we discuss implications and trade-offs involved in designing
effective online spaces for mental health support.

1

Introduction

Over 400 million people globally struggle with mental
health challenges, with approximately 300 million experi-
encing depression (WHO 2018b). Depression leads to eco-
nomic costs totalling more than $100 billion annually in
the United States alone (Twenge et al. 2019). Rates of seri-
ous psychological distress – including suicidal ideation and
suicide attempts – have increased 71% in adolescents and
young adults since 2005 (Twenge et al. 2019). Although
psychotherapy and social support can be effective treat-
ments (Wampold and Imel 2015; WHO 2018a), vulnerable

Copyright © 2021, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

individuals often have limited access to therapy and coun-
seling (Bose et al. 2018).

Instead, more and more people are turning to online men-
tal health communities to express emotions, share stigma-
tized experiences, and receive helpful information (Eysen-
bach et al. 2004). These communities offer an accessible
way for users to connect to a large network of peers ex-
periencing similar challenges. Participants unable to access
other treatment options can ﬁnd social support and relief
through these conversations (De Choudhury and De 2014;
Sharma and De Choudhury 2018; Naslund et al. 2016). Re-
cently, social support networks have begun to offer a more
personalized experience by matching people sharing similar
struggles in live, private conversations for support (Althoff,
Clark, and Leskovec 2016).

While online mental health communities can provide a
valuable setting for giving and receiving support, the quality
of support provided by peers is less well-characterized. Can
conversation participants temporarily assume the role of a
psychological counselor to assist those in serious distress?
In addition, the often unrestricted and anonymous environ-
ment of online discussions can become a platform for anti-
social behavior, such as online abuse or harassment (Cheng,
Danescu-Niculescu-Mizil, and Leskovec 2015; Zhang et al.
2018). Are these concerns relevant in the setting of an app
designed expressly for mental health discussion? Perhaps
users of this platform are more thoughtful and considerate
than the average forum participant. On the other hand, if bad
behavior is an issue, moderation has been shown to be ef-
fective tool to combat undesirable behavior in online discus-
sions (Seering et al. 2019; Matias 2019; Lampe et al. 2014;
Seo 2007). But little is known about the effectiveness of
moderation in the context of mental health applications. Do
moderators need to be highly involved to keep users safe? Or
does simply the knowledge that a moderator is present in-
ﬂuence behavior without active intervention? Furthermore,
what roles do moderators assume in mental health discus-
sions? Are they mostly discipline-keepers, or do they also
act as counselors and"
"MentalHealthAI: Utilizing Personal Health Device Data to Optimize
  Psychiatry Treatment","['Manan Shukla', 'Oshani Seneviratne']","Mental health disorders remain a significant challenge in modern healthcare,
with diagnosis and treatment often relying on subjective patient descriptions
and past medical history. To address this issue, we propose a personalized
mental health tracking and mood prediction system that utilizes patient
physiological data collected through personal health devices. Our system
leverages a decentralized learning mechanism that combines transfer and
federated machine learning concepts using smart contracts, allowing data to
remain on users' devices and enabling effective tracking of mental health
conditions for psychiatric treatment and management in a privacy-aware and
accountable manner. We evaluate our model using a popular mental health dataset
that demonstrates promising results. By utilizing connected health systems and
machine learning models, our approach offers a novel solution to the challenge
of providing psychiatrists with further insight into their patients' mental
health outside of traditional office visits.",2023,http://arxiv.org/abs/2307.04777v1,http://arxiv.org/pdf/2307.04777v1,"3
2
0
2

l
u
J

9

]

G
L
.
s
c
[

1
v
7
7
7
4
0
.
7
0
3
2
:
v
i
X
r
a

MentalHealthAI: Utilizing Personal Health Device Data to
Optimize Psychiatry Treatment

Manan Shukla and Oshani Seneviratne, PhD
Rensselaer Polytechnic Institute, Troy, NY, USA

Abstract

Mental health disorders remain a significant challenge in modern healthcare, with diagnosis and treatment
often relying on subjective patient descriptions and past medical history. To address this issue, we propose
a personalized mental health tracking and mood prediction system that utilizes patient physiological data
collected through personal health devices. Our system leverages a decentralized learning mechanism that
combines transfer and federated machine learning concepts using smart contracts, allowing data to remain
on users’ devices and enabling effective tracking of mental health conditions for psychiatric treatment and
management in a privacy-aware and accountable manner. We evaluate our model using a popular mental
health dataset that demonstrates promising results. By utilizing connected health systems and machine
learning models, our approach offers a novel solution to the challenge of providing psychiatrists with further
insight into their patients’ mental health outside of traditional office visits.

Introduction

Mental health conditions such as depression and anxiety are some of the most challenging medical problems to
diagnose and treat. Current treatment guidelines for these disorders primarily utilize subjective assessments,
relying on patient self-report or clinician evaluation to inform clinical decisions. As such, the lack of objective
markers for clinical outcomes presents a significant bottleneck in psychiatry. Furthermore, a patient’s mood
or emotions may change over time, but clinicians only have access to a patient’s data at the time of the visit,
leading to a potentially biased sampling of the patient’s mental state. To address this, collecting data from
the patient over a long period would be ideal for effective diagnosis and treatment. However, collecting such
data is also challenging due to privacy concerns. Connected health applications enable data to be generated
and stored in a decentralized manner, where the data may reside cross-device. A common challenge in health
informatics in federated and decentralized settings is that training and test data are not independently and
identically distributed (non-IID), which is especially true in scenarios that apply to predict the mental health
of individuals using a combination of medical and environmental signals. Because health data is typically not
identically distributed, the generalization performance tends to be worse, and lower accuracy can result from
overlooking the distribution shift in the training and testing data 20. More importantly, since non-IID data
in healthcare applications comes from different clients, protecting data privacy is crucial in decentralized
learning settings 15.

Furthermore, applying connected health technologies in a mental health population poses multiple problems 8.
First is the concern about data security and privacy. Studies have shown that mental health populations
typically consider their data sensitive and vary in sharing this information due to perceived mental health
stigmas. Surveys have shown that 65% of patients with mental health disorders are unlikely to share patient
data with their psychiatrists 7. If the psychiatrists aim to rely on patients’ history, studies 16 have shown
patient histories only to be 62% accurate, leading to psychiatric misdiagnoses as high as 65.9% for major
depressive disorders and 85.8% for panic disorders. Therefore, a technological solution is necessary to provide
psychiatrists with health insights without collecting raw data from the patient’s smart health devices. Second,
current models do not account for the granularity of mental health disorders. As explained in the American
Psychiatric Association’s Clinical Practice Guidelines 1, patient emotions are subject to rapid changes within
the span of a day or a week, and elements such as sleep or diet can lead to quick changes in mood. While
many have utilized information from Electronic Health Records (EHR) to predict mental health crises 6,
these models overlook granular patient changes. Therefore, they cannot generate a patient baseline (in fact,
getting data through facial expressions or EHR systems can lead to biased results). Understanding the

1

 
 
 
 
 
 
immediate effects of medication, such as antidepressants, is crucial for psychiatrists and requires granular
patient data that cannot be retrieved otherwise. Currently, the most feasible way to collect this granular
patient data is through a smartphone and a patient’s health devices. This method, however, has the issue
of unequal data streams. Different patients have different personal health devices. For example, while one
patient may have five devices, another may only have one. While trai"
RSDD-Time: Temporal Annotation of Self-Reported Mental Health Diagnoses,"['Sean MacAvaney', 'Bart Desmet', 'Arman Cohan', 'Luca Soldaini', 'Andrew Yates', 'Ayah Zirikly', 'Nazli Goharian']","Self-reported diagnosis statements have been widely employed in studying
language related to mental health in social media. However, existing research
has largely ignored the temporality of mental health diagnoses. In this work,
we introduce RSDD-Time: a new dataset of 598 manually annotated self-reported
depression diagnosis posts from Reddit that include temporal information about
the diagnosis. Annotations include whether a mental health condition is present
and how recently the diagnosis happened. Furthermore, we include exact temporal
spans that relate to the date of diagnosis. This information is valuable for
various computational methods to examine mental health through social media
because one's mental health state is not static. We also test several baseline
classification and extraction approaches, which suggest that extracting
temporal information from self-reported diagnosis statements is challenging.",2018,http://arxiv.org/abs/1806.07916v1,http://arxiv.org/pdf/1806.07916v1,"RSDD-Time: Temporal Annotation of Self-Reported Mental Health
Diagnoses

Sean MacAvaney*, Bart Desmet†*, Arman Cohan*, Luca Soldaini*,
Andrew Yates‡*, Ayah Zirikly§, Nazli Goharian*

*IR Lab, Georgetown University, US
{firstname}@ir.cs.georgetown.edu

†LT3, Ghent University, BE
bart.desmet@ugent.be

‡Max Planck Institute for Informatics, DE
ayates@mpi-inf.mpg.de

§ National Institutes of Health, US
ayah.zirikly@nih.gov

8
1
0
2

n
u
J

0
2

]
L
C
.
s
c
[

1
v
6
1
9
7
0
.
6
0
8
1
:
v
i
X
r
a

Abstract

Self-reported diagnosis statements have been
widely employed in studying language related
to mental health in social media. However, ex-
isting research has largely ignored the tempo-
rality of mental health diagnoses. In this work,
we introduce RSDD-Time: a new dataset of
598 manually annotated self-reported depres-
sion diagnosis posts from Reddit that include
temporal information about the diagnosis. An-
notations include whether a mental health con-
dition is present and how recently the diagno-
sis happened. Furthermore, we include exact
temporal spans that relate to the date of diag-
nosis. This information is valuable for vari-
ous computational methods to examine men-
tal health through social media because one’s
mental health state is not static. We also test
several baseline classiﬁcation and extraction
approaches, which suggest that extracting tem-
poral information from self-reported diagnosis
statements is challenging.

1

Introduction

Researchers have long sought to identify early
warning signs of mental health conditions to al-
low for more effective treatment (Feightner and
Worrall, 1990). Recently, social media data has
been utilized as a lens to study mental health (Cop-
persmith et al., 2017). Data from social media
users who are identiﬁed as having various mental
health conditions can be analyzed to study com-
mon language patterns that indicate the condition;
language use could give subtle indications of a
person’s wellbeing, allowing the identiﬁcation of
at-risk users. Once identiﬁed, users could be pro-
vided with relevant resources and support.

While social media offers a huge amount of
data, acquiring manually-labeled data relevant to
mental health conditions is both expensive and

not scalable. However, a large amount of la-
beled data is crucial for classiﬁcation and large-
scale analysis. To alleviate this problem, NLP
researchers in mental health have used unsuper-
vised heuristics to automatically label data based
on self-reported diagnosis statements such as “I
have been diagnosed with depression” (De Choud-
hury et al., 2013; Coppersmith et al., 2014a, 2015;
Yates et al., 2017).

A binary status of a user’s mental health condi-
tions does not tell a complete story, however. Peo-
ple’s mental condition changes over time (Wilkin-
son and Pickett, 2010), so the assumption that
language characteristics found in a person’s so-
cial media posts historically reﬂects their current
state is invalid. For example, the social media
language of an adult diagnosed with depression
in early adolescence might no longer reﬂect any
depression. Although the extraction of temporal
information has been well-studied in the clinical
domain (Lin et al., 2016; Bethard et al., 2017; Dli-
gach et al., 2017), temporal information extrac-
tion has remained largely unexplored in the mental
health domain. Given the speciﬁc language related
to self-reported diagnoses posts and the volatility
of mental conditions in time, the time of diagno-
sis provides critical signals on examining mental
health through language.

this

To address

shortcoming of available
datasets, we introduce RSDD-Time: a dataset
of temporally annotated self-reported diagnosis
statements, based on the Reddit Self-Reported De-
pression Diagnosis (RSDD) dataset (Yates et al.,
2017). RSDD-Time includes 598 diagnosis state-
ments that are manually annotated to include perti-
nent temporal information. In particular, we iden-
tify if the conditions are current, meaning that the
condition is apparently present according the the

 
 
 
 
 
 
self-reported diagnosis post. Next, we identify
how recently a particular diagnosis has occurred.
We refer to these as condition state and diagno-
sis recency, respectively. Furthermore, we identify
the time expressions that relate to the diagnosis, if
provided.

In summary, our contributions are:

(i) We
explain the necessity of temporal considerations
(ii)
when working with self-reported diagnoses.
We release a dataset of annotations for 598 self-
(iii) We provide
reported depression diagnoses.
and analyze baseline classiﬁcation and extraction
results.

Related work Public social media has become a
lens through which mental health can be studied as
it provides a public narration of user activities and
behaviors (Conway and O’Connor, 2016). Un-
derstanding and identifying mental health condi-
tions in social media (e.g., Twitter and Reddit) has
been widely studied (De Choudhury et al., 2013;
Coppersmith et"
Mental Health and Sensing,"['Abdul Kawsar Tushar', 'Muhammad Ashad Kabir', 'Syed Ishtiaque Ahmed']","Mental health is a global epidemic, affecting close to half a billion people
worldwide. Chronic shortage of resources hamper detection and recovery of
affected people. Effective sensing technologies can help fight the epidemic
through early detection, prediction, and resulting proper treatment. Existing
and novel technologies for sensing mental health state could address the
aforementioned concerns by activating granular tracking of physiological,
behavioral, and social signals pertaining to problems in mental health. Our
paper focuses on the available methods of sensing mental health problems
through direct and indirect measures. We see how active and passive sensing by
technologies as well as reporting from relevant sources can contribute toward
these detection methods. We also see available methods of therapeutic treatment
available through digital means. We highlight a few key intervention
technologies that are being developed by researchers to fight against mental
illness issues.",2020,http://arxiv.org/abs/2009.12488v1,http://arxiv.org/pdf/2009.12488v1,"Mental Health and Sensing

Abdul Kawsar Tushar1, Muhammad Ashad Kabir2, and Syed Ishtiaque
Ahmed1

1Department of Computer Science, University of Toronto, Toronto, Canada
2School of Computing and Mathematics, Charles Sturt University, NSW, Australia
tushar.kawsar@gmail.com, akabir@csu.edu.au, ishtiaque@cs.toronto.edu

Abstract. Mental health is a global epidemic, aﬀecting close to half a
billion people worldwide. Chronic shortage of resources hamper detec-
tion and recovery of aﬀected people. Eﬀective sensing technologies can
help ﬁght the epidemic through early detection, prediction, and result-
ing proper treatment. Existing and novel technologies for sensing mental
health state could address the aforementioned concerns by activating
granular tracking of physiological, behavioral, and social signals pertain-
ing to problems in mental health. Our paper focuses on the available
methods of sensing mental health problems through direct and indirect
measures. We see how active and passive sensing by technologies as well
as reporting from relevant sources can contribute toward these detection
methods. We also see available methods of therapeutic treatment avail-
able through digital means. We highlight a few key intervention tech-
nologies that are being developed by researchers to ﬁght against mental
illness issues.

Keywords: Mental health, wearables, sensing.

1

Introduction

Mental health can be termed as a concern that is plaguing the entire earth. There
is a worrying number of 450 million around the globe that have been diagnosed
with some form of mental or neurodevelopmental illnesses [1] and they often lead
to various levels of disability [2]. Mental and neurodevelopmental illnesses give
rise to a mortality rate that has been compared at a level more than double that
of the general population, leading to approximately 8 million deaths [3]. Another
impact of such sheer numbers related to these conditions is the ﬁnancial burden,
which generate from expenditure for care as well as the loss in productivity. The
numbers related to economic loss has been estimated at more than $400 billion
dollars, that only in the United States of America for a year [4].

Well-being of patients suﬀering from serious mental illness for a sustainable
period can be ensured through treatment, management, and care and this can
be achieved through granular symptom monitoring [5]. However, existing clinical
tools and resources are limited in terms of accessibility and scalability [6]. Mo-
bile health, often termed as mHealth for brevity, is where mobile (or electronic)
devices converge with medical professionals and public health administration [7]

0
2
0
2

p
e
S
6
2

]

C
H
.
s
c
[

1
v
8
8
4
2
1
.
9
0
0
2
:
v
i
X
r
a

 
 
 
 
 
 
2

Mental Health and Sensing

and has been a well-researched area for exploring the scope of involving qualita-
tive research methods with a view to providing accessible treatment, participant
monitoring and retention, and progress of treatment. The growth in the number
of mobile devices has also been a signiﬁcant factor in lending more weight to this
type of solutions, since close to 4 billion people around the world own at least one
phone( the number is scheduled to double by 2022) [8]. This is remarkable when
we consider the fact that studies found more than 70% people suﬀering from
serious mental illness have mobile phones [9]. In addition, an increase of sensors
embedded in mobile phones is giving birth to novel possibilities of utilizing these
devices into mental health care based on digital evidence, such as quantitative
functional and behavioral labels eﬃciently and without obstacles [10, 11].

What is holding an widespread adoption of sensors in mental health care
and management is the scattered and restricted state of evidence that proves
the connection between, on one hand, sensor data obtained using wearables and
ubiquitous smartphones and, on the other hand, the prevalence and status of
mental illnesses [6, 12]. In this paper, we show how technology can help in detec-
tion and sensing of mental health problems around the around. Speciﬁcally, we
focus on the major mental illnesses that are tormenting billions of people across
various countries. We see how active and passive sensing by technologies as well
as reporting from relevant sources can contribute toward these detection meth-
ods. We also see available methods of therapeutic treatment available through
digital means. We highlight a few key intervention technologies that are being
developed by researchers to ﬁght against mental illness issues.

2 Mental Health Problems

In this section, we do not aim to classify mental health disorders as that is
not our target for this paper. Instead, our discussion would revolve around the
prevalence of these disorder to provide a sense of their diﬀerent presentations.
Characteristics of major mental disorders include a permutation of irregular and
atypical belief, concepts, attitude, and expressio"
"Impact of closing schools on mental health during the COVID-19 pandemic:
  Evidence using panel data from Japan","['Eiji Yamamura', 'Yoshiro Tsutsui']","The spread of the novel coronavirus disease caused schools in Japan to close
to cope with the pandemic. In response to this, parents of students were
obliged to care for their children during the daytime when they were usually at
school. Does the increase in burden of childcare influence parents mental
health? Based on short panel data from mid-March to mid-April 2020, we explored
how school closures influenced the mental health of parents with school-aged
children. Using the fixed effects model, we found that school closures lead to
students mothers suffering from worse mental health than other females, while
the fathers mental health did not differ from other males. This tendency was
only observed for less educated mothers who had children attending primary
school, but not those attending junior high school. The contribution of this
paper is to show that school closures increased the inequality of mental health
between genders and the educational background of parents.",2021,http://arxiv.org/abs/2101.08476v1,http://arxiv.org/pdf/2101.08476v1,"Impact  of  closing  schools  on  mental  health  during  the  COVID-19  pandemic: 

Evidence using panel data from Japan 

Eiji YAMAMURA 

Department of Economics, Seinan Gakuin University/ 6-2-92 Nishijin Sawaraku Fukuoka, 814-8511.   

Email: yamaei@seinan-gu.ac.jp 

Yoshiro TSUSTSUI 

Department of Sociology, Kyoto Bunkyo University, Japan. 

Email: tsutsui@econ.osaka-u.ac.jp 

Corresponding Author: Eiji YAMAMURA. Email: yamaei@seinan-gu.ac.jp 

 
 
 
 
 
 
Abstract 

The  spread of  the  novel  coronavirus  disease caused schools in Japan to close to  cope with the pandemic. In 

response to this, parents of students were obliged to care for their children during the daytime when they were usually 

at school. Does the increase in burden of childcare influence parents’ mental health? Based on short panel data from 

mid-March to mid-April 2020, we explored how school closures influenced the mental health of parents with school-

aged children. Using the fixed effects model, we found that school closures lead to student’s mothers suffering from 

worse mental health than other females, while the fathers’ mental health did not differ from other males. This tendency 

was only observed for less educated mothers who had children attending primary school, but not those attending junior 

high school. The contribution of this paper is to show that school closures increased the inequality of mental health 

between genders and the educational background of parents.   

Keywords: COVID-19; mental health; children; school closure; primary school; gender difference. 

JEL Classification: I18; J13 

 
 
 
 
 
 
 
1.  Introduction 

To  mitigate  the  coronavirus  disease  (COVID-19)  pandemic,  many  countries  have  adopted  policies  to  enforce 

citizens to stay home in 2020. Under this restricted life, a question that arises: how and to what degree does the COVID-

19 outbreak affect mental health? Previous studies have shown that the COVID-19 outbreak has negatively affected 

mental health (e.g. Brodeur et al. 2020; Sabat et al. 2020; Yamamura and Tsutsui 2020a)1. There is a gap in working 

from  home  between  working  mothers  having  children  of  primary  school  age  and  other  working  women  during  the 

COVID-19 spread (Yamamura and Tsutsui, 2020 b). Changes in working style seem to influence mental health. The 

allocation of time spent on housework differs between husbands and wives in the normal situation in Japan (Yamamura 

and Tsutsui 2021). However, it is unknown how school students influence their parents’ mental health and how this 

influence differs between mothers and fathers during the school closure. This study examines the influence of school 

closure on parents’ mental health by focusing on gender differences among parents2.   

The  COVID-19  pandemic  has  drastically  changed  working  styles  and  time  use  in  various  countries 3 .  As  a 

consequence of the lockdown to cope with COVID-19, the percentage of people who stay at home increased by 8% 

across the United States counties (Brzezinski et al. 2020)4. In addition, schools were closed because of the emergent 

situation under the diffusion of COVID-19 in various countries (Baldwin and Mauro 2020). Parents’ care for school-

aged children plays a critical role in child growth5. The closure of primary schools resulted in parents taking care of 

their children at home, as childcare services were not available because of the COVID-19 pandemic. Therefore, parents’ 

childcare burden increased.   

According to the Global Gender Gap Index 2020 rankings, Japan was 121st among 153 countries (World Economic 

Forum 2020). Under the COVID-19 pandemic, even for two-income households, mainly women worked from home to 

take care of their primary school children (Yamamura and Tsustui 2020 b)6. In Japan, the mental health of mothers with 

school-aged children was predicted to deteriorate more than fathers’ due to school closure caused by the COVID-19 

1  Existing studies consider the effect of COVID-19 on mental health and subjective view (e.g. Fetzer et al. 2020a, 2020b, Layard 
et al. 2020).   
2  There were studies that considered the differences in the effects of COVID-19 between genders (Adams 2020; Alon et al. 2020). 
3  Unexpected external shocks, such as the Great Recession, were observed to change time allocation in the daily life (e.g. Aguiar 
et al. 2013; Gorsuch 2016; Pabilonia 2017). 
4  The recession caused by COVID-19 is different from other types of recessions to the extent that COVID-19 has a greater impact 
on sectors with high female employment shares (Alon et al. 2020). 
5  Self-care after school increased risk of skipping school and use of alcohol and drugs (Aizer 2004). Economic recessions increased 
teenagers' risky behaviors (Pabilonia 2017). A mother’s absence reduced the time a child spends in school (Pörtner 2016).   
6  One major topic regarding parental time with children in the field of househo"
"""For an App Supposed to Make Its Users Feel Better, It Sure is a Joke""
  -- An Analysis of User Reviews of Mobile Mental Health Applications","['MD Romael Haque', 'Sabirat Rubya']","Mobile mental health applications are seen as a promising way to fulfill the
growing need for mental health care. Although there are more than ten thousand
mental health apps available on app marketplaces, such as Google Play and Apple
App Store, many of them are not evidence-based, or have been minimally
evaluated or regulated. The real-life experience and concerns of the app users
are largely unknown. To address this knowledge gap, we analyzed 2159 user
reviews from 117 Android apps and 2764 user reviews from 76 iOS apps. Our
findings include the critiques around inconsistent moderation standards and
lack of transparency. App-embedded social features and chatbots were criticized
for providing little support during crises. We provide research and design
implications for future mental health app developers, discuss the necessity of
developing a comprehensive and centralized app development guideline, and the
opportunities of incorporating existing AI technology in mental health
chatbots.",2022,http://arxiv.org/abs/2209.07796v1,http://arxiv.org/pdf/2209.07796v1,"“For an App Supposed to Make Its Users Feel Better, It Sure is
a Joke” - An Analysis of User Reviews of Mobile Mental
Health Applications

MD ROMAEL HAQUE and SABIRAT RUBYA, Marquette University, USA

Mobile mental health applications are seen as a promising way to fulfill the growing need for mental health
care. Although there are more than ten thousand mental health apps available on app marketplaces, such as
Google Play and Apple App Store, many of them are not evidence-based, or have been minimally evaluated
or regulated. The real-life experience and concerns of the app users are largely unknown. To address this
knowledge gap, we analyzed 2159 user reviews from 117 Android apps and 2764 user reviews from 76 iOS apps.
Our findings include the critiques around inconsistent moderation standards and lack of transparency. App-
embedded social features and chatbots were criticized for providing little support during crises. We provide
research and design implications for future mental health app developers, discuss the necessity of developing
a comprehensive and centralized app development guideline, and the opportunities of incorporating existing
AI technology in mental health chatbots.

CCS Concepts: • Human-centered computing → Empirical studies in HCI ; Empirical studies in ubiquitous
and mobile computing.

Additional Key Words and Phrases: Mobile applications, Mental health, User review analysis.

ACM Reference Format:
MD Romael Haque and Sabirat Rubya. 2022. “For an App Supposed to Make Its Users Feel Better, It Sure is a
Joke” - An Analysis of User Reviews of Mobile Mental Health Applications. Proc. ACM Hum.-Comput. Interact.
6, CSCW2, Article 421 (November 2022), 29 pages. https://doi.org/10.1145/3555146

1 INTRODUCTION
One out of every four persons on the world has been impacted by mental or neurological issues
at some point in their lives [82]. Mental health issues affect around 450 million people globally,
making them one of the primary causes of ill-health and disability according to WHO [82]. In
2019, 20.6% of adults in the United States (51.5 million individuals) were affected by mental illness,
representing 1 in every 5 adults and a sharp increase of 4% in just three years [57]. Due to the
inaccessibility and high cost of traditional treatment, around 55% of people with severe mental
illnesses do not receive treatment [91]. With the advancement of mobile technologies in the last
ten years developers recognized a strong promise for digital tools like mobile phone applications
to expand better accessibility at low cost to mental health (MH) treatment and services [9]. Prior
study has acknowledged this breakthrough for making MH treatment more accessible, convenient,
and adaptable to the patient’s lifestyle [19]. By 2018, there were over 10,000 MH and wellness apps
available for immediate download [114], with services ranging from symptom tracking and mon-
itoring to implementing scientifically grounded therapy, such as CBT and Mindfulness, as well

Authors’ address: MD Romael Haque, mdromael.haque@marquette.edu; Sabirat Rubya, sabirat.rubya@marquette.edu,
Marquette University, Milwaukee, WI, USA, 53233.

Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses,
contact the owner/author(s).
© 2022 Copyright held by the owner/author(s).
2573-0142/2022/11-ART421
https://doi.org/10.1145/3555146

Proc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW2, Article 421. Publication date: November 2022.

421

421:2

MD Romael Haque and Sabirat Rubya

as various interactive tools and modules for self-guidance [8]. However, prior study has shown
that while access and availability of MH applications has increased, concerns about privacy, effec-
tiveness, and usability have also been raised [113]. According to a recent study, 7–42% of users
continued to use the apps after four weeks, but just 0.5–28.6% after six weeks [87]. The use and
adherence with MH applications in real-world settings may range between 1% and 29% [39]. Fur-
thermore, because the majority of the applications accessible are not evidence-based, their efficacy
in aiding people with MH concerns is questionable [8].

Prior research has attempted to understand these challenges using data from a variety of sources,
including the descriptions of applications in mobile app stores [29], publicly available peer-review
databases [8], frameworks and evaluation criteria from engineering and informatics literature, and
interdisciplinary organizations [20], etc. Smartphone-based apps represent a unique opportunity
to expand the availability and quality of MH treatment, and the COVID-19 pandemic caused a
surge in MH and wellness app downloads [119]. But on"
"Domain-specific Continued Pretraining of Language Models for Capturing
  Long Context in Mental Health","['Shaoxiong Ji', 'Tianlin Zhang', 'Kailai Yang', 'Sophia Ananiadou', 'Erik Cambria', 'Jörg Tiedemann']","Pretrained language models have been used in various natural language
processing applications. In the mental health domain, domain-specific language
models are pretrained and released, which facilitates the early detection of
mental health conditions. Social posts, e.g., on Reddit, are usually long
documents. However, there are no domain-specific pretrained models for
long-sequence modeling in the mental health domain. This paper conducts
domain-specific continued pretraining to capture the long context for mental
health. Specifically, we train and release MentalXLNet and MentalLongformer
based on XLNet and Longformer. We evaluate the mental health classification
performance and the long-range ability of these two domain-specific pretrained
models. Our models are released in HuggingFace.",2023,http://arxiv.org/abs/2304.10447v1,http://arxiv.org/pdf/2304.10447v1,"Domain-speciﬁc Continued Pretraining of Language Models
for Capturing Long Context in Mental Health

Shaoxiong Ji 1 Tianlin Zhang 2 Kailai Yang 2 Sophia Ananiadou 2

Erik Cambria 3

Jörg Tiedemann 1

1 University of Helsinki

2 The University of Manchester

3 Nanyang Technological University

{shaoxiong.ji; jorg.tiedemann}@helsinki.fi; cambria@ntu.edu.sg
{kailai.yang,tianlin.zhang}@postgrad.manchester.ac.uk
{sophia.ananiadou}@manchester.ac.uk

Abstract

Pretrained language models have been used
in various natural language processing appli-
cations. In the mental health domain, domain-
speciﬁc language models are pretrained and
released, which facilitates the early detection
of mental health conditions.
Social posts,
e.g., on Reddit, are usually long documents.
there are no domain-speciﬁc pre-
However,
trained models for long-sequence modeling in
the mental health domain. This paper conducts
domain-speciﬁc continued pretraining to cap-
ture the long context for mental health. Specif-
ically, we train and release MentalXLNet and
MentalLongformer based on XLNet and Long-
former. We evaluate the mental health classiﬁ-
cation performance and the long-range ability
of these two domain-speciﬁc pretrained mod-
els. Our models are released in HuggingFace1.

1

Introduction

Natural Language Processing (NLP) applied to
mental healthcare (Le Glaz et al., 2021; Zhang
et al., 2022) has received much attention with spe-
ciﬁc applications to bipolar disorder detection (Har-
vey et al., 2022), depression detection (Ansari
et al., 2023), and suicidal ideation detection (Ji
et al., 2021). Recent work applied pretrained lan-
guage models and domain-speciﬁc continued pre-
training in the mental health domain with public
models released, such as MentalBERT and Men-
talRoBERTa (Ji et al., 2022b). However, due to
the quadratic complexity of self-attention in the
transformer network (Vaswani et al., 2017), the
pretrained Bidirectional Encoder Representations
from Transformers (BERT) (Devlin et al., 2019)
and its domain-speciﬁc variants have limited abil-
ity to capture long-range context, and the pretri-
aned models can only process sequence within 512
tokens in the downstream applications.

1https://huggingface.co/AIMH

To address this issue, efﬁcient transformers are
proposed, such as Longformer (Beltagy et al.,
2020) and Transformer-XL (Dai et al., 2019) to
capture long context. Qin et al. (2023) conducted
a systematic analysis on the long-range ability of
efﬁcient transformers. In mental healthcare, texts
such as self-reported mental conditions are usually
long documents. For example, in social network
analysis on Reddit, users’ posts are long, and each
user might have multiple posts.

This paper focuses on mental health analysis
with long documents. We conduct domain-speciﬁc
continued pretraining with Longformer and XL-
Net architectures in the mental health domain. Our
contributions are as follows. We train and release
two domain-speciﬁc language models, i.e., Men-
talXLNet and MentalLongformer. We evaluate the
performance of these two models on various men-
tal healthcare classiﬁcation datasets. Finally, we
discuss the long-range ability of these two models
and summarize how to choose pretrained language
representations for speciﬁc applications.

2 Methods and Materials

This section presents the methods and materials.
The self-attention in the standard transformer ar-
chitecture suffers from quadratic complexity with
sequence length. As a result, the BERT model pre-
trained with a masked language modeling (MLM)
objective limits the maximum sequence length to
512 tokens.

We introduce two transformer networks for long
documents and domain-speciﬁc pretraining to con-
tinue the pretraining in the mental healthcare do-
main. Table 1 summarizes the learning objectives
and sequence lengths of existing pretrained models
for mental healthcare and models trained in this pa-
per. For downstream classiﬁcation tasks, the max
sequence length of BERT and RoBERTa is 512.

3
2
0
2

r
p
A
0
2

]
L
C
.
s
c
[

1
v
7
4
4
0
1
.
4
0
3
2
:
v
i
X
r
a

 
 
 
 
 
 
Model

Objective

Seq. Length

MentalBERT
MentalRoBERTa
MentalXLNet
MentalLongformer

MLM
MLM
PLM
MLM

128
128
512
4096

Table 1: A summary of pretrained models for mental
healthcare

2.1 Transformers for Long Sequence

Modeling

Longformer Longformer (Beltagy et al., 2020)
proposes an efﬁcient attention mechanism with a
linear complexity that leverages local windowed
attention and task-motivated global attention. It
is better at autoregressive language modeling on
long sequences than prior works. When pretrained
with MLM objective, Longformer achieves better
long sequence modeling capacity on various down-
stream tasks.

XLNet Transformer-XL (Dai et al., 2019) solves
the context fragmentation issue of ﬁxed-length con-
texts by devising the recurrent operations for seg-
ments in the self-attention network. XLNet (Yang
et al., 2019) combines the best of autoregressive
and autoencoding la"
"PsyEval: A Suite of Mental Health Related Tasks for Evaluating Large
  Language Models","['Haoan Jin', 'Siyuan Chen', 'Dilawaier Dilixiati', 'Yewei Jiang', 'Mengyue Wu', 'Kenny Q. Zhu']","Evaluating Large Language Models (LLMs) in the mental health domain poses
distinct challenged from other domains, given the subtle and highly subjective
nature of symptoms that exhibit significant variability among individuals. This
paper presents PsyEval, the first comprehensive suite of mental health-related
tasks for evaluating LLMs. PsyEval encompasses five sub-tasks that evaluate
three critical dimensions of mental health. This comprehensive framework is
designed to thoroughly assess the unique challenges and intricacies of mental
health-related tasks, making PsyEval a highly specialized and valuable tool for
evaluating LLM performance in this domain. We evaluate twelve advanced LLMs
using PsyEval. Experiment results not only demonstrate significant room for
improvement in current LLMs concerning mental health but also unveil potential
directions for future model optimization.",2023,http://arxiv.org/abs/2311.09189v2,http://arxiv.org/pdf/2311.09189v2,"4
2
0
2

n
u
J

3

]
L
C
.
s
c
[

2
v
9
8
1
9
0
.
1
1
3
2
:
v
i
X
r
a

Proceedings of Machine Learning Research LEAVE UNSET:1–18, 2024

Conference on Health, Inference, and Learning (CHIL) 2024

PsyEval: A Suite of Mental Health Related Tasks

for Evaluating Large Language Models

Haoan Jin
Siyuan Chen
Shanghai Jiao Tong University, China

Dilawaier Dilixiati
Yewei Jiang
Shanghai Jiao Tong University School of Medicine, China

Mengyue Wu
Shanghai Jiao Tong University, China

Kenny Q. Zhu
University of Texas at Arlington, USA

pilgrim@sjtu.edu.cn
chensiyuan925@sjtu.edu.cn

dilawur1@sjtu.edu.cn
zoe8188@sjtu.edu.cn

mengyuewu@sjtu.edu.cn

kenny.zhu@uta.edu

Abstract
Evaluating Large Language Models (LLMs) in
the mental health domain poses distinct chal-
lenged from other domains, given the subtle
and highly subjective nature of symptoms that
exhibit significant variability among individu-
als. This paper presents PsyEval, the first
comprehensive suite of mental health-related
tasks for evaluating LLMs. PsyEval encom-
passes five sub-tasks that evaluate three crit-
ical dimensions of mental health. This com-
prehensive framework is designed to thoroughly
assess the unique challenges and intricacies of
mental health-related tasks, making PsyEval a
highly specialized and valuable tool for evalu-
ating LLM performance in this domain. We
evaluate twelve advanced LLMs using PsyEval.
Experiment results not only demonstrate sig-
nificant room for improvement in current LLMs
concerning mental health but also unveil poten-
tial directions for future model optimization.

Data and Code Availability The data utilized
in this study, along with relevant citations where ap-
plicable, are made accessible to fellow researchers, in-
cluding MedQA1 (Jin et al., 2021), SMHD2 (Cohan
et al., 2018), D43 (Yao et al., 2022) and PsyQA4 (Sun
et al., 2021). The datasets we constructed, USMLE-

1. https://github.com/jind11/MedQA
2. https://ir.cs.georgetown.edu/resources/
3. https://x-lance.github.io/D4/
4. https://github.com/thu-coai/PsyQA

© 2024 H. Jin, S. Chen, D. Dilixiati, Y. Jiang, M. Wu & K.Q. Zhu.

mental and Crisis Response QA, are also open-
source.5

1. Introduction

Nowadays, the rising prevalence of mental
illness
presents a significant and growing threat to global
public health. The pervasive specter of mental illness,
especially depression, poses substantial challenges on
a global scale, with the World Health Organization
(WHO) estimating that 3.8% of the global popula-
tion experiences depression (World Health Organi-
zation, 2023). Despite these high numbers, treat-
ment rates remain alarmingly low: only 13.7% of 12-
month DSM-IV/CIDI cases in lower-middle-income
countries, 22.0% in upper-middle-income countries,
and 36.8% in high-income countries receive any form
of treatment (Evans-Lacko et al., 2018). These
challenges are often underestimated due to societal
stigma and a lack of public awareness (Pirina and
C¸ ¨oltekin, 2018).

In the face of the escalating global public health
challenge posed by mental illness, an increasing co-
hort of researchers has redirected substantial efforts
towards this critical domain (Lamichhane, 2023).
The advent of large language models (LLMs) has
emerged as a transformative force, offering novel solu-
tions to persistent challenges within the field of men-

5. https://github.com/KaguraRuri/Psy-Eval

 
 
 
 
 
 
PsyEval

Figure 1: Overview diagram of PsyEval.

tal health. Notable models such as ChatGPT (Schul-
man et al., 2022), LLaMA (Touvron et al., 2023), and
Vicuna (Chiang et al., 2023) have made substantial
strides in Natural Language Processing (NLP). These
models leverage extensive pretraining data and mas-
sive neural networks, achieving commendable results
on standard NLP benchmark tests.
In the specific
domain of mental health, these LLMs have shown
promising applications (Xu et al., 2023; Lamichhane,
2023). Concurrently, researchers have recognized the
unique demands of the mental health domain and
have introduced specialized LLM explicitly designed
for mental health applications (Yang et al., 2023b).

The application of LLMs in mental health domain
presents unique challenges and opportunities. Un-
like other fields, assessing LLMs for mental health re-
quires a careful approach due to the subtle and highly
subjective nature of symptoms, which vary widely
among individuals (Taschereau-Dumouchel et al.,
2022).
Ideally, LLMs should function akin to pro-
fessional psychologists, equipped with the capacity
to diagnose illnesses, exhibit empathy, and adhere to
ethical standards (International Association of Ap-
plied Psychology, 2016). Their effectiveness in the
mental health field hinges not only on domain-specific
knowledge but also on comprehensive capabilities in-
cluding reasoning, planning, and social intelligence.
For instance, interpreting subtle emotional cues and
responding empathetically demands a sophisticated
understanding of language and social dynamics. Fur-
thermore,"
"Public sentiment analysis and topic modeling regarding ChatGPT in mental
  health on Reddit: Negative sentiments increase over time","['Yunna Cai', 'Fan Wang', 'Haowei Wang', 'Qianwen Qian']","In order to uncover users' attitudes towards ChatGPT in mental health, this
study examines public opinions about ChatGPT in mental health discussions on
Reddit. Researchers used the bert-base-multilingual-uncased-sentiment
techniques for sentiment analysis and the BERTopic model for topic modeling. It
was found that overall, negative sentiments prevail, followed by positive ones,
with neutral sentiments being the least common. The prevalence of negative
emotions has increased over time. Negative emotions encompass discussions on
ChatGPT providing bad mental health advice, debates on machine vs. human value,
the fear of AI, and concerns about Universal Basic Income (UBI). In contrast,
positive emotions highlight ChatGPT's effectiveness in counseling, with
mentions of keywords like ""time"" and ""wallet."" Neutral discussions center
around private data concerns. These findings shed light on public attitudes
toward ChatGPT in mental health, potentially contributing to the development of
trustworthy AI in mental health from the public perspective.",2023,http://arxiv.org/abs/2311.15800v1,http://arxiv.org/pdf/2311.15800v1,"Public sentiment analysis and topic modeling regarding ChatGPT in mental health 
on Reddit: Negative sentiments increase over time 

Yunna Cai1, Fan Wang1†, Haowei Wang1 and Qianwen Qian1. 

1School of Information Management, Wuhan Univerisity  

Abstract 

In  order  to  uncover  users'  attitudes  towards 
ChatGPT in mental health, this study examines 
public  opinions  about  ChatGPT  in  mental 
health discussions on Reddit. Researchers used 
the  bert-base-multilingual-uncased-sentiment 
techniques  for  sentiment  analysis  and  the 
BERTopic  model  for  topic  modeling.  It  was 
found that overall, negative sentiments prevail, 
followed  by  positive  ones,  with  neutral 
sentiments  being  the  least  common.  The 
prevalence of negative emotions has increased 
over  time.  Negative  emotions  encompass 
discussions on ChatGPT providing bad mental 
health advice, debates on machine vs. human 
value,  the  fear  of  AI,  and  concerns  about 
Universal  Basic  Income  (UBI).  In  contrast, 
positive 
emotions  highlight  ChatGPT's 
effectiveness in counseling, with mentions of 
keywords  like  ""time""  and  ""wallet.""    Neutral 
discussions  center  around  private  data 
concerns. These findings shed light on public 
attitudes  toward  ChatGPT  in  mental  health, 
potentially contributing to the development of 
trustworthy AI in mental health from the public 
perspective. 

study is to delve into the emotions and viewpoints 
of these users when it comes to ChatGPT in mental 
health.  
This study poses the following questions: 

1. What  are  the  overall  sentiments  and  topics  in 
discussions  related  to  ChatGPT  in  mental 
health? 

2. How  do  the  overall  sentiments  and  topics 

change over time? 

3. What are the topics associated with positive and 
negative  sentiments  in  discussions  related  to 
ChatGPT in mental health? 

To address these questions, this study seeks to 
examine public sentiments and opinions regarding 
ChatGPT in mental health from Reddit (a popular 
social  media  platform).  We  employed  the  bert-
base-multilingual-uncased-sentiment  model  for 
sentiment  analysis  and  utilized  BERTopic  for 
topic modeling. Both models exhibited exemplary 
performance  in  their  designated  tasks  and  are 
commonly  employed  in  scholarly  circles  for 
sentiment and topic analysis (Maarten, 2022). 

1 

Introduction 

WARNING:  This  paper  contains  examples  and 
descriptions which are depressive or aggressive in 
nature. 
Since its inception, ChatGPT has been regarded as 
a  significant  opportunity  for  various  fields, 
including  mental  health. Academia  has  assessed 
ChatGPT's  outstanding  performance  in  various 
mental  health  tasks,  signaling  a  new  era  in 
internet-based psychological interventions (P et al., 
2023).  However,  the  application  of  ChatGPT  in 
the  field  of  mental  health  also  raises  ethical 
concerns  (Tirth  et  al.,  2023).  It  is  imperative  to 
understand the public's attitudes towards this and 
future  of  generative  artificial 
explore 
intelligence  in  mental  health.  However,  there  is 
currently  a  lack  of  empirical  research  to  unveil 
users'  perspectives  on  ChatGPT's  application  in 
mental  health.  Therefore,  the  objective  of  this 

the 

† Corresponding author 

that 

The  results  revealed 

in  discussions 
concerning  ChatGPT  in  mental  health,  negative 
sentiments  outweighed  positive  sentiments,  with 
neutral sentiments being the least prevalent. Over 
time,  there  was  a  continuous  increase  in  the 
proportion  of  negative 
sentiments.  Users 
discussed various aspects, including their overall 
experiences  with  ChatGPT  in  mental  health, 
prompts,  associated  risks  (privacy  and  societal 
implications), and the impact of version updates. 
These findings enrich our comprehension of the 
public's  perceptions  regarding  the  application  of 
ChatGPT  in  mental  health.  Significantly,  the 
outcomes  of  this  study  will  provide  valuable 
guidance 
reliable 
Language  Models  (LLMs)  in  the  mental  health 
domain,  both  for 
industry  and  government 
applications. 

the  development  of 

for 

 
 
2  Related Work 

2.1  The Transformative Influence of ChatGPT 
on Mental Health 

Due to its exceptional knowledge of mental health, 
ChatGPT  is  being  recognized  as  a  promising 
future  in  providing  assistance  for  psychological 
counseling (Chow et al., 2023). In the field of NLP, 
numerous studies have substantiated the excellent 
performance  of  ChatGPT  in  applications  related 
to  mental  health,  encompassing  tasks  such  as 
stress,  depression,  and  suicidality  detection 
(Lamichhane,  2023;  Amin  et  al.,  2023;  Kailai, 
2023).  Given  the  real-world  challenges  such  as 
psychological  stress  and  resource  scarcity  that 
human  therapists  may  bring,  ChatGPT  could 
potentially  become  a  significant  avenue  for  the 
future "
"Robust language-based mental health assessments in time and space
  through social media","['Siddharth Mangalik', 'Johannes C. Eichstaedt', 'Salvatore Giorgi', 'Jihu Mun', 'Farhan Ahmed', 'Gilvir Gill', 'Adithya V. Ganesan', 'Shashanka Subrahmanya', 'Nikita Soni', 'Sean A. P. Clouston', 'H. Andrew Schwartz']","Compared to physical health, population mental health measurement in the U.S.
is very coarse-grained. Currently, in the largest population surveys, such as
those carried out by the Centers for Disease Control or Gallup, mental health
is only broadly captured through ""mentally unhealthy days"" or ""sadness"", and
limited to relatively infrequent state or metropolitan estimates. Through the
large scale analysis of social media data, robust estimation of population
mental health is feasible at much higher resolutions, up to weekly estimates
for counties. In the present work, we validate a pipeline that uses a sample of
1.2 billion Tweets from 2 million geo-located users to estimate mental health
changes for the two leading mental health conditions, depression and anxiety.
We find moderate to large associations between the language-based mental health
assessments and survey scores from Gallup for multiple levels of granularity,
down to the county-week (fixed effects $\beta = .25$ to $1.58$; $p<.001$).
Language-based assessment allows for the cost-effective and scalable monitoring
of population mental health at weekly time scales. Such spatially fine-grained
time series are well suited to monitor effects of societal events and policies
as well as enable quasi-experimental study designs in population health and
other disciplines. Beyond mental health in the U.S., this method generalizes to
a broad set of psychological outcomes and allows for community measurement in
under-resourced settings where no traditional survey measures - but social
media data - are available.",2023,http://arxiv.org/abs/2302.12952v1,http://arxiv.org/pdf/2302.12952v1,"Robust language-based mental health assessments
in time and space through social media

Siddharth Mangalika,1, Johannes C. Eichstaedtb,c,1, Salvatore Giorgie, Jihu Muna, Farhan Ahmeda, Gilvir Gilla, Adithya V.
Ganesana, Shashanka Subrahmanyac, Nikita Sonia, Sean A. P. Cloustond, and H. Andrew Schwartza,1

aDepartment of Computer Science, Stony Brook University, Stony Brook, NY, USA; bDepartment of Psychology, Stanford University, Stanford, CA, USA; cInstitute for
Human-Centered A.I., Stanford University, CA, USA; dDepartment of Family, Population, and Preventive Medicine, Renaissance School of Medicine, Stony Brook University,
Stony Brook, NY, USA; eDepartment of Computer and Information Science, University of Pennsylvania

This manuscript was compiled on February 25, 2023

Compared to physical health, population mental health measurement in the U.S. is very coarse-grained. Currently, in the largest population
surveys, such as those carried out by the Centers for Disease Control or Gallup, mental health is only broadly captured through ""mentally
unhealthy days"" or ""sadness"", and limited to relatively infrequent state or metropolitan estimates. Through the large scale analysis of social
media data, robust estimation of population mental health is feasible at much higher resolutions, up to weekly estimates for counties. In the
present work, we validate a pipeline that uses a sample of 1.2 billion Tweets from 2 million geo-located users to estimate mental health changes
for the two leading mental health conditions, depression and anxiety. We find moderate to large associations between the language-based
mental health assessments and survey scores from Gallup for multiple levels of granularity, down to the county-week (fixed effects β = .25
to 1.58; p < .001). Language-based assessment allows for the cost-effective and scalable monitoring of population mental health at weekly
time scales. Such spatially fine-grained time series are well suited to monitor effects of societal events and policies as well as enable
quasi-experimental study designs in population health and other disciplines. Beyond mental health in the U.S., this method generalizes to
a broad set of psychological outcomes and allows for community measurement in under-resourced settings where no traditional survey
measures – but social media data – are available.

Pre-Print | Depression | Anxiety | Social Media Analysis | Spatiotemporal

M ental health is a large public health concern, causing

large economic impact and loss of quality of life. Recent
estimates suggest that depression affects 19.4 million Ameri-
cans (7.8% of the population, 2020 est.) each year (1), while
generalized anxiety disorder affects approximately 6% of the
US population (19.8 million people, 2010 est.) (2). Globally,
mental health conditions are the fifth-most common cause of
reduced quality of life (3). Critically, poor mental health is
thought to play a central role driving recent increases in preva-
lence and severity of “deaths of despair” (4, 5) in part due
to the influence of poorer mental health on suicide attempts
and suicide mortality obesity (6), and opioid-related overdoses
(7).

Public health researchers and policy makers seek to under-
stand and actively respond to emerging and changing condi-
tions (8, 9). Yet, current standards for monitoring mental
health outcomes rely on subjective information from surveys
that have limited temporal or regional resolution. For example,
annual changes in depression are measured only by annual
Gallup polling (10) and a handful of national surveys (11)
while anxiety is not regularly assessed in any of these sur-
veys (12). Nevertheless, improving geospatial resolution can
provide researchers with tools to more reliably assess the dis-
tribution (13) and determinants of disease (14). Similarly,
a wealth of small studies using ecological momentary assess-
ment suggest that observations made on shorter timescales
routinely identifies symptoms and correlates that are otherwise
inaccessible to researchers (15, 16).

Applying validated measures of depression and anxiety, as-
sessed objectively at regular time-intervals at the county-level
could transform research in population mental health, allowing

researchers for the first time to locate clusters and reasons for
changes to poorer mental health (17). Since originally pro-
posed, language-based assessments have developed to become
as a flexible source of objective information about individuals’
emotions and behaviors (18), often with greater accuracy and
predictive power than existing survey-based measures (19).
Further, recent work has found significant increases in conver-
gent validity via post-stratification techniques (20) to address
known selection biases (21, 22).

Here, we bring integrate a series of recent advances into
a single pipeline, language-based mental health assessment
(LBMHA: Figure 1), to produce anxiety and depression esti-
mates over regions and time. We firs"
"Identifying Mentions of Pain in Mental Health Records Text: A Natural
  Language Processing Approach","['Jaya Chaturvedi', 'Sumithra Velupillai', 'Robert Stewart', 'Angus Roberts']","Pain is a common reason for accessing healthcare resources and is a growing
area of research, especially in its overlap with mental health. Mental health
electronic health records are a good data source to study this overlap.
However, much information on pain is held in the free text of these records,
where mentions of pain present a unique natural language processing problem due
to its ambiguous nature. This project uses data from an anonymised mental
health electronic health records database. The data are used to train a machine
learning based classification algorithm to classify sentences as discussing
patient pain or not. This will facilitate the extraction of relevant pain
information from large databases, and the use of such outputs for further
studies on pain and mental health. 1,985 documents were manually
triple-annotated for creation of gold standard training data, which was used to
train three commonly used classification algorithms. The best performing model
achieved an F1-score of 0.98 (95% CI 0.98-0.99).",2023,http://arxiv.org/abs/2304.01240v2,http://arxiv.org/pdf/2304.01240v2,"Identifying Mentions of Pain in Mental Health Records 
Text: A Natural Language Processing Approach 

Jaya Chaturvedi (Institute of Psychiatry, Psychology and Neurosciences, King’s College London),  
Sumithra Velupillai (Institute of Psychiatry, Psychology and Neurosciences, King’s College London),  
Robert Stewart (Institute of Psychiatry, Psychology and Neurosciences, King’s College London, Health Data 
Research UK, South London and Maudsley Biomedical Research Centre, London, United Kingdom 
Angus Roberts (Institute of Psychiatry, Psychology and Neurosciences, King’s College London, Health Data 
Research UK) 

Pain is a common reason for accessing healthcare resources and is a growing area of research, especially in its 
overlap with mental health. Mental health electronic health records are a good data source to study this overlap. 
However, much information on pain is held in the free text of these records, where mentions of pain present a 
unique  natural  language  processing  problem  due  to  its  ambiguous  nature.  This  project  uses  data  from  an 
anonymised mental health electronic health records database. The data are used to train a machine learning based 
classification algorithm to classify sentences as discussing patient pain or not. This will facilitate the extraction of 
relevant pain information from large databases, and the use of such outputs for further studies on pain and mental 
health.  1,985  documents  were  manually  triple-annotated  for  creation  of  gold  standard  training data,  which  was 
used to train three commonly used classification algorithms. The best performing model achieved an F1-score of 
0.98 (95% CI 0.98-0.99). 

Keywords. Natural Language Processing, Electronic Health Records, Pain, Mental Health, Transformers. 

1. 

Introduction 

Pain is defined as an unpleasant sensory and emotional experience, and is influenced by a variety of biological, 
psychological, and social factors [1]. Pain is a common reason for people to access healthcare facilities, thereby 
making electronic health records (EHR) a potential source for information on pain [2]. 

EHRs are longitudinal compilations of electronic data pertaining to a person's medical history or healthcare 
[3]. They have been increasingly used in research as they provide the opportunity to explore patient symptoms 
and findings from structured and unstructured fields. Since pain is not well recorded in these structured fields, it 
may help to supplement this information with data from unstructured clinical text [4]. 

A commonly used machine learning based NLP approach is text classification, in which labels are assigned 
to units of text (sentences/paragraphs/documents) [5]. Commonly used classification algorithms include Support 
Vector  Machines  [6–8]  and  K-Nearest  Neighbours  [9–11].  Recent  state  of  the  art  approaches  use  embedding 
models  and  transformer-based  neural  network  architectures  [12],  such  as  the  bi-directional  encoder 
representations  of  BERT  [13].  Many  healthcare  domain  related  models  have  emerged,  such  as  PubMedBERT 
[14],  BioBERT  [15],  ClinicalBERT  [16],  UmlsBERT  [17]  and  SAPBERT  [18]  which  were  developed  after 
recognition of the need for specialized models due to linguistic differences between general and biomedical text 
[19].  

This  paper  describes  the  methods  undertaken  to  develop  an  NLP  application  for  a  sentence-level 
classification of mentions of physical pain within clinical text. Two BERT models were trained - bert_base and 
SAPBERT  -  and  compared  to  two  conventional  models  -  support  vector  machines  (SVM)  and  K-Nearest 
Neighbours (KNN). To the best of our knowledge, such extraction of information about pain from mental health 
clinical text using NLP has not been done. 

2.  Methods 

2.1. 

 Data Source 

An anonymised version of EHR data from The South London and Maudsley NHS Foundation Trust (SLaM), one 
of  the  largest  mental  healthcare  organizations  in  Europe,  is  stored  in  the  Clinical  Record  Interactive  Search 

(CRIS)  database  [20].  The  infrastructure  of  CRIS  has  been  described  in  detail  with  an  overview  of  the  cohort 
profile [21]. CRIS contains over 30 million documents, averaging 90 documents per patient [22]. There are 23 
different  text  sources  (such  as  attachments,  event  notes,  nurse  assessment  letters,  etc.).  Most  of  the  text  is 
contained within attachments and event notes, and so these were used as the data sources in this project. 

2.2. 

 Ethics and Data Access 

Ethics approval for CRIS has been granted  by (Oxford C Research Ethics Committee, reference 18/SC/0372). 
Research projects that use the CRIS database are reviewed and approved by a patient-led oversight committee 
(described in [23]). An opt-out model is in place for service users and is advertised in all publicity material and 
initiatives. Data are owned by a third party, "
"Towards Knowledge-based Mining of Mental Disorder Patterns from Textual
  Data",['Maryam Shahabikargar'],"Mental health disorders may cause severe consequences on all the countries'
economies and health. For example, the impacts of the COVID-19 pandemic, such
as isolation and travel ban, can make us feel depressed. Identifying early
signs of mental health disorders is vital. For example, depression may increase
an individual's risk of suicide. The state-of-the-art research in identifying
mental disorder patterns from textual data, uses hand-labelled training sets,
especially when a domain expert's knowledge is required to analyse various
symptoms. This task could be time-consuming and expensive. To address this
challenge, in this paper, we study and analyse the various clinical and
non-clinical approaches to identifying mental health disorders. We leverage the
domain knowledge and expertise in cognitive science to build a domain-specific
Knowledge Base (KB) for the mental health disorder concepts and patterns. We
present a weaker form of supervision by facilitating the generating of training
data from a domain-specific Knowledge Base (KB). We adopt a typical scenario
for analysing social media to identify major depressive disorder symptoms from
the textual content generated by social users. We use this scenario to evaluate
how our knowledge-based approach significantly improves the quality of results.",2022,http://arxiv.org/abs/2207.06254v1,http://arxiv.org/pdf/2207.06254v1,"Towards Knowledge-based Mining of Mental Disorder Patterns from
Textual Data

Maryam Shahabikargar*a

aMacquarie University, Sydney, Australia

maryam.shahabi-kargar@hdr.mq.edu.au

2
2
0
2

l
u
J

7

]

R

I
.
s
c
[

1
v
4
5
2
6
0
.
7
0
2
2
:
v
i
X
r
a

ABSTRACT
Mental health disorders may cause severe consequences on all the countries’ economies and health. For example,
the impacts of the COVID-19 pandemic, such as isolation and travel ban, can make us feel depressed. Identifying
early signs of mental health disorders is vital. For example, depression may increase an individual’s risk of suicide.
The state-of-the-art research in identifying mental disorder patterns from textual data, uses hand-labelled train-
ing sets, especially when a domain expert’s knowledge is required to analyse various symptoms. This task could
be time-consuming and expensive. To address this challenge, in this paper, we study and analyse the various clin-
ical and non-clinical approaches to identifying mental health disorders. We leverage the domain knowledge and
expertise in cognitive science to build a domain-speciﬁc Knowledge Base (KB) for the mental health disorder con-
cepts and patterns. We present a weaker form of supervision by facilitating the generating of training data from
a domain-speciﬁc Knowledge Base (KB). We adopt a typical scenario for analysing social media to identify major
depressive disorder symptoms from the textual content generated by social users. We use this scenario to evaluate
how our knowledge-based approach signiﬁcantly improves the quality of results.

KEYWORDS
Cognitive Science, Knowledge Base, Machine learning; Business Process Analytics

INTRODUCTION

1
We begin this Section with an overview of the research problem and challenges in identifying and understanding
mental health disorder patterns from textual data. We present our contributions and discuss how the proposed
method may facilitate acquiring insight into the mental status of individuals who may be suﬀering from mental
disorders in general and depression in particular. Finally, we present the structure of this paper.

1.1 Overview and Research Problem

The mental health of individuals and communities is a pressing challenge in the world, nowadays. Since COVID-
191 pandemic outbreak in 2019, most governments have been preoccupied with handling and combating the epi-
demic. The prevalence of the Covid-19 has been signiﬁcantly controlled and lowered as a result of the global suc-
cess in vaccine development and mass inoculation. But now, for most governments, a key concern is harnessing
and dealing with the impacts of years of virus exposure, including the associated psychological and economic prob-
lems. COVID-19 has impacted our lifestyles and workplaces. These changes can cause us to feel frustrated, stressed,
and anxious, which may seriously aﬀect our mental health. Based on a recent study, after being diagnosed with
Covid, roughly one out of every ﬁve people develops a mental disorder 198, 201. Hence, governments are trying to
guide families and business owners to deal with these devastating eﬀects and improve the situation. On the other
hand, as businesses reopen, it is important for organisations to provide a mentally healthy workplace2.

1https://en.wikipedia.org/wiki/COVID-19
2https://covid19.swa.gov.au/collection/covid-19-resource-kit

 
 
 
 
 
 
Prior to any support, mental disorders need to be diagnosed. On the other hand, due to their complexity, identify-
ing mental disorder symptoms (e.g., depression symptoms) and their patterns could be a challenging task. Hence,
it is necessary to identify mental health issues accurately and facilitate their treatment. As a critical mental health
issue, depression is one of the leading causes of disability worldwide. It plays an essential role in the overall global
disease burden 69, 124 and could turn into a drastic health condition 3. Depression is a leading cause of disabil-
ity, with 5% of adults and 5.7% of 60-year-old and above people suﬀering from it. Data from the United States
and Australia show elevated rates of depression and anxiety throughout the epidemic. It is estimated that during
the outbreak, depression level (i.e., 25%) is seven times higher than pre-pandemic levels worldwide (i.e., less than
4%)4. Consequently, due to its importance, we focus on depression identiﬁcation in this research.

There are various clinical and non-clinical approaches available to identify depression symptoms. Using question-
naires and interviews are two main clinical approaches for depression identiﬁcation. On the other hand, analysing
medical data (e.g., EEG and fMRI images) and vocal, video, and textual data are diﬀerent approaches to iden-
tifying and predicting depression. In addition, there are very few recent studies that proposed knowledge-based
approaches to identify behavioural and mental disorders such as depression.

To extend the state-of-the-art in this line of work, in this paper,"
"Speech Emotion Recognition using Supervised Deep Recurrent System for
  Mental Health Monitoring","['Nelly Elsayed', 'Zag ElSayed', 'Navid Asadizanjani', 'Murat Ozer', 'Ahmed Abdelgawad', 'Magdy Bayoumi']","Understanding human behavior and monitoring mental health are essential to
maintaining the community and society's safety. As there has been an increase
in mental health problems during the COVID-19 pandemic due to uncontrolled
mental health, early detection of mental issues is crucial. Nowadays, the usage
of Intelligent Virtual Personal Assistants (IVA) has increased worldwide.
Individuals use their voices to control these devices to fulfill requests and
acquire different services. This paper proposes a novel deep learning model
based on the gated recurrent neural network and convolution neural network to
understand human emotion from speech to improve their IVA services and monitor
their mental health.",2022,http://arxiv.org/abs/2208.12812v3,http://arxiv.org/pdf/2208.12812v3,"IEEE Copyright Notice

Copyright (c) 2022 IEEE

in any current or future media,

Personal use of this material is permitted. Per-
mission from IEEE must be obtained for all other
including
uses,
reprinting/republishing this material for advertising
or promotional purposes, creating new collective
works, for resale or redistribution to servers or lists,
or reuse of any copyrighted component of this work
in other works.

Accepted to be published in: IEEE WFIoT-2022;
26 October - 11 November , 2022 - Yokohoma,
Japan. https://wﬁot2022.iot.ieee.org/

2
2
0
2

t
c
O
7
2

]
S
A
.
s
s
e
e
[

3
v
2
1
8
2
1
.
8
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
Speech Emotion Recognition using Supervised Deep
Recurrent System for Mental Health Monitoring

Nelly Elsayed
School of Information Technology
University of Cincinnati
OH, United States
elsayeny@ucmail.uc.edu

Zag ElSayed
School of Information Technology
University of Cincinnati
Ohio, United States
elsayezs@ucmail.uc.edu

Navid Asadizanjani
Dep. of Electrical & Computer Engineering
University of Florida
Florida, United States
nasadi@ece.uﬂ.edu

Murat Ozer
School of Information Technology
University of Cincinnati
Ohio, United States
ozermm@ucmail.uc.edu

Ahmed Abdelgawad
School of Engineering and Technology
Central Michigan University
Michigan, United States
abdel1a@cmich.edu

Magdy Bayoumi
Dep. of Electrical & Computer Engineering
University of Louisiana at Lafayette
Louisiana, Unted States
magdy.bayoumi@louisiana.edu

Abstract—Understanding human behavior and monitoring
mental health are essential to maintaining the community and
society’s safety. As there has been an increase in mental health
problems during the COVID-19 pandemic due to uncontrolled
mental health, early detection of mental issues is crucial. Nowa-
days, the usage of Intelligent Virtual Personal Assistants (IVA)
has increased worldwide. Individuals use their voices to control
these devices to fulﬁll requests and acquire different services.
This paper proposes a novel deep learning model based on the
gated recurrent neural network and convolution neural network
to understand human emotion from speech to improve their IVA
services and monitor their mental health.

Index Terms—Speech emotion recognition, intelligent personal

assistants, GRU, speech detection, mental health

I. INTRODUCTION

Mental health is one of the crucial health aspects that must
be monitored and treated for better physical health and a safer
community and social life [1]. Mental disorders cases are
rising globally. According to the Institute for Health Metrics
and Evaluation (IHME), the number of diagnosed individuals
with one of the mental disorders globally has exceeded 1.1
billion individuals in 2016 [2]. According to the World Health
Organization (WHO), during the ﬁrst year of the COVID-19
pandemic, depression and anxiety disorders have increased by
25% globally, especially among young people and women.
Due to late or unreceived mental care, the number of related
suicide has increased as well. The number of suicides has ex-
ceeded 700,000, meaning one person every 40 seconds dies by
suicidal action related to a mental disorder [3]. Moreover, the
number of mass shootings in the United States has exceeded
200 cases in less than the ﬁrst half of the year [4].

Speech is the primary form of communication and emo-
tional expression [5]. From childhood, even before being able
to speak correct words, children express their emotions in their
ununderstandable talks, such as their happiness and confusion.
Juvenile, adults, and elderly individuals also express their
emotions in their speech. All individuals express common

emotions such as happy, sad, angry, happy, worry, fear, and
neutral in their speech. However, different spoken languages
produce differences in how these emotions are expressed in
the speech tone and voice [6], [7]. In this paper, we focused
on English as the most widely spoken language worldwide [8].
In addition, the availability of open-access data that addresses
the speech emotion recognition problem is using English as
the primary language.

There are several mental disorders that can be identiﬁed
from individual’s emotion changes [9], [10] such as depression
disorder [11], [12], stress disorder [13], [14], and anxiety
(worry/fear) disorders [15], [16]. Early diagnostic of mental
disorders allows the individual to recieve the correct treatment
and prevent sever illensses and even protect fom suisidal
action [17], [18].

Intelligent Virtual Personal Assistants (IVA) [19], [20] is s
a software agent that can perform services for an individual
based on processing users’ questions or commands via text
or voice, depending on the IVA design and purpose. The text-
based interaction IVA are sometimes called chatbots, primarily
when they are assessed by an online chat. The voice-based
interaction IVA is also known as an intelligent voice assistant.
The voice assistants can recognize the human speech and
interpret its commands and ques"
"Privacy Aware Question-Answering System for Online Mental Health Risk
  Assessment","['Prateek Chhikara', 'Ujjwal Pasupulety', 'John Marshall', 'Dhiraj Chaurasia', 'Shweta Kumari']","Social media platforms have enabled individuals suffering from mental
illnesses to share their lived experiences and find the online support
necessary to cope. However, many users fail to receive genuine clinical
support, thus exacerbating their symptoms. Screening users based on what they
post online can aid providers in administering targeted healthcare and minimize
false positives. Pre-trained Language Models (LMs) can assess users' social
media data and classify them in terms of their mental health risk. We propose a
Question-Answering (QA) approach to assess mental health risk using the
Unified-QA model on two large mental health datasets. To protect user data, we
extend Unified-QA by anonymizing the model training process using differential
privacy. Our results demonstrate the effectiveness of modeling risk assessment
as a QA task, specifically for mental health use cases. Furthermore, the
model's performance decreases by less than 1% with the inclusion of
differential privacy. The proposed system's performance is indicative of a
promising research direction that will lead to the development of privacy-aware
diagnostic systems.",2023,http://arxiv.org/abs/2306.05652v1,http://arxiv.org/pdf/2306.05652v1,"Privacy Aware Question-Answering System for Online Mental Health Risk
Assessment

Prateek Chhikara∗ †, Ujjwal Pasupulety†, John Marshall,
Dhiraj Chaurasia and Shweta Kumari
University of Southern California, Los Angeles, USA
{pchhikar,upasupul,jjmarsha,dchauras,shwetaku}@usc.edu

Abstract

Social media platforms have enabled individu-
als suffering from mental illnesses to share their
lived experiences and find the online support
necessary to cope. However, many users fail
to receive genuine clinical support, thus exacer-
bating their symptoms. Screening users based
on what they post online can aid providers in
administering targeted healthcare and minimize
false positives. Pre-trained Language Models
(LMs) can assess users’ social media data and
classify them in terms of their mental health
risk. We propose a Question-Answering (QA)
approach to assess mental health risk using
the Unified-QA model on two large mental
health datasets. To protect user data, we ex-
tend Unified-QA by anonymizing the model
training process using differential privacy. Our
results demonstrate the effectiveness of model-
ing risk assessment as a QA task, specifically
for mental health use cases. Furthermore, the
model’s performance decreases by less than 1%
with the inclusion of differential privacy. The
proposed system’s performance is indicative of
a promising research direction that will lead to
the development of privacy-aware diagnostic
systems.

1

Introduction

In recent years, Natural Language Processing
(NLP) has emerged as a powerful field of study
that focuses on the interaction between human lan-
guage and computational systems (Singh et al.,
2020). Mental health is a crucial aspect of overall
well-being, and gaining insights into individuals’
mental states has become an increasingly important
area of study. NLP techniques have been useful
in identifying text markers that indicate an individ-
ual’s mental well-being (Zhang et al., 2022). Social
media websites, such as Twitter and Reddit, pro-
vide a wealth of textual data that offers a unique

∗ Corresponding author
† These authors contributed equally to this work

opportunity to analyze the mental health status of
their users at scale, enabling the exploration of
patterns, trends, and potential interventions (Skaik
and Inkpen, 2020). Assessing users’ mental health
risk can be reduced to a basic text classification
task, where the Transformer architecture (Vaswani
et al., 2017) has demonstrated state-of-the-art per-
formance. BERT (Devlin et al., 2019) encodings
have been utilized for training a variety of mental
health risk detection systems (Jiang et al., 2020;
Nisa and Muhammad, 2021; Zeberga et al., 2022).
BERT models fine-tuned on social media data (Ji
et al., 2022; Murarka et al., 2020) are able to clas-
sify at-risk individuals with high accuracy.

However, advances in text classification models
have stagnated with the advent of BERT encodings.
Posing the risk assessment problem as a QA task
is more analogous to consulting a trained clinician
(Mutabazi et al., 2021). QA systems built using
BERT have been used for public education on top-
ics in mental health (Guo et al., 2021). Nearly
30% of QA healthcare systems focus on mental
health applications such as workplace empower-
ment, screening, effecting behavior change, and re-
ducing smoking/alcohol dependence (Cilar Budler
et al., 2023). Multiple-choice QA models demon-
strate a promising alternative approach to depres-
sion severity estimation even with low amounts
of training data (Gabín et al., 2021). Further de-
velopment of QA models could lead to better au-
tonomous diagnostic systems. This work proposes
the use of AllenAI’s Unified-QA model (Khashabi
et al., 2020) to assess the mental health risk of users
from their social media posts. The research objec-
tive is to explore whether QA transformer models
are better than text classification transformers at
assessing the risk to mental health and modeling
language markers that are indicative of specific
mental illnesses. We compare Unified-QA to state-
of-the-art pre-trained language models that perform
text classification on the same data.

3
2
0
2

n
u
J

9

]
L
C
.
s
c
[

1
v
2
5
6
5
0
.
6
0
3
2
:
v
i
X
r
a

 
 
 
 
 
 
(a) Binary Classification

(b) Multi Classification

Figure 1: Proposed Pipeline.

Training models on sensitive user data in their
raw form makes them non-compliant with data
privacy rules which can have serious legal rami-
fications in the case of unexpected data breaches
(Brown et al., 2022). By using Differential Privacy,
language models can be trained such that they do
not memorize the training data, leading to data se-
curity and better model generalization (Basu et al.,
2021; Behnia et al., 2022). This work also studies
the impact of differential private training on QA
model performance. The contributions of the paper
are as follows.

1. We approached the text classification task for
mental health posts using a QA framework.
Specifi"
"A Hybrid Approach for Depression Classification: Random Forest-ANN
  Ensemble on Motor Activity Signals","['Anket Patil', 'Dhairya Shah', 'Abhishek Shah', 'Mokshit Gala']","Regarding the rising number of people suffering from mental health illnesses
in today's society, the importance of mental health cannot be overstated.
Wearable sensors, which are increasingly widely available, provide a potential
way to track and comprehend mental health issues. These gadgets not only
monitor everyday activities but also continuously record vital signs like heart
rate, perhaps providing information on a person's mental state. Recent research
has used these sensors in conjunction with machine learning methods to identify
patterns relating to different mental health conditions, highlighting the
immense potential of this data beyond simple activity monitoring. In this
research, we present a novel algorithm called the Hybrid Random forest - Neural
network that has been tailored to evaluate sensor data from depressed patients.
Our method has a noteworthy accuracy of 80\% when evaluated on a special
dataset that included both unipolar and bipolar depressive patients as well as
healthy controls. The findings highlight the algorithm's potential for reliably
determining a person's depression condition using sensor data, making a
substantial contribution to the area of mental health diagnostics.",2023,http://arxiv.org/abs/2310.09277v1,http://arxiv.org/pdf/2310.09277v1,"A HYBRID APPROACH FOR DEPRESSION CLASSIFICATION:
RANDOM FOREST-ANN ENSEMBLE ON MOTOR ACTIVITY
SIGNALS

3
2
0
2

t
c
O
3
1

]

G
L
.
s
c
[

1
v
7
7
2
9
0
.
0
1
3
2
:
v
i
X
r
a

Anket Patil∗
Department of Information Technology
K. J. Somaiya Institute of Technology
Maharashtra, India
patilanket11@gmail.com

Abhishek Shah
Department of Information Technology
K. J. Somaiya Institute of Technology
Maharashtra, India
ahs1@somaiya.edu

Dhairya Shah
Department of Information Technology
K. J. Somaiya Institute of Technology
Maharashtra, India
dhairya.as@somaiya.edu

Mokshit Gala
Department of Information Technology
K. J. Somaiya Institute of Technology
Maharashtra, India
mokshit.gala@somaiya.edu

October 16, 2023

ABSTRACT

Regarding the rising number of people suffering from mental health illnesses in today’s society,
the importance of mental health cannot be overstated. Wearable sensors, which are increasingly
widely available, provide a potential way to track and comprehend mental health issues. These
gadgets not only monitor everyday activities but also continuously record vital signs like heart rate,
perhaps providing information on a person’s mental state. Recent research has used these sensors in
conjunction with machine learning methods to identify patterns relating to different mental health
conditions, highlighting the immense potential of this data beyond simple activity monitoring. In this
research, we present a novel algorithm called the Hybrid Random forest - Neural network that has
been tailored to evaluate sensor data from depressed patients. Our method has a noteworthy accuracy
of 80% when evaluated on a special dataset that included both unipolar and bipolar depressive patients
as well as healthy controls. The findings highlight the algorithm’s potential for reliably determining
a person’s depression condition using sensor data, making a substantial contribution to the area of
mental health diagnostics.

Keywords Depression · Motor Activity · Machine Learning · Random Forest · Neural Network · Hybrid Model ·
Artificial Intelligence

1

Introduction

Global health is greatly impacted by the widespread mental health problems of depression and bipolar disorder. The
World Health Organization (WHO) estimates that over 264 million people worldwide suffer from depression, making it
the main cause of disability [1]. Although bipolar disorder only affects 1% to 2% of the world’s population, it has a
significant negative impact on the affected population’s quality of life and functional impairment [2]. These diseases
have significant financial repercussions; depression and anxiety are estimated to cost US$ 1 trillion annually in lost
productivity [3]. With the introduction of on-body sensors, personal health monitoring has undergone a revolutionary
change. Today’s people use enormous amounts of data every day for a variety of goals, such as improving life quality,

∗

 
 
 
 
 
 
A PREPRINT - OCTOBER 16, 2023

tracking their fitness levels, and changing unhealthy habits. This information includes continuous records of heart rate
and activity levels, which have considerable promise in the field of psychiatry and go beyond the simple metrics of
daily steps taken or calories burned. Growing emphasis has been paid to the complex association between activity
data and a variety of mental health problems such mood swings, stress management, and social disengagement [4–5].
Since 2010, mental health issues—with depression leading the list of most common illnesses [6]–[8] have been the
primary reason for years lived with disability worldwide. Depression presents a variety of difficulties in the physical,
financial, and emotional spheres, which frequently result in problems at work and sick days [9]. The underlying etiology
of these illnesses involves a complex combination of genetic, environmental, and social variables, with biological
rhythm disruptions—often sparked by environmental disturbances—showing up in afflicted people as altered motor
activity patterns [10]. By examining actigraph data to find patterns of motor activity suggestive of depressive and
bipolar illnesses, this study aims to advance our understanding of these disorders. The study intends to clarify the
distinctive motor activity patterns connected to various mood disorders using cutting-edge statistical and machine
learning technologies, potentially permitting better diagnostic and curative approaches.

The main contributions of this paper are:

1. Our study introduces a groundbreaking Hybrid Random Forest – Neural Network model for depression

classification, promising enhanced accuracy in mental health diagnosis.

2. Our findings directly benefit clinical practice by enabling early depression detection, potentially improving

patient outcomes in mental healthcare.

The paper is organized as follows: Section 2 provides a comprehensive literature review, summarizing prior work
and baseline algorithms. Section 3 presents the proposed approach, whi"
Challenges of Large Language Models for Mental Health Counseling,"['Neo Christopher Chung', 'George Dyer', 'Lennart Brocki']","The global mental health crisis is looming with a rapid increase in mental
disorders, limited resources, and the social stigma of seeking treatment. As
the field of artificial intelligence (AI) has witnessed significant
advancements in recent years, large language models (LLMs) capable of
understanding and generating human-like text may be used in supporting or
providing psychological counseling. However, the application of LLMs in the
mental health domain raises concerns regarding the accuracy, effectiveness, and
reliability of the information provided. This paper investigates the major
challenges associated with the development of LLMs for psychological
counseling, including model hallucination, interpretability, bias, privacy, and
clinical effectiveness. We explore potential solutions to these challenges that
are practical and applicable to the current paradigm of AI. From our experience
in developing and deploying LLMs for mental health, AI holds a great promise
for improving mental health care, if we can carefully navigate and overcome
pitfalls of LLMs.",2023,http://arxiv.org/abs/2311.13857v1,http://arxiv.org/pdf/2311.13857v1,"3
2
0
2

v
o
N
3
2

]
L
C
.
s
c
[

1
v
7
5
8
3
1
.
1
1
3
2
:
v
i
X
r
a

Challenges of Large Language Models for Mental Health
Counseling

Neo Christopher Chunga,b,∗, George Dyerb, Lennart Brockia,b

aInstitute of Informatics, University of Warsaw, Poland
bInformatism, New Mexico, United States

Abstract

The global mental health crisis is looming with a rapid increase in mental
disorders, limited resources, and the social stigma of seeking treatment. As
the ﬁeld of artiﬁcial intelligence (AI) has witnessed signiﬁcant advancements
in recent years, large language models (LLMs) capable of understanding and
generating human-like text may be used in supporting or providing psycho-
logical counseling. However, the application of LLMs in the mental health
domain raises concerns regarding the accuracy, eﬀectiveness, and reliability of
the information provided. This paper investigates the major challenges asso-
ciated with the development of LLMs for psychological counseling, including
model hallucination, interpretability, bias, privacy, and clinical eﬀectiveness.
We explore potential solutions to these challenges that are practical and ap-
plicable to the current paradigm of AI. From our experience in developing
and deploying LLMs for mental health, AI holds a great promise for improv-
ing mental health care, if we can carefully navigate and overcome pitfalls of
LLMs.
Keywords:
counseling, psychology, chat bot, bias, interpretability
2000 MSC: 68T07, 68T35, 68T50

large language model, artiﬁcial intelligence, mental health,

The global prevalence of mental disorders is increasing owing to a lack of
treatment, services, and clinical professionals [1, 2]. Over 658 million people
suﬀer from psychological distress worldwide [3].
In the United Kingdom,
only 35% of people with mental health issues receive any form of therapy

∗n.chung@uw.edu.pl

Preprint submitted to Elsevier

November 27, 2023

 
 
 
 
 
 
or treatment [4]. In this setting, the use of large language models (LLMs),
recently popularized by the transformer architecture [5, 6, 7], presents both
promising opportunities and unique challenges in the ﬁeld of psychological
counseling.

These AI models have the potential to assist therapists in the daily provi-
sion of mental health services, through content suggestion and patient man-
agement [8, 9]. These eﬀorts tend to focus on mental health issues that
are not life-threatening and rather requires counseling. In this role, AI can
help providers scale the delivery of mental health services and reduce patient
costs, thus helping to address the global shortage of counselors and thera-
pists. Additionally, several applications have been developed that place an
LLM model in the role of digital counselor [10, 11, 12]. The primary chal-
lenge to all of these proposed uses is model accuracy and reliability, which
are both critical for delivering ethical and eﬀective services. In this paper,
we will lay out major challenges and actionable solutions for using LLMs in
the mental health ﬁeld.

LLMs are a subset of artiﬁcial neural networks (ANN) that demonstrate
human-like general-purpose language understanding and generation. A broad
review of ML methods used in mental health counseling is available in [13].
LLMs for language generation are built on the principle of autoregression,
meaning that the model is trained to predict the next token (roughly equiv-
alent to the next word) in a given sequence of tokens. Their training is per-
formed using large data sets of language [14, 15, 16] and the model learns to
predict, given a sequence of tokens, a probability distribution over all tokens
in its vocabulary for the next token in the sequence. In the current paradigm
of LLMs (e.g., recurrent neural network [17]; transformer architecture [18]),
the apparent language understanding is therefore of purely stochastic nature
and amounts to predicting what’s the most probable thing to “say” in a given
context. Despite the ostensibly simple training objective of predicting the
next word,” LLMs acquire impressive capabilities when trained on extremely
large sets of data [19, 20]. But the models do reﬂect the biases and patterns
existing in the training data [21, 22].

Several mental health applications for use by individuals and institutions
incorporate LLMs into their architecture. They can be divided into two
broad categories: 1) user facing counseling and therapy; and 2) therapist
assistants. Among user facing applications, we ﬁnd some that provide an
immersive conversation experience directly with the underlying model (e.g.,
[10, 11]), others that oﬀer a combination of open-ended conversation with

2

the model and rule-based elements (e.g. [23]), and ﬁnally, those that rely on
the LLM primarily to understand and categorize the user’s message input,
so as to better connect them with a “real” human therapist working for
the service [24, 9]. This last category of user facing apps may overlap with
therapist assistant apps, whose"
"An Integrative Survey on Mental Health Conversational Agents to Bridge
  Computer Science and Medical Perspectives","['Young Min Cho', 'Sunny Rai', 'Lyle Ungar', 'João Sedoc', 'Sharath Chandra Guntuku']","Mental health conversational agents (a.k.a. chatbots) are widely studied for
their potential to offer accessible support to those experiencing mental health
challenges. Previous surveys on the topic primarily consider papers published
in either computer science or medicine, leading to a divide in understanding
and hindering the sharing of beneficial knowledge between both domains. To
bridge this gap, we conduct a comprehensive literature review using the PRISMA
framework, reviewing 534 papers published in both computer science and
medicine. Our systematic review reveals 136 key papers on building mental
health-related conversational agents with diverse characteristics of modeling
and experimental design techniques. We find that computer science papers focus
on LLM techniques and evaluating response quality using automated metrics with
little attention to the application while medical papers use rule-based
conversational agents and outcome metrics to measure the health outcomes of
participants. Based on our findings on transparency, ethics, and cultural
heterogeneity in this review, we provide a few recommendations to help bridge
the disciplinary divide and enable the cross-disciplinary development of mental
health conversational agents.",2023,http://arxiv.org/abs/2310.17017v1,http://arxiv.org/pdf/2310.17017v1,"An Integrative Survey on Mental Health Conversational Agents to Bridge
Computer Science and Medical Perspectives

Young-Min Cho1
João Sedoc2

Sunny Rai1 Lyle Ungar1

Sharath Chandra Guntuku1

3
2
0
2

t
c
O
5
2

]
L
C
.
s
c
[

1
v
7
1
0
7
1
.
0
1
3
2
:
v
i
X
r
a

1University of Pennsylvania

2New York University

{jch0,sunnyrai,ungar,sharathg}@seas.upenn.edu, jsedoc@stern.nyu.edu

Abstract

Mental health conversational agents (a.k.a.
chatbots) are widely studied for their poten-
tial to offer accessible support to those experi-
encing mental health challenges. Previous sur-
veys on the topic primarily consider papers pub-
lished in either computer science or medicine,
leading to a divide in understanding and hin-
dering the sharing of beneficial knowledge be-
tween both domains. To bridge this gap, we
conduct a comprehensive literature review us-
ing the PRISMA framework, reviewing 534
papers published in both computer science and
medicine. Our systematic review reveals 136
key papers on building mental health-related
conversational agents with diverse characteris-
tics of modeling and experimental design tech-
niques. We find that computer science papers
focus on LLM techniques and evaluating re-
sponse quality using automated metrics with
little attention to the application while medi-
cal papers use rule-based conversational agents
and outcome metrics to measure the health out-
comes of participants. Based on our findings on
transparency, ethics, and cultural heterogeneity
in this review, we provide a few recommenda-
tions to help bridge the disciplinary divide and
enable the cross-disciplinary development of
mental health conversational agents.

1

Introduction

The proliferation of conversational agents (CAs),
also known as chatbots or dialog systems, has
been spurred by advancements in Natural Language
Processing (NLP) technologies. Their application
spans diverse sectors, from education (Okonkwo
and Ade-Ibijola, 2021; Durall and Kapros, 2020) to
e-commerce (Shenoy et al., 2021), demonstrating
their increasing ubiquity and potency.

The utility of CAs within the mental health do-
main has been gaining recognition. Over 30% of
the world’s population suffers from one or more
mental health conditions; about 75% individuals in
low and middle-income countries and about 50%

individuals in high-income countries do not receive
care and treatment (Kohn et al., 2004; Arias et al.,
2022). The sensitive (and often stigmatized) nature
of mental health discussions further exacerbates
this problem, as many individuals find it difficult
to disclose their struggles openly (Corrigan and
Matthews, 2003).

Conversational agents like Woebot (Fitzpatrick
et al., 2017) and Wysa (Inkster et al., 2018) were
some of the first mobile applications to address this
issue. They provide an accessible and consider-
ably less intimidating platform for mental health
support, thereby assisting a substantial number of
individuals. Their effectiveness highlights the po-
tential of mental health-focused CAs as one of the
viable solutions to ease the mental health disclosure
and treatment gap.

Despite the successful implementation of certain
CAs in mental health, a significant disconnect per-
sists between research in computer science (CS)
and medicine. This disconnect is particularly ev-
ident when we consider the limited adoption of
advanced NLP (e.g. large language models) mod-
els in the research published in medicine. While CS
researchers have made substantial strides in NLP,
there is a lack of focus on the human evaluation
and direct impacts these developments have on pa-
tients. Furthermore, we observe that mental health
CAs are drawing significant attention in medicine,
yet remain underrepresented in health-applications-
focused research in NLP. This imbalance calls for
a more integrated approach in future studies to op-
timize the potential of these evolving technologies
for mental health applications.

In this paper, we present a comprehensive anal-
ysis of academic research related to mental health
conversational agents, conducted within the do-
mains of CS and medicine1. Employing the Pre-
ferred Reporting Items for Systematic Reviews

1Our data and papers are available on our GitHub:

https://github.com/JeffreyCh0/mental_chatbot_survey

 
 
 
 
 
 
and Meta-Analyses (PRISMA) framework (Mo-
her et al., 2010), we systematically reviewed 136
pertinent papers to discern the trends and research
directions in the domain of mental health conversa-
tional agents over the past five years. We find that
there is a disparity in research focus and technol-
ogy across communities, which is also shown in the
differences in evaluation. Furthermore, we point
out the issues that apply across domains, including
transparency and language/cultural heterogeneity.
The primary objective of our study is to con-
duct a systematic and transparent review of mental
health CA research papers across the domains of
CS and medicine. This process aims not on"
Usable Security for ML Systems in Mental Health: A Framework,"['Helen Jiang', 'Erwen Senge']","While the applications and demands of Machine learning (ML) systems in mental
health are growing, there is little discussion nor consensus regarding a
uniquely challenging aspect: building security methods and requirements into
these ML systems, and keep the ML system usable for end-users. This question of
usable security is very important, because the lack of consideration in either
security or usability would hinder large-scale user adoption and active usage
of ML systems in mental health applications.
  In this short paper, we introduce a framework of four pillars, and a set of
desired properties which can be used to systematically guide and evaluate
security-related designs, implementations, and deployments of ML systems for
mental health. We aim to weave together threads from different domains,
incorporate existing views, and propose new principles and requirements, in an
effort to lay out a clear framework where criteria and expectations are
established, and are used to make security mechanisms usable for end-users of
those ML systems in mental health. Together with this framework, we present
several concrete scenarios where different usable security cases and profiles
in ML-systems in mental health applications are examined and evaluated.",2020,http://arxiv.org/abs/2008.07738v1,http://arxiv.org/pdf/2008.07738v1,"0
2
0
2

g
u
A
8
1

]

Y
C
.
s
c
[

1
v
8
3
7
7
0
.
8
0
0
2
:
v
i
X
r
a

Usable Security for ML Systems in Mental Health: A Framework

Helen Jiang
Independent (aﬃliated with Georgia Institute of
Technology)
helen.h.jiang@gmail.com

ABSTRACT
While the applications and demands of Machine learning (ML) sys-
tems in mental health are growing, there is little discussion nor
consensus regarding a uniquely challenging aspect: building secu-
rity methods and requirements into these ML systems, and keep
the ML system usable for end-users. This question of usable secu-
rity is very important, because the lack of consideration in either
security or usability would hinder large-scale user adoption and
active usage of ML systems in mental health applications.

In this short paper, we introduce a framework of four pillars,
and a set of desired properties which can be used to systematically
guide and evaluate security-related designs, implementations, and
deployments of ML systems for mental health. We aim to weave to-
gether threads from diﬀerent domains, incorporate existing views,
and propose new principles and requirements, in an eﬀort to lay
out a clear framework where criteria and expectations are estab-
lished, and are used to make security mechanisms usable for end-
users of those ML systems in mental health. Together with this
framework, we present several concrete scenarios where diﬀerent
usable security cases and proﬁles in ML-systems in mental health
applications are examined and evaluated.

KEYWORDS
Mental Health, Machine Learning (ML), Security, Usability, Evalu-
ation, Computer System Life Cycle, Failure Modes

1 INTRODUCTION
With a mental health crisis looming large and many ML systems
being built for mental health use cases, it is challenging to trace,
analyze, and compare all the designs and implementations of such
systems. So far, there is a lack of well-deﬁned framework that de-
scribes properties relating to the security of such ML systems in
mental health, and even less considerations are given to how such
security mechanisms can be usable for those systems’ end users.
However, without usable security, undiscovered, undisclosed, and
ill-considered limitations and properties of security decisions would
hold back large-scale adoption and usage[2] of ML systems in men-
tal health use cases. For more detailed and nuanced discussions, see
our treatment at section 4.3.

The goal of this framework is to establish discussions in commu-
nities of mental health, ML, and security, so we can build a com-
mon ground for directions and expectations for usable security in

KDD 2020 Workshop: Designing AI in Support of Good Mental Health (GOOD), August
24th, 2020,
© 2020 Association for Computing Machinery.
This is the author’s version of the work. It is posted here for your personal use. Not
for redistribution. The deﬁnitive Version of Record was published in KDD’20: KDD
GOOD Workshop, August 24th 2020, https://doi.org/10.1145/1122445.1122456.

Erwen Senge
Independent
erwen@protonmail.com

ML systems used in mental health scenarios. Moreover, this frame-
work serves to raise awareness, so that both ML and mental health
communities will heed this critical aspect of usable security in ML
systems for mental health. We hope that this new, interdisciplinary
framework would allow researchers and practitioners to system-
atically compare usable security attributes across ML systems for
mental health, meanwhile to identify potential limitations of par-
ticular approaches and trade-oﬀs in diﬀerent scenarios.

In this short paper, we propose that ML systems in mental health
use cases, beyond the privacy and security requirements already
mandated by legislation’s and regulations — for example, Health
Insurance Portability and Accountability Act (HIPPA)[38, 43, 64]
in United States, and General Data Protection Regulation (GDPR)
in European Union and its member states’ national laws[11, 12]
— should consider properties of usable security proposed by this
framework’s four pillars, and be evaluated on their (1)context mod-
els, (2)functionality criteria, (3)trustworthiness requirements,
and (4)recovery principles across their life cycles.

This work presents our eﬀort to generate discussions and con-
sensus for a common framework in a naturally interdisciplinary
area. We built our research on the foundation of computer security
research, which has a rich history and long tradition of devising
criteria and evaluation rubrics for system designs and implemen-
tations. We also incorporated important and recent literature from
human-computer interaction (HCI), usable security, and fairness,
accountability, and transparency (FAT) research of ML. Weaving
these interdisciplinary threads together, we hope that our frame-
work will beneﬁt both researchers and practitioners working on
ML systems in mental health.

2 RELATED WORK
There is a long and distinguished tradition in computer security re-
search: presciently deﬁne evaluation criteri"
Mobile Mental Health Apps: Alternative Intervention or Intrusion?,"['Shalini Saini', 'Dhiral Panjwani', 'Nitesh Saxena']","Mental health is an extremely important subject, especially in these
unprecedented times of the COVID-19 pandemic. Ubiquitous mobile phones can
equip users to supplement psychiatric treatment and manage their mental health.
Mobile Mental Health (MMH) apps emerge as an effective alternative to assist
with a broad range of psychological disorders filling the much-needed
patient-provider accessibility gap. However, it also raises significant
concerns with sensitive information leakage.The absence of a transparent
privacy policy and lack of user awareness may pose a significant threat to
undermining the applicability of such tools. We conducted a multifold study of
- 1) Privacy Policies (Manually and with Polisis, an automated framework to
evaluate privacy policies); 2) App permissions; 3) Static Analysis for inherent
security issues; 4) Dynamic Analysis for threat surface and vulnerabilities
detection, and 5) Traffic Analysis.
  Our results indicate that apps' exploitable flaws, dangerous permissions, and
insecure data handling pose a potential threat to the users' privacy and
security. The Dynamic analysis identified 145 vulnerabilities in 20 top-rated
MMH apps where attackers and malicious apps can access sensitive information.
45% of MMH apps use a unique identifier, Hardware Id, which can link a unique
id to a particular user and probe users' mental health. Traffic analysis shows
that sensitive mental health data can be leaked through insecure data
transmission. MMH apps need better scrutiny and regulation for more widespread
usage to meet the increasing need for mental health care without being
intrusive to the already vulnerable population.",2022,http://arxiv.org/abs/2206.10728v2,http://arxiv.org/pdf/2206.10728v2,"Mobile Mental Health Apps:
Alternative Intervention or Intrusion?

Shalini Saini
Department of Computer Science
Texas A&M University
College Station, TX, USA
s.saini@tamu.edu

Dhiral Panjwani
IT- Department of Medicine
Univeristy of Alabama at Birmingham
Birmingham, AL, USA
dpanjwani@uabmc.edu

Nitesh Saxena
Department of Computer Science
Texas A&M University
College Station, TX, USA
nsaxena@tamu.edu

2
2
0
2

l
u
J

9

]

Y
C
.
s
c
[

2
v
8
2
7
0
1
.
6
0
2
2
:
v
i
X
r
a

Abstract—Mental health is an extremely important subject,
especially in these unprecedented times of the COVID-19 pan-
demic. Ubiquitous mobile phones can equip users to supplement
psychiatric treatment and manage their mental health. Mobile
Mental Health (MMH) apps emerge as an effective alternative
to assist with a broad range of psychological disorders ﬁlling
the much-needed patient-provider accessibility gap. However, it
also raises signiﬁcant concerns with sensitive information leakage.
The absence of a transparent privacy policy and lack of user
awareness may pose a signiﬁcant threat to undermining the
applicability of such tools. We conducted a multifold study of
- 1) Privacy policies (Manually and with Polisis, an automated
framework to evaluate privacy policies); 2) App permissions; 3)
Static Analysis for inherent security issues; 4) Dynamic Analysis
for threat surface and vulnerabilities detection, and 5) Trafﬁc
Analysis.

Our results indicate that apps’ exploitable ﬂaws, dangerous
permissions, and insecure data handling pose a potential threat to
the users’ privacy and security. The Dynamic analysis identiﬁed
145 vulnerabilities in 20 top-rated MMH apps where attackers
and malicious apps can access sensitive information. 45% of
MMH apps use a unique identiﬁer, Hardware Id, which can
link a unique id to a particular user and probe users’ mental
health. Trafﬁc analysis shows that sensitive mental health data
can be leaked through insecure data transmission. MMH apps
need better scrutiny and regulation for more widespread usage
to meet the increasing need for mental health care without being
intrusive to the already vulnerable population.

Index Terms—Mobile Apps, Mental Health, Privacy and Se-

curity

I. INTRODUCTION

As per the Centers for Disease Control and Prevention
(CDC), from mid-2020 to early 2021 (after starting COVID-
19 ), there is an increase in anxiety or depressive disorder
from 36.4% to 41.5%. The percentage of unmet mental health
care needs is increased from 9.2% to 11.7% [1]. Depression,
anxiety, and other mental disorders can cripple everyday
functioning and even can claim lives as suicide is the tenth
leading cause of death in the U.S. [2]. Winkler et al. found
that COVID-19 increased the prevalence of major depressive
disorder and suicide risk three times and almost doubled
the current anxiety disorders [3]. However, a shortage of
providers may encourage people to seek alternatives more
often for immediate help [4]. Ubiquitous mobile devices can
help to bridge the patient-provider gap and health divide for

underserved and hard-to-reach populations to manage their
mental health needs [5]. As per Wang et al., MMH apps
have the potential to improve mental health, but most of the
currently available apps lack clinical evidence to support their
efﬁcacy [6]. Mainstream clinical practice incorporating MMH
apps is also challenging as research is open to ensure that
technological vulnerabilities do not compromise the privacy
and safety of patients [7]–[9].

Mobile app developers may need standard guidelines to
develop a secure MMH app with the help of the medical
community on the usability [10]. Selecting a secure and
reliable MMH app from a vast pool of available MMH apps
may be daunting for the end-user. A well-deﬁned privacy
policy may be the starting point for app users in making de-
cisions balancing information-sharing and preserving privacy.
No explicit declaration on apps’ permissions, information is
collected, and intended usage of collected information makes it
difﬁcult to grade the apps on security and privacy parameters.
Unfortunately, unintended biases towards mental disorders
increase a victim’s vulnerability to unwanted or unknown
disclosure of his/her mental disorder.

There is a lack of reproducible rigorous scientiﬁc testing
to support rapidly developed MMH apps and quick launches
in awaiting market. Currently, there is no national standard
for evaluating the effectiveness of the available hundreds of
mental health apps [11]. It is essential to maintain transparency
in privacy policies to build the needed trust for the broader
usage of MMH apps. Our contribution is manifold through
this study as follows:

• Analyzing the availability, accessibility, and deﬁciencies

of MMH apps’ privacy policies.

• Dynamic analysis to explore the threat surface, dangerous

permissions, and injection vulnerabilities.

• Static analysis to study the apps’ code ﬁles exposing

major exploitable security and privacy ﬂaws"
Bias Reducing Multitask Learning on Mental Health Prediction,"['Khadija Zanna', 'Kusha Sridhar', 'Han Yu', 'Akane Sano']","There has been an increase in research in developing machine learning models
for mental health detection or prediction in recent years due to increased
mental health issues in society. Effective use of mental health prediction or
detection models can help mental health practitioners re-define mental
illnesses more objectively than currently done, and identify illnesses at an
earlier stage when interventions may be more effective. However, there is still
a lack of standard in evaluating bias in such machine learning models in the
field, which leads to challenges in providing reliable predictions and in
addressing disparities. This lack of standards persists due to factors such as
technical difficulties, complexities of high dimensional clinical health data,
etc., which are especially true for physiological signals. This along with
prior evidence of relations between some physiological signals with certain
demographic identities restates the importance of exploring bias in mental
health prediction models that utilize physiological signals. In this work, we
aim to perform a fairness analysis and implement a multi-task learning based
bias mitigation method on anxiety prediction models using ECG data. Our method
is based on the idea of epistemic uncertainty and its relationship with model
weights and feature space representation. Our analysis showed that our anxiety
prediction base model introduced some bias with regards to age, income,
ethnicity, and whether a participant is born in the U.S. or not, and our bias
mitigation method performed better at reducing the bias in the model, when
compared to the reweighting mitigation technique. Our analysis on feature
importance also helped identify relationships between heart rate variability
and multiple demographic groupings.",2022,http://arxiv.org/abs/2208.03621v1,http://arxiv.org/pdf/2208.03621v1,"Bias Reducing Multitask Learning on Mental
Health Prediction

Khadija Zanna, Kusha Sridhar, Han Yu, Akane Sano
Department of Electrical and Computer Engineering
Rice University
Houston, USA
(khzanna, kh82, hy29, Akane.Sano)@rice.edu

2
2
0
2

g
u
A
7

]

G
L
.
s
c
[

1
v
1
2
6
3
0
.
8
0
2
2
:
v
i
X
r
a

Abstract—There has been an increase in research in developing
machine learning models for mental health detection or predic-
tion in recent years due to increased mental health issues in
society. Effective use of mental health prediction or detection
models can help mental health practitioners re-deﬁne mental
illnesses more objectively than currently done, and identify
illnesses at an earlier stage when interventions may be more
effective. However, there is still a lack of standard in evaluating
bias in such machine learning models in the ﬁeld, which leads
to challenges in providing reliable predictions and in addressing
disparities. This lack of standards persists due to factors such as
technical difﬁculties, complexities of high dimensional clinical
health data, etc., which are especially true for physiological
signals. This along with prior evidence of relations between some
physiological signals with certain demographic identities restates
the importance of exploring bias in mental health prediction
models that utilize physiological signals. In this work, we aim
to perform a fairness analysis and implement a multi-task
learning based bias mitigation method on anxiety prediction
models using ECG data. Our method is based on the idea of
epistemic uncertainty and its relationship with model weights
and feature space representation. Our analysis showed that our
anxiety prediction base model introduced some bias with regards
to age, income, ethnicity, and whether a participant is born in the
U.S. or not, and our bias mitigation method performed better at
reducing the bias in the model, when compared to the reweighting
mitigation technique. Our analysis on feature importance also
helped identify relationships between heart rate variability and
multiple demographic groupings.

Index Terms—bias, epistemic uncertainty,

fairness metric,

Monte-Carlo dropout, protected label, multi-task learning

I. INTRODUCTION AND BACKGROUND

Irrespective of the advancements that machine learning has
made possible in several ﬁelds such as language technologies,
computer vision and medical applications, negative bias is
often embedded in the essence of machine learning algorithms.
Negative bias is an erroneous assumption made by an algo-
rithm, that is systemically prejudiced against certain groups
of people. Negative biases can be encoded in algorithms
due to a number of factors, the ﬁrst being imbalance in the
representation of different population categories in the training

This work was supported by NSF #1840167 and #2047296.

data. If certain demographics are lacking from the sample
data, models trained on this data often do not generalize when
applied to new data that contains those missing demographics
[12]. The second factor that could introduce negative bias in
machine learning algorithms is biased human labeling. This is
due to the fact that data that are fed into models, especially
supervised or semi-supervised models which are widely used
in various jurisdictions, are manually labeled by humans who
are inherently biased. These models ultimately reﬂect people’s
impressions and sustain or further magnify bias from the
labeled data [34]. Training and labeled data aside, there is
still risk of introducing bias in the functional form of a model
through features and modeling techniques [12].

Due to the expanding popularity of machine learning and the
inherent biases that come with it, there has been an increased
focus on bias and fairness in the ﬁeld. There are several works
on how to accurately deﬁne and measure fairness in systems
[18], [21], [29], how to analyze and mitigate bias using various
techniques [12], [22], [38], and a few works that assess the
trade-offs between fairness and accuracy in these models [26],
[33].

Mental health poses a signiﬁcant challenge for an individ-
ual’s well-being, and it is estimated that 792 million people
lived with a mental health disorder in 2017 [27]. This is
slightly more than one in ten people globally (10.7%). Rising
statistics like this has led to an increase in research on mental
health, including mental health and well-being prediction using
physiological signals over the past couple of years. Several
authors research on predicting stress levels, and various mental
health conditions using data collected both in clinical settings
and in the wild [1], [7], [30], [31], [36], [39].

With the rise in popularity of this ﬁeld of research and
its widespread applications in psychiatry and psychology, the
need for effective bias mitigation techniques has become
apparent, especially with the sensitive nature of physiological
data. Previous research that explored emotional responses
cap"
"Identifying Risk Factors for Post-COVID-19 Mental Health Disorders: A
  Machine Learning Perspective","['Maitham G. Yousif', 'Fadhil G. Al-Amran', 'Hector J. Castro']","In this study, we leveraged machine learning techniques to identify risk
factors associated with post-COVID-19 mental health disorders. Our analysis,
based on data collected from 669 patients across various provinces in Iraq,
yielded valuable insights. We found that age, gender, and geographical region
of residence were significant demographic factors influencing the likelihood of
developing mental health disorders in post-COVID-19 patients. Additionally,
comorbidities and the severity of COVID-19 illness were important clinical
predictors. Psychosocial factors, such as social support, coping strategies,
and perceived stress levels, also played a substantial role. Our findings
emphasize the complex interplay of multiple factors in the development of
mental health disorders following COVID-19 recovery. Healthcare providers and
policymakers should consider these risk factors when designing targeted
interventions and support systems for individuals at risk. Machine
learning-based approaches can provide a valuable tool for predicting and
preventing adverse mental health outcomes in post-COVID-19 patients. Further
research and prospective studies are needed to validate these findings and
enhance our understanding of the long-term psychological impact of the COVID-19
pandemic. This study contributes to the growing body of knowledge regarding the
mental health consequences of the COVID-19 pandemic and underscores the
importance of a multidisciplinary approach to address the diverse needs of
individuals on the path to recovery. Keywords: COVID-19, mental health, risk
factors, machine learning, Iraq",2023,http://arxiv.org/abs/2309.16055v1,http://arxiv.org/pdf/2309.16055v1,"  https://www.isohe.org/medical-advances-and-innovations-journal     August  2023 | Volume 1 | Issue 3 

Identifying Risk Factors for Post-COVID-19 Mental Health Disorders: A Machine 
Learning Perspective 

Maitham G. Yousif*1

 , Fadhil G. Al-Amran2, Hector J. Castro3  

1Biology Department, College of Science, University of Al-Qadisiyah, Iraq, Visiting Professor in Liverpool John Moors 
University, Liverpool, United Kingdom 

2Cardiovascular Department, College of Medicine, Kufa University, Iraq  

3Specialist in Internal Medicine - Pulmonary Disease in New York, USA  

Received 3/10/2022, Accepted 2/2/2023, Published 1/8/2023 

 This work is licensed under a Creative Commons Attribution 4.0 International License. 

Abstract 

   In this study, we leveraged machine learning techniques to identify risk factors associated with post-
COVID-19  mental  health  disorders.  Our  analysis,  based  on  data  collected  from  669  patients  across 
various  provinces  in  Iraq,  yielded  valuable  insights.  We  found  that  age,  gender,  and  geographical 
region  of  residence  were  significant  demographic  factors  influencing  the  likelihood  of  developing 
mental  health  disorders  in  post-COVID-19  patients.  Additionally,  comorbidities  and  the  severity  of 
COVID-19  illness  were  important  clinical  predictors.  Psychosocial  factors,  such  as  social  support, 
coping strategies, and perceived stress levels, also played a substantial role. Our findings emphasize 
the  complex  interplay  of  multiple  factors  in  the  development  of  mental  health  disorders  following 
COVID-19  recovery.  Healthcare  providers and  policymakers  should  consider  these  risk  factors when 
designing targeted interventions and support systems for individuals at risk. Machine learning-based 
approaches  can  provide  a  valuable  tool  for  predicting  and  preventing  adverse  mental  health 
outcomes in post-COVID-19 patients. Further research and prospective studies are needed to validate 
these findings and enhance our understanding of the long-term psychological impact of the COVID-19 
pandemic.  This  study  contributes  to  the  growing  body  of  knowledge  regarding  the  mental  health 
consequences  of  the  COVID-19  pandemic  and  underscores  the  importance  of  a  multidisciplinary 
approach to address the diverse needs of individuals on the path to recovery. 

Keywords: COVID-19, mental health, risk factors, machine learning, Iraq 

*Corresponding author: Maithm Ghaly Yousif  matham.yousif@qu.edu.iq    m.g.alamran@ljmu.ac.uk 

                     https://www.isohe.org/medical-advances-and-innovations-journal                               

1 

                                               August  2023 | Volume 1 | Issue 3 

 
 
 
                                 
 
 
 
 
  https://www.isohe.org/medical-advances-and-innovations-journal     August  2023 | Volume 1 | Issue 3 

Introduction 

to 

various 

The  COVID-19  pandemic,  caused  by  the  novel 
coronavirus  SARS-CoV-2,  has  not  only  posed  a 
significant threat to global public health but has 
indirect 
light 
also  brought 
consequences affecting individuals' mental well-
being[1-5].  As  healthcare  systems  around  the 
world grapple with the immediate challenges of 
treating  COVID-19  patients, 
it  has  become 
increasingly  evident  that  there  is  a  pressing 
need  to  understand  and  address  the  potential 
long-term  mental  health  repercussions  of  this 
global crisis. Numerous studies have reported a 
spectrum  of  mental  health  issues  emerging  in 
including 
the  wake  of  COVID-19  recovery, 
anxiety,  depression,  post-traumatic 
stress 
disorder  (PTSD),  and  other  neuropsychiatric 
often 
disorders[4-6]. 
collectively referred to as post-COVID-19 mental 
health disorders, can be debilitating and require 
comprehensive evaluation, risk assessment, and 
timely intervention. To effectively mitigate these 
mental  health  challenges,  it  is  imperative  to 
identify  the  risk  factors  contributing  to  their 
its 
development.  Machine 
capacity  to  analyze  vast  datasets  and  extract 

learning,  with 

conditions, 

These 

facilities 

intricate  patterns,  presents  an  invaluable  tool 
for this purpose[7-9]. By leveraging data-driven 
insights, we can gain a deeper understanding of 
the variables and circumstances that predispose 
individuals  to  post-COVID-19  mental  health 
disorders.  In  this  study,  we  utilize  a  machine 
learning  perspective  to  identify  key  risk  factors 
associated  with  the  onset  of  mental  health 
disorders in individuals recovering from COVID-
19.  Our  dataset  comprises  medical  information 
from  669  patients  collected  across  various 
Iraq.  By  applying 
in 
healthcare 
advanced  analytical  techniques,  we  aim  to 
pinpoint 
significantly 
influence  the  likelihood  of  developing  mental 
health 
following  COVID-19 
infection.  This  "
"What Makes Digital Support Effective? How Therapeutic Skills Affect
  Clinical Well-Being","['Anna Fang', 'Wenjie Yang', 'Raj Sanjay Shah', 'Yash Mathur', 'Diyi Yang', 'Haiyi Zhu', 'Robert Kraut']","Online mental health support communities have grown in recent years for
providing accessible mental and emotional health support through volunteer
counselors. Despite millions of people participating in chat support on these
platforms, the clinical effectiveness of these communities on mental health
symptoms remains unknown. Furthermore, although volunteers receive some
training based on established therapeutic skills studied in face-to-face
environments such as active listening and motivational interviewing, it remains
understudied how the usage of these skills in this online context affects
people's mental health status. In our work, we collaborate with one of the
largest online peer support platforms and use both natural language processing
and machine learning techniques to measure how one-on-one support chats affect
depression and anxiety symptoms. We measure how the techniques and
characteristics of support providers, such as using affirmation, empathy, and
past experience on the platform, affect support-seekers' mental health changes.
We find that online peer support chats improve both depression and anxiety
symptoms with a statistically significant but relatively small effect size.
Additionally, support providers' techniques such as emphasizing the autonomy of
the client lead to better mental health outcomes. However, we also found that
some behaviors (e.g. persuading) are actually harmful to depression and anxiety
outcomes. Our work provides key understanding for mental health care in the
online setting and designing training systems for online support providers.",2023,http://arxiv.org/abs/2312.10775v1,http://arxiv.org/pdf/2312.10775v1,"3
2
0
2
c
e
D
7
1

]

C
H
.
s
c
[

1
v
5
7
7
0
1
.
2
1
3
2
:
v
i
X
r
a

What Makes Digital Support Effective? How Therapeutic Skills Affect Clinical
Well-Being

WENJIE YANG* and ANNA FANG*, Carnegie Mellon University, USA
RAJ SANJAY SHAH, Georgia Institute of Technology, USA
YASH MATHUR, Carnegie Mellon University, USA
DIYI YANG, Stanford University, USA
HAIYI ZHU, Carnegie Mellon University, USA
ROBERT KRAUT, Carnegie Mellon University, USA

Online mental health support communities have grown in recent years for providing accessible mental and emotional health support

through volunteer counselors. Despite millions of people participating in chat support on these platforms, the clinical effectiveness of

these communities on mental health symptoms remains unknown. Furthermore, although volunteers receive some training based on

established therapeutic skills studied in face-to-face environments such as active listening and motivational interviewing, it remains

understudied how the usage of these skills in this online context affects people’s mental health status. In our work, we collaborate

with one of the largest online peer support platforms and use both natural language processing and machine learning techniques to

measure how one-on-one support chats affect depression and anxiety symptoms. We measure how the techniques and characteristics

of support providers, such as using affirmation, empathy, and past experience on the platform, affect support-seekers’ mental health

changes. We find that online peer support chats improve both depression and anxiety symptoms with a statistically significant but

relatively small effect size. Additionally, support providers’ techniques such as emphasizing the autonomy of the client lead to better

mental health outcomes. However, we also found that some behaviors (e.g. persuading) are actually harmful to depression and anxiety

outcomes. Our work provides key understanding for mental health care in the online setting and designing training systems for online

support providers.

CCS Concepts: • Human-centered computing → Empirical studies in collaborative and social computing.

Additional Key Words and Phrases: online communities, mental health, peer support, social computing

ACM Reference Format:

Wenjie Yang*, Anna Fang*, Raj Sanjay Shah, Yash Mathur, Diyi Yang, Haiyi Zhu, and Robert Kraut. 2023. What Makes Digital Support

Effective? How Therapeutic Skills Affect Clinical Well-Being. 1, 1 (December 2023), 27 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn

1 INTRODUCTION

Mental health issues continue to rise globally and under-treatment of serious mental health problems remains a major

problem, with more than one in ten people living with a mental health disorder [20]. Although there is significant

Authors’ addresses: Wenjie Yang*; Anna Fang*, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Raj Sanjay Shah, Georgia Institute of
Technology, USA; Yash Mathur, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Diyi Yang, Stanford University, USA; Haiyi Zhu, Carnegie
Mellon University, Pittsburgh, Pennsylvania, USA; Robert Kraut, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA.

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.

© 2023 Association for Computing Machinery.
Manuscript submitted to ACM

Manuscript submitted to ACM

1

 
 
 
 
 
 
2

Fang and Yang et al.

evidence supporting the effectiveness of professional treatments, such as therapy, a substantial proportion of people

with mental health problems fail to receive any treatment due to reasons such as lacking access to services or having

needs unmet by health services [48, 65]. As a result, peer-to-peer support through online mental health communities

(OMHCs) has emerged as an accessible tool for achieving mental and emotional support. OMHCs include sites like 7

Cups and TalkLife, which usually provide free 24/7 peer-to-peer support from volunteers; online support communities

are thus able to provide mental and emotional support at scale and on a wide variety of challenges [25, 31].

Despite the many benefits available through OMHCs, support providers on online platforms receive relatively

little training [105] in contrast to the extensive training for mental health professionals and even volunteers for crisis

intervention programs [10, 35, 67, 71]. OMHCs often require volunteer support providers to complete short training

sessions along with opt"
Share with Me: A Study on a Social Robot Collecting Mental Health Data,"['Raida Karim', 'Edgar Lopez', 'Katelynn Oleson', 'Tony Li', 'Elin A. Björling', 'Maya Cakmak']","Social robots have been used to assist with mental well-being in various ways
such as to help children with autism improve on their social skills and
executive functioning such as joint attention and bodily awareness. They are
also used to help older adults by reducing feelings of isolation and
loneliness, as well as supporting mental well-being of teens and children.
However, existing work in this sphere has only shown support for mental health
through social robots by responding interactively to human activity to help
them learn relevant skills. We hypothesize that humans can also get help from
social robots in mental well-being by releasing or sharing their mental health
data with the social robots. In this paper, we present a human-robot
interaction (HRI) study to evaluate this hypothesis. During the five-day study,
a total of fifty-five (n=55) participants shared their in-the-moment mood and
stress levels with a social robot. We saw a majority of positive results
indicating it is worth conducting future work in this direction, and the
potential of social robots to largely support mental well-being.",2022,http://arxiv.org/abs/2208.04389v1,http://arxiv.org/pdf/2208.04389v1,"2
2
0
2

g
u
A
8

]

O
R
.
s
c
[

1
v
9
8
3
4
0
.
8
0
2
2
:
v
i
X
r
a

Share with Me: A Study on a Social Robot
Collecting Mental Health Data(cid:63)

Raida Karim1[0000−0002−2854−3985], Edgar Lopez1[0000−0001−6835−855X],
Katelynn Oleson1, Tony Li1[0000−0001−7552−6689], Elin A.
Bj¨orling1[0000−0002−0385−2562], and Maya Cakmak1[0000−0001−8457−6610]

University of Washington WA 98195, USA
{rk1997, mcakmak}@cs.washington.edu,
{lopeze7, kjoleson, tonywli, bjorling}@uw.edu

Abstract. Social robots have been used to assist with mental well-being
in various ways such as to help children with autism improve on their
social skills and executive functioning such as joint attention and bodily
awareness. They are also used to help older adults by reducing feelings of
isolation and loneliness, as well as supporting mental well-being of teens
and children. However, existing work in this sphere has only shown sup-
port for mental health through social robots by responding interactively
to human activity to help them learn relevant skills. We hypothesize that
humans can also get help from social robots in mental well-being by re-
leasing or sharing their mental health data with the social robots. In this
paper, we present a human-robot interaction (HRI) study to evaluate this
hypothesis. During the ﬁve-day study, a total of ﬁfty-ﬁve (n=55) partic-
ipants shared their in-the-moment mood and stress levels with a social
robot. We saw a majority of positive results indicating it is worth con-
ducting future work in this direction, and the potential of social robots
to largely support mental well-being.

Keywords: Social Robot · Mental Health · Data Sharing.

1

Introduction

Apart from genetic or birth related causes, any kind of mental health issues
in our daily lives are usually caused by some kind of trouble such as stressful
events, grief from accidents or deaths, and trauma from tragic or fearful inci-
dents [19]. Research shows that sharing these troubling experiences helps gain
insights from others which helps develop coping skills, and makes one feel less
alone in pain which helps to tackle trouble more eﬀectively [3][12]. Therefore,
sharing about trouble can potentially help treat or lessen mental health issues.
However, people are not always willing to share their mental health with oth-
ers or publicly, even with their family members, let alone outside community

(cid:63) This study was funded in part by National Science Foundation: National Robotics
Initiative, SES: Award Abstract 1734100 - Design and Development of a Social Robot
for Gathering Ecological Momentary Stress Data from Teens.

 
 
 
 
 
 
2

R. Karim et al.

members due to social stigma, personal beliefs or limitations [18]. Therefore, to
tackle mental health issues, the main source of support is usually individualized
therapy, which is expensive and thus inaccessible to many [7][17]. Digital therapy
is a relatively more accessible option compared to in-person therapy because of
lower cost and availability in any location [1][20]. However, digital therapy has
drawbacks, such as lack of face-to-face interaction, user disengagement, and soft-
ware incompatibility [8]. So, we hypothesize that sharing mental health with an
endearing social robot that overcomes these challenges of therapy options can
help support mental health.

2 Related Work

When people share their personally relevant emotions in social media like Face-
book, they experience satisfaction causing positive mental state [3]. People tend
to be discreet about sharing their emotional data, as we see Facebook users
share more intense and negative emotions in private messages [3]. Prior work
that looked into sharing one’s emotions through technologies like a virtual mood
wall reported a positive relation between online emotional sharing and comfort
in negative emotions [12]. Social robots are often perceived as friendly or pet-like
companions by humans for their endearing appearances (e.g., outﬁt, facial ex-
pressions) and capabilities that can include haptics, sounds, and movements [16].
Such perceptions or relationships boost user engagement with social robots [4].
Thus, social robots can better foster emotional support with mental health data
compared to other technologies (e.g., smartphone apps, websites rendered by
touch screen devices) [6]. In a study conducted by Bj¨orling et al. [5], teens re-
ported social robots as a plausible source of emotional support. Additionally,
social robots have been studied in the context of assisting mental healthcare by
sharing its emotions with people [11], having behavioral models fulﬁlling user
needs [15], and providing companionship [9].
To the best of our knowledge, the existing literature in this domain does indicate
that social robots have not yet been used as a means for collecting mental health
data from humans, which makes this research direction a novel one in HRI.

3 Sharing Mental Health Data with a Social Robot

3.1 Study Setup

We conduct a ﬁ"
"WellXplain: Wellness Concept Extraction and Classification in Reddit
  Posts for Mental Health Analysis",['Muskan Garg'],"During the current mental health crisis, the importance of identifying
potential indicators of mental issues from social media content has surged.
Overlooking the multifaceted nature of mental and social well-being can have
detrimental effects on one's mental state. In traditional therapy sessions,
professionals manually pinpoint the origins and outcomes of underlying mental
challenges, a process both detailed and time-intensive. We introduce an
approach to this intricate mental health analysis by framing the identification
of wellness dimensions in Reddit content as a wellness concept extraction and
categorization challenge. We've curated a unique dataset named WELLXPLAIN,
comprising 3,092 entries and totaling 72,813 words. Drawing from Halbert L.
Dunn's well-regarded wellness theory, our team formulated an annotation
framework along with guidelines. This dataset also includes human-marked
textual segments, offering clear reasoning for decisions made in the wellness
concept categorization process. Our aim in publishing this dataset and
analyzing initial benchmarks is to spearhead the creation of advanced language
models tailored for healthcare-focused concept extraction and categorization.",2023,http://arxiv.org/abs/2308.13710v1,http://arxiv.org/pdf/2308.13710v1,"Highlights

WELLXPLAIN: Wellness Concept Extraction and Classification in Reddit Posts for Mental Health
Analysis
Muskan Garg

• Introducing the need of datasets for reliable simulations in mental healthcare.

• Corpus construction for wellness concept extraction and classification.

• Analyzing domain-specific transformers and large language models for this task.

• Examining reliability of traditional multi-class classifiers.

3
2
0
2

g
u
A
5
2

]
L
C
.
s
c
[

1
v
0
1
7
3
1
.
8
0
3
2
:
v
i
X
r
a

 
 
 
 
 
 
WELLXPLAIN: Wellness Concept Extraction and Classification in
Reddit Posts for Mental Health Analysis

Muskan Garga,∗,1

aMayo Clinic, Rochester, 55901 MN, USA

A R T I C L E I N F O

A B S T R A C T

Keywords:
Corpus construction
mental health
WellXplain
wellness dimensions

Amid the ongoing mental health crisis, there is an increasing need to discern possible signs of mental
disturbance manifested in social media text. Neglecting multi-dimensional aspects of social and mental
well-being (i.e., wellness dimensions) over time can adversely affect an individual’s mental health.
During in-person therapy sessions, manual efforts are used to identify the causes and consequences
of triggering latent factors of mental disturbance, which is a meticulous and time-consuming task for
mental health professionals. To enable such fine-grained mental health screening, we define the task
of determining wellness dimensions in Reddit posts as wellness concept extraction and classification
problem. We construct a novel dataset called WELLXPLAIN, which consists of 3,092 instances and
a total of 72,813 words. Our experts developed an annotation scheme and perplexity guidelines for
annotation based on a well-adapted Halbert L. Dunn’s theory of wellness dimensions. Further, the
data encompasses human-annotated text spans as pertinent explanations for decision-making during
wellness concept classification. We anticipate that releasing the dataset and evaluating the baselines
will facilitate the development of new language models for concept extraction and classification in
healthcare domain.

1. Introduction

A clinically significant impairment in a person’s in-
tellect, emotional control, or behavior is what is known
as a mental disorder, suggesting cognitive decline. The
UN Resolution of “Transforming our World: the Agenda
2030 for Sustainable Development” adopted in September
2015 [1], outlined an ambitious vision to tackle Goal 3:
Ensure healthy lives and promote well-being for all at all
ages of Sustainable Development Goals (SDG). By 2030,
UN plans to reduce by one-third premature mortality from
non-communicable diseases through prevention/treatment
and promote the mental health and well-being.1 Untreated
depression is conjectured to be the leading cause of sui-
cide [2]. Reports released in August 20212 indicate that
1.6 million people in England were on waiting lists to seek
professional help with mental health care.

Despite significant technological advances, mental health
assessment remains a dark mark on public health efforts.
Causes for mental health disturbances are broad, including
an unspecific gamut of factors such as physical health prob-
lems, social conflicts (e.g., bullying, prejudice, stigma, race
issues), abuse, grief, financial and professional difficulties,
etc.. These causes are aggravated when patients do not
disclose their concerns to mental health professionals, rather
find solace on social media [3]. Motivated with non-intrusive
high value information, social media data lessens the effect
of limited availability of mental health practitioners. In these
dire circumstances, online platforms are frequently relied

garg.muskan@mayo.edu (M. Garg)

ORCID(s):
1https://www.un.org/development/desa/disabilities/envision2030-

goal3.html

2https://www.theguardian.com/society/2021/aug/29/strain-on-mental-

health-care-leaves-8m-people-without-help-say-nhs-leaders

upon not only as open and unobtrusive sources of informa-
tion, but also as a place for honest disclosure, where people
may freely express themselves along with their thoughts,
beliefs, and emotions [4].

However, social media is extremely noisy because of
popular culture references and slang terms that are pervasive
in online expressions. This noise makes it hard to develop
automated methods for mental health screening methods that
levels with mental health professionals [5, 6]. Furthermore,
prior work on mental health analyses from social media
focuses on assessing posts that already exhibit particular
mental health traits (e.g., analyzing mental health subreddits
related to suicidality and depression) [7, 8, 9].

Amid the huge social impact of COVID-19 pandemic,
the research community witness the presence of mental
disorders in an individual through consequential affect on
wellness dimensions due to prevailing reasons behind men-
tal disturbance. We do not intend to invalidate the prior
works with causal analysis such as CAMS, but expect to
"
"Associational and plausible causal effects of COVID-19 public health
  policies on economic and mental distress","['Reka Sundaram-Stukel', 'Richard J Davidson']","Background The COVID-19 pandemic has increased mental distress globally. The
proportion of people reporting anxiety is 26%, and depression is 34% points.
Disentangling associational and causal contributions of behavior, COVID-19
cases, and economic distress on mental distress will dictate different
mitigation strategies to reduce long-term pandemic-related mental distress.
Methods We use the Household Pulse Survey (HPS) April 2020 to February 2021
data to examine mental distress among U.S. citizens attributable to COVID-19.
We combined HPS survey data with publicly available state-level weekly:
COVID-19 case and death data from the Centers for Disease Control, public
policies, and Apple and Google mobility data. Finally, we constructed economic
and mental distress measures to estimate structural models with lag dependent
variables to tease out public health policies' associational and causal path
coefficients on economic and mental distress. Findings From April 2020 to
February 2021, we found that anxiety and depression had steadily climbed in the
U.S. By design, mobility restrictions primarily affected public health policies
where businesses and restaurants absorbed the biggest hit. Period t-1 COVID-19
cases increased job loss by 4.1% and economic distress by 6.3% points in the
same period. Job-loss and housing insecurity in t-1 increased period t mental
distress by 29.1% and 32.7%, respectively. However, t-1 food insecurity
decreased mental distress by 4.9% in time t. The pandemic-related potential
causal path coefficient of period t-1 economic distress on period t depression
is 57.8%, and anxiety is 55.9%. Thus, we show that period t-1 COVID-19 case
information, behavior, and economic distress may be causally associated with
pandemic related period t mental distress.",2021,http://arxiv.org/abs/2112.11564v1,http://arxiv.org/pdf/2112.11564v1,"Title: Associational and plausible causal effects of COVID-19 public health policies on economic and 
mental distress. 

Reka Sundaram-Stukel1 and Richard J Davidson2 

Summary 
Background  
The COVID-19 pandemic has increased mental distress globally. The proportion of people reporting 
anxiety is 26%, and depression is 34% points. Disentangling associational and causal contributions of 
behavior, COVID-19 cases, and economic distress on mental distress will dictate different mitigation 
strategies to reduce long-term pandemic-related mental distress. 
Methods We use the Household Pulse Survey (HPS) April 2020 – February 2021 data to examine 
mental distress among U.S. citizens attributable to COVID-19. We combined HPS survey data with 
publicly available state-level weekly: COVID-19 case and death data from the Centers for Disease 
Control, public policies, and Apple and Google mobility data. Finally, we constructed economic and 
mental distress measures to estimate structural models with lag dependent variables to tease out public 
health policies' associational and causal path coefficients on economic and mental distress.  
Findings  
From April 2020 to February 2021, we found that anxiety and depression had steadily climbed in the 
U.S. By design, mobility restrictions primarily affected public health policies where businesses and 
restaurants absorbed the biggest hit. Period t-1 COVID-19 cases increased job-loss by 4.1% and 
economic distress by 6.3% points in the same period. Job-loss and housing insecurity in t-1 increased 
period t mental distress by 29.1% and 32.7%, respectively. However, t-1 food insecurity decreased 
mental distress by 4.9% in time t. The pandemic-related potential causal path coefficient of period t-1 
economic distress on period t depression is 57.8%, and anxiety is 55.9%. Thus, we show that period t-1 
COVID-19 case information, behavior, and economic distress may be causally associated with 
pandemic-related period t mental distress. 
Interpretation  
Exploring the association and potential causal relationships between economic distress at t-1 and 
mental distress at t may have several interpretations. First, long-term pandemic-related involuntary job 
loss could have persistent wage scarring effects for many workers post-pandemic. Second, labor 
productivity may decline because of the lingering effects of mental distress. Third, as the economy 
recovers, investments in job-retraining programs with skill appreciation complemented with resilience 
training for displaced workers would enhance welfare. Finally, expanded mental health teleservices for 
workers adjusting to post-pandemic work-life may increase emotional well-being.  
Funding No funding was used to support this research. 
Acknowledgements 
We thank Dr. Adams for many discussions, valuable feedback, and detailed comments. Ms. Stukel for 
editing. All errors are our own. 

Author Information 
1Dr. Reka Sundaram-Stukel (corresponding author) 
Research Fellow, Department of Economics 
7415 Social Sciences, University of Wisconsin–Madison, Madison, Wisconsin 53706 
rsundara@wisc.edu 

2Dr. Richard J Davidson 
William James Professor of Psychology and Psychiatry 
318 Psychology, University of Wisconsin–Madison, Madison, Wisconsin 53706 
rjdavids@wisc.edu 

1 

 
 
 
 
 
Research in context  

Evidence before this study  
Our search terms in APA, PubMed, medRxiv, arXiv, NBER, and Econlit included “anxiety,” “fear,” 
“depression,” “mental health,” “COVID-19”, “COVID-19”, “economic fallout,” “stimulus,” “unemployment 
insurance,” “employment,” “eviction,” and “economic distress.” We focused on all studies from April 
2020 to May 2021 that met the search criteria and were COVID-19 relevant. We found five major 
empirical studies that directly addressed either significant mental health or economic consequences of 
COVID-19. We excluded the studies that relied on simulated data or studies that used theoretical 
models unsupported by data. Nevertheless, there is a consensus that mental distress restricts 
consumption behavior, that mental distress is rising among the US population, those in high contact 
sectors disproportionately feel economic fallout, and that recovery from the COVID-19 pandemic is 
likely to follow a “K” shaped path where some economic sectors recover fast, and others fall behind. 
The mental health side of the story acknowledges that there are widespread increases in anxiety, fear, 
worry, and depression. Still, no large-scale studies explicitly link these factors to economic distress. 

Added value of this study  
The unique large-scale shock of COVID-19 that precipitated stringent public health containment 
measures caused an economic and mental health crisis. We unpack the causal implications of case 
information, behavior, and public policy on economic and mental distress. 

Implications of all the available evidence  
Compared to pre-pandemic reported prevalence rates for anxiety and depression, the "
"MentalBERT: Publicly Available Pretrained Language Models for Mental
  Healthcare","['Shaoxiong Ji', 'Tianlin Zhang', 'Luna Ansari', 'Jie Fu', 'Prayag Tiwari', 'Erik Cambria']","Mental health is a critical issue in modern society, and mental disorders
could sometimes turn to suicidal ideation without adequate treatment. Early
detection of mental disorders and suicidal ideation from social content
provides a potential way for effective social intervention. Recent advances in
pretrained contextualized language representations have promoted the
development of several domain-specific pretrained models and facilitated
several downstream applications. However, there are no existing pretrained
language models for mental healthcare. This paper trains and release two
pretrained masked language models, i.e., MentalBERT and MentalRoBERTa, to
benefit machine learning for the mental healthcare research community. Besides,
we evaluate our trained domain-specific models and several variants of
pretrained language models on several mental disorder detection benchmarks and
demonstrate that language representations pretrained in the target domain
improve the performance of mental health detection tasks.",2021,http://arxiv.org/abs/2110.15621v1,http://arxiv.org/pdf/2110.15621v1,"MentalBERT:
Publicly Available Pretrained Language Models for Mental Healthcare

Shaoxiong Ji†, Tianlin Zhang‡, Luna Ansari†, Jie Fu§, Prayag Tiwari†, and Erik Cambria¶
† Aalto University, Finland ‡ The University of Manchester, UK
§ Mila, Québec AI Institute, Canada ¶ Nanyang Technological University, Singapore
{shaoxiong.ji; luna.ansari; prayag.tiwari}@aalto.fi
tianlin.zhang@postgrad.manchester.ac.uk

fujie@mila.quebec

cambria@ntu.edu.sg

Abstract

Mental health is a critical issue in modern so-
ciety, and mental disorders could sometimes
turn to suicidal ideation without adequate treat-
ment. Early detection of mental disorders and
suicidal ideation from social content provides
a potential way for effective social interven-
tion. Recent advances in pretrained contextual-
ized language representations have promoted
the development of several domain-speciﬁc
pretrained models and facilitated several down-
stream applications. However, there are no
existing pretrained language models for men-
tal healthcare. This paper trains and release
two pretrained masked language models, i.e.,
MentalBERT and MentalRoBERTa, to bene-
ﬁt machine learning for the mental healthcare
research community. Besides, we evaluate
our trained domain-speciﬁc models and sev-
eral variants of pretrained language models on
several mental disorder detection benchmarks
and demonstrate that language representations
pretrained in the target domain improve the
performance of mental health detection tasks.

1

Introduction

Mental health is a global issue, especially severe
in most developed countries and many emerging
markets. According to the mental health action
plan (2013 - 2020) from the World Health Organi-
zation, 1 in 4 people worldwide suffer from mental
disorders to some extent. Moreover, 3 out of 4
people with severe mental disorders do not receive
treatment, worsening the problem. During some
periods like the pandemic, people struggle with
mental health issues, and many may not get mental
health practitioners’ help. Previous studies reveal
that suicide risk usually has a connection to mental
disorders (Windfuhr and Kapur, 2011). Partly due
to severe mental disorders, 900,000 people com-
mit suicide each year worldwide, making suicide
the second most common cause of death among
the young. Suicide attempters have been reported

as suffering from mental disorders, with an inves-
tigation on a shift from mental health to suicidal
ideation conducted by language and interactional
measures (De Choudhury et al., 2016).

Early identiﬁcation is a practical approach to
mental illness and suicidal ideation prevention. Ex-
cept for traditional proactive screening, social me-
dia is a good channel for mental health care. Social
media platforms such as Reddit and Twitter provide
anonymous space for users to discuss stigmatic top-
ics and self-report personal issues. Social content
from users who wrote about mental health issues
and posted suicidal ideation has been widely used
to study mental health issues (e.g., Ji et al., 2018;
Tadesse et al., 2019). Machine learning-based de-
tection techniques can empower healthcare workers
in early detection and assessment to take an action
of proactive prevention.

Recent advances in deep learning facilitate the
development of effective early detection meth-
ods (Ji et al., 2021a). A new trend in natural lan-
guage processing (NLP), contextualized pretrained
language models, has attracted much attention for
various text processing tasks. The seminal work
on a pretrained language model called BERT (De-
vlin et al., 2019) utilizes bidirectional transformer-
based text encoders and trains the model on a large-
scale corpus. With the success of BERT, several
domain-speciﬁc pretrained language models for
learning text representations have also been devel-
oped and released, such as biomedical BERT (Lee
et al., 2020) and clinical BERT (Alsentzer et al.,
2019; Huang et al., 2019) for the biomedical and
clinical domain, respectively.

However, there are no pretrained language mod-
els customized for the domain of mental healthcare.
Our paper trains and releases two representative
bidirectional masked language models, i.e., BERT
and RoBERTa (Liu et al., 2019), with corpus col-
lected from social forums for mental health discus-
sion. The pretrained models in the mental health

1
2
0
2

t
c
O
9
2

]
L
C
.
s
c
[

1
v
1
2
6
5
1
.
0
1
1
2
:
v
i
X
r
a

 
 
 
 
 
 
domain are dubbed MentalBERT and Mental-
RoBERTa. To our best knowledge, this work is the
ﬁrst to pre-train language models for mental health-
care. Besides, we conduct a comprehensive eval-
uation on several mental health detection datasets
with pretrained language models in different do-
mains. We release the pretrained MentalBERTs
with Huggingface’s model repository, available at
https://huggingface.co/mental.

2 Methods and Setup

This section introduces the language model pre-
training technique and the pretraining corpus we
collected. We then present th"
"Opportunities in Mental Health Support for Informal Dementia Caregivers
  Suffering from Verbal Agitation","['Taewook Kim', 'Hyeok Kim', 'Angela Roberts', 'Maia Jacobs', 'Matthew Kay']","People with dementia (PwD) often present verbal agitation such as cursing,
screaming, and persistently complaining. Verbal agitation can impose mental
distress on informal caregivers (e.g., family, friends), which may cause severe
mental illnesses, such as depression and anxiety disorders. To improve informal
caregivers' mental health, we explore design opportunities by interviewing 11
informal caregivers suffering from verbal agitation of PwD. In particular, we
first characterize how the predictability of verbal agitation impacts informal
caregivers' mental health and how caregivers' coping strategies vary before,
during, and after verbal agitation. Based on our findings, we propose design
opportunities to improve the mental health of informal caregivers suffering
from verbal agitation: distracting PwD (in-situ support; before), prompting
just-in-time maneuvers (information support; during), and comfort and education
(social & information support; after). We discuss our reflections on cultural
disparities between participants. Our work envisions a broader design space for
supporting informal caregivers' well-being and describes when and how that
support could be provided.",2023,http://arxiv.org/abs/2311.10912v1,http://arxiv.org/pdf/2311.10912v1,"3
2
0
2

v
o
N
7
1

]

C
H
.
s
c
[

1
v
2
1
9
0
1
.
1
1
3
2
:
v
i
X
r
a

Opportunities in Mental Health Support for Informal
Dementia Caregivers Suﬀering from Verbal Agitation

TAEWOOK KIM, Northwestern University, USA
HYEOK KIM, Northwestern University, USA
ANGELA ROBERTS, University of Western Ontario, Canada
MAIA JACOBS, Northwestern University, USA
MATTHEW KAY, Northwestern University, USA

People with dementia (PwD) often present verbal agitation such as cursing, screaming, and persistently com-
plaining. Verbal agitation can impose mental distress on informal caregivers (e.g., family, friends), which
may cause severe mental illnesses, such as depression and anxiety disorders. To improve informal caregivers’
mental health, we explore design opportunities by interviewing 11 informal caregivers suﬀering from verbal
agitation of PwD. In particular, we ﬁrst characterize how the predictability of verbal agitation impacts in-
formal caregivers’ mental health and how caregivers’ coping strategies vary before, during, and after verbal
agitation. Based on our ﬁndings, we propose design opportunities to improve the mental health of informal
caregivers suﬀering from verbal agitation: distracting PwD (in-situ support; before), prompting just-in-time
maneuvers (information support; during), and comfort and education (social & information support; after).
We discuss our reﬂections on cultural disparities between participants. Our work envisions a broader design
space for supporting informal caregivers’ well-being and describes when and how that support could be
provided.
CCS Concepts: • Human-centered computing → Empirical studies in HCI.

Additional Key Words and Phrases: Informal caregivers, Mental health, People with dementia, Verbal agitation

1 INTRODUCTION

People with dementia (PwD) often exhibit verbal agitation, a major behavioral symptom of de-
mentia that includes screaming, swearing, and repeating phrases [9, 20, 88]. Verbal agitation is
more common for people in advanced stages of Alzheimer’s and vascular dementia [49, 83, 87, 97],
in conjunction with other psychological symptoms such as aggression and disinhibition [87, 89].
Such verbal agitation often causes signiﬁcant mental distress in caregivers [7, 44], which may im-
pede them from performing their essential care activities (e.g., changing a diaper, assisting with
eating).

Informal caregivers, such as family members, spouses, or friends, are a primary care source for
many PwD [28, 38, 79]. They often suﬀer from mental distress due to verbal agitation, impeding
their care responsibilities for PwD [34, 45, 82]. For instance, informal caregivers often experience
cursing or threats from PwD while providing daily personal care, such as changing diapers and

Authors’ addresses: Taewook Kim, taewook@u.northwestern.edu, Northwestern University, Evanston, IL, USA; Hyeok
Kim, hyeokkim2024@u.northwestern.edu, Northwestern University, Evanston, IL, USA; Angela Roberts, angela.roberts@
uwo.ca, University of Western Ontario, London, Ontario, Canada; Maia Jacobs, maia.jacobs@northwestern.edu, North-
western University, Evanston, IL, USA; Matthew Kay, mjskay@northwestern.edu, Northwestern University, Evanston, IL,
USA.

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and
the full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior speciﬁc permission and/or a fee. Request permissions from permissions@acm.org.
© 2023 Association for Computing Machinery.
XXXX-XXXX/2023/11-ART $15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn

, Vol. 1, No. 1, Article . Publication date: November 2023.

 
 
 
 
 
 
2

Taewook Kim, Hyeok Kim, Angela Roberts, Maia Jacobs, and Matthew Kay

brushing teeth [29, 86]. A substantial number of informal caregivers experience serious mental
health issues such as depression [19] and anxiety disorder [35, 50]. The poor mental health con-
ditions of informal caregivers impacted by verbal agitation can be a barrier to sustainable and
comprehensive care for their loved ones with dementia. In addition, many informal caregivers
lack access to helpful resources and professional education on dementia care practices, as they
are caregivers by necessity, not by training [77, 78]. Hence, exploring design opportunities for
informal caregivers to handle verbal agitation from PwD and manage their mental health is an
important step toward developing technological support to better sustain their care activities.

With this in mind, we interviewed 11 informal caregivers who suﬀer from verbal agitation of
PwD in South Korea and the USA. We asked them in what contexts they face verbal agitat"
"Financial technologies (FinTech) for mental health: The potential of
  objective financial data to better understand the relationships between
  financial behavior and mental health","['Johnna Blair', 'Jeff Brozena', 'Mark Matthews', 'Thomas Richardson', 'Saeed Abdullah']","In this paper, we present novel research methods for collecting and analyzing
personal financial data alongside mental health factors, illustrated through a
N=1 case study using data from one individual with bipolar disorder. While we
have not found statistically significant trends nor our findings are
generalizable beyond this case, our approach provides an insight into the
challenges of accessing objective financial data. We outline what data is
currently available, what can be done with it, and what factors to consider
when working with financial data. More specifically, using these methods
researchers might be able to identify symptomatic traces of mental ill health
in personal financial data such as identifying early warning signs and thereby
enable preemptive care for individuals with serious mental illnesses. Based on
this work, we have also explored future directions for developing interventions
to support financial wellbeing. Furthermore, we have described the technical,
ethical, and equity challenges for financial data-driven assessments and
intervention methods, as well as provided a broad research agenda to address
these challenges. By leveraging objective, personalized financial data in a
privacy-preserving and ethical manner help lead to a shift in mental health
care.",2022,http://arxiv.org/abs/2204.05448v4,http://arxiv.org/pdf/2204.05448v4,"3
2
0
2

n
a
J

9

]

C
H
.
s
c
[

4
v
8
4
4
5
0
.
4
0
2
2
:
v
i
X
r
a

Financial technologies (FinTech) for mental
health: The potential of objective ﬁnancial
data to better understand the relationships
between ﬁnancial behavior and mental health
Johnna Blair 1,∗, Jeff Brozena 1, Mark Matthews 2, Thomas Richardson 3 and
Saeed Abdullah 1
1Penn State University, PA, USA
2University College Dublin, Ireland
3University of Southampton, UK
Correspondence*:
Johnna Blair
jlb883@psu.edu

ABSTRACT

Financial stability is a key challenge for individuals with mental illnesses. Symptomatic periods
often manifest
in poor ﬁnancial decision-making including compulsive spending and risky
behaviors. This article explores research opportunities and challenges in developing ﬁnancial
technologies (FinTech) to support individuals with mental health. Speciﬁcally, we focus on
how objective ﬁnancial data might lead to novel mental health assessment and intervention
methods. We have used data from one individual with bipolar disorder (i.e., an N=1 case study)
to illustrate feasibility of collecting and analyzing objective ﬁnancial data alongside mental health
factors. While we have not found statistically signiﬁcant trends nor our ﬁndings are generalizable
beyond this case, our approach provides an insight into the potential of using objective ﬁnancial
data to identify early warning signs and thereby, enable preemptive care for individuals with
serious mental illnesses. We have also identiﬁed challenges of accessing objective ﬁnancial
data. The paper outlines what data is currently available, what can be done with it, and what
factors to consider when working with ﬁnancial data. We have also explored future directions
for developing interventions to support ﬁnancial wellbeing and stability. Furthermore, we have
described the technical, ethical, and equity challenges for ﬁnancial data-driven assessments and
intervention methods, as well as provided a broad research agenda to address these challenges.

Keywords: Mental Health, Financial technologies, FinTech, Open banking, Intervention, Impulsive spending, Privacy preserving

1 INTRODUCTION

Mental illness is a serious public health crisis on a global scale. It affects more than one billion individuals
(1). This results in signiﬁcant economic consequences, with an estimated total annual cost of $2.5
trillion globally (1). This growing issue impacts many facets of daily life, including a strong association
between mental health and ﬁnancial instability. Individuals with mental health issues are more likely to
live in relative poverty (2, 3). Symptoms of some illnesses can also manifest in poor ﬁnancial decision

1

 
 
 
 
 
 
Blair et al.

FinTech for mental health

making. More speciﬁcally, bipolar disorder (BD) appears to be linked with greater risk of impulsive
ﬁnancial behaviors—The diagnostic criteria for hypomanic and manic episodes speciﬁcally lists impulsive
spending as possible symptoms (4). Those with BD are at greater risk of problem gambling (5), and 71%
report impulsive spending whilst hypomanic (6). This impulsive spending has also been shown to be
linked to negative feelings and subsequent comfort spending (7, 8). As this illustrates, there is often a
cyclical and bidirectional relationship between ﬁnancial stability and mental health—ﬁnancial instability
can worsen mental health, which in turn, can cause further ﬁnancial challenges, leading to a vicious cycle
(9, 10, 7, 8).

The lack of access to objective ﬁnancial data has been a key challenge in understanding the nuanced
relationship between mental health and ﬁnancial behaviors. Prior studies have mostly used surveys (2)
and focus group interviews (10) to assess ﬁnancial behaviors associated with serious mental illnesses.
This means that much of what we know about this relationship is mediated through subjective methods
that may be prone to bias and retrospective recall error. For example, Richardson et al. (8) measured
self-reported compulsive spending in Bipolar Disorder, rather than objective data on spending patterns.
While this provides a useful broad overview, there remains a knowledge gap regarding how idiosyncratic,
context-driven, and illness-speciﬁc factors impact ﬁnancial decision making and stability of an individual
living with mental illness. Furthermore, the lack of granular, in-situ assessment methods is a key barrier
against developing just-in-time, adaptive, and personalized interventions focusing on ﬁnancial stability
for this population. Given the importance of ﬁnancial wellbeing for mental health, this remains a serious
knowledge gap with broad practical implications.

In recent years, there has been considerable progress toward more open and accessible ﬁnancial data.
Financial institutes are increasingly adopting open banking application programming interface (API)
mandating access to accounts, payments, and transactions. There have also been third-party tools and
platforms (e.g., Plaid (11)) "
Multi-Task Learning for Mental Health using Social Media Text,"['Adrian Benton', 'Margaret Mitchell', 'Dirk Hovy']","We introduce initial groundwork for estimating suicide risk and mental health
in a deep learning framework. By modeling multiple conditions, the system
learns to make predictions about suicide risk and mental health at a low false
positive rate. Conditions are modeled as tasks in a multi-task learning (MTL)
framework, with gender prediction as an additional auxiliary task. We
demonstrate the effectiveness of multi-task learning by comparison to a
well-tuned single-task baseline with the same number of parameters. Our best
MTL model predicts potential suicide attempt, as well as the presence of
atypical mental health, with AUC > 0.8. We also find additional large
improvements using multi-task learning on mental health tasks with limited
training data.",2017,http://arxiv.org/abs/1712.03538v1,http://arxiv.org/pdf/1712.03538v1,"Multi-Task Learning for Mental Health
using Social Media Text

Adrian Benton
Johns Hopkins University
adrian@cs.jhu.edu

Margaret Mitchell
Microsoft Research∗
mmitchellai@google.com

Dirk Hovy
University of Copenhagen
mail@dirkhovy.com

7
1
0
2
c
e
D
0
1

]
L
C
.
s
c
[

1
v
8
3
5
3
0
.
2
1
7
1
:
v
i
X
r
a

Abstract

We introduce initial groundwork for esti-
mating suicide risk and mental health in
a deep learning framework. By model-
ing multiple conditions, the system learns
to make predictions about suicide risk and
mental health at a low false positive rate.
Conditions are modeled as tasks in a multi-
task learning (MTL) framework, with gen-
der prediction as an additional auxiliary
task. We demonstrate the effectiveness
of multi-task learning by comparison to
a well-tuned single-task baseline with the
same number of parameters. Our best
MTL model predicts potential suicide at-
tempt, as well as the presence of atypical
mental health, with AUC > 0.8. We also
ﬁnd additional large improvements using
multi-task learning on mental health tasks
with limited training data.

1

Introduction

Suicide is one of the leading causes of death
worldwide, and over 90% of individuals who die
by suicide experience mental health conditions.1
However, detecting the risk of suicide, as well
as monitoring the effects of related mental health
conditions, is challenging. Traditional methods
rely on both self-reports and impressions formed
during short sessions with a clinical expert, but it is
often unclear when suicide is a risk in particular.2
Consequently, conditions leading to preventable
suicides are often not adequately addressed.

∗Now at Google Research.
1https://www.nami.org/Learn-

More/Mental-Health-Conditions/Related-
Conditions/Suicide#sthash.dMAhrKTU.dpuf

2Communication with clinicians at the 2016 JSALT work-

shop (Hollingshead, 2016).

Automated monitoring and risk assessment of
patients’ language has the potential to complement
traditional assessment methods, providing objec-
tive measurements to motivate further care and ad-
ditional support for people with difﬁculties related
to mental health. This paves the way towards ver-
ifying the need for additional care with insurance
coverage, for example, as well as offering direct
beneﬁts to clinicians and patients.

We explore some of the possibilities in the deep
learning and mental health space using written so-
cial media text that people with different mental
health conditions are already producing. Uncov-
ering methods that work with such text provides
the opportunity to help people with different men-
tal health conditions by leveraging a task they are
already participating in.

Social media text carries implicit information
about the author, which has been modeled in nat-
ural language processing (NLP) to predict au-
thor characteristics such as age (Goswami et al.,
2009; Rosenthal and McKeown, 2011; Nguyen
et al., 2014), gender (Sarawgi et al., 2011; Ciot
et al., 2013; Liu and Ruths, 2013; Volkova et
al., 2015; Hovy, 2015), personality (Schwartz
et al., 2013; Volkova et al., 2014; Plank and
Hovy, 2015; Park et al., 2015; Preot¸iuc-Pietro et
al., 2015), and occupation (Preotiuc-Pietro et al.,
2015). Similar text signals have been effectively
used to predict mental health conditions such as
depression (De Choudhury et al., 2013; Copper-
smith et al., 2015b; Schwartz et al., 2014), suici-
dal ideation (Coppersmith et al., 2016; Huang et
al., 2015), schizophrenia (Mitchell et al., 2015) or
post-traumatic stress disorder (PTSD) (Pedersen,
2015).

However, these studies typically model each
condition in isolation, which misses the op-
portunity to model coinciding inﬂuence factors.
Tasks with underlying commonalities (e.g., part-

 
 
 
 
 
 
of-speech tagging, parsing, and NER) have been
shown to beneﬁt from multi-task learning (MTL),
as the learning implicitly leverages interactions
between them (Caruana, 1993; Sutton et al., 2007;
Rush et al., 2010; Collobert et al., 2011; Søgaard
and Goldberg, 2016). Suicide risk and related
mental health conditions are therefore good can-
didates for modeling in a multi-task framework.

In this paper, we propose multi-task learning
for detecting suicide risk and mental health condi-
tions. The tasks of our model include neuroatypi-
cality (i.e., atypical mental health) and suicide at-
tempt, as well as the related mental health condi-
tions of anxiety, depression, eating disorder, panic
attacks, schizophrenia, bipolar disorder, and post-
traumatic stress disorder (PTSD), and we explore
the effect of task selection on model performance.
We additionally include the effect of modeling
gender, which has been shown to improve accu-
racy in tasks using social media text (Volkova et
al., 2013; Hovy, 2015).

Predicting suicide risk and several mental health
conditions jointly opens the possibility for the
to leverage a shared representation for
model
conditions that frequently occur together, a phe-
nomenon known as comorbidity. "
"Can We Assess Mental Health through Social Media and Smart Devices?
  Addressing Bias in Methodology and Evaluation","['Adam Tsakalidis', 'Maria Liakata', 'Theo Damoulas', 'Alexandra I. Cristea']","Predicting mental health from smartphone and social media data on a
longitudinal basis has recently attracted great interest, with very promising
results being reported across many studies. Such approaches have the potential
to revolutionise mental health assessment, if their development and evaluation
follows a real world deployment setting. In this work we take a closer look at
state-of-the-art approaches, using different mental health datasets and
indicators, different feature sources and multiple simulations, in order to
assess their ability to generalise. We demonstrate that under a pragmatic
evaluation framework, none of the approaches deliver or even approach the
reported performances. In fact, we show that current state-of-the-art
approaches can barely outperform the most na\""ive baselines in the real-world
setting, posing serious questions not only about their deployment ability, but
also about the contribution of the derived features for the mental health
assessment task and how to make better use of such data in the future.",2018,http://arxiv.org/abs/1807.07351v1,http://arxiv.org/pdf/1807.07351v1,"8
1
0
2

l
u
J

9
1

]

Y
C
.
s
c
[

1
v
1
5
3
7
0
.
7
0
8
1
:
v
i
X
r
a

Can We Assess Mental Health through Social
Media and Smart Devices? Addressing Bias in
Methodology and Evaluation

Adam Tsakalidis1,2, Maria Liakata1,2, Theo Damoulas1,2, and Alexandra I.
Cristea1,3

1 University of Warwick, UK
{a.tsakalidis, m.liakata, t.damoulas, a.i.cristea}@warwick.ac.uk
2 The Alan Turing Institute, UK
3 Durham University, UK

Abstract. Predicting mental health from smartphone and social media
data on a longitudinal basis has recently attracted great interest, with
very promising results being reported across many studies [3,9,13,26].
Such approaches have the potential to revolutionise mental health as-
sessment, if their development and evaluation follows a real world de-
ployment setting. In this work we take a closer look at state-of-the-art
approaches, using diﬀerent mental health datasets and indicators, dif-
ferent feature sources and multiple simulations, in order to assess their
ability to generalise. We demonstrate that under a pragmatic evaluation
framework, none of the approaches deliver or even approach the reported
performances. In fact, we show that current state-of-the-art approaches
can barely outperform the most na¨ıve baselines in the real-world setting,
posing serious questions not only about their deployment ability, but
also about the contribution of the derived features for the mental health
assessment task and how to make better use of such data in the future.

Keywords: mental health · bias · evaluation · wellbeing · natural lan-
guage processing · smartphones · sensors · social media

1

Introduction

Establishing the right indicators of mental well-being is a grand challenge posed
by the World Health Organisation [7]. Poor mental health is highly correlated
with low motivation, lack of satisfaction, low productivity and a negative eco-
nomic impact [20]. The current approach is to combine census data at the pop-
ulation level [19], thus failing to capture well-being on an individual basis. The
latter is only possible via self-reporting on the basis of established psychological
scales, which are hard to acquire consistently on a longitudinal basis, and they
capture long-term aggregates instead of the current state of the individual.

The widespread use of smart-phones and social media oﬀers new ways of
assessing mental well-being, and recent research [1,2,3,5,9,10,13,14,22,23,26] has
started exploring the eﬀectiveness of these modalities for automatically assessing

 
 
 
 
 
 
2

A. Tsakalidis et al.

the mental health of a subject, reporting very high accuracy. What is typically
done in these studies is to use features based on the subjects’ smart phone
logs and social media, to predict some self-reported mental health index (e.g.,
“wellbeing”, “depression” and others), which is provided either on a Likert scale
or on the basis of a psychological questionnaire (e.g., PHQ-8 [12], PANAS [29],
WEMWBS [25] and others).

Most of these studies are longitudinal, where data about individuals is col-
lected over a period of time and predictions of mental health are made over a
sliding time window. Having such longitudinal studies is highly desirable, as it
can allow ﬁne-grained monitoring of mental health. However, a crucial question
is what constitutes an appropriate evaluation framework, in order for such ap-
proaches to be employable in a real world setting. Generalisation to previously
unobserved users can only be assessed via leave-N-users-out cross-validation se-
tups, where typically, N is equal to one (LOUOCV, see Table 1). However,
due to the small number of subjects that are available, such generalisation is
hard to achieve by any approach [13]. Alternatively, personalised models [3,13]
for every individual can be evaluated via a within-subject, leave-N-instances-out
cross-validation (for N=1, LOIOCV), where an instance for a user u at time i
is deﬁned as a {Xui, yui} tuple of {features(u, i), mental-health-score(u, i)}. In a
real world setting, a LOIOCV model is trained on some user-speciﬁc instances,
aiming to predict her mental health state at some future time points. Again how-
ever, the limited number of instances for every user make such models unable to
generalize well. In order to overcome these issues, previous work [2,5,9,10,22,26]
has combined the instances {Xuj i, yuj i} from diﬀerent individuals uj and per-
formed evaluation using randomised cross validation (MIXED). While such
approaches can attain optimistic performance, the corresponding models fail to
generalise to the general population and also fail to ensure eﬀective personalised
assessment of the mental health state of a single individual.

LOUOCV
Build a model m that
generalises to a previ-
ously unseen user u

Real
world
aim
Train {{X(cid:54)ui, y(cid:54)ui}}
Test

{Xui, yui}
Few users for training
and evaluation

Limits

LOIOCV
Build a personalised model mu per
user u that generalises on u, given
some manual inp"
"Smartphone app to investigate the relationship between social
  connectivity and mental health","['Tjeerd W. Boonstra', 'Aliza Werner-Seidler', ""Bridianne O'Dea"", 'Mark E. Larsen', 'Helen Christensen']","Interpersonal relationships are necessary for successful daily functioning
and wellbeing. Numerous studies have demonstrated the importance of social
connectivity for mental health, both through direct peer-to-peer influence and
by the location of individuals within their social network. Passive monitoring
using smartphones provides an advanced tool to map social networks based on the
proximity between individuals. This study investigates the feasibility of using
a smartphone app to measure and assess the relationship between social network
metrics and mental health. The app collected Bluetooth and mental health data
in 63 participants. Social networks of proximity were estimated from Bluetooth
data and 95% of the edges were scanned at least every 30 minutes. The majority
of participants found this method of data collection acceptable and reported
that they would be likely to participate in future studies using this app.
These findings demonstrate the feasibility of using a smartphone app that
participants can install on their own phone to investigate the relationship
between social connectivity and mental health.",2017,http://arxiv.org/abs/1702.02644v2,http://arxiv.org/pdf/1702.02644v2,"Smartphone App to Investigate the Relationship between Social 
Connectivity and Mental Health* 

Tjeerd W. Boonstra, Aliza Werner-Seidler, Bridianne O'Dea, Mark E. Larsen, and Helen Christensen 

Abstract—  Interpersonal  relationships  are  necessary  for 
successful  daily  functioning  and  wellbeing.  Numerous  studies 
have  demonstrated  the  importance  of  social  connectivity  for 
mental  health,  both  through  direct  peer-to-peer  influence  and 
by  the  location  of  individuals  within  their  social  network. 
Passive  monitoring  using  smartphones  provides  an  advanced 
tool  to  map  social  networks  based  on  the  proximity  between 
individuals.  This  study  investigates  the  feasibility  of  using  a 
smartphone  app  to  measure  and  assess  the  relationship 
between  social  network  metrics  and  mental  health.  The  app 
collected  Bluetooth  and  mental  health  data  in  63  participants. 
Social  networks  of  proximity  were  estimated  from  Bluetooth 
data  and  95%  of  the  edges  were  scanned  at  least  every  30 
minutes.  The  majority  of  participants  found  this  method  of 
data  collection  acceptable  and  reported  that  they  would  be 
likely  to  participate  in  future  studies  using  this  app.  These 
findings demonstrate the feasibility of using a smartphone app 
that  participants  can  install  on  their  own  phone  to  investigate 
the relationship between social connectivity and mental health. 

I.  INTRODUCTION 

Social  connections  are  critically  important  to  health  and 
wellbeing,  with  numerous  studies  finding  that  aspects  of 
social  connection  affect  morbidity  and  mortality  at  levels 
comparable  to  smoking  and  obesity  [1].  Social  connectivity 
also shares an important and specific relationship with mental 
health,  with  studies  showing  that  individuals  who  have 
smaller  networks,  fewer  interpersonal  relationships  or  lower 
levels  of  social  support  consistently  report  elevated  rates  of 
depression  [2,  3].  Furthermore,  a  significant  proportion  of 
those who die by suicide have a history of social isolation [4].  

Although  both  prospective  and  cross-sectional  studies 
have  been  conducted  to  investigate  the  association  between 
social  network  factors  and  mental  illness,  these  studies  rely 
primarily  on  questionnaire  data.  Studies  have  typically 
depended  on  an  array  of  self-report  indices,  such  as  name 
generators  (identifying  who  is  in  one’s  social  network), 
number  of  friends,  frequency  of  participation  in  social 
activity, and whether someone is living alone or not, in order 
to  identify  the  size  and  nature  of  social  networks  [5,  6]. 
However,  these  measures  are  limited  by  the  nature  of  self-
report  –  which  is  inherently  vulnerable  to  confounding  and 
systematic  bias  [7].  These  methods  are  also  practically 

*  Research  supported  by  the  NHMRC  Centre  of  Research  Excellence  in 
Suicide  Prevention  APP1042580  and  NHMRC  John  Cade  Fellowship 
APP1056964.  B.  O’Dea  and  M.  E.  Larsen  are  supported  by  Society  of 
Mental Health 2015 Early Career Research Awards. 

 T.  W.  Boonstra,  A.  Werner-Seidler,  B.  O'Dea,  M.  E.  Larsen,  H. 
Christensen  are  with  the  Black  Dog  Institute,  University  of  New  South 
Wales,  Sydney,  NSW  2031,  Australia.  T.  W.  Boonstra  is  also  with  QIMR 
Institute,  Brisbane,  Australia.  Email: 
Berghofer  Medial  Research 
t.boonstra@unsw.edu, 
mark.larsen, 
b.odea, 
h.christensen}@blackdog.org.au.  

{a.werner-seidler, 

limited  by  the  time  and  effort  required  to  administer  and 
process  such  data.  This  can  severely  impede  the  extent  to 
which  certain  populations,  communities,  and  individual 
networks  can  be  studied.  New  technologies  are  needed  to 
advance the field of social network analysis. 

Sensor-enabled  mobile  phones  have  recently  been  tested 
as  a  method  to  measure  the  proximity  between  participants 
and  map  face-to-face  interactions,  with  evidence  showing 
that  proximity  is  a  valid  metric  of  social  connections  [8]. 
Social connections can be accurately deduced from proximity 
by  distinguishing  typical  proximal  behavioral  patterns  (for 
example,  proximity  to  colleagues  at  work  during  the  day) 
from  other  behaviors  (proximity 
to  others  outside  of 
workplace).  However,  this  technology  has  been  limited  by 
several  factors.  First,  Bluetooth  data  has  only  been  captured 
on Nokia smartphones [8] or those with an Android operating 
system  [9].  As  such,  this  technology  is  not  available  to  the 
estimated  700  million  iPhone  users  who  rely  on  the  iOS 
operating system. Second, past studies involved pre-installing 
the  application  on  a  device  that  was  then  distributed  to 
participants for the duration of the study [10, 11]. "
"Hashtag Healthcare: From Tweets to Mental Health Journals Using Deep
  Transfer Learning","['Benjamin Shickel', 'Martin Heesacker', 'Sherry Benton', 'Parisa Rashidi']","As the popularity of social media platforms continues to rise, an
ever-increasing amount of human communication and self- expression takes place
online. Most recent research has focused on mining social media for public user
opinion about external entities such as product reviews or sentiment towards
political news. However, less attention has been paid to analyzing users'
internalized thoughts and emotions from a mental health perspective. In this
paper, we quantify the semantic difference between public Tweets and private
mental health journals used in online cognitive behavioral therapy. We will use
deep transfer learning techniques for analyzing the semantic gap between the
two domains. We show that for the task of emotional valence prediction, social
media can be successfully harnessed to create more accurate, robust, and
personalized mental health models. Our results suggest that the semantic gap
between public and private self-expression is small, and that utilizing the
abundance of available social media is one way to overcome the small sample
sizes of mental health data, which are commonly limited by availability and
privacy concerns.",2017,http://arxiv.org/abs/1708.01372v1,http://arxiv.org/pdf/1708.01372v1,"7
1
0
2

g
u
A
4

]
L
C
.
s
c
[

1
v
2
7
3
1
0
.
8
0
7
1
:
v
i
X
r
a

HashtagHealthcare:FromTweetstoMentalHealthJournalsUsingDeepTransferLearningBenjaminShickel1,a,MartinHeesacker2,b,SherryBenton3,c,andParisaRashidi4,d1DepartmentofComputerandInformationScienceandEngineering,UniversityofFlorida,Gainesville,FL,32611,USA2DepartmentofPsychology,UniversityofFlorida,Gainesville,FL,32611,USA3TAOConnect,Inc.,St.Petersburg,FL,33701,USA4DepartmentofBiomedicalEngineering,UniversityofFlorida,Gainesville,FL,32611,USAashickelb@uﬂ.edubheesack@uﬂ.educsherry.benton@taoconnect.orgdparisa.rashidi@uﬂ.eduABSTRACTAsthepopularityofsocialmediaplatformscontinuestorise,anever-increasingamountofhumancommunicationandself-expressiontakesplaceonline.Mostrecentresearchhasfocusedonminingsocialmediaforpublicuseropinionaboutexternalentitiessuchasproductreviewsorsentimenttowardspoliticalnews.However,lessattentionhasbeenpaidtoanalyzingusers’internalizedthoughtsandemotionsfromamentalhealthperspective.Inthispaper,wequantifythesemanticdifferencebetweenpublicTweetsandprivatementalhealthjournalsusedinonlinecognitivebehavioraltherapy.Wewillusedeeptransferlearningtechniquesforanalyzingthesemanticgapbetweenthetwodomains.Weshowthatforthetaskofemotionalvalenceprediction,socialmediacanbesuccessfullyharnessedtocreatemoreaccurate,robust,andpersonalizedmentalhealthmodels.Ourresultssuggestthatthesemanticgapbetweenpublicandprivateself-expressionissmall,andthatutilizingtheabundanceofavailablesocialmediaisonewaytoovercomethesmallsamplesizesofmentalhealthdata,whicharecommonlylimitedbyavailabilityandprivacyconcerns.IntroductionSentimentanalysis,thetaskreferringtotheautomaticdeterminationofuseropinionfromtext,hasreceivedincreasedattentioninthepastdecade1–5.Muchofthesuccessofsentimentanalysistechniquescanbeattributedtotheriseofsocialmediaplatforms,wheremillionsofuserssharetheiropinionsonawidevarietyofsubjects.Themajorityofsentimentanalysismethodsareaimedataggregatingopinionstowardsentitieslikemovies,people,products,orcompanies.Werefertothiswell-knownresearchareaasexternalsentimentanalysis,inwhichsentimentandtextualpolarityiscalculatedwithrespecttoaspeciﬁcexternalentity.Incontrast,wedeﬁneinternalsentimentanalysisasthestudyofthepolarityofusertextwithrespecttothemselves,primarilyconcernedwithstatementsofemotionandmentalhealth6.Inthispaper,wedealstrictlywithinternalsentimentanalysis,speciﬁcallywiththevalencepredictionofprivatejournalsinamentalhealththerapysetting.Ourworkpartlyalignswithpreviousresearchregardingemotiondetectionintext7–12,asubtaskoftheﬁeldofaffectivecomputingandanalysis,butunlikepreviouswork,wefocusontheexpansionofvalencecategoriesinamentalhealthsetting.Oneusefulapplicationdomainofautomatedinternalsentimentanalysisframeworksistheburgeoningﬁeldofonlinementalhealththerapyservices13–23.Theseprogramsprovidethepatienteducationcomponentsinherentincognitivebehavioraltherapy(CBT).PracticeidentifyingandchangingunhelpfulthoughtpatternsorcognitivedistortionsisacentralpartofCBT.Ongoingpracticewithfeedbackcanincreasepatients’abilitytoaccuratelyidentifymorehelpfulandlesshelpfulthoughts,butupuntilnow,ongoingfeedbackhasbeendifﬁculttoprovide.Aspartofonlinetreatment,userstypicallysubmitseveraldirectedjournalsfordocumentingtheirdailythoughtsandfeelingsastheyimprovetheirmentalwell-beingusingself-directedstrategiestaughtaspartoftherapy.Anaccurateandvalidatedsystemforautomaticallycategorizingusertexthasobviousbeneﬁtstosuchatherapyservice,suchasﬂaggingtextwhichmaybeanearlywarningforsuiciderisk,providingapositiveandalways-availablefeedbackforpatientswithdistortedthinking,orsimplyprovidingenhancedandmoreﬁne-grainedanalysisofoverallpatientwell-being.Traditionalsentimentanalysisinvolvesdetectingwhetheragiventextfragmentissubjectiveorobjective,andinthecaseofsubjectivity,classiﬁesthetextaseitherpositiveornegative.Whilecertainlythemoststraightforwarddesignforexternalopinionmining,wetakethisanalysisastepfurtherformentalhealthpolarity.Ratherthanframingthesubjectivityidentiﬁcation 
 
 
 
 
 
taskasabinaryclassiﬁcationbetweenpositivityandnegativity,weintroducetwoadditionalclassesofpolarity:bothpositiveandnegative,andneitherpositivenornegative.Wemadethisdecisionbasedonpsychologicalresearch,whichsuggestsemotionscannotberepresentedonasingleaxisofvalence24–28.Thus,textclassiﬁedasneutralusingtraditionalframeworkswould,usingournewannotationscheme,fallintoeitherofthetwoaugmentedclasses.Unfortunately,publicly-availablementalhealthdatasetssuitableformachinelearning-basedinternalsentimentanalysisarefewandfarbetween.However,largeamountsofsocialmediatexthavebecomeavailableinrecentyears,andseveralstudieshaveexaminedtraditionalsentimentanalysisinthecontextofsocialmediaplatformssuchasTwitter?,29–34.Givensocialmediausers’tendencytowardsself-expression,wehypothesizethatthesocialmediadomainisquitesimilartothementalhealthdomainwithregardstotextuallanguagemodelingandclassiﬁcation,andcanbeusedtohelptrainmentalhealthmodelsandsystems.Wequantifythesimilaritybetweenthetwodomainsusingamachinelearningtechniquekn"
Quantifying the Effects of COVID-19 on Mental Health Support Forums,"['Laura Biester', 'Katie Matton', 'Janarthanan Rajendran', 'Emily Mower Provost', 'Rada Mihalcea']","The COVID-19 pandemic, like many of the disease outbreaks that have preceded
it, is likely to have a profound effect on mental health. Understanding its
impact can inform strategies for mitigating negative consequences. In this
work, we seek to better understand the effects of COVID-19 on mental health by
examining discussions within mental health support communities on Reddit.
First, we quantify the rate at which COVID-19 is discussed in each community,
or subreddit, in order to understand levels of preoccupation with the pandemic.
Next, we examine the volume of activity in order to determine whether the
quantity of people seeking online mental health support has risen. Finally, we
analyze how COVID-19 has influenced language use and topics of discussion
within each subreddit.",2020,http://arxiv.org/abs/2009.04008v1,http://arxiv.org/pdf/2009.04008v1,"Quantifying the Effects of COVID-19 on Mental Health Support Forums

Laura Biester∗, Katie Matton∗, Janarthanan Rajendran,
Emily Mower Provost, Rada Mihalcea
Computer Science & Engineering, University of Michigan, USA
{lbiester,katiemat,rjana,emilykmp,mihalcea}@umich.edu

0
2
0
2

p
e
S
8

]
L
C
.
s
c
[

1
v
8
0
0
4
0
.
9
0
0
2
:
v
i
X
r
a

Abstract

The COVID-19 pandemic, like many of the
disease outbreaks that have preceded it,
is
likely to have a profound effect on men-
tal health. Understanding its impact can in-
form strategies for mitigating negative conse-
quences.
In this work, we seek to better un-
derstand the effects of COVID-19 on mental
health by examining discussions within mental
health support communities on Reddit. First,
we quantify the rate at which COVID-19 is
discussed in each community, or subreddit, in
order to understand levels of preoccupation
with the pandemic. Next, we examine the vol-
ume of activity in order to determine whether
the quantity of people seeking online mental
health support has risen. Finally, we analyze
how COVID-19 has inﬂuenced language use
and topics of discussion within each subreddit.

1

Introduction

The implications of COVID-19 extend far beyond
its immediate physical health effects. Uncertainty
and fear surrounding the disease and its effects, in
addition to a lack of consistent and reliable infor-
mation, contribute to rising levels of anxiety and
stress (Torales et al., 2020). Policies designed to
help contain the disease also have signiﬁcant conse-
quences. Social distancing policies and lockdowns
lead to increased feelings of isolation and uncer-
tainty (Huremovi´c, 2019). They have also triggered
an economic downturn (ahin et al., 2020), resulting
in soaring unemployment rates and causing many
to experience ﬁnancial stress. Therefore, in ad-
dition to the profound effects on physical health
around the world, psychiatrists have warned that
we should also brace for a mental health crisis as a
result of the pandemic (Qiu et al., 2020; Greenberg
et al., 2020; Yao et al., 2020; Torales et al., 2020).

∗Denotes equal contribution.

Indeed, the literature on the impact of past epi-
demics indicates that they are associated with a
myriad of adverse mental health effects. In a re-
view of studies on the 2002-2003 SARS outbreak,
the 2009 H1N1 inﬂuenza outbreak, and the 2018
Ebola outbreak, Chew et al. (2020) found that
anxiety, fear, depression, anger, guilt, grief, and
post-traumatic stress were all commonly observed
psychological responses. Furthermore, many of
the factors commonly cited for inducing these re-
sponses are applicable to the situation with COVID-
19; these include: fear of contracting the disease,
a disruption in daily routines, isolation related to
being quarantined, and uncertainty regarding the
disease treatment process and outcomes, the well
being of loved ones, and one’s economic situation.
While disease outbreaks pose a risk to the men-
tal health of the general population, research sug-
gests that this risk is heightened for those with pre-
existing mental health concerns. People with men-
tal health disorders are particularly susceptible to
experiencing negative mental health consequences
during times of social isolation (Usher et al., 2020).
Further, as Yao et al. (2020) warns, they are likely
to have a stronger emotional response to the feel-
ings of fear, anxiety, and depression that come
along with COVID-19 than the general population.
Given the potential for the COVID-19 outbreak
to have devastating consequences for mental health,
it is critical that we work to understand and miti-
gate its negative psychological effects. In this work,
we use Reddit, a popular social media platform, to
study how COVID-19 has impacted the behavior
of people who express mental health concerns. We
focus on three Reddit sub-forums, referred to as
subreddits, that are designed to offer peer support
for users who are struggling with speciﬁc types of
mental illness. We ﬁrst measure changes in the
amount of activity on these subreddits to determine
whether, for a subset of the population, the need for

 
 
 
 
 
 
online mental health support has increased or de-
creased. We then analyze the content of subreddit
discussions, gaining insight into how the pandemic
affects what people choose to discuss when seek-
ing support and what types of issues push people
to seek support. Our ﬁndings provide insights into
how and when COVID-19 related stressors affect
people dealing with mental health concerns. Criti-
cally, we believe that this information can help to
better understand the nature of a potential COVID-
19 related mental health crisis.

2 Related Work

2.1 Studying Mental Health via Social Media

In the past decade, social media has emerged as
a powerful tool for understanding human behav-
ior, and correspondingly mental health. A grow-
ing number of studies have applied computational
methods to data collected from social media plat-
forms in order to "
"A Computational Approach to Understanding Empathy Expressed in
  Text-Based Mental Health Support","['Ashish Sharma', 'Adam S. Miner', 'David C. Atkins', 'Tim Althoff']","Empathy is critical to successful mental health support. Empathy measurement
has predominantly occurred in synchronous, face-to-face settings, and may not
translate to asynchronous, text-based contexts. Because millions of people use
text-based platforms for mental health support, understanding empathy in these
contexts is crucial. In this work, we present a computational approach to
understanding how empathy is expressed in online mental health platforms. We
develop a novel unifying theoretically-grounded framework for characterizing
the communication of empathy in text-based conversations. We collect and share
a corpus of 10k (post, response) pairs annotated using this empathy framework
with supporting evidence for annotations (rationales). We develop a multi-task
RoBERTa-based bi-encoder model for identifying empathy in conversations and
extracting rationales underlying its predictions. Experiments demonstrate that
our approach can effectively identify empathic conversations. We further apply
this model to analyze 235k mental health interactions and show that users do
not self-learn empathy over time, revealing opportunities for empathy training
and feedback.",2020,http://arxiv.org/abs/2009.08441v1,http://arxiv.org/pdf/2009.08441v1,
On the State of Social Media Data for Mental Health Research,"['Keith Harrigian', 'Carlos Aguirre', 'Mark Dredze']","Data-driven methods for mental health treatment and surveillance have become
a major focus in computational science research in the last decade. However,
progress in the domain, in terms of both medical understanding and system
performance, remains bounded by the availability of adequate data. Prior
systematic reviews have not necessarily made it possible to measure the degree
to which data-related challenges have affected research progress. In this
paper, we offer an analysis specifically on the state of social media data that
exists for conducting mental health research. We do so by introducing an
open-source directory of mental health datasets, annotated using a standardized
schema to facilitate meta-analysis.",2020,http://arxiv.org/abs/2011.05233v2,http://arxiv.org/pdf/2011.05233v2,"On the State of Social Media Data for Mental Health Research

Keith Harrigian, Carlos Aguirre, Mark Dredze
Johns Hopkins University
kharrigian@jhu.edu, caguirr4@jhu.edu, mdredze@cs.jhu.edu

1
2
0
2

r
p
A
5
2

]
L
C
.
s
c
[

2
v
3
3
2
5
0
.
1
1
0
2
:
v
i
X
r
a

Abstract

Data-driven methods for mental health treat-
ment and surveillance have become a major
focus in computational science research in the
last decade. However, progress in the do-
main remains bounded by the availability of
adequate data. Prior systematic reviews have
not necessarily made it possible to measure
the degree to which data-related challenges
have affected research progress. In this paper,
we offer an analysis speciﬁcally on the state
of social media data that exists for conduct-
ing mental health research. We do so by in-
troducing an open-source directory of mental
health datasets, annotated using a standardized
schema to facilitate meta-analysis.1

1

Introduction

The last decade has seen exponential growth
in computational research devoted to modeling
mental health phenomena using non-clinical data
(Bucci et al., 2019). Studies analyzing data from
the web, such as social media platforms and peer-
to-peer messaging services, have been particularly
appealing to the research community due to their
scale and deep entrenchment within contemporary
culture (Perrin, 2015; Fuchs, 2015; Graham et al.,
2015). Such studies have yielded novel insights
into population-level mental health (De Choudhury
et al., 2013; Amir et al., 2019a) and shown promis-
ing avenues for the incorporation of data-driven
analyses in the treatment of psychiatric disorders
(Eichstaedt et al., 2018).

These research achievements have come despite
complexities speciﬁc to the mental health space
often making it difﬁcult to obtain a sufﬁcient sam-
ple size of high-quality data. For instance, be-
havioral disorders are known to display variable
clinical presentations amongst different popula-
tions, rendering annotations of ground truth inher-

1https://github.com/kharrigian/

mental-health-datasets

ently noisy (De Choudhury et al., 2017; Arseniev-
Koehler et al., 2018). Scalable methods for cap-
turing an individual’s mental health status, such as
using regular expressions to identify self-reported
diagnoses or grouping individuals based on activity
patterns, have provided opportunities to construct
datasets aware of this heterogeneity (Coppersmith
et al., 2015b; Kumar et al., 2015). However, they
typically rely on oversimpliﬁcations that lack the
same clinical validation and robustness as some-
thing like a mental health battery (Zhang et al.,
2014; Ernala et al., 2019).

Ethical considerations further complicate data
acquisition, with the sensitive nature of mental
health data requiring tremendous care when con-
structing, analyzing, and sharing datasets (Benton
et al., 2017). Privacy-preserving measures, such
as de-identifying individuals and requiring IRB
approval to access data, have made it possible to
share some data across research groups. However,
these mechanisms can be technically cumbersome
to implement and are subject to strict governance
policies when clinical information is involved due
to HIPAA (Price and Cohen, 2019). Moreover,
many privacy-preserving practices require that sig-
nal relevant to modeling mental health, such as an
individual’s demographics or their social network,
are discarded (Bakken et al., 2004). This miss-
ingness has the potential to limit algorithmic fair-
ness, statistical generalizability, and experimental
reproducibility (Gorelick, 2006). Although mental
health researchers may anecdotally recall difﬁcul-
ties acquiring quality data or reproducing prior art
due to data sharing constraints, no study to our
knowledge has explicitly quantiﬁed this challenge.
Indeed, prior reviews of computational research
for mental health have noted several of the afore-
mentioned challenges, but have predominantly dis-
cussed technical methods (e.g. model architectures,
feature engineering) developed to surmount exist-
ing constraints (Guntuku et al., 2017; Wongkoblap

 
 
 
 
 
 
et al., 2017). Recent work from Chancellor and
De Choudhury (2020), completed concurrently
with our own, was the ﬁrst review to focus speciﬁ-
cally on the shortcomings of data for mental health
research. Our study afﬁrms the ﬁndings of Chancel-
lor and De Choudhury (2020), using an expanded
pool of literature that more acutely focuses on lan-
guage found in social media data. To this end,
we construct a new open-source directory of men-
tal health datasets, annotated using a standardized
schema that not only enables researchers to iden-
tify relevant datasets, but also to identify accessible
datasets. We draw upon this resource to offer nu-
anced recommendations regarding future dataset
curation efforts.

2 Data

To generate evidence-based recommendations re-
garding mental health dataset curation, we require
knowledge of the extant data landscape. Unlike
some comput"
"Teacher Mental Health During the COVID-19 Pandemic: Informing Policies
  to Support Teacher Well-being and Effective Teaching Practices","['Joseph M. Kush', 'Elena Badillo-Goicoechea', 'Rashelle J. Musci', 'Elizabeth A. Stuart']","While there is an emergence of research investigating the educational impacts
of the COVID-19 pandemic, empirical studies assessing teacher mental health
throughout the pandemic have been scarce. Using a large national dataset, the
current study first compared mental health outcomes during the pandemic between
pK-12 teachers and professionals in other occupations. Further, we compared the
prevalence of mental health outcomes between in-person and remote teachers (n =
131,154). Findings indicated teachers reported greater mental health concerns
than those in other professions, and that remote teachers reported
significantly higher levels of distress than those teaching in-person. Policy
implications are discussed, with a focus on providing support to meet the
evolving needs of teachers.",2021,http://arxiv.org/abs/2109.01547v1,http://arxiv.org/pdf/2109.01547v1,"1
2
0
2

p
e
S
3

]
P
A

.
t
a
t
s
[

1
v
7
4
5
1
0
.
9
0
1
2
:
v
i
X
r
a

Teacher Mental Health During the COVID-19 Pandemic:

Informing Policies to Support Teacher Well-being and Eﬀective

Teaching Practices

Joseph M. Kush1∗, Elena Badillo-Goicoechea1, Rashelle J. Musci1, and Elizabeth A.
Stuart1

1Department of Mental Health, Johns Hopkins Bloomberg School of Public Health

September 3, 2021

Abstract

While there is an emergence of research investigating the educational impacts of the COVID-19

pandemic, empirical studies assessing teacher mental health throughout the pandemic have been

scarce. Using a large national dataset, the current study ﬁrst compared mental health outcomes

during the pandemic between pK-12 teachers and professionals in other occupations. Further, we

compared the prevalence of mental health outcomes between in-person and remote teachers (n =

131,154). Findings indicated teachers reported greater mental health concerns than those in other

professions, and that remote teachers reported signiﬁcantly higher levels of distress than those

teaching in-person. Policy implications are discussed, with a focus on providing support to meet

the evolving needs of teachers.

1 Introduction

School districts across the United States faced an unprecedented disruption during the spring

of 2020 and the 2020/2021 academic year due to the COVID-19 pandemic. Although the initial

response of most districts was to switch to fully virtual learning (National Academies of Sciences,

Engineering, and Medicine, 2020), schools varied in their instructional policies throughout the course

of the pandemic: pivoting between fully remote, full onsite, and a combination of remote and onsite,

sometimes allowing both students and teachers in school buildings, and other times not. While there

is an ongoing emergence of research investigating the eﬀects of the COVID-19 pandemic on student

achievement (e.g., Bailey et al., 2021; Kuhfeld et al., 2020), student mental health (e.g., Prowse et

∗Correspondence concerning this article should be addressed to Joseph Kush, Johns Hopkins Bloomberg School of

Public Health, 624 N Broadway Room 841, Baltimore, MD 21205. Email: jkush1@jhu.edu

1

 
 
 
 
 
 
al., 2021; Tortella et al., 2021; Wasil et al., 2021), and public health and safety measures in academic

settings (e.g., Lessler et al., 2021; Doyle et al., 2021; Ismail et al., 2021), there has been less focus
on teacher mental health during the pandemic and how the instructional modalities, and changes in

them, might relate to teacher mental health.

Even before the challenges brought about by the pandemic, teacher stress has long been a major

concern, with teachers consistently experiencing some of the highest levels of occupational stress among

most occupations (Johnson et al., 2005; Markow et al., 2013).With the quick initial pivot to remote

teaching, followed by uncertainty due to modiﬁcations of instructional policies, we might expect that

there would be particularly high levels of stress and negative mental health outcomes among teachers

during the pandemic. As districts continue to grapple with decisions regarding in-person and remote

modalities as the ongoing public health emergency evolves, teachers face even higher uncertainty. More

research is needed to understand teacher mental health during the pandemic, in an eﬀort to identify

groups in need of additional supports and potential interventions in the context of necessary public

health containment measures, such as school closures.

The current study aims to address this gap in the literature by examining associations between

the COVID-19 pandemic and teachers’ mental health among primary and secondary school teachers

across the United States. Utilizing a large national dataset, we ﬁrst examined diﬀerences in mental

health during the pandemic between pre-Kindergarten through 12th grade (pK-12) teachers and other

professionals, including healthcare workers, oﬃce workers, and “other” professionals. Second, we

compared diﬀerences in mental health outcomes between individuals teaching in-person and remote

modalities. Findings from our study contribute to the growing body of literature on the educational

impacts of the pandemic by focusing explicitly on teachers and teacher mental health, and is the ﬁrst

study to do so using a large national dataset.

2 Teacher Stress

Teachers experience some of the highest levels of occupational stress and lowest levels of well-being

among all professions (Johnson et al., 2005; Bauer et al., 2006). Nearly one in four public school

teachers in elementary and secondary schools in the U.S. indicates stress as a reason to discontinue

teaching, a number that continues to increase over time (Snyder et al., 2019). Markow et al. (2013)

found that 51% of teachers U.S. K-12 public school teachers report “feeling under great stress several

days a week”, culminating in the lowest levels of teacher satisfactio"
"Incorporating Financial Hardship in Measuring the Mental Health Impact
  of Housing Stress","['Timothy Ludlow', 'Jonas Fooken', 'Christiern Rose', 'Kam Tang']","Housing expenditure tends to be sticky and costly to adjust, and makes up a
large proportion of household expenditure. Additionally, the loss of housing
can have catastrophic consequences. These specific features of housing
expenditure imply that housing stress could cause negative mental health
impacts. This research investigates the effects of housing stress on mental
health, contributing to the literature by nesting housing stress within a
measure of financial hardship, thus improving robustness to omitted variables
and creating a natural comparison group for matching. Fixed effects (FE)
regressions and a difference-in-differences (DID) methodology are estimated
utilising data from the Household Income and Labour Dynamics in Australia
(HILDA) Survey. The results show that renters who are in housing stress have a
significant decline in self-reported mental health, with those in prior
financial hardship being more severely affected. In contrast, there is little
to no evidence of housing stress impacting on owners with a mortgage. The
results also suggest that the mental health impact of housing stress is more
important than some, but not all, aspects of financial hardship.",2022,http://arxiv.org/abs/2205.01255v1,http://arxiv.org/pdf/2205.01255v1,"Incorporating Financial Hardship in Measuring the Mental

Health Impact of Housing Stress

Timothy Ludlow1,2

Jonas Fooken3

Christiern Rose1

Kam Ki Tang1

May 4, 2022

Abstract

Housing expenditure tends to be sticky and costly to adjust, and makes up a large

proportion of household expenditure. Additionally, the loss of housing can have catas-

trophic consequences. These speciﬁc features of housing expenditure imply that housing

stress could cause negative mental health impacts. This research investigates the eﬀects

of housing stress on mental health, contributing to the literature by nesting housing stress

within a measure of ﬁnancial hardship, thus improving robustness to omitted variables

and creating a natural comparison group for matching. Fixed eﬀects (FE) regressions

and a diﬀerence-in-diﬀerences (DID) methodology are estimated utilising data from the

Household Income and Labour Dynamics in Australia (HILDA) Survey. The results show

that renters who are in housing stress have a signiﬁcant decline in self-reported mental

health, with those in prior ﬁnancial hardship being more severely aﬀected. In contrast,

there is little to no evidence of housing stress impacting on owners with a mortgage. The

results also suggest that the mental health impact of housing stress is more important

than some, but not all, aspects of ﬁnancial hardship.

2
2
0
2

y
a
M
3

]

N
G
.
n
o
c
e
[

1
v
5
5
2
1
0
.
5
0
2
2
:
v
i
X
r
a

1School of Economics, The University of Queensland
2Corresponding author: timothy.ludlow1@uqconnect.edu.au
3Centre for the Business and Economics of Health, The University of Queensland

1

 
 
 
 
 
 
1

Introduction

A frequent research ﬁnding is that lower socioeconomic status is associated with higher rates of

common mental health disorders, suggesting prima facie that living and working in lower so-

cioeconomic environments can lead to poor mental health outcomes (Dohrenwend et al., 1992;

Lorant et al., 2003). A prominent explanation is that disadvantaged environmental circum-

stances can cause chronic arousal of stress pathways, with physiological disregulation increasing

the risk of developing mental illness (Tafet & Bernardini, 2003; Fisher & Baum, 2010). Al-

though a number of socioeconomic factors, such as poverty, low eduction, unemployment, and

housing circumstances, are associated with poor mental health, the highly correlated nature of

socioeconomic variables makes causal pathways hard to identify (Fuchs, 2004). This research

investigates the eﬀects of housing stress on mental health. It contributes to the literature by

nesting housing stress within a measure of ﬁnancial hardship, allowing for a natural comparison

group, and therefore increasing robustness to omitted variables and reverse causality.

Housing is a commonly investigated social determinant of health, with some researchers

hypothesising that the experience of housing stress, where housing costs become overly bur-

densome on individual ﬁnances, can lead to declines in mental health, contributing towards the

observed socioeconomic gradient in mental health (Bentley et al., 2011; Reeves et al., 2016).

The economic features of housing expenditure means it has a particularly strong inﬂuence on

personal ﬁnances, especially for those with limited resources. Housing costs make up a large

proportion of total expenditure for most lower income individuals, and actions taken to reduce

this expenditure can involve large adjustment costs. Additionally, housing is a necessity and,

thus, the loss of housing can have catastrophic consequences.

Previous research investigating the eﬀect of housing stress on mental health has tended to

ﬁnd that unaﬀordable housing leads to small but signiﬁcant declines in mental health (Mason

et al., 2013; Bentley et al., 2011). However the challenges of reverse causality and omitted

variables suggest there are limitations to these results. Reverse causation is a concern as it

is highly plausible that individuals with declining mental health are more prone to ﬁnancial

diﬃculties, including housing stress. This could occur, for example, if mental health declines

are associated with more erratic or impulsive behaviour, which in turn increases the probability

of experiencing housing stress. Omitted variables are a challenge for any observational setting

and especially when investigating housing stress, as many socioeconomic variables are highly

correlated (Fuchs, 2004). One concern is that the literature on housing stress tends to omit

2

ﬁnancial hardship from the analyses, despite ﬁnancial hardship and mental health having

strong associations (Fryers et al., 2003; Butterworth et al., 2009). If results are based on a

ﬁxed eﬀects (FE) regressions alone, the predominant methodology used in this research area,

then they could be prone to bias in the presence of omitted variables and reverse causality.

A further complication encountered in this line of research "
"Facilitating Self-Guided Mental Health Interventions Through
  Human-Language Model Interaction: A Case Study of Cognitive Restructuring","['Ashish Sharma', 'Kevin Rushton', 'Inna Wanyin Lin', 'Theresa Nguyen', 'Tim Althoff']","Self-guided mental health interventions, such as ""do-it-yourself"" tools to
learn and practice coping strategies, show great promise to improve access to
mental health care. However, these interventions are often cognitively
demanding and emotionally triggering, creating accessibility barriers that
limit their wide-scale implementation and adoption. In this paper, we study how
human-language model interaction can support self-guided mental health
interventions. We take cognitive restructuring, an evidence-based therapeutic
technique to overcome negative thinking, as a case study. In an IRB-approved
randomized field study on a large mental health website with 15,531
participants, we design and evaluate a system that uses language models to
support people through various steps of cognitive restructuring. Our findings
reveal that our system positively impacts emotional intensity for 67% of
participants and helps 65% overcome negative thoughts. Although adolescents
report relatively worse outcomes, we find that tailored interventions that
simplify language model generations improve overall effectiveness and equity.",2023,http://arxiv.org/abs/2310.15461v2,http://arxiv.org/pdf/2310.15461v2,"4
2
0
2

r
p
A
0
1

]

C
H
.
s
c
[

2
v
1
6
4
5
1
.
0
1
3
2
:
v
i
X
r
a

Facilitating Self-Guided Mental Health Interventions Through
Human-Language Model Interaction: A Case Study of Cognitive
Restructuring

Ashish Sharma
ashshar@cs.washington.edu
University of Washington
Seattle, WA, USA

Kevin Rushton
krushton@mhanational.org
Mental Health America
Alexandria, VA, USA

Inna Wanyin Lin
ilin@cs.washington.edu
University of Washington
Seattle, WA, USA

Theresa Nguyen
tnguyen@mhanational.org
Mental Health America
Alexandria, VA, USA

Tim Althoff
althoff@cs.washington.edu
University of Washington
Seattle, WA, USA

ABSTRACT
Self-guided mental health interventions, such as “do-it-yourself”
tools to learn and practice coping strategies, show great promise
to improve access to mental health care. However, these interven-
tions are often cognitively demanding and emotionally triggering,
creating accessibility barriers that limit their wide-scale implemen-
tation and adoption. In this paper, we study how human-language
model interaction can support self-guided mental health interven-
tions. We take cognitive restructuring, an evidence-based therapeutic
technique to overcome negative thinking, as a case study. In an
IRB-approved randomized field study on a large mental health web-
site with 15,531 participants, we design and evaluate a system that
uses language models to support people through various steps of
cognitive restructuring. Our findings reveal that our system posi-
tively impacts emotional intensity for 67% of participants and helps
65% overcome negative thoughts. Although adolescents report rel-
atively worse outcomes, we find that tailored interventions that
simplify language model generations improve overall effectiveness
and equity.

CCS CONCEPTS
• Human-centered computing → Interactive systems and
tools; • Computing methodologies → Natural language pro-
cessing.

KEYWORDS
mental health, language models, human-AI collaboration, cognitive
restructuring, field study, randomized trial

ACM Reference Format:
Ashish Sharma, Kevin Rushton, Inna Wanyin Lin, Theresa Nguyen, and Tim
Althoff. 2024. Facilitating Self-Guided Mental Health Interventions Through

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CHI’24, May 11–16, 2024, Honolulu, HI, USA
© 2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0330-0/24/05.
https://doi.org/10.1145/3613904.3642761

Human-Language Model Interaction: A Case Study of Cognitive Restruc-
turing. In CHI’24: ACM CHI conference on Human Factors in Computing
Systems, May 11–16, 2024, Hawaii, USA. ACM, New York, NY, USA, 29 pages.
https://doi.org/10.1145/3613904.3642761

1 INTRODUCTION
As mental health conditions surge worldwide, healthcare systems
are struggling to provide accessible mental health care for all [62,
63, 83]. Self-guided mental health interventions, such as tools to
journal and reflect on negative thoughts, offer great promise to
expand modes of care and help people learn coping strategies [64,
71, 72, 82]. While not a replacement for formal psychotherapy, these
interventions provide immediate on-demand access to resources
that can help develop techniques for mental well-being, especially
for those who lack access to a trained professional, are on waiting
lists, or seek to supplement therapy with other forms of care [1].

However, developing interventions that individuals can effec-
tively use without the assistance of a professional therapist is
challenging [34]. Currently, most self-guided interventions sim-
ply transform traditional manual therapeutic worksheets into digi-
tal online formats with limited instructions and support [82]. Us-
ing these worksheets without professional support often leads to
cognitively demanding and emotionally triggering experiences,
limiting engagement and usage [7, 32, 34, 94]. For example, a pop-
ular self-guided intervention involves independently practicing
Cognitive Restructuring of Negative Thoughts, an evidence-based,
well-established process that helps people notice and change their
negative thinking patterns [9, 21]. However, the practice includes
complex steps like identifying thinking traps (faulty or distorted
patterns of thinking like “all-or-nothing thinking”), which pose a
significant challenge for many [9, 21]. Most individuals lack the
necessary knowledge or experience to successfully use such in-
terventions independently without explicit training and support.
Moreover, analyzing one’s own thoughts, emotions, and behav-
ioral patterns can be emotionally triggering, especially for those
actively experiencing distress. Such accessibility barriers inhibit the
wid"
Intelligent interactive technologies for mental health and well-being,"['Mladjan Jovanovic', 'Aleksandar Jevremovic', 'Milica Pejovic-Milovancevic']","Mental healthcare has seen numerous benefits from interactive technologies
and artificial intelligence. Various interventions have successfully used
intelligent technologies to automate the assessment and evaluation of
psychological treatments and mental well-being and functioning. These
technologies include different types of robots, video games, and conversational
agents. The paper critically analyzes existing solutions with the outlooks for
their future. In particular, we: i)give an overview of the technology for
mental health, ii) critically analyze the technology against the proposed
criteria, and iii) provide the design outlooks for these technologies.",2021,http://arxiv.org/abs/2105.05306v1,http://arxiv.org/pdf/2105.05306v1,"1
2
0
2

y
a
M
1
1

]

C
H
.
s
c
[

1
v
6
0
3
5
0
.
5
0
1
2
:
v
i
X
r
a

Intelligent interactive technologies for mental
health and well-being

Mladjan Jovanovic, Aleksandar Jevremovic, Milica Pejovic-Milovancevic

Abstract 1 Mental healthcare has seen numerous beneﬁts from interactive tech-
nologies and artiﬁcial intelligence. Various interventions have successfully used
intelligent technologies to automate the assessment and evaluation of psychological
treatments and mental well-being and functioning. These technologies include dif-
ferent types of robots, video games, and conversational agents. The paper critically
analyzes existing solutions with the outlooks for their future. In particular, we: i)
give an overview of the technology for mental health, ii) critically analyze the tech-
nology against the proposed criteria, and iii) provide the design outlooks for these
technologies.

Key words: Human-AI interaction, intelligent systems, digital healthcare, mental
health, mental well-being, review, survey, robotic technologies, video games, con-
versational agents, chatbots, aﬀective computing.

1 Introduction

Artiﬁcial Intelligence (AI) is among the oldest disciplines of computer science that
builds systems that resemble humans in learning, thinking, problem-solving, and

Mladjan Jovanovic
Singidunum University, Belgrade, Serbia, e-mail: mjovanovic@singidunum.ac.rs

Aleksandar Jevremovic
Singidunum University, Belgrade, Serbia, e-mail: ajevremovic@singidunum.ac.rs

Milica Pejovic-Milovancevic
Institute of Mental Health and Faculty of Medicine, University of Belgrade, Serbia, e-mail:
milica.pejovic@imh.org.rs

1 This a pre-print version of the paper published in: E. Pap (ed.), Artiﬁcial Intelligence: Theory and
Applications, Studies in Computational Intelligence 973, Springer Nature Switzerland AG 2021,
DOI: https://doi.org/10.1007/978-3-030-72711-6_18

1

 
 
 
 
 
 
2

Mladjan Jovanovic, Aleksandar Jevremovic, Milica Pejovic-Milovancevic

decision making. The ﬁeld received signiﬁcant interest in the previous decade, mainly
due to advances in automated machine learning (ML) and deep learning (DL). They
learn useful patterns from a large amount of data and keep the acquired knowledge
as model structures and parameters that can be further applied to make predictions
by interpreting unseen data [1]. These models are either a set of elements or features
that contribute when making decisions (in ML) or are organized into several layers
of abstraction (such as neural networks) for general and speciﬁc interpretation tasks
(in DL).

Healthcare provision and medicine are one of the most signiﬁcant challenges
of AI due to being the pillars for a global society and the necessity of providing
higher-quality assistance to the healthcare workforce [2].

An emerging and expanding domain for for application of AI is mental health.
Readily available and ubiquitous devices and applications enable the provision of
ﬂexible mental care - on-demand, at any time, both at healthcare facilities and at
home. Societal challenges, such as the ongoing Covid-19 pandemic, can necessitate
physical distancing. Consequently, prolonged social isolation brings common risks
for mental health and well-being, potentially triggering conditions such as loneliness,
anxiety, and depression [3, 4]. The growing demand for telemedicine as contactless,
remote, and accessible healthcare services can help users stay connected, visit their
doctors remotely, and self-manage their mental functioning during the global Covid-
19 lockdown [3].

As they move into the digital era, mental healthcare is seeing substantial beneﬁts
from interactive technologies and ML/DL, including treatment both at home and
in hospitals. Medical decision-making is by its very nature uncertain, unknown,
inconsistent, and lacking data from multi-dimensional spaces. At the same time, it
must capture patients’ heterogeneity to adjust healthcare decisions, prescriptions,
and therapies to the individual. Moreover, healthcare professionals must understand
the automated decision-making process to verify it. Prevention is crucial here. It
maintains normal mental functioning, avoids the onset of critical conditions, pre-
vents existing illnesses from progressing, reduces healthcare burden, and makes
people satisﬁed and happier [5]. Reducing the gap between health and well-being is
something that traditional healthcare may struggle to achieve. These technologies can
help by ingraining positive health habits through sustained user engagement [6, 7].

This paper does not focus on the implementation and performance details of the AI
models and algorithms, but the consequences they have for the user experience of a
speciﬁc healthcare technology employing these models. In particular, we concentrate
on user-related aspects of these technologies that may inﬂuence their acceptance and
the eﬀectiveness of mental healthcare provision.

The paper is structured as follows. Section 2 describes a landsc"
"Counseling Summarization using Mental Health Knowledge Guided Utterance
  Filtering","['Aseem Srivastava', 'Tharun Suresh', 'Sarah Peregrine', 'Lord', 'Md. Shad Akhtar', 'Tanmoy Chakraborty']","The psychotherapy intervention technique is a multifaceted conversation
between a therapist and a patient. Unlike general clinical discussions,
psychotherapy's core components (viz. symptoms) are hard to distinguish, thus
becoming a complex problem to summarize later. A structured counseling
conversation may contain discussions about symptoms, history of mental health
issues, or the discovery of the patient's behavior. It may also contain
discussion filler words irrelevant to a clinical summary. We refer to these
elements of structured psychotherapy as counseling components. In this paper,
the aim is mental health counseling summarization to build upon domain
knowledge and to help clinicians quickly glean meaning. We create a new dataset
after annotating 12.9K utterances of counseling components and reference
summaries for each dialogue. Further, we propose ConSum, a novel
counseling-component guided summarization model. ConSum undergoes three
independent modules. First, to assess the presence of depressive symptoms, it
filters utterances utilizing the Patient Health Questionnaire (PHQ-9), while
the second and third modules aim to classify counseling components. At last, we
propose a problem-specific Mental Health Information Capture (MHIC) evaluation
metric for counseling summaries. Our comparative study shows that we improve on
performance and generate cohesive, semantic, and coherent summaries. We
comprehensively analyze the generated summaries to investigate the capturing of
psychotherapy elements. Human and clinical evaluations on the summary show that
ConSum generates quality summary. Further, mental health experts validate the
clinical acceptability of the ConSum. Lastly, we discuss the uniqueness in
mental health counseling summarization in the real world and show evidences of
its deployment on an online application with the support of mpathic.ai",2022,http://arxiv.org/abs/2206.03886v1,http://arxiv.org/pdf/2206.03886v1,"Counseling Summarization using Mental Health Knowledge
Guided Utterance Filtering
Aseem Srivastava1, Tharun Suresh1, Sarah Peregrine (Grin) Lord2, 3,
Md. Shad Akhtar1, Tanmoy Chakraborty1
1IIIT-Delhi, India; 2University of Washington; 3Mpathic.ai
{aseems,tharun20119,shad.akhtar,tanmoy}@iiitd.ac.in;grin@mpathic.ai

2
2
0
2

n
u
J

8

]
L
C
.
s
c
[

1
v
6
8
8
3
0
.
6
0
2
2
:
v
i
X
r
a

ABSTRACT
The psychotherapy intervention technique is a multifaceted con-
versation between a therapist and a patient. Unlike general clinical
discussions, psychotherapy’s core components (viz. symptoms) are
hard to distinguish, thus becoming a complex problem to sum-
marize later. A structured counseling conversation may contain
discussions about symptoms, history of mental health issues, or
the discovery of the patient’s behavior. It may also contain discus-
sion filler words irrelevant to a clinical summary. We refer to these
elements of structured psychotherapy as counseling components.
In this paper, the aim is mental health counseling summarization
to build upon domain knowledge and to help clinicians quickly
glean meaning. We create a new dataset after annotating 12.9𝐾
utterances of counseling components and reference summaries for
each dialogue. Further, we propose ConSum, a novel counseling-
component guided summarization model. ConSum undergoes three
independent modules. First, to assess the presence of depressive
symptoms, it filters utterances utilizing the Patient Health Question-
naire (PHQ-9), while the second and third modules aim to classify
counseling components. At last, we propose a problem-specific Men-
tal Health Information Capture (MHIC) evaluation metric for coun-
seling summaries. Our comparative study shows that we improve
on performance and generate cohesive, semantic, and coherent
summaries. We comprehensively analyze the generated summaries
to investigate the capturing of psychotherapy elements. Human and
clinical evaluations on the summary show that ConSum generates
quality summary. Further, mental health experts validate the clini-
cal acceptability of the ConSum. Lastly, we discuss the uniqueness
in mental health counseling summarization in the real world and
show evidences of its deployment on an online application with
the support of mpathic.ai.

CCS CONCEPTS
• Computing methodologies → Discourse, dialogue and prag-
matics; Natural language generation.

KEYWORDS
Dialogue Summarization, Natural Language Processing

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
KDD ’22, August 14–18, 2022, Washington, DC, USA
© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9385-0/22/08. . . $15.00
https://doi.org/10.1145/3534678.3539187

Figure 1: A sample counseling session instance from the
MEMO dataset. Symptom and History, Patient Discovery, Re-
flecting, and Discussion Filler are psychotherapy elements.
The summaries pertaining to this truncated snippet of con-
versation is shown at the bottom. Note: The summary and
conversation are truncated for brevity.

1 INTRODUCTION
Mental health counseling is one of the front-line defenses against
mental health illness. In medical and primary care settings, the
doctor follows a highly-structured assessment approach that elic-
its specific information about the patient’s medical problems to
rule out different diagnoses. In psychotherapy counseling sessions,
patients take center stage in elucidating their situation with sub-
tle details. The therapist introduces diverse auxiliary context in
conversations to put the patient at ease, discuss events happening
in the patient’s recent past including the feelings, reflections and
emotions that the patient experiences, and other relevant topics.
Follow-up conversations with the patient are also vital for a suc-
cessful treatment. The points of the counseling session that are
crucial for continuity of care in follow-up and treatment planning
include: (a) the patient’s presenting problem, (b) symptoms and
diagnosis, (c) treatments (current and prior), (d) mental status and

Therapist: I'm doing well. Thanks for asking. I understand you had some symptoms recently they've been bothering you.Patient: Yeah Therapist: Could you tell me about those? Patient: Yeah, for the last eight months, you know, I have this position at work where I have to make these weekly presentations and it's killing me. I can't do it anymore.Therapist: Tell me about how these presentations are set up?Patient: So it's a it's"
Benefits and Harms of Large Language Models in Digital Mental Health,"['Munmun De Choudhury', 'Sachin R. Pendse', 'Neha Kumar']","The past decade has been transformative for mental health research and
practice. The ability to harness large repositories of data, whether from
electronic health records (EHR), mobile devices, or social media, has revealed
a potential for valuable insights into patient experiences, promising early,
proactive interventions, as well as personalized treatment plans. Recent
developments in generative artificial intelligence, particularly large language
models (LLMs), show promise in leading digital mental health to uncharted
territory. Patients are arriving at doctors' appointments with information
sourced from chatbots, state-of-the-art LLMs are being incorporated in medical
software and EHR systems, and chatbots from an ever-increasing number of
startups promise to serve as AI companions, friends, and partners. This article
presents contemporary perspectives on the opportunities and risks posed by LLMs
in the design, development, and implementation of digital mental health tools.
We adopt an ecological framework and draw on the affordances offered by LLMs to
discuss four application areas -- care-seeking behaviors from individuals in
need of care, community care provision, institutional and medical care
provision, and larger care ecologies at the societal level. We engage in a
thoughtful consideration of whether and how LLM-based technologies could or
should be employed for enhancing mental health. The benefits and harms our
article surfaces could serve to help shape future research, advocacy, and
regulatory efforts focused on creating more responsible, user-friendly,
equitable, and secure LLM-based tools for mental health treatment and
intervention.",2023,http://arxiv.org/abs/2311.14693v1,http://arxiv.org/pdf/2311.14693v1,"Benefits and Harms of Large Language Models
in Digital Mental Health

Munmun De Choudhury†, Sachin R. Pendse, Neha Kumar
School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA
{munmund, sachin.r.pendse, neha.kumar}@gatech.edu

† Corresponding author

Abstract

The past decade has been transformative for mental health research and practice. The abil-
ity to harness large repositories of data, whether from electronic health records (EHR), mobile
devices, or social media, has revealed a potential for valuable insights into patient experiences,
promising early, proactive interventions, as well as personalized treatment plans. Recent devel-
opments in generative artificial intelligence, particularly large language models (LLMs), show
promise in leading digital mental health to uncharted territory. Patients are arriving at doctors’
appointments with information sourced from chatbots, state-of-the-art LLMs are being incor-
porated in medical software and EHR systems, and chatbots from an ever-increasing number
of startups promise to serve as AI companions, friends, and partners. This article presents
contemporary perspectives on the opportunities and risks posed by LLMs in the design, devel-
opment, and implementation of digital mental health tools. We adopt an ecological framework
and draw on the affordances offered by LLMs to discuss four application areas—care-seeking
behaviors from individuals in need of care, community care provision, institutional and med-
ical care provision, and larger care ecologies at the societal level. We engage in a thoughtful
consideration of whether and how LLM-based technologies could or should be employed for
enhancing mental health. The benefits and harms our article surfaces could serve to help shape
future research, advocacy, and regulatory efforts focused on creating more responsible, user-
friendly, equitable, and secure LLM-based tools for mental health treatment and intervention.

3
2
0
2

v
o
N
7

]
L
C
.
s
c
[

1
v
3
9
6
4
1
.
1
1
3
2
:
v
i
X
r
a

1

Introduction

“When I use ChatGPT to talk things through and vent about how I feel, it goes on to tell me
to get help and that I’m not alone. But why does it feel as if it’s mocking me? It feels as if it’s
having a laugh at my expense.” – A paraphrased social media post

In November 2022 [1], OpenAI released ChatGPT. ChatGPT followed the mold of past chatbots by
providing a simple interface for people to easily interact with a conversational agent. However, unlike past
publicly accessible chatbots, ChatGPT was powered by OpenAI’s proprietary language generation model,
often called Large Language Models (LLMs). OpenAI’s LLM (named GPT, for Generative Pre-trained

1

 
 
 
 
 
 
Transformers [2]) was created through a large-scale collection of text from the Internet combined with man-
ual review through a process often called Reinforcement Learning From Human Feedback (RLHF) [3].
ChatGPT’s underlying language and simple interface astonished users with answers that were surprisingly
coherent and wide-ranging. Since then, conversations across academic, medical, industry, and policy do-
mains have begun to discuss how LLMs could offer new possibilities for diagnosis, treatment, and patient
care in mental health.

Over the past decade, there has been increased conversation around the growing potential for digital
technologies, artificial intelligence (AI), and machine learning to contribute value to mental health research
and practice. Research has demonstrated some of this potential. For example, methods from natural lan-
guage processing (such as sentiment analysis) have been used to assess people’s emotional states from their
text, speech, or social media language [4, 5]. These studies have consistently shown that computational or
predictive analyses of digital data can accurately detect mood [6], mental health states [7], and even the risk
of potential harm [8] and suicide [9]. Collectively, the implications of this research include the potential for
valuable insights into daily patient experiences, a paving of the way for early and proactive interventions,
and the design of personalized treatment plans. However, as people further rely on online tools to seek
care for their mental health, researchers and activists have sounded the alarm about the potential for harm
if digital mental health interventions are staged without the awareness or consent of people experiencing
distress [10, 11]. Scholars have also expressed concern that the use of predictive analytics in mental health
could compromise patient and clinician agency [12], exacerbate systemic disparities encoded in the training
data of AI models [10, 13], and propagate insights poor in clinical grounding or construct validity [14].
The challenges in implementing an AI-informed mental health care model have further invited criticism and
skepticism around the role of AI in this field [15], even as researchers have increasingly sought to draw upon"
Big Data Analytics and AI in Mental Healthcare,"['Ariel Rosenfeld', 'David Benrimoh', 'Caitrin Armstrong', 'Nykan Mirchi', 'Timothe Langlois-Therrien', 'Colleen Rollins', 'Myriam Tanguay-Sela', 'Joseph Mehltretter', 'Robert Fratila', 'Sonia Israel', 'Emily Snook', 'Kelly Perlman', 'Akiva Kleinerman', 'Bechara Saab', 'Mark Thoburn', 'Cheryl Gabbay', 'Amit Yaniv-Rosenfeld']","Mental health conditions cause a great deal of distress or impairment;
depression alone will affect 11% of the world's population. The application of
Artificial Intelligence (AI) and big-data technologies to mental health has
great potential for personalizing treatment selection, prognosticating,
monitoring for relapse, detecting and helping to prevent mental health
conditions before they reach clinical-level symptomatology, and even delivering
some treatments. However, unlike similar applications in other fields of
medicine, there are several unique challenges in mental health applications
which currently pose barriers towards the implementation of these technologies.
Specifically, there are very few widely used or validated biomarkers in mental
health, leading to a heavy reliance on patient and clinician derived
questionnaire data as well as interpretation of new signals such as digital
phenotyping. In addition, diagnosis also lacks the same objective 'gold
standard' as in other conditions such as oncology, where clinicians and
researchers can often rely on pathological analysis for confirmation of
diagnosis. In this chapter we discuss the major opportunities, limitations and
techniques used for improving mental healthcare through AI and big-data. We
explore both the computational, clinical and ethical considerations and best
practices as well as lay out the major researcher directions for the near
future.",2019,http://arxiv.org/abs/1903.12071v1,http://arxiv.org/pdf/1903.12071v1,"9
1
0
2

r
a

M
2
1

]

Y
C
.
s
c
[

1
v
1
7
0
2
1
.
3
0
9
1
:
v
i
X
r
a

Big Data Analytics and AI in Mental Healthcare

Ariel Rosenfeld∗

Bar-Ilan University, Israel

David Benrimoh∗

McGill University, Canada. Aifred Health

Caitrin Armstrong, Nykan Mirchi, Timothe Langlois-Therrien, Colleen Rollins, Myriam Tanguay-Sela,
Joseph Mehltretter, Robert Fratila, Sonia Israel, Emily Snook, Kelly Perlman

Aifred Health

Akiva Kleinerman

Bar-Ilan University, Israel

Bechara Saab, Mark Thoburn

Mobio Interactive

Cheryl Gabbay

McGill University, Canada

Amit Yaniv-Rosenfeld

Tel-Aviv University, Israel

Abstract

Mental health conditions cause a great deal of distress or impairment; depression alone will aﬀect 11% of the

world’s population. The application of Artiﬁcial Intelligence (AI) and big-data technologies to mental health

has great potential for personalizing treatment selection, prognosticating, monitoring for relapse, detecting

and helping to prevent mental health conditions before they reach clinical-level symptomatology, and even

delivering some treatments. However, unlike similar applications in other ﬁelds of medicine, there are several

unique challenges in mental health applications which currently pose barriers towards the implementation

of these technologies. Speciﬁcally, there are very few widely used or validated biomarkers in mental health,

leading to a heavy reliance on patient and clinician derived questionnaire data as well as interpretation of

new signals such as digital phenotyping. In addition, diagnosis also lacks the same objective gold standard as

in other conditions such as oncology, where clinicians and researchers can often rely on pathological analysis

for conﬁrmation of diagnosis. In this chapter we discuss the major opportunities, limitations and techniques

used for improving mental healthcare through AI and big-data. We explore both the computational, clinical

and ethical considerations and best practices as well as lay out the major researcher directions for the near

future.

Preprint submitted to Journal of LATEX Templates

March 29, 2019

 
 
 
 
 
 
1. Introduction

The conceptualization, diagnosis, treatment and prevention of mental disorders is limited by existing

options for collecting, organizing and analyzing information. Big data and machine learning/artiﬁcial intel-

ligence (ML/AI) can be applied to the development of tools that could help patients, providers and systems

overcome these limitations. As many as 1 in 5 people experience mental illness. Mental disorders aﬀect

individuals’ abilities to function, engage meaningfully in daily activities and maintain relationships. They

cause signiﬁcant suﬀering to individuals and their families and are a signiﬁcant source of socio-economic

burden [1]. Many mental disorders are also risk factors for suicide which occurs at an alarming rate globally

[2]. These are disorders that often strike young and otherwise healthy people, a socially and economically

critical segment of the population. As such, improving the detection, treatment, and monitoring of mental

illness is crucial.

Designing tools for practical use-cases in mental healthcare requires a deep understanding of psychiatric

illness, the current mental healthcare system, and medical ethics. We begin with an introduction of mental

illness and healthcare, and proceed to discussing their complexities from a clinical and data-driven per-

spective, before discussing speciﬁc use cases and applications of big data and machine learning approaches.

To the reader from engineering and computer science: perhaps the most important conclusion from this

chapter is that close collaboration with domain experts and clinicians will be required invariably in order to

successfully build safe, eﬀective, and useful mental healthcare applications.

Mental illnesses are a group of diverse conditions with varying severity, complexity, and duration. In

considering deviations from normal thought, feeling and behavior, characteristic of mental illness, it is

critical to recognize the extent to which they lead to functional impairment. To be classiﬁed as a disorder,

a set of symptoms must cause signiﬁcant suﬀering or interference with daily functions or life goals [3]. This

means that the treatment of mental illnesses has largely the same objective as other branches of medicine:

the alleviation of suﬀering, the improvement of function and quality of life, and the reduction of morbidity

(the incidence of new diseases or impairments) and mortality (or the rate of death, primarily from suicide

or reduced life expectancy because of impaired self-care). These then are the objectives of the clinical

professionals who treat patients with mental illness. Family doctors are the primary providers of mental

healthcare [4] and are accompanied by many other healthcare workers and specialists such as psychiatrists,

psychologists, nurses, social workers, case managers, occu"
"Mental Health Diagnosis in the Digital Age: Harnessing Sentiment
  Analysis on Social Media Platforms upon Ultra-Sparse Feature Content","['Haijian Shao', 'Ming Zhu', 'Shengjie Zhai']","Amid growing global mental health concerns, particularly among vulnerable
groups, natural language processing offers a tremendous potential for early
detection and intervention of people's mental disorders via analyzing their
postings and discussions on social media platforms. However, ultra-sparse
training data, often due to vast vocabularies and low-frequency words, hinders
the analysis accuracy. Multi-labeling and Co-occurrences of symptoms may also
blur the boundaries in distinguishing similar/co-related disorders. To address
these issues, we propose a novel semantic feature preprocessing technique with
a three-folded structure: 1) mitigating the feature sparsity with a weak
classifier, 2) adaptive feature dimension with modulus loops, and 3)
deep-mining and extending features among the contexts. With enhanced semantic
features, we train a machine learning model to predict and classify mental
disorders. We utilize the Reddit Mental Health Dataset 2022 to examine
conditions such as Anxiety, Borderline Personality Disorder (BPD), and
Bipolar-Disorder (BD) and present solutions to the data sparsity challenge,
highlighted by 99.81% non-zero elements. After applying our preprocessing
technique, the feature sparsity decreases to 85.4%. Overall, our methods, when
compared to seven benchmark models, demonstrate significant performance
improvements: 8.0% in accuracy, 0.069 in precision, 0.093 in recall, 0.102 in
F1 score, and 0.059 in AUC. This research provides foundational insights for
mental health prediction and monitoring, providing innovative solutions to
navigate challenges associated with ultra-sparse data feature and intricate
multi-label classification in the domain of mental health analysis.",2023,http://arxiv.org/abs/2311.05075v1,http://arxiv.org/pdf/2311.05075v1,"Mental  Health  Diagnosis  in  the  Digital  Age:  Harnessing  Sentiment 
Analysis on Social Media Platforms upon Ultra-Sparse Feature Content 

Haijian Shao, Ming Zhu, Shengjie Zhai* 
Dept. of Electrical and Computer Engineering, University of Nevada, Las Vegas, NV 89154, USA 

Corresponding author: Dr. Shengjie Zhai (shengjie.zhai@unlv.edu) 

Abstract:  
Amid  growing  global  mental  health  concerns,  particularly  among  vulnerable  groups, 
natural  language  processing  offers  a  tremendous  potential  for  early  detection  and 
intervention of people’s mental disorders via analyzing their postings and discussions on 
social media platforms. However, ultra-sparse training data, often due to vast vocabularies 
and low-frequency words, hinders the analysis accuracy. Multi-labeling/Cooccurrences of 
symptoms may also blur the boundaries in distinguishing similar/co-related disorders. To 
address these issues, we propose a novel semantic feature preprocessing technique with a 
three-folded structure: 1) mitigating the feature sparsity with a weak classifier, 2) adaptive 
feature dimension with modulus loops, and 3) deep-mining and extending features among 
the  contexts.  With  enhanced  semantic  features,  we  train  a  machine  learning  model  to 
predict and classify mental disorders. We utilize the Reddit Mental Health Dataset 2022 to 
examine conditions such as Anxiety, Borderline Personality Disorder (BPD), and Bipolar-
Disorder (BD) and present solutions to the data sparsity challenge, highlighted by 99.81% 
non-zero  elements.  After  applying  our  preprocessing  technique,  the  feature  sparsity 
decreases to 85.4%. Overall, our methods, when compared to seven benchmark models, 
demonstrate significant performance improvements: 8.0% in accuracy, 0.069 in precision, 
0.093 in recall, 0.102 in F1 score, and 0.059 in AUC. This research provides foundational 
insights  for  mental  health  prediction  and  monitoring,  providing  innovative  solutions  to 
navigate  challenges  associated  with  ultra-sparse  data/feature  and  intricate  multi-label 
classification in the domain of mental health analysis. 

1. Introduction 

       Over the last decade, the prevalence and increasing impact of mental health disorders 
have raised a pivotal concern in global public health discourses (World Health Organization, 
2021)1.  These  disorders  transcend  age,  gender,  and  socio-economic  statuses.  However, 
particular  populations  find  themselves  more  susceptible  due  to  a  confluence  of  social 
determinants, including but not limited to, economic deprivation, systemic discrimination, 
and  restricted  educational  opportunities2.  Such  socio-economic  determinants  have  been 
empirically  shown  to  widen  health  disparities,  particularly  for  marginalized  groups.  To 
elucidate, data suggests that ethnic minorities within the United States frequently encounter 
barriers to accessing premium mental health services, especially when compared to their 
non-Hispanic white counterparts3. Such systematic inadequacies in prevention, treatment, 
and  access  for  these  vulnerable  demographics  underscore  and  amplify  the  overarching 

Page 1 of 21 

 
 
challenges of mental health care.        
      Concurrently, as we navigate through the digital era, there has been a transformative 
ascendancy  of  social  media  platforms.  These  platforms  have  evolved  beyond  their 
foundational role as communication tools, encompassing multifarious roles ranging from 
news dissemination and entertainment to e-commerce and public service facilitation4. This 
paradigm shift is most evident in the massive user engagements observed on platforms like 
Facebook and Reddit. What is particularly salient about contemporary social media is its 
democratization of information, empowering users not only as passive consumers, but also 
as active participants and creators, fostering direct, meaningful engagements with others. 
In this vast ocean of user-generated content lies an untapped reservoir of potential insights 
for the mental health sector. Pioneering researchers have begun harnessing the capabilities 
of Natural  Language Processing (NLP)  and machine learning  (ML) techniques, such as 
sentiment  analysis,  to  distill  actionable  insights  from  this  vast  and  dynamic  data  pool. 
These  methodologies  are  poised  to  revolutionize  early  detection  mechanisms  for 
individuals grappling with mental health issues5. Yet, a quintessential challenge specific to 
social  media  data  lies  in  its  linguistic  informality—abbreviated  lexicons,  syntactic 
anomalies,  and  sometimes  logical  inconsistencies.  Such  linguistic  traits  are  especially 
pronounced in posts from users with mental disorders, leading to an overall reduction in 
the “informatic feature density”. Consequently, enhancing the robustness and accuracy of 
sentiment analysis in such contexts demands rigorous exploratio"
"Identifying physical health comorbidities in a cohort of individuals
  with severe mental illness: An application of SemEHR","['Rebecca Bendayan', 'Honghan Wu', 'Zeljko Kraljevic', 'Robert Stewart', 'Tom Searle', 'Jaya Chaturvedi', 'Jayati Das-Munshi', 'Zina Ibrahim', 'Aurelie Mascio', 'Angus Roberts', 'Daniel Bean', 'Richard Dobson']","Multimorbidity research in mental health services requires data from physical
health conditions which is traditionally limited in mental health care
electronic health records. In this study, we aimed to extract data from
physical health conditions from clinical notes using SemEHR. Data was extracted
from Clinical Record Interactive Search (CRIS) system at South London and
Maudsley Biomedical Research Centre (SLaM BRC) and the cohort consisted of all
individuals who had received a primary or secondary diagnosis of severe mental
illness between 2007 and 2018. Three pairs of annotators annotated 2403
documents with an average Cohen's Kappa of 0.757. Results show that the NLP
performance varies across different diseases areas (F1 0.601 - 0.954)
suggesting that the language patterns or terminologies of different condition
groups entail different technical challenges to the same NLP task.",2020,http://arxiv.org/abs/2002.08901v1,http://arxiv.org/pdf/2002.08901v1,"Identifying physical health comorbidities in a cohort of individuals with 
severe mental illness: An application of SemEHR 

Rebecca Bendayan1, 2, Honghan Wu,3,4, Zeljko Kraljevic1, Robert Stewart2,5, Tom Searle1, 
Jaya Chaturvedi1, Jayati Das-Munshi2,5, Zina Ibrahim1, Aurelie Mascio1, Angus Roberts1,2, 
Daniel Bean1,6, Richard Dobson1,2,6,7  

1Department of Biostatistics and Health Informatics, Institute of Psychiatry, Psychology and Neuroscience, 
King’s College London, London, United Kingdom 
2NIHR Biomedical Research Centre at South London and Maudsley NHS Foundation Trust and King’s 
College London, London, United Kingdom 
3Centre for Medical Informatics, Usher Institute, University of Edinburgh, United Kingdom 
4Health Data Research UK Edinburgh, University of Edinburgh, United Kingdom 
5Department of Psychological Medicine, Institute of Psychiatry, Psychology and Neuroscience, King’s College 
London, London, United Kingdom 
6Health Data Research UK London, University College London, London, United Kingdom 
7Institute of Health Informatics, University College London, London, United Kingdom 

Abstract 

Multimorbidity research in mental health services requires data from physical health conditions which is traditionally 
limited in mental health care electronic health records. In this study, we aimed to extract data from physical health 
conditions from clinical notes using SemEHR. Data was extracted from Clinical Record Interactive Search (CRIS) 
system  at  South  London  and Maudsley  Biomedical  Research  Centre  (SLaM  BRC)  and  the  cohort  consisted  of  all 
individuals who had received a primary or  secondary diagnosis of severe mental illness between 2007 and 2018. 
Three pairs of annotators annotated 2403 documents with an average Cohen's κ of 0.757. Results show that the NLP 
performance  varies  across  different  diseases  areas  (F1  0.601  –  0.954)  suggesting  that  the  language  patterns  or 
terminologies of different condition groups entail different technical challenges to the same NLP task.  

Introduction 

The Academy of Medical Sciences (2018) has highlighted that the increase of multimorbidity (2 or more co-existent 
health  conditions)  in  our  population  constitutes  a  challenge  for  our  health  care.  Research  on  multimorbidity 
traditionally  focuses  on  the  ageing  population,  however  there  is  a  need  to  understand  multimorbidity  in  other 
populations such as individuals with mental health disorders. Similarly, the Framework for Mental Health Research 
developed by the Department of Health (2017) acknowledged the need to account for the interactions between mental 
and  physical  health  to  reduce  the  mortality  gap  between  individuals  with  severe  mental  illnesses  (SMI),  such  as 
schizophrenia or bipolar disorder, and the general population.  

Large national population studies have very limited data for individuals with mental health disorders and therefore 
studies have to use other data sources such as electronic health records (EHRs). The rise of the use of EHRs and the 
UK  government’s  commitment  for  the  NHS  to  be  paperless  by  2020  provides  us  a  unique  opportunity  to  access 
relevant data for this population. One of the largest providers of secondary mental health care in UK and Europe is 
the  South London and Maudsley (SLaM) NHS Foundation Trust.  In 2007, the SLaM NIHR Biomedical Research 
Centre (BRC) developed the Clinical Record Interactive Search (CRIS) system to enable routinely collected mental 
health EHRs to be used in research, and since 2013 this has been deployed successfully at other mental health NHS 
Foundation Trusts across the UK. However, structured data on physical health conditions is limited in mental health 
care EHRs and this data is mainly hidden in unstructured clinical notes which has so far limited their use for the study 
of multimorbidity in SMI. Within this context, there is a need to make this data on physical health conditions available 
for researchers. 

SemEHR,  an  open  source  toolkit  that  integrates  text  mining  and  semantic  computing  for  identifying  mentions  of 
Unified  Medical  Language  System  (UMLS)  concepts  from  clinical  documents,  has  been  particularly  helpful  in 
extracting data from systems such as the CRIS system [1]. A preliminary study [2] focusing in schizophrenia patients 

 
 
 
has  used  SemEHR  to  extract  and  validate  9  ICD-10  chapter  level  codes  representing  viral  infection,  endocrine, 
neurologic, cardiovascular, respiratory, digestive, skin, musculoskeletal and urogenital systems. The present study 
builds on this work as we aim to identify a larger number of chapter level codes and validate them in the larger SMI 
cohort, including additionally bipolar affective disorders and non-organic psychoses.  

Methods 

Corpus selection and preprocessing: The South London and Maudsley Mental Health Case Register 

Data was extracte"
"Personal Mental Health Navigator: Harnessing the Power of Data, Personal
  Models, and Health Cybernetics to Promote Psychological Well-being","['Amir M. Rahmani', 'Jocelyn Lai', 'Salar Jafarlou', 'Asal Yunusova', 'Alex. P. Rivera', 'Sina Labbaf', 'Sirui Hu', 'Arman Anzanpour', 'Nikil Dutt', 'Ramesh Jain', 'Jessica L. Borelli']","Traditionally, the regime of mental healthcare has followed an episodic
psychotherapy model wherein patients seek care from a provider through a
prescribed treatment plan developed over multiple provider visits. Recent
advances in wearable and mobile technology have generated increased interest in
digital mental healthcare that enables individuals to address episodic mental
health symptoms. However, these efforts are typically reactive and
symptom-focused and do not provide comprehensive, wrap-around, customized
treatments that capture an individual's holistic mental health model as it
unfolds over time. Recognizing that each individual is unique, we present the
notion of Personalized Mental Health Navigation (MHN): a therapist-in-the-loop,
cybernetic goal-based system that deploys a continuous cyclic loop of
measurement, estimation, guidance, to steer the individual's mental health
state towards a healthy zone. We outline the major components of MHN that is
premised on the development of an individual's personal mental health state,
holistically represented by a high-dimensional cover of multiple knowledge
layers such as emotion, biological patterns, sociology, behavior, and
cognition. We demonstrate the feasibility of the personalized MHN approach via
a 12-month pilot case study for holistic stress management in college students
and highlight an instance of a therapist-in-the-loop intervention using MHN for
monitoring, estimating, and proactively addressing moderately severe depression
over a sustained period of time. We believe MHN paves the way to transform
mental healthcare from the current passive, episodic, reactive process (where
individuals seek help to address symptoms that have already manifested) to a
continuous and navigational paradigm that leverages a personalized model of the
individual, promising to deliver timely interventions to individuals in a
holistic manner.",2020,http://arxiv.org/abs/2012.09131v1,http://arxiv.org/pdf/2012.09131v1,"0
2
0
2
c
e
D
5
1

]

C
H
.
s
c
[

1
v
1
3
1
9
0
.
2
1
0
2
:
v
i
X
r
a

Personal Mental Health Navigator: Harnessing the Power of Data, Personal
Models, and Health Cybernetics to Promote Psychological Well-being

Amir M. Rahmania,b,∗, Jocelyn Laic, Salar Jafarloua, Asal Yunusovac, Alex. P. Riverac, Sina Labbafa, Sirui Hud,e,
Arman Anzanpourf, Nikil Dutta, Ramesh Jaina, Jessica L. Borellic

aDepartment of Computer Science, University of California, Irvine, USA
bSchool of Nursing, University of California, Irvine, USA
cDepartment of Psychological Science, University of California, Irvine, USA
dDepartment of Statistics, University of California, Irvine, USA
eDepartment of Economics, University of California, Irvine, USA
fDepartment of Future Technologies, University of Turku, Turku, Finland

Abstract

Traditionally, the regime of mental healthcare has followed an episodic psychotherapy model wherein patients seek
care from a provider through a prescribed treatment plan developed over multiple provider visits. Recent advances in
wearable and mobile technology have generated increased interest in digital mental healthcare that enables individuals
to address episodic mental health symptoms such as depression and anxiety. However, despite providers’ best inten-
tions, these efforts are typically reactive and symptom-focused, and do not provide comprehensive, wrap-around,
customized treatments that capture an individual’s holistic mental health model as it unfolds over time. Recogniz-
ing that each individual is unique and requires personally tailored mental health treatment, we present the notion of
Personalized Mental Health Navigation (MHN): a therapist-in-the-loop, cybernetic goal-based system that deploys
a continuous cyclic loop of measurement, estimation, guidance, to steer the individual’s mental health state towards
a healthy zone. We outline the major components of MHN that is premised on the development of an individual’s
personal mental health state, holistically represented by a high-dimensional cover of multiple knowledge layers such
as emotion, biological patterns, sociology, behavior, and cognition. We demonstrate the feasibility of the personalized
MHN approach via a 12-month pilot case study for holistic stress reduction and management in college students, and
highlight an instance of a therapist-in-the-loop intervention using MHN for monitoring, estimating, and proactively
addressing moderately severe depression over a sustained period of time. We believe MHN paves the way to transform
mental healthcare from the current passive, episodic, reactive process (where individuals seek help to address symp-
toms that have already manifested) to a continuous and navigational paradigm that leverages a personalized model of
the individual, promising to deliver timely interventions to individuals in a holistic manner.

Keywords: Mental Health, Stress, Anxiety, Personicle, Life-logging, Internet-of-Things, Wearable Technology,
Health Cybernetics, Personal Health Models

1. Introduction

Mental health is an important factor in determining an individual’s quality of life. While it can directly affect the
quality of life, mental health can also have indirect effects, for instance by changing the ways in which individuals
engage in decision making processes, resulting in potential long-term effects across the lifespan [1, 2]. Recognizing
that each person is unique, the recent P4 medicine approach [3] aims to transform the practice of medicine from a
traditionally reactive, symptomatic approach to a proactive systems approach that addresses the causes via predictive,
preventive, personalized and participatory strategies. The current mental healthcare system similarly deploys an acute
and symptom-focused reactive approach to patient well-being. Healthcare providers often intervene after symptoms

∗Corresponding author
Email address: a.rahmani@uci.edu (Amir M. Rahmani)

1

 
 
 
 
 
 
have already manifested within an individual, as opposed to adopting an approach that seeks to prevent illness from
developing or sustain well-being. One major drawback of this system is its passive approach to mental health. Indeed,
in many cases individuals only become conscious of their issues once their conditions become severe or reach a point
where they perceive a need for the issue to be addressed [4, 5]. In this passive, reactive model, there would be little
effort to monitor one’s own behavior or experiences as well as actively seek guidance in the absence of conscious
discomfort.

Furthermore, the traditional episodic medical and psychotherapy model of treatment for mental health is premised
on the notion that providers interact with the individual during scheduled appointments potentially few and far be-
tween, or otherwise for prearranged circumscribed amounts of time per week. The provider relies upon the individual
to be an accurate reporter of their symptoms and health, both in the present moment and over a period of t"
Extended Reality for Mental Health Evaluation -A Scoping Review,"['Omisore Olatunji', 'Ifeanyi Odenigbo', 'Joseph Orji', 'Amelia Beltran', 'Nilufar Baghaei', 'Meier Sandra', 'Rita Orji']","Mental health disorders are the leading cause of health-related problems
globally. It is projected that mental health disorders will be the leading
cause of morbidity among adults as the incidence rates of anxiety and
depression grows globally. Recently, extended reality (XR), a general term
covering virtual reality (VR), augmented reality (AR) and mixed reality (MR),
is paving a new way to deliver mental health care. In this paper, we conduct a
scoping review on the development and application of XR in the area of mental
disorders. We performed a scoping database search to identify the relevant
studies indexed in Google Scholar, PubMed, and the ACM Digital Library. A
search period between August 2016 and December 2023 was defined to select
articles related to the usage of VR, AR, and MR in a mental health context. We
identified a total of 85 studies from 27 countries across the globe. By
performing data analysis, we found that most of the studies focused on
developed countries such as the US (16.47%) and Germany (12.94%). None of the
studies were for African countries. The majority of the articles reported that
XR techniques led to a significant reduction in symptoms of anxiety or
depression. More studies were published in the year 2021, i.e., 31.76% (n =
31). This could indicate that mental disorder intervention received a higher
attention when COVID-19 emerged. Most studies (n = 65) focused on a population
between 18 and 65 years old, only a few studies focused on teenagers (n = 2).
Also, more studies were done experimentally (n = 67, 78.82%) rather than by
analytical and modeling approaches (n = 8, 9.41%). This shows that there is a
rapid development of XR technology for mental health care. Furthermore, these
studies showed that XR technology can effectively be used for evaluating mental
disorders in similar or better way as the conventional approaches.",2022,http://arxiv.org/abs/2204.01348v2,http://arxiv.org/pdf/2204.01348v2,"Accepted for Publication in JMIR Serious Games 

Review 

Extended Reality for Mental Health Evaluation —A Scoping 
Review 

Olatunji Omisore, PhD1; Ifeanyi Odenigbo, MSc2; Joseph Orji, MSc2; Amelia Beltran, MSc2; 
Meier Sandra, PhD, MD3; Nilufar Baghaei, PhD4; Rita Orji, PhD2 

1

Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen 518055, China. 

2

3

4

Faculty of Computer Science, Dalhousie University, Halifax, Canada 

School of Information Technology and Electrical Engineering, University of Queensland, Brisbane, Australia 

Department of Psychiatry, Dalhousie University, Halifax, Nova Scotia, Canada  

Corresponding Author: 
Olatunji Omisore, 
Shenzhen Institutes of Advanced Technology,  
Chinese Academy of Sciences, Shenzhen 518055, China.  
Phone: 8613172482240  
Email: ootsorewilly@gmail.com  

Abstract 
Background:  Mental  health disorders  are the  leading cause  of health-related  problems globally. It  is  projected 
that mental health disorders will be the leading cause of morbidity among adults as the incidence rates of anxiety 
and  depression  grows  globally.  Recently,  extended  reality  (XR),  a  general  term  covering  virtual  reality  (VR), 
augmented reality (AR) and mixed reality (MR), is paving a new way to deliver mental health care. In this paper, 
we conduct a scoping review of the development and application of XR in the area of mental disorders.  
Objective: We investigated the adoption and implementation XR technologies used for the intervention of mental 
disorders. This study aims to provide statistical analyses of the design, usage, and effectiveness of XR technology 
for mental health intervention with a global demographic focus.  
Methods:  We performed a scoping database search to identify the relevant studies indexed in Google Scholar, 
PubMed, and the ACM Digital Library. A search period between August 2016 and December 2023 was defined 
to select articles related to the usage of VR, AR, and MR in a mental health context. The database search was 
performed with pre-defined queries, and a total of 831 articles were identified. Ten (10) additional articles were 
identified  through  professional  recommendation.  Inclusion  and  exclusion  criteria  were  designed  and  applied  to 
ensure that only the relevant studies were included in the literature review. 
Results:  W e identified a total of 85 studies from 27 countries across the globe. By performing data analysis, we 
found that most of the studies focused on developed countries such as the United States (16.47%) and Germany 
(12.94%).  None  of  the  studies  were  for  African  countries.  The  majority  of  the  articles  reported  that  XR 
techniques  led  to  a  significant  reduction  in  symptoms  of  anxiety  or  depression.  The  majority  of  studies  were 
published in the year 2021, i.e., 31.76% (n = 31) of the included studies. This could indicate that mental disorder 
intervention received a higher attention when COVID-19 emerged. Most studies (n = 65, 76.47%) focused on a 
population between the age range of 18 to 65 years old, while only fewer studies focused on teenagers (n = 2, 
3.35%), i.e. subjects between the ages of 10 to 19 years old. Also, more studies were done experimentally (n = 
67, 78.82%) rather than by analytical and modeling approaches (n = 8, 9.41%). This shows that there is a rapid 
development  of  XR  technology  for  mental  health  care.  Furthermore,  these  studies  showed  that  XR  technology 
can effectively be used for evaluating mental disorders in similar or better way as the conventional approaches. 
Conclusions: In this scoping review, we studied the adoption and implementation of XR technology for mental 
disorder care. This covers 85 studies that used different types of VR, AR, and MR techniques for managing 14 
types of mental disorders. Our study identifies that XR treatment yields high patient satisfaction and follow-up 
assessments show significant improvement with large effect sizes. Moreover, the studies adopted unique designs 
that  are  set  up  to  record  and  analyze  the  symptoms  reported  by  their  participants.  This  review  study  may  aid 
future research and development of various XR mechanisms for differentiated mental disorder procedures. 

KEYWORDS:  
Extended reality; mental health; depression; anxiety; exposure therapy;  

 
 
 
 
Omisore et al. 2024 

Introduction 
Background 
Mental disorders are defined as behavioral or mental patterns that cause significant distress or impairment 
for an individual. These are highly prevalent and, currently, are the leading cause of disability globally. In 
the last decades, a global increase in the incidence of these disorders has been observed [1, 2]. According 
to  the  World  Health  Organization  (WHO),  mental  disorders  are  the  leading  cause  of  disability  in  the 
United States and the United Kingdom. The WHO predicted that mental disorders would accou"
"Mental-LLM: Leveraging Large Language Models for Mental Health
  Prediction via Online Text Data","['Xuhai Xu', 'Bingsheng Yao', 'Yuanzhe Dong', 'Saadia Gabriel', 'Hong Yu', 'James Hendler', 'Marzyeh Ghassemi', 'Anind K. Dey', 'Dakuo Wang']","Advances in large language models (LLMs) have empowered a variety of
applications. However, there is still a significant gap in research when it
comes to understanding and enhancing the capabilities of LLMs in the field of
mental health. In this work, we present a comprehensive evaluation of multiple
LLMs on various mental health prediction tasks via online text data, including
Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4. We conduct a broad range of
experiments, covering zero-shot prompting, few-shot prompting, and instruction
fine-tuning. The results indicate a promising yet limited performance of LLMs
with zero-shot and few-shot prompt designs for mental health tasks. More
importantly, our experiments show that instruction finetuning can significantly
boost the performance of LLMs for all tasks simultaneously. Our best-finetuned
models, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of
GPT-3.5 (25 and 15 times bigger) by 10.9% on balanced accuracy and the best of
GPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with the
state-of-the-art task-specific language model. We also conduct an exploratory
case study on LLMs' capability on mental health reasoning tasks, illustrating
the promising capability of certain models such as GPT-4. We summarize our
findings into a set of action guidelines for potential methods to enhance LLMs'
capability for mental health tasks. Meanwhile, we also emphasize the important
limitations before achieving deployability in real-world mental health
settings, such as known racial and gender bias. We highlight the important
ethical risks accompanying this line of research.",2023,http://arxiv.org/abs/2307.14385v4,http://arxiv.org/pdf/2307.14385v4,"32

4
2
0
2

n
a
J

8
2

]
L
C
.
s
c
[

4
v
5
8
3
4
1
.
7
0
3
2
:
v
i
X
r
a

Mental-LLM: Leveraging Large Language Models for Mental Health
Prediction via Online Text Data
XUHAI XU, Massachusetts Institute of Technology & University of Washington, USA
BINGSHENG YAO, Rensselaer Polytechnic Institute, USA
YUANZHE DONG, Stanford University, USA
SAADIA GABRIEL, Massachusetts Institute of Technology, USA
HONG YU, University of Massachusetts Lowell, USA
JAMES HENDLER, Rensselaer Polytechnic Institute, USA
MARZYEH GHASSEMI, Massachusetts Institute of Technology, USA
ANIND K. DEY, University of Washington, USA
DAKUO WANG, Northeastern University, USA

Advances in large language models (LLMs) have empowered a variety of applications. However, there is still a significant
gap in research when it comes to understanding and enhancing the capabilities of LLMs in the field of mental health. In this
work, we present a comprehensive evaluation of multiple LLMs on various mental health prediction tasks via online text data,
including Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4. We conduct a broad range of experiments, covering zero-shot
prompting, few-shot prompting, and instruction fine-tuning. The results indicate a promising yet limited performance of
LLMs with zero-shot and few-shot prompt designs for mental health tasks. More importantly, our experiments show that
instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned
models, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of GPT-3.5 (25 and 15 times bigger) by
10.9% on balanced accuracy and the best of GPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with
the state-of-the-art task-specific language model. We also conduct an exploratory case study on LLMs’ capability on mental
health reasoning tasks, illustrating the promising capability of certain models such as GPT-4. We summarize our findings into
a set of action guidelines for potential methods to enhance LLMs’ capability for mental health tasks. Meanwhile, we also
emphasize the important limitations before achieving deployability in real-world mental health settings, such as known racial
and gender bias. We highlight the important ethical risks accompanying this line of research.

CCS Concepts: • Human-centered computing → Ubiquitous and mobile computing; • Applied computing → Life
and medical sciences.

Additional Key Words and Phrases: Mental Health, Large Language Model, Instruction Finetuning

ACM Reference Format:
Xuhai Xu, Bingsheng Yao, Yuanzhe Dong, Saadia Gabriel, Hong Yu, James Hendler, Marzyeh Ghassemi, Anind K. Dey,
and Dakuo Wang. 2024. Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 8, 1, Article 32 (March 2024), 32 pages. https://doi.org/10.1145/3643540

Authors’ addresses: Xuhai Xu, xuhaixu@uw.edu, Massachusetts Institute of Technology & University of Washington, USA; Bingsheng Yao,
Rensselaer Polytechnic Institute, USA; Yuanzhe Dong, Stanford University, USA; Saadia Gabriel, Massachusetts Institute of Technology, USA;
Hong Yu, University of Massachusetts Lowell, USA; James Hendler, Rensselaer Polytechnic Institute, USA; Marzyeh Ghassemi, Massachusetts
Institute of Technology, USA; Anind K. Dey, University of Washington, USA; Dakuo Wang, Northeastern University, USA.

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that
copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy
otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from
permissions@acm.org.
© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
2474-9567/2024/3-ART32 $15.00
https://doi.org/10.1145/3643540

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 8, No. 1, Article 32. Publication date: March 2024.

 
 
 
 
 
 
32:2

• Xu et al.

1

INTRODUCTION

The recent surge of Large Language Models (LLMs), such as GPT-4 [18], PaLM [23], FLAN-T5 [24], and Al-
paca [115], demonstrates the promising capability of large pre-trained models to solve various tasks in zero-shot
settings (i.e., tasks not encountered during training). Example tasks include question answering [87, 100], logic
reasoning [124, 135], machine translation [15, 45], etc. A number of experiments have revealed that, built on
hundreds of billions of parameters, these LLMs have started to show the capability to understand the human
common sense beneath the natural language and do proper reasoning and inference accordingly [18, 85].

Among d"
"FedTherapist: Mental Health Monitoring with User-Generated Linguistic
  Expressions on Smartphones via Federated Learning","['Jaemin Shin', 'Hyungjun Yoon', 'Seungjoo Lee', 'Sungjoon Park', 'Yunxin Liu', 'Jinho D. Choi', 'Sung-Ju Lee']","Psychiatrists diagnose mental disorders via the linguistic use of patients.
Still, due to data privacy, existing passive mental health monitoring systems
use alternative features such as activity, app usage, and location via mobile
devices. We propose FedTherapist, a mobile mental health monitoring system that
utilizes continuous speech and keyboard input in a privacy-preserving way via
federated learning. We explore multiple model designs by comparing their
performance and overhead for FedTherapist to overcome the complex nature of
on-device language model training on smartphones. We further propose a
Context-Aware Language Learning (CALL) methodology to effectively utilize
smartphones' large and noisy text for mental health signal sensing. Our
IRB-approved evaluation of the prediction of self-reported depression, stress,
anxiety, and mood from 46 participants shows higher accuracy of FedTherapist
compared with the performance with non-language features, achieving 0.15 AUROC
improvement and 8.21% MAE reduction.",2023,http://arxiv.org/abs/2310.16538v1,http://arxiv.org/pdf/2310.16538v1,"FedTherapist: Mental Health Monitoring with User-Generated
Linguistic Expressions on Smartphones via Federated Learning

Jaemin Shin1, Hyungjun Yoon1, Seungjoo Lee1, Sungjoon Park2,
Yunxin Liu3, Jinho D. Choi4, Sung-Ju Lee1
1KAIST 2SoftlyAI 3Tsinghua University 4Emory University
{jaemin.shin, hyungjun.yoon, seungjoo.lee, profsj}@kaist.ac.kr,

sungjoon.park@softly.ai, liuyunxin@air.tsinghua.edu.cn, jinho.choi@emory.edu

Abstract

Psychiatrists diagnose mental disorders via the
linguistic use of patients. Still, due to data
privacy, existing passive mental health mon-
itoring systems use alternative features such
as activity, app usage, and location via mo-
bile devices. We propose FedTherapist, a mo-
bile mental health monitoring system that uti-
lizes continuous speech and keyboard input in
a privacy-preserving way via federated learn-
ing. We explore multiple model designs by
comparing their performance and overhead for
FedTherapist to overcome the complex nature
of on-device language model training on smart-
phones. We further propose a Context-Aware
Language Learning (CALL) methodology to ef-
fectively utilize smartphones’ large and noisy
text for mental health signal sensing. Our IRB-
approved evaluation of the prediction of self-
reported depression, stress, anxiety, and mood
from 46 participants shows higher accuracy of
FedTherapist compared with the performance
with non-language features, achieving 0.15 AU-
ROC improvement and 8.21% MAE reduction.

1

Introduction

Nearly a billion people worldwide are living with
mental disorders, which seriously affect one’s cog-
nition, emotion regulation, and behavior. Early
diagnosis and proper treatment are the keys to alle-
viating the negative impact of the mental disor-
der (Sharp and Lipsky, 2002). However, most
patients have been unaware of their disorder for
years (Epstein et al., 2010), which delays treatment
while the symptoms worsen.

Given their ubiquity in users’ lives, researchers
have leveraged smartphones to resolve this un-
awareness problem, using features such as phone
usage patterns, location, and activity for seam-
less mental health monitoring (LiKamWa et al.,
2013; Wang et al., 2014, 2018; Li and Sano, 2020;
Tlachac et al., 2022a). However, these features fail
to reflect how licensed psychiatrists diagnose men-

tal disorders by conversing with patients (Murphy
et al., 2000). While analyzing linguistic use is ideal
for monitoring smartphone users’ mental health,
substantial privacy concerns it raises present chal-
lenges in amassing sufficient data to train advanced
NLP neural networks (Devlin et al., 2019).

We propose FedTherapist, a privacy-preserving
mental health monitoring system that leverages
user-generated text (speech and keyboard) on
smartphones via Federated Learning (FL). FL de-
centralizes model training on client devices (e.g.,
smartphones) using locally stored data (McMahan
et al., 2016), ensuring privacy on FedTherapist by
only collecting securely aggregated model updates.
For a detailed introduction to FL, see Appendix A.
Despite recent advances in FL + NLP (Lin et al.,
2022; Xu et al., 2023; Zhang et al., 2023a), on-
device training (i.e., training on smartphones) of
language models for mental status monitoring re-
mains unexplored. We explore the best model de-
sign for FedTherapist across multiple candidates,
including Large Language Models (LLMs), by
comparing their mental health monitoring perfor-
mance and smartphone overhead.

In realizing FedTherapist, the challenge remains
to effectively capture mental health-related signals
from a large corpus of spoken and typed user lan-
guage on smartphones, which differs from prior
NLP mental health studies based on social me-
dia (Yates et al., 2017; Park et al., 2020) – see
Appendix G. To address such a challenge, we pro-
pose Context-Aware Language Learning (CALL)
methodology, which integrates various temporal
contexts of users (e.g., time, location) captured on
smartphones to enhance the model’s ability to sense
mental health signals from the text data. Our eval-
uation of 46 participants shows that FedTherapist
with CALL achieves more accurate mental health
prediction than the model trained with non-text
data (Wang et al., 2018), achieving 0.15 AUROC
improvement and 8.21% reduction in MAE.

3
2
0
2

t
c
O
5
2

]
L
C
.
s
c
[

1
v
8
3
5
6
1
.
0
1
3
2
:
v
i
X
r
a

 
 
 
 
 
 
2 Data Collection

We conducted an IRB (Institutional Review Board)-
approved data collection study to evaluate FedTher-
apist on real-world user data. Although FL works
without user data collection, we collected the data
to fully explore the potential of smartphone text
data on mental health monitoring. We recruited
52 participants over the Amazon Mechanical Turk
(MTurk) who identified English as the first and
only language they use daily. Participants collected
data for 10 days on our Android application, where
we provided no instructions or restrictions to the
participants’ behavior during the stud"
"Gender differences of the effect of vaccination on perceptions of
  COVID-19 and mental health in Japan","['Eiji Yamamura', 'Youki Kosaka', 'Yoshiro Tsutsui', 'Fumio Ohtake']","Vaccination has been promoted to mitigate the spread of the coronavirus
disease 2019 (COVID-19). Vaccination is expected to reduce the probability of
and alleviate the seriousness of COVID-19 infection. Accordingly, this might
significantly change an individuals subjective well-being and mental health.
However, it is unknown how vaccinated people perceive the effectiveness of
COVID-19 and how their subjective well-being and mental health change after
vaccination. We thus observed the same individuals on a monthly basis from
March 2020 to September 2021 in all parts of Japan. Then, large sample panel
data (N=54,007) were independently constructed. Using the data, we compared the
individuals perceptions of COVID-19, subjective well-being, and mental health
before and after vaccination. Furthermore, we compared the effect of
vaccination on the perceptions of COVID-19 and mental health for females and
males. We used the fixed-effects model to control for individual time-invariant
characteristics. The major findings were as follows: First, the vaccinated
people perceived the probability of getting infected and the seriousness of
COVID-19 to be lower than before vaccination. This was observed not only when
we used the whole sample, but also when we used sub-samples. Second, using the
whole sample, subjective well-being and mental health improved. The same
results were also observed using the sub-sample of females, whereas the
improvements were not observed using a sub-sample of males.",2022,http://arxiv.org/abs/2203.07663v1,http://arxiv.org/pdf/2203.07663v1,"Gender  differences  of  the  effect  of  vaccination  on  perceptions  of 

COVID-19 and mental health in Japan 

Eiji Yamamura1*, Youki Kosaka2, Yoshiro Tsutsui3, Fumio Ohtake4, 

1  Department  of  Economics,  Seinan  Gakuin  University,  Fukuoka,  Japan  2  Kyoto 

Economic College, Japan 3 Kyoto-Bunkyo University, Japan 4 Osaka University, Japan 

Abstract 

Vaccination  has  been  promoted  to  mitigate  the  spread  of  the  coronavirus  disease 

2019 (COVID-19). Vaccination is expected to reduce the probability of and alleviate the 

seriousness  of  COVID-19  infection.  Accordingly,  this  might  significantly  change  an 

individual’s  subjective  well-being  and  mental  health.  However,  it  is  unknown  how 

vaccinated people perceive the effectiveness of COVID-19 and how their subjective well-

being and mental health change after vaccination. We thus observed the same individuals 

on a monthly basis from March 2020 to September 2021 in all parts of Japan. Then, large 

sample  panel  data  (N=54,007)  were  independently  constructed.  Using  the  data,  we 

compared the individuals’ perceptions of COVID-19, subjective well-being, and mental 

health before and after vaccination. Furthermore, we compared the effect of vaccination 
on the perceptions of COVID-19 and mental health for females and males. We used the 
fixed-effects  model  to  control  for  individual  time-invariant  characteristics.  The  major 

findings were as follows: First, the vaccinated people perceived the probability of getting 

infected and the seriousness of COVID-19 to be lower than before vaccination. This was 

observed not only when we used the whole sample, but also when we used sub-samples. 
Second, using the whole sample, subjective well-being and mental health improved. The 

same  results  were  also  observed  using  the  sub-sample  of  females,  whereas  the 

improvements were not observed using a sub-sample of males.   

Keywords: Vaccination, COVID-19, Subjective well-being, Mental health, Japan, Panel 

data. 

1 

 
 
 
 
 
1. Introduction 

Vaccination against the coronavirus disease 2019 (COVID-19) is anticipated to play 

a  critical  role  in  mitigating  the  spread  of  COVID-19.  Many  newly  reported  cases  of 

COVID-19  have  been  reduced  in  countries  where  vaccines  have  become  rapidly 

pervasive(WHO  Coronavirus  (COVID-19)  Dashboard  2021).  Through  scientific 

experiments,  the  COVID-19  vaccine  reduced  the  probability  of  infection  and  the 

seriousness of COVID-19. The sufficient rate of the vaccinated population in society must 

reach herd immunity to terminate the COVID-19 pandemic(Randolph and Barreiro 2020). 

However, some individuals hesitate to receive the COVID-19 vaccine(Almaghaslah et al. 

2021a; Lucia, Kelekar, and Afonso 2021a; Machingaidze and Wiysonge 2021a; Murphy 

et  al.  2021a;  Solís  Arce  et  al.  2021).  Their  attitude  may  change  if  they  know  that 

vaccinated people have  a  more positive view about  the vaccination  after  receiving the 

vaccine.  Therefore,  how  and  the  extent  to  which  the  subjective  views  about  the 

effectiveness  of  the  COVID-9  vaccine  changes  after  one  gets  vaccinated  should  be 

examined.   

Various  measures  against  COVID-19,  such  as  lockdown  restrictions,  cause 

significant  economic  loss(Inoue,  Murase,  and  Todo  2021;  Mottaleb,  Mainuddin,  and 

Sonobe 2020) and exert a detrimental impact on individuals’ mental health(Chinna et al. 

2 

 
2021; Fiorenzato et al. 2021; Greyling, Rossouw, and Adhikari 2021; Ogden 2021). In 

Japan, even without enforcement, individuals voluntarily exhibit preventive behaviors, 

such  as  staying  indoors  and  avoiding  face-to-face  conversations(Muto  et  al.  2020; 

Watanabe  and  Yabu  2021;  Yamamura  and  Tsutsui  2020).  Accordingly,  this  changed 

lifestyle, for instance, lack of exercise and short sleep duration, results  in  a decline  in 

mental health(Nagasu and Yamamoto 2020; Yamamura and Tsustsui 2021a; Yamamura 

and  Tsutsui  2020).  Vaccination  is  anticipated  to  reduce  the  probability  of  contracting 

COVID-19; thus, vaccinated individuals can return to normal daily life. This return to 

normal daily life improves subjective well-being and mental health, so vaccination for 

people with mental illness is necessary(Mazereel et al. 2021a, 2021b; Siva 2021; Warren, 

Kisely, and Siskind 2021). 

The mental conditions of vaccinated individuals improved in the U.S(Perez-Arce et 

al.  2021).  However,  hesitancy 

to  be  vaccinated  was  observed 

in  various 

countries(Almaghaslah et al. 2021b; Machingaidze and Wiysonge 2021b; Murphy et al. 

2021b; Solís Arce et al. 2021). This has hampered the establishment of herd immunity 

and increased social costs caused by COVID-19. Furthermore, people are less likely to 

receive the vaccination  and to trust health experts(Lucia, Kelekar, and Afonso 2021b)."
"The Relationship between Deteriorating Mental Health Conditions and
  Longitudinal Behavioral Changes in Google and YouTube Usages among College
  Students in the United States during COVID-19: Observational Study","['Anis Zaman', 'Boyu Zhang', 'Ehsan Hoque', 'Vincent Silenzio', 'Henry Kautz']","Mental health problems among the global population are worsened during the
coronavirus disease (COVID-19). How individuals engage with online platforms
such as Google Search and YouTube undergoes drastic shifts due to pandemic and
subsequent lockdowns. Such ubiquitous daily behaviors on online platforms have
the potential to capture and correlate with clinically alarming deteriorations
in mental health profiles in a non-invasive manner. The goal of this study is
to examine, among college students, the relationship between deteriorating
mental health conditions and changes in user behaviors when engaging with
Google Search and YouTube during COVID-19. This study recruited a cohort of 49
students from a U.S. college campus during January 2020 (prior to the pandemic)
and measured the anxiety and depression levels of each participant. This study
followed up with the same cohort during May 2020 (during the pandemic), and the
anxiety and depression levels were assessed again. The longitudinal Google
Search and YouTube history data were anonymized and collected. From
individual-level Google Search and YouTube histories, we developed 5 signals
that can quantify shifts in online behaviors during the pandemic. We then
assessed the differences between groups with and without deteriorating mental
health profiles in terms of these features. Significant features included
late-night online activities, continuous usages, and time away from the
internet, porn consumptions, and keywords associated with negative emotions,
social activities, and personal affairs. Though further studies are required,
our results demonstrated the feasibility of utilizing pervasive online data to
establish non-invasive surveillance systems for mental health conditions that
bypasses many disadvantages of existing screening methods.",2020,http://arxiv.org/abs/2009.09076v1,http://arxiv.org/pdf/2009.09076v1,"Original Paper 

The Relationship between Deteriorating Mental Health 
Conditions and Longitudinal Behavioral Changes in Google and 
YouTube Usages among College Students in the United States 
during COVID-19: Observational Study 

1Anis	Zaman*,	1Boyu	Zhang*,	1Ehsan	Hoque,	2Vincent	Silenzio,	1Henry	Kautz	

1Department	of	Computer	Science,	University	of	Rochester,	Rochester,	NY,	USA	

2Department	of	Urban-Global	Public	Health,	Rutgers	University,	Jersey	City,	NJ,	USA	

*Equal	Contribution	

Correspondence	to	

Mr.	Boyu	Zhang	

Department	of	Computer	Science,	University	of	Rochester,	Rochester,	NY	14627,	

USA	

E-mail:	bzhang25@u.rochester.edu	

&	

Mr.	Anis	Zaman	

Department	of	Computer	Science,	University	of	Rochester,	Rochester,	NY	14627,	

USA	

E-mail:	azaman2@cs.rochester.edu	

Abstract 
Background:	Mental	health	problems	among	the	global	population	are	worsened	
during	the	coronavirus	disease	(COVID-19).	Yet,	current	methods	for	screening	
mental	health	issues	rely	on	in-person	interviews,	which	can	be	expensive,	time-
consuming,	blocked	by	social	stigmas	and	quarantines.	Meanwhile,	how	individuals	
engage	with	online	platforms	such	as	Google	Search	and	YouTube	undergoes	drastic	
shifts	due	to	COVID-19	and	subsequent	lockdowns.	Such	ubiquitous	daily	behaviors	
on	online	platforms	have	the	potential	to	capture	and	correlate	with	clinically	
alarming	deteriorations	in	mental	health	profiles	of	users	in	a	non-invasive	manner.	

	
	
	
	
Objective:	The	goal	of	this	study	is	to	examine,	among	college	students	in	the	United	
States,	the	relationship	between	deteriorating	mental	health	conditions	and	changes	
in	user	behaviors	when	engaging	with	Google	Search	and	YouTube	during	COVID-19.	

Methods:	This	study	recruited	a	cohort	of	undergraduate	students	(N=49)	from	a	
U.S.	college	campus	during	January	2020	(prior	to	the	pandemic)	and	measured	the	
anxiety	and	depression	levels	of	each	participant.	The	anxiety	level	was	assessed	via	
the	General	Anxiety	Disorder-7	(GAD-7).	The	depression	level	was	assessed	via	the	
Patient	Health	Questionnaire-9	(PHQ-9).	This	study	followed	up	with	the	same	
cohort	during	May	2020	(during	the	pandemic),	and	the	anxiety	and	depression	
levels	were	assessed	again.	The	longitudinal	Google	Search	and	YouTube	history	
data	of	all	participants	were	anonymized	and	collected.	From	individual-level	
Google	Search	and	YouTube	histories,	we	developed	5	signals	that	can	quantify	
shifts	in	online	behaviors	during	the	pandemic.	We	then	assessed	the	differences	
between	groups	with	and	without	deteriorating	mental	health	profiles	in	terms	of	
these	features.		

Results:	Of	the	49	participants,	41%	(n=20)	of	them	reported	a	significant	increase	
(increase	in	the	PHQ-9	score	³	5)	in	depression,	denoted	as	DEP;	45%	(n=22)	of	
them	reported	a	significant	increase	(increase	in	the	GAD-7	score	³	5)	in	anxiety,	
denoted	as	ANX.	Of	the	5	features	proposed	to	quantify	online	behavior	changes,	
statistical	significances	were	found	between	the	DEP	and	non-DEP	groups	for	all	of	
them	(P£.01,	effect	sizes	𝜂!""#$%""&
significances	were	found	between	the	ANX	and	non-ANX	groups	for	4	of	them	
(P£.02,	effect	sizes	𝜂!""#$%""&
	ranging	between	0.115	to	0.231).	Significant	features	
included	late-night	online	activities,	continuous	usages	and	time	away	from	the	
internet,	porn	consumptions,	and	keywords	associated	with	negative	emotions,	
social	activities,	and	personal	affairs.	

	ranging	between	0.130	to	0.320);	statistical	

’

’

Conclusions:	The	results	suggested	strong	discrepancies	between	college	student	
groups	with	and	without	deteriorating	mental	health	conditions	in	terms	of	
behavioral	changes	in	Google	Search	and	YouTube	usages	during	the	COVID-19.	
Though	further	studies	are	required,	our	results	demonstrated	the	feasibility	of	
utilizing	pervasive	online	data	to	establish	non-invasive	surveillance	systems	for	
mental	health	conditions	that	bypasses	many	disadvantages	of	existing	screening	
methods.		

Keywords:	mental	health;	anxiety;	depression;	Google	Search;	YouTube;	pandemic;	
COVID-19	

Introduction 

Background 
Globally,	mental	health	problems	such	as	depression,	anxiety,	and	suicide	ideations	
are	severely	worsened	during	the	coronavirus	disease	(COVID-19)	[1–3],	specifically	

	
	
	
	
	
for	college	students	[4,5–7].	Yet,	current	methods	for	screening	mental	health	issues	
and	identifying	vulnerable	individuals	rely	on	in-person	interviews.	Such	
assessments	can	be	expensive,	time-consuming,	and	blocked	by	social	stigmas,	not	
to	mention	the	reluctancy	induced	by	travel	restrictions	and	exposure	risks.	It	has	
been	reported	that	very	few	patients	in	need	were	correctly	identified	and	received	
proper	mental	health	treatments	on	time	under	the	current	healthcare	system	[8,9].	
Even	with	emerging	Telehealth	technologies	and	online	surveys,	the	screening	
requires	patients	to	actively	reach	out	to	care	providers.		

At	the	same	time,	because	of	the	lockdown	enforced	by	the	global	pandemic	"
Towards Interpretable Mental Health Analysis with Large Language Models,"['Kailai Yang', 'Shaoxiong Ji', 'Tianlin Zhang', 'Qianqian Xie', 'Ziyan Kuang', 'Sophia Ananiadou']","The latest large language models (LLMs) such as ChatGPT, exhibit strong
capabilities in automated mental health analysis. However, existing relevant
studies bear several limitations, including inadequate evaluations, lack of
prompting strategies, and ignorance of exploring LLMs for explainability. To
bridge these gaps, we comprehensively evaluate the mental health analysis and
emotional reasoning ability of LLMs on 11 datasets across 5 tasks. We explore
the effects of different prompting strategies with unsupervised and distantly
supervised emotional information. Based on these prompts, we explore LLMs for
interpretable mental health analysis by instructing them to generate
explanations for each of their decisions. We convey strict human evaluations to
assess the quality of the generated explanations, leading to a novel dataset
with 163 human-assessed explanations. We benchmark existing automatic
evaluation metrics on this dataset to guide future related works. According to
the results, ChatGPT shows strong in-context learning ability but still has a
significant gap with advanced task-specific methods. Careful prompt engineering
with emotional cues and expert-written few-shot examples can also effectively
improve performance on mental health analysis. In addition, ChatGPT generates
explanations that approach human performance, showing its great potential in
explainable mental health analysis.",2023,http://arxiv.org/abs/2304.03347v4,http://arxiv.org/pdf/2304.03347v4,"Towards Interpretable Mental Health Analysis with Large Language
Models

Kailai Yang 1

Shaoxiong Ji ∗ 2 Tianlin Zhang ∗ 1 Qianqian Xie †1
Sophia Ananiadou 1,3

Ziyan Kuang 4
1 The University of Manchester

2 University of Helsinki

3 Artificial Intelligence Research Center, AIST

4 Jiangxi Normal University

{kailai.yang,tianlin.zhang}@postgrad.manchester.ac.uk; shaoxiong.ji@helsinki.fi
sophia.ananiadou@manchester.ac.uk; {xqq.sincere,plumjane1225}@gmail.com

3
2
0
2

t
c
O
1
1

]
L
C
.
s
c
[

4
v
7
4
3
3
0
.
4
0
3
2
:
v
i
X
r
a

Abstract

The latest large language models (LLMs) such
as ChatGPT, exhibit strong capabilities in au-
tomated mental health analysis. However,
existing relevant studies bear several limita-
tions, including inadequate evaluations, lack of
prompting strategies, and ignorance of explor-
ing LLMs for explainability. To bridge these
gaps, we comprehensively evaluate the mental
health analysis and emotional reasoning abil-
ity of LLMs on 11 datasets across 5 tasks. We
explore the effects of different prompting strate-
gies with unsupervised and distantly super-
vised emotional information. Based on these
prompts, we explore LLMs for interpretable
mental health analysis by instructing them to
generate explanations for each of their deci-
sions. We convey strict human evaluations to
assess the quality of the generated explanations,
leading to a novel dataset with 163 human-
assessed explanations1. We benchmark existing
automatic evaluation metrics on this dataset to
guide future related works. According to the
results, ChatGPT shows strong in-context learn-
ing ability but still has a significant gap with ad-
vanced task-specific methods. Careful prompt
engineering with emotional cues and expert-
written few-shot examples can also effectively
improve performance on mental health analysis.
In addition, ChatGPT generates explanations
that approach human performance, showing
its great potential in explainable mental health
analysis.

1

Introduction

WARNING: This paper contains examples and de-
scriptions that are depressive in nature.

Mental health conditions such as depression
and suicidal ideation seriously challenge global

∗ Equal contribution, listed alphabetically.
† Corresponding author. Qianqian is now affiliated with
Yale University. The work was done when she was at The
University of Manchester.
data

https://github.com/

released

1The

at

is

SteveKGYang/MentalLLaMA

health care (Zhang et al., 2022a). NLP researchers
have devoted much effort to automatic mental
health analysis, with current mainstream meth-
ods leveraging the Pre-trained Language Models
(PLMs) (Yang et al., 2022; Abed-Esfahani et al.,
2019). Most recently Large Language Models
(LLMs) (Brown et al., 2020; Ouyang et al., 2022),
especially ChatGPT 2 and GPT-4 (OpenAI, 2023),
have exhibited strong general language processing
ability (Wei et al., 2022; Luo et al., 2023; Yuan
et al., 2023). In mental health analysis, Lamich-
hane (2023) evaluated ChatGPT on stress, depres-
sion, and suicide detection and glimpsed its strong
language understanding ability to mental health-
related texts. Amin et al. (2023) compared the zero-
shot performance of ChatGPT on suicide and de-
pression detection with previous fine-tuning-based
methods.

Though previous works depict a promising fu-
ture for a new LLM-based paradigm in mental
health analysis, several issues remain unresolved.
Firstly, mental health condition detection is a safe-
critical task requiring careful evaluation and high
transparency for any predictions (Zhang et al.,
2022a), while these works simply tested on a few
binary mental health condition detection tasks and
lack the explainability on detection results. More-
over, other important mental health analysis tasks,
such as the cause/factor detection of mental health
conditions (Mauriello et al., 2021; Garg et al.,
2022), were ignored. Secondly, previous works
mostly use simple prompts to detect mental health
conditions directly. These vanilla methods ig-
nore useful information, especially emotional cues,
which are widely utilized for mental health analysis
in previous works (Zhang et al., 2023). We believe
it requires a comprehensive exploration and evalu-
ation of the ability and explainability of LLMs on
mental health analysis, including mental health de-
tection, emotional reasoning, and cause detection

2https://openai.com/blog/chatgpt

 
 
 
 
 
 
Figure 1: The pipeline of obtaining and evaluating the LLM-generated explanations for mental health analysis.
In LLM responses, red, green, and blue words are marked as relevant clues for rating fluency, reliability, and
completeness in human evaluations.

of mental health conditions. Therefore, we raise
the following three research questions (RQ):

• RQ 1: How well can LLMs perform in gen-
eralized mental health analysis and emotional
reasoning with zero-shot/few-shot settings?

• RQ 2: How do different prompting strategies
and emotional cues impact the mental "
Discovering Mental Health Research Topics with Topic Modeling,"['Xin Gao', 'Cem Sazara']","Mental health significantly influences various aspects of our daily lives,
and its importance has been increasingly recognized by the research community
and the general public, particularly in the wake of the COVID-19 pandemic. This
heightened interest is evident in the growing number of publications dedicated
to mental health in the past decade. In this study, our goal is to identify
general trends in the field and pinpoint high-impact research topics by
analyzing a large dataset of mental health research papers. To accomplish this,
we collected abstracts from various databases and trained a customized
Sentence-BERT based embedding model leveraging the BERTopic framework. Our
dataset comprises 96,676 research papers pertaining to mental health, enabling
us to examine the relationships between different topics using their abstracts.
To evaluate the effectiveness of the model, we compared it against two other
state-of-the-art methods: Top2Vec model and LDA-BERT model. The model
demonstrated superior performance in metrics that measure topic diversity and
coherence. To enhance our analysis, we also generated word clouds to provide a
comprehensive overview of the machine learning models applied in mental health
research, shedding light on commonly utilized techniques and emerging trends.
Furthermore, we provide a GitHub link* to the dataset used in this paper,
ensuring its accessibility for further research endeavors.",2023,http://arxiv.org/abs/2308.13569v1,http://arxiv.org/pdf/2308.13569v1,"Discovering Mental Health Research Topics with Topic Modeling

Xin Gao 1 Cem Sazara 1

Abstract

Mental health significantly influences various as-
pects of our daily lives, and its importance has
been increasingly recognized by the research com-
munity and the general public, particularly in the
wake of the COVID-19 pandemic. This height-
ened interest is evident in the growing number of
publications dedicated to mental health in the past
decade. In this study, our goal is to identify gen-
eral trends in the field and pinpoint high-impact
research topics by analyzing a large dataset of
mental health research papers. To accomplish this,
we collected abstracts from various databases and
trained a customized Sentence-BERT based em-
bedding model leveraging the BERTopic frame-
work. Our dataset comprises 96,676 research pa-
pers pertaining to mental health, enabling us to
examine the relationships between different top-
ics using their abstracts. To evaluate the effective-
ness of the model, we compared it against two
other state-of-the-art methods: Top2Vec model
and LDA-BERT model. The model demonstrated
superior performance in metrics that measure
topic diversity and coherence. To enhance our
analysis, we also generated word clouds to pro-
vide a comprehensive overview of the machine
learning models applied in mental health research,
shedding light on commonly utilized techniques
and emerging trends. Furthermore, we provide
a GitHub link* to the dataset used in this paper,
ensuring its accessibility for further research en-
deavors.

3
2
0
2

g
u
A
5
2

]
L
C
.
s
c
[

1
v
9
6
5
3
1
.
8
0
3
2
:
v
i
X
r
a

1. Introduction

The COVID-19 pandemic, which has significantly impacted
our lifestyle for nearly two years, has led to a rise in psy-

1Amazon Web Services, Seattle, WA, USA. Correspondence

to: Xin Gao <goxi@amazon.com>.

Workshop on Interpretable ML in Healthcare at International Con-
ference on Machine Learning (ICML), Honolulu, Hawaii, USA.
2023. Copyright 2023 by the author(s).

*https://github.com/stella-gao/Mental-Health-Research-Paper-

Dataset

1

chosocial stressors and mental health problems. Conse-
quently, there has been a notable surge in mental health
research as a response to these challenges. To understand
the specific topics studied by the research community, we
employed topic modeling methods on the titles and abstracts
of conference and journal research papers focused on men-
tal health field. Our primary objective is to identify studies
aimed at improving mental health and analyze the prominent
research topics of the past decade.

To accomplish this, we collected abstracts from various
databases, including arXiv, ACM, bioRxiv, medRxiv, and
PubMed, spanning the period from Jan 2010 to March 2023.
This extensive dataset reveals a growing interest in mental
health-related research during the last decade, with a signifi-
cant peak occurring during the COVID-19 pandemic. Our
study aims to identify key trends and significant research
topics by analyzing a dataset of 96,676 research papers. To
extract meaningful insights from the dataset, we employed a
Sentence-BERT based embedding model called BERTopic
(Grootendorst, 2022). BERTopic generates document em-
beddings and clusters them into semantically coherent top-
ics, enabling further analysis. By applying this model, we
can identify specific concepts associated with each topic,
providing a basis for further analysis and investigation. For
instance, the topic related to suicide prominently includes
terms such as “suicidal,” “ideation,” and “attempt.” These
identified topics may help uncover interdisciplinary connec-
tions and foster collaboration among different fields.

In evaluating our approach, we conducted performance eval-
uation using various metrics (Ferdinand Kapl, 2022). These
metrics included TD (Topic Distinctiveness/Diversity), mea-
suring topic uniqueness and diversity. Inv. RBO (Inverted
Rank-Biased Overlap) evaluates topic coherence and word
order similarity. NPMI (Normalized Pointwise Mutual In-
formation) measures semantic coherence within topics by
calculating the average pairwise similarity between words
within a topic. Cv (Coefficient of Topic Coherence) as-
sesses coherence among top-ranked words. Higher metric
values indicate better topic coherence and interpretability.
By evaluating these metrics, we optimized topic model-
ing by experimenting with hyperparameters. Our goal was
to find the configuration that yielded topics with high co-
herence, diversity, and interpretability, as indicated by the
metrics mentioned above. These performance evaluation

 
 
 
 
 
 
Discovering Mental Health Research Topics with Topic Modeling

metrics provided valuable insights into the quality of the
generated topics and guided our decision-making process
in selecting the values that optimized the topic modeling
results. We evaluated the BERTopic based model’s effec-
tiveness by comparing it against two other state-of-the-art
methods, "
"Canada Protocol: an ethical checklist for the use of Artificial
  Intelligence in Suicide Prevention and Mental Health","['Carl-Maria Mörch', 'Abhishek Gupta', 'Brian L. Mishara']","Introduction: To improve current public health strategies in suicide
prevention and mental health, governments, researchers and private companies
increasingly use information and communication technologies, and more
specifically Artificial Intelligence and Big Data. These technologies are
promising but raise ethical challenges rarely covered by current legal systems.
It is essential to better identify, and prevent potential ethical risks.
Objectives: The Canada Protocol - MHSP is a tool to guide and support
professionals, users, and researchers using AI in mental health and suicide
prevention. Methods: A checklist was constructed based upon ten international
reports on AI and ethics and two guides on mental health and new technologies.
329 recommendations were identified, of which 43 were considered as applicable
to Mental Health and AI. The checklist was validated, using a two round Delphi
Consultation. Results: 16 experts participated in the first round of the Delphi
Consultation and 8 participated in the second round. Of the original 43 items,
38 were retained. They concern five categories: ""Description of the Autonomous
Intelligent System"" (n=8), ""Privacy and Transparency"" (n=8), ""Security"" (n=6),
""Health-Related Risks"" (n=8), ""Biases"" (n=8). The checklist was considered
relevant by most users, and could need versions tailored to each category of
target users.",2019,http://arxiv.org/abs/1907.07493v1,http://arxiv.org/pdf/1907.07493v1,"Canada Protocol: an ethical checklist for the use of Artificial Intelligence in 
Suicide Prevention and Mental Health 

Carl-Maria Mörch, M.Psy., Ph.D. Student1 

Contribution : Lead researcher, study design, writing, coordinated the validation 
Abhishek Gupta, B.A.2 

Contribution : Co-author, co-designed the checklist, participated to the selection of the checklist’s items.  

Brian L. Mishara, Ph.D.3 

Contribution : Scientific supervision, complete revisions 

Abstract 

Introduction: To improve current public health strategies in suicide prevention and mental health, governments, 
researchers and private companies increasingly use information and communication technologies, and more 
specifically Artificial Intelligence and Big Data. These technologies are promising but raise ethical challenges rarely 
covered by current legal systems. It is essential to better identify, and prevent potential ethical risks. Objectives: The 
Canada Protocol - MHSP is a tool to guide and support professionals, users, and researchers using AI in mental 
health and suicide prevention. Methods: A checklist was constructed based upon ten international reports on AI and 
ethics and two guides on mental health and new technologies. 329 recommendations were identified, of which 43 
were considered as applicable to Mental Health and AI. The checklist was validated, using a two round Delphi 
Consultation. Results: 16 experts participated in the first round of the Delphi Consultation and 8 participated in the 
second round. Of the original 43 items, 38 were retained. They concern five categories: ""Description of the 
Autonomous Intelligent System"" (n=8), ""Privacy and Transparency"" (n=8), ""Security"" (n=6), ""Health-Related 
Risks"" (n=8), ""Biases"" (n=8). The checklist was considered relevant by most users, and could need versions tailored 
to each category of target users. 

Funding: This article has not been funded.  

Conflict of Interests: The authors declare no conflict of interests.  

Ethics: In agreement with the Université du Québec à Montréal’s ethics board rules, this research did not include 
any sensitive or identifiable information on individuals.  

1 Centre for Research and Intervention on Suicide, Ethical Issues and End of Life Practices (CRISE) 

Psychology Department, Université du Québec à Montréal 
c.p. 8888, Succ. Centre-Ville, Montréal, Québec, H3C 3P8, Canada 
cmmorch@gmail.com  
2 Montreal AI Ethics Institute, Canada 

Microsoft, Montreal, Canada 

3  Centre for Research and Intervention on Suicide, Ethical Issues and End of Life Practices (CRISE) 

Psychology Department, Université du Québec à Montréal 

 
 
 
 
 
 
                                                
 
Table 1 : The Canada Protocol – the ethical checklist 

DESCRIPTION 

Objectives 

Technology 

Funding & 
conflict of interest 

Credentials 

Target population 

Evidence 

Testing 

Complaints 

Describe your project's objectives and/or rationale and describe the role and functioning of your 
Autonomous Intelligent System 
Name and describe the technologies and techniques used (e.g. supervised or unsupervised learning, 
machine learning, random forest, decision tree...). You can refer to the report of the AI Initiative incubated 
at Harvard http://ai-initiative.org/wp-content/uploads/2017/08/Making-the-AI-Revolution-work-for-
everyone.-Report-to-OECD.-MARCH-2017.pdf. Mention the names of any technological intermediary or 
supplier allowing you to use the technology (e.g. technical provider, cloud provider)  
Indicate all sources of funding for your project (public and private) and who might have an interest (e.g. 
financial, political) in your Autonomous Intelligent System 
If you have noted that you or someone in your team has an expertise in relation to the Autonomous 
Intelligent System (e.g. in a document, a webpage, an interview), clearly indicate the name of the 
professional, their technical, academic or medical credentials, and their training (e.g. ""Professor Smith, 
PhD in computer systems engineering from Harvard University. Specialist in the Online Detection of 
Depression"") 
Describe your target population and its size, or identify its subgroups and their sizes. Describe if and how 
the target population (and, or its subgroups) assisted in the design of your Autonomous Intelligent System. 
If you made claims about your Autonomous Intelligent System's efficacy, performance, or benefits, please 
justify them and provide the evidence underlying them. If you have mentioned or used scientific papers, 
please cite your sources 
If you have run your Autonomous Intelligent System under adversarial examples or worst-case scenarios, 
describe the type of tests used and their outcomes 
Describe the process whereby users can formally complain or express their concerns about your 
Autonomous Intelligent System 

PRIVACY & TRANSPARENCY 
Responsibility 

Data collection 

Accessibility 

Informed consent 

Consent withdrawal 

Access to the data "
"Mental Illness Classification on Social Media Texts using Deep Learning
  and Transfer Learning","['Iqra Ameer', 'Muhammad Arif', 'Grigori Sidorov', 'Helena Gòmez-Adorno', 'Alexander Gelbukh']","Given the current social distance restrictions across the world, most
individuals now use social media as their major medium of communication.
Millions of people suffering from mental diseases have been isolated due to
this, and they are unable to get help in person. They have become more reliant
on online venues to express themselves and seek advice on dealing with their
mental disorders. According to the World health organization (WHO),
approximately 450 million people are affected. Mental illnesses, such as
depression, anxiety, etc., are immensely common and have affected an
individuals' physical health. Recently Artificial Intelligence (AI) methods
have been presented to help mental health providers, including psychiatrists
and psychologists, in decision making based on patients' authentic information
(e.g., medical records, behavioral data, social media utilization, etc.). AI
innovations have demonstrated predominant execution in numerous real-world
applications broadening from computer vision to healthcare. This study analyzes
unstructured user data on the Reddit platform and classifies five common mental
illnesses: depression, anxiety, bipolar disorder, ADHD, and PTSD. We trained
traditional machine learning, deep learning, and transfer learning multi-class
models to detect mental disorders of individuals. This effort will benefit the
public health system by automating the detection process and informing
appropriate authorities about people who require emergency assistance.",2022,http://arxiv.org/abs/2207.01012v1,http://arxiv.org/pdf/2207.01012v1,"2
2
0
2

l
u
J

3

]

G
L
.
s
c
[

1
v
2
1
0
1
0
.
7
0
2
2
:
v
i
X
r
a

Mental Illness Classiﬁcation on Social Media
Texts using Deep Learning and Transfer
Learning

Iqra Ameer1[0000−0002−1134−9713], Muhammad Arif1[0000−0001−06141−02047],
Grigori Sidorov1[0000−0003−3901−3522], Helena
G´omez-Adorno2[0000−0002−6966−9912], Alexander Gelbukh1[0000−0001−7845−9039],
and

1 Instituto Polit´ecnico Nacional, Centro de Investigaci´on en Computaci´on, Mexico
City, Mexico
{iameer2019,mariff2021,sidorov,gelbukh}@cic.ipn.mx
2 Instituto de Investigaciones en Matem´aticas Aplicadas y en Sistemas, Universidad
Nacional Aut´onoma de M´exico, Mexico City, Mexico
helena.gomez@iimas.unam.mx

Abstract. Given the current social distance restrictions across the world,
most individuals now use social media as their major medium of com-
munication. Millions of people suﬀering from mental diseases have been
isolated due to this, and they are unable to get help in person. They
have become more reliant on online venues to express themselves and
seek advice on dealing with their mental disorders. According to the
World health organization (WHO), approximately 450 million people
are aﬀected. Mental illnesses, such as depression, anxiety, etc., are im-
mensely common and have aﬀected an individual’s physical health. Re-
cently Artiﬁcial Intelligence (AI) methods have been presented to help
mental health providers, including psychiatrists and psychologists, in
decision-making based on patients’ authentic information (e.g., medi-
cal records, behavioral data, social media utilization, etc.). AI innova-
tions have demonstrated predominant execution in numerous real-world
applications broadening from computer vision to healthcare. This study
analyzes unstructured user data on the Reddit platform and classiﬁes ﬁve
common mental illnesses: depression, anxiety, bipolar disorder, ADHD,
and PTSD. We trained traditional machine learning, deep learning, and
transfer learning multi-class models to detect mental disorders of indi-
viduals. This eﬀort will beneﬁt the public health system by automating
the detection process and informing appropriate authorities about people
who require emergency assistance.

Keywords: Mental Illnesses Classiﬁcation · Machine Learning · Deep
Learning · Transfer Learning · Reddit

1

Introduction

Mental illness could be a sort of health condition that changes a person’s intellect,
feelings, or behavior (or all three) and has been appeared to aﬀect an individual’s

 
 
 
 
 
 
2

I. Ameer et al.

physical health [28,23]. Mental health issues including depression, schizophre-
nia, attention-deﬁcit hyperactivity disorder (ADHD), autism spectrum disorder
(ASD), etc., are highly prevalent today, and it is estimated that around 450
million people worldwide suﬀer from such problems[28].

To way better get the mental health conditions and provide care, early de-
tection of mental health problems is a basic step. Diﬀerent from the diagnosis of
other chronic conditions that depend on research facility tests and measurements,
mental illnesses are regularly diagnosed based on an individual’s self-report to
particular surveys planned for the detection of speciﬁc patterns of feelings or
social interactions [18].

Amid these uncertain times when COVID-19 torments the world, many peo-
ple have indicated clinical anxiety or depression. This could be due to lockdown,
limited social activities, a higher unemployment rate, economic depression, and
fatigue related to work. American Foundation for Suicide Anticipation reported
that individuals encounter anxiety (53%) and sadness (51%) more regularly now
as compared to the time before covid-19 widespread.

Within the past decade, social media has changed social interaction. Along
with sharing data and news, individuals eﬀectively communicate their day-to-day
activities, experiences, hopes, emotions, etc., and generate tons of data online.
This textual data gives information that can be utilized to design systems to
predict people’s mental health. Moreover, the current limited social interaction
state has forced people to express their thoughts on social media. It gives people
an open stage to share their opinions with others numerous times attempt to
ﬁnd assistance [25].

A previous study explored the application of Machine Learning (ML) tech-
niques in mental health [31]. They reviewed literature by grouping them into four
main application domains, such as detection and diagnosis (ii) prognosis, treat-
ment and support, (iii) public health applications, and (iv) research and clinical
administration. Another study explored the emerging area of application of DL
techniques in psychiatry. They focused on DL by embedding semantically inter-
pretable computational models of brain dynamics or behavior into a statistical
machine learning context [15].

This study uses reddit.com3 user data proposed by Murarka and Radhakrish-
nan [25] to determine mental illnesses, see sample of dataset instances in "
Engaging with mental health: a global challenge,"['David Coyle', 'Mark Matthews', 'Gavin Doherty', 'John Sharry']","Using the metrics of the World Health Organisation, the Global Burden of
Disease Study has found that mental health difficulties are currently the
leading cause of disability in developed countries [1]. Projections also
indicate that the global burden of mental health difficulties will continue to
rise in the coming decades. The human and economic costs of this trend will be
substantial. In this paper we discuss how effectively designed interactive
systems, developed through collaborative, interdisciplinary efforts, can play a
significant role in helping to address this challenge. Our discussion is
grounded in a description of four exploratory systems, each of which has
undergone initial clinical evaluations. Directions for future research on
mental health technologies are also identified.",2013,http://arxiv.org/abs/1307.3174v1,http://arxiv.org/pdf/1307.3174v1,"Presented at the Workshop on Interactive Systems in Healthcare at CHI 2010, Atlanta, Georgia. April 11th 2010.  

Engaging with mental health: a global challenge

David Coyle 

Gavin Doherty 

The Computer Laboratory 

School of Computer Science      

University of Cambridge 

and Statistics 

William Gates Building 

Trinity College Dublin 

15 JJ Thomson Avenue  

College Green 

Cambridge CB3 0FD, UK 

Dublin 2, Ireland 

coyledt@tcd.ie 

gavin.doherty@cs.tcd.ie 

Mark Matthews 

John Sharry 

Student Counselling Service 

Child and Adolescent Psychiatry 

Trinity College Dublin 

Mater Misericordiae Hospital 

College Green 

Dublin 2, Ireland 

Metropolitan Building 

James Joyce Street 

mark.matthews@cs.tcd.ie 

Dublin 1, Ireland 

jsharry@mater.ie  

Copyright is held by the author/owner(s).  
WISH 2010 April 11, 2010, Atlanta, Georgia, USA. 

Abstract 
Using the metrics of the World Health Organisation, the 
Global Burden of Disease Study has found that mental 
health difficulties are currently the leading cause of 
disability in developed countries [1]. Projections also 
indicate that the global burden of mental health 
difficulties will continue to rise in the coming decades. 
The human and economic costs of this trend will be 
substantial. In this paper we discuss how effectively 
designed interactive systems, developed through 
collaborative, interdisciplinary efforts, can play a 
significant role in helping to address this challenge. Our 
discussion is grounded in a description of four 
exploratory systems, each of which has undergone 
initial clinical evaluations. Directions for future research 
on mental health technologies are also identified. 

Keywords 
Mental health, collaborative design, interactive systems 

ACM Classification Keywords 
H.5.m [Information Interfaces and Presentation]: 
Miscellaneous – interdisciplinary design, mental health 

Introduction 
Mental disorders are health conditions defined by the 
experiencing of severe and distressing psychological 
symptoms, to the extent that normal functioning is 
seriously impaired, and some form of help is usually 
needed for recovery. The US Surgeon General’s first 
report on mental health concluded that (1) the efficacy 

 
 
 
 
 
 
 
 
 
of mental health treatments is well documented and (2) 
a range of effective treatments exist for most mental 
disorders [2]. Unfortunately international studies also 
conclude that the majority of people experiencing 
difficulties do not receive appropriate specialist 
treatment [2, 3]. Research concludes that in the UK 
mental health has now overtaken unemployment as the 
nation’s most expensive social problem [4]. 

An interdisciplinary challenge 
Addressing the challenges of providing more effective 
mental healthcare (MHC) services will require the 
concerted efforts of professionals across a range of 
disciplines. It is likely – indeed necessary – that 
technology will play a significant role in future service 
delivery. Coyle et al [5] identifies two broad challenges 
which interactive systems can help in addressing [5]: 

1.  Access/capacity constraints: traditional mental 
health intervention strategies, particularly talk-based 
strategies, are time and resource intensive. As a result 
existing services often do not have sufficient capacity to 
meet the needs of people requiring professional help. 

2.  Engagement: research suggests that, even when 
professional help is available, many clients find it 
difficult to successfully engage with traditional 
treatment. The level to which clients engage with their 
treatment, and draw on their own personal resources, 
is a major factor in the success of interventions.  

With several notable exceptions, early research on the 
use of technology was generally justified on the basis of 
increased access - e.g. electronic contact as a natural 
extension of face-to-face dialogue and the 
computerisation of self-help materials. Increased 
engagement and actual improvements in the 

effectiveness of treatment have received less attention 
[5]. Collaboration between HCI and MHC professionals 
can help in maximising the effectiveness of new 
technologies. While MHC professionals have the 
necessary domain expertise, HCI researchers are 
experienced in design methodologies and are likely to 
have a broader knowledge of the potential uses of new 
technologies. For example the experience of HCI 
researchers is important given the high cost of systems 
failures in sensitive interventions. Other ongoing areas 
of HCI research, such as designing for personal 
reflection and behaviour change, can play a valuable 
role in future research on mental health technologies. 

Examples of exploratory systems 
We have primarily focused on the design of technology 
to support talk-based, psychological approaches to 
mental health treatment, e.g. psychotherapy. Reviews 
of previous research on technology in this area are 
available in [5, 6]. Over the past 7 years we h"
Semiparametric count data regression for self-reported mental health,"['Daniel R. Kowal', 'Bohan Wu']","""For how many days during the past 30 days was your mental health not good?""
The responses to this question measure self-reported mental health and can be
linked to important covariates in the National Health and Nutrition Examination
Survey (NHANES). However, these count variables present major distributional
challenges: the data are overdispersed, zero-inflated, bounded by 30, and
heaped in five- and seven-day increments. To meet these challenges, we design a
semiparametric estimation and inference framework for count data regression.
The data-generating process is defined by simultaneously transforming and
rounding (STAR) a latent Gaussian regression model. The transformation is
estimated nonparametrically and the rounding operator ensures the correct
support for the discrete and bounded data. Maximum likelihood estimators are
computed using an EM algorithm that is compatible with any continuous data
model estimable by least squares. STAR regression includes asymptotic
hypothesis testing and confidence intervals, variable selection via information
criteria, and customized diagnostics. Simulation studies validate the utility
of this framework. STAR is deployed to study the factors associated with
self-reported mental health and demonstrates substantial improvements in
goodness-of-fit compared to existing count data regression models.",2021,http://arxiv.org/abs/2106.09114v2,http://arxiv.org/pdf/2106.09114v2,"Semiparametric count data regression for

self-reported mental health

Daniel R. Kowal and Bohan Wu∗

Abstract

“For how many days during the past 30 days was your mental health not good?”

The responses to this question measure self-reported mental health and can be linked

to important covariates in the National Health and Nutrition Examination Survey

(NHANES). However, these count variables present major distributional challenges:

the data are overdispersed, zero-inﬂated, bounded by 30, and heaped in ﬁve- and seven-

day increments. To address these challenges—which are especially common for health

questionnaire data—we design a semiparametric estimation and inference framework

for count data regression. The data-generating process is deﬁned by simultaneously

transforming and rounding (star) a latent Gaussian regression model. The transfor-

mation is estimated nonparametrically and the rounding operator ensures the correct

support for the discrete and bounded data. Maximum likelihood estimators are com-

puted using an EM algorithm that is compatible with any continuous data model

estimable by least squares. star regression includes asymptotic hypothesis testing

and conﬁdence intervals, variable selection via information criteria, and customized

diagnostics. Simulation studies validate the utility of this framework. Using star

regression, we identify key factors associated with self-reported mental health and

demonstrate substantial improvements in goodness-of-ﬁt compared to existing count

data regression models.

Keywords: generalized linear model; health data; questionnaire data; transformation.
∗Department of Statistics, Rice University, Houston, TX (Correspondence: daniel.kowal@rice.edu).

1
2
0
2

t
c
O
3
1

]
E
M

.
t
a
t
s
[

2
v
4
1
1
9
0
.
6
0
1
2
:
v
i
X
r
a

 
 
 
 
 
 
1

Introduction

The National Health and Nutrition Examination Survey (NHANES) asks a critical question:

“For how many days during the past 30 days was your mental health not good?” The

responses (DaysMentHlthNotGood) provide insights on self-reporting of mental health issues

and can be linked to demographic, socioeconomic, behavioral, and health-related covariates.

Mental health and mental disorders are key factors in quality of life, depression, and risk of

self-harm, and are focal points of many research studies (Scheid and Wright, 2017). Previous

research has sought to associate mental health, mental disorders, or depression with gender

(Seedat et al., 2009), race (Williams et al., 2010a), socioeconomic status (Ortega and Corzine,

1990), marital status (Williams et al., 2010b), age (Mirowsky and Ross, 1999), smoking

(Klungsøyr et al., 2006), and blood pressure (Tzourio et al., 1999), among many other

factors. Notably, NHANES data include relevant covariates for all of these factors—and

several others (see Table 4)—on a large sample of individuals, and thus oﬀers a unique

opportunity for a joint analysis of multiple factors.

Our goal is to construct an adequate count regression model for these health question-

naire data and characterize the eﬀects of covariates on self-reported mental health. Health

questionnaire data often require customized statistical methodology, including life event

stressors (Herring et al., 2004), sleep quality (Dunson, 2005), nutritional and food intake

(Kipnis et al., 2009), and drug use (Song et al., 2017), among many others. From a sta-

tistical modeling perspective, DaysMentHlthNotGood is an overdispersed, zero-inﬂated, and

bounded count variable. Figure 1 shows the empirical probability mass function (PMF) for

DaysMentHlthNotGood. The PMF has spikes at both the lower bound (zero days) and the

upper bound (30 days) and, most uniquely, heaping in ﬁve- and seven-day increments. This

is an expected consequence of self-reported behavior: individuals are more likely to report

1

14 or 15 days than they are 16 or 17 days regardless of the exact truth. Hence, a regression

model for DaysMentHlthNotGood must be capable of modeling discreteness, overdispersion,

zero-inﬂation, boundedness, and heaping.

Figure 1: Empirical probability mass function (PMF) for DaysMentHlthNotGood with estimated
PMFs for zero-inﬂated Poisson (ZIP, left) and star (right). While star neatly captures zero-
inﬂation, heaping (light gray), and boundedness, ZIP is inadequate for the nonzero counts.

Most count regression models build upon the Poisson distribution. Poisson regression

can be suitable for point estimation or point prediction (see Section 5), but is often in-

adequate for modeling and inference due to the rigid equidispersion requirements. Exten-

sions for over/underdispersion typically introduce additional parameters or latent variables,

such as quasi-Poisson, Negative Binomial, or Conway-Maxwell-Poisson (Sellers and Shmueli,

2010). Other features such as zero-inﬂation can be appended to the Poisson model or its

generalizations. However, the added complexity of generalized"
"Measuring Depression Symptom Severity from Spoken Language and 3D Facial
  Expressions","['Albert Haque', 'Michelle Guo', 'Adam S Miner', 'Li Fei-Fei']","With more than 300 million people depressed worldwide, depression is a global
problem. Due to access barriers such as social stigma, cost, and treatment
availability, 60% of mentally-ill adults do not receive any mental health
services. Effective and efficient diagnosis relies on detecting clinical
symptoms of depression. Automatic detection of depressive symptoms would
potentially improve diagnostic accuracy and availability, leading to faster
intervention. In this work, we present a machine learning method for measuring
the severity of depressive symptoms. Our multi-modal method uses 3D facial
expressions and spoken language, commonly available from modern cell phones. It
demonstrates an average error of 3.67 points (15.3% relative) on the
clinically-validated Patient Health Questionnaire (PHQ) scale. For detecting
major depressive disorder, our model demonstrates 83.3% sensitivity and 82.6%
specificity. Overall, this paper shows how speech recognition, computer vision,
and natural language processing can be combined to assist mental health
patients and practitioners. This technology could be deployed to cell phones
worldwide and facilitate low-cost universal access to mental health care.",2018,http://arxiv.org/abs/1811.08592v2,http://arxiv.org/pdf/1811.08592v2,"8
1
0
2

v
o
N
7
2

]

V
C
.
s
c
[

2
v
2
9
5
8
0
.
1
1
8
1
:
v
i
X
r
a

Measuring Depression Symptom Severity from
Spoken Language and 3D Facial Expressions

Albert Haque1

Michelle Guo1

Adam S Miner2,3

Li Fei-Fei1

1Department of Computer Science, Stanford University
2Department of Psychiatry and Behavioral Sciences, Stanford University
3Department of Health Research and Policy, Stanford University

Abstract

With more than 300 million people depressed worldwide, depression is a global
problem. Due to access barriers such as social stigma, cost, and treatment availabil-
ity, 60% of mentally-ill adults do not receive any mental health services. Effective
and efﬁcient diagnosis relies on detecting clinical symptoms of depression. Au-
tomatic detection of depressive symptoms would potentially improve diagnostic
accuracy and availability, leading to faster intervention. In this work, we present a
machine learning method for measuring the severity of depressive symptoms. Our
multi-modal method uses 3D facial expressions and spoken language, commonly
available from modern cell phones. It demonstrates an average error of 3.67 points
(15.3% relative) on the clinically-validated Patient Health Questionnaire (PHQ)
scale. For detecting major depressive disorder, our model demonstrates 83.3%
sensitivity and 82.6% speciﬁcity. Overall, this paper shows how speech recognition,
computer vision, and natural language processing can be combined to assist mental
health patients and practitioners. This technology could be deployed to cell phones
worldwide and facilitate low-cost universal access to mental health care.

1

Introduction

Worldwide, more than 300 million people are depressed [48]. In the worst case, depression can lead to
suicide, with close to 800,000 people committing suicide every year. In general, patients with mental
disorders are seen by a wide spectrum of health care providers, including primary care physicians
[22]. However, compared to physical illnesses, mental disorders are more difﬁcult to detect. The
burden of mental health is exacerbated by barriers to care such as social stigma, ﬁnancial cost, and
a lack of accessible treatment options. To address entrenched barriers to care, scalable approaches
for detecting mental health symptoms have been called for [19]. If successful, early detection may
impact access for the 60% of mentally-ill adults who do not receive treatment [33].

In practice, clinicians identify depression in patients by ﬁrst measuring the severity of depressive
symptoms1 during in-person clinical interviews. During these interviews, clinicians assess both verbal
and non-verbal indicators of depressive symptoms including monotone pitch, reduced articulation
rate, lower speaking volumes [16, 41], fewer gestures, and more downward gazes [46, 40, 37]. If
such symptoms persist for two weeks [4], the patient is considered to have a major depressive episode.
Structured questionnaires have been developed and validated in clinical populations to assess the
severity of depressive symptoms. One of the most common questionnaires is the Patient Health
Questionnaire (PHQ) [23]. This clinically-validated tool measures depression symptom severity
across several personal dimensions [21]. Assessing symptom severity is time-intensive, and critical
for both initial diagnosis and improvement across time. Thus, AI-based solutions to assessing
symptom severity may address entrenched barriers to access and treatment.

1Depressive symptoms include feelings of worthlessness, loss of interest in hobbies, or thoughts of suicide.

Machine Learning for Health (ML4H) Workshop at NeurIPS 2018, Montréal, Canada.

 
 
 
 
 
 
Figure 1: Multi-modal data. For each clinical interview, we use: (a) video of 3D facial scans, (b)
audio recording, visualized as a log-mel spectrogram, and (c) text transcription of the patient’s speech.
Our model predicts the severity of depressive symptoms using all three modalities.

We envision an AI-based solution where depressed individuals can receive evidence-based mental
health services while avoiding existing barriers to access. Such a solution could leverage multi-modal
sensors or text messages, as is common on modern smartphones, to increase timely and cost-effective
symptom screening [3]. Conversational AIs are another potential solution [31, 32]. Our hope is that
automated feedback will (i) provide actionable feedback to individuals who may be depressed, and
(ii) improve automated depression screening tools for clinicians, by including visual, audio, and
linguistic signals.

Contributions. We propose a machine learning method for measuring depressive symptom severity
from de-identiﬁed multi-modal data. The input to our model is audio, 3D video of facial keypoints,
and a text transcription of a patient speaking during a clinical interview. The output of our model is
either a PHQ score or classiﬁcation label indicating major depressive disorder. Our method leverages
a causal conv"
"EmoMent: An Emotion Annotated Mental Health Corpus from two South Asian
  Countries","['Thushari Atapattu', 'Mahen Herath', 'Charitha Elvitigala', 'Piyanjali de Zoysa', 'Kasun Gunawardana', 'Menasha Thilakaratne', 'Kasun de Zoysa', 'Katrina Falkner']","People often utilise online media (e.g., Facebook, Reddit) as a platform to
express their psychological distress and seek support. State-of-the-art NLP
techniques demonstrate strong potential to automatically detect mental health
issues from text. Research suggests that mental health issues are reflected in
emotions (e.g., sadness) indicated in a person's choice of language. Therefore,
we developed a novel emotion-annotated mental health corpus (EmoMent),
consisting of 2802 Facebook posts (14845 sentences) extracted from two South
Asian countries - Sri Lanka and India. Three clinical psychology postgraduates
were involved in annotating these posts into eight categories, including
'mental illness' (e.g., depression) and emotions (e.g., 'sadness', 'anger').
EmoMent corpus achieved 'very good' inter-annotator agreement of 98.3% (i.e. %
with two or more agreement) and Fleiss' Kappa of 0.82. Our RoBERTa based models
achieved an F1 score of 0.76 and a macro-averaged F1 score of 0.77 for the
first task (i.e. predicting a mental health condition from a post) and the
second task (i.e. extent of association of relevant posts with the categories
defined in our taxonomy), respectively.",2022,http://arxiv.org/abs/2208.08486v1,http://arxiv.org/pdf/2208.08486v1,"EmoMent: An Emotion Annotated Mental Health Corpus from two South
Asian Countries

Thushari Atapattu1, Mahen Herath2, Charith Elvitigala3, Piyanjali de Zoysa4,
Kasun Gunawardane3, Menasha Thilakaratne1,
Kasun de Zoysa3 and Katrina Falkner1
1School of Computer Science, The University of Adelaide, Adelaide, Australia
2Department of Computer Science & Engineering, University of Moratuwa, Katubedda, Sri Lanka
3University of Colombo School of Computing, Colombo, Sri Lanka
4Department of Psychology, University of Colombo, Sri Lanka
email: thushari.atapattu@adelaide.edu.au

Abstract

People often utilise online media (e.g., Face-
book, Reddit) as a platform to express their
psychological distress and seek support. State-
of-the-art NLP techniques demonstrate strong
potential to automatically detect mental health
issues from text. Research suggests that men-
tal health issues are reﬂected in emotions (e.g.,
sadness) indicated in a person’s choice of
language. Therefore, we developed a novel
emotion-annotated mental health corpus (Emo-
Ment), consisting of 2802 Facebook posts
(14845 sentences) extracted from two South
Asian countries - Sri Lanka and India. Three
clinical psychology postgraduates were in-
volved in annotating these posts into eight cate-
gories, including ‘mental illness’ (e.g., depres-
sion) and emotions (e.g., ‘sadness’, ‘anger’).
EmoMent corpus achieved ‘very good’ inter-
annotator agreement of 98.3% (i.e. % with two
or more agreement) and Fleiss’ Kappa of 0.82.
Our RoBERTa based models achieved an F1
score of 0.76 and a macro-averaged F1 score
of 0.77 for the ﬁrst task (i.e. predicting a men-
tal health condition from a post) and the sec-
ond task (i.e. extent of association of relevant
posts with the categories deﬁned in our taxon-
omy), respectively.

1

Introduction

Mental health issues remain a leading cause for
poor well-being and suicide. The World Health
Organisation (WHO) indicates that 400 million
people are affected by mental disorders such as
depression, resulting in a cost of US$ 1 trillion
per year from the global economy allocated for de-
pression and anxiety disorders alone (WHO, 2019;
James et al., 2018). Recent research using AI and
NLP demonstrates strong potential to automatically
detect mental health issues from digital footprints
such that professionals could provide timely inter-
ventions and mental health resources to vulnerable

persons. These data contain useful information to
understand patients’ distressed state of mind out-
side a traditional clinical environment.

Research suggests that mental health issues are
reﬂected in the ‘emotions’ (e.g., sadness, anger)
indicated in one’s expression of language. De-
spite the popularity of research studies in detecting
mental disorders using online data such as Twit-
ter (Coppersmith et al., 2014, 2015; Cohan et al.,
2018) and emotion modeling (Strapparava and Mi-
halcea, 2007; Mohammad et al., 2018; Demszky
et al., 2020; Oberländer and Klinger, 2018), the au-
tomated identiﬁcation of the association between
emotions and mental disorders have largely being
ignored, apart from a recent study (CEASE corpus
(Ghosh et al., 2020)) that focused on the role of
emotions on suicidal ideation.

Motivated by this, we introduce a novel,
emotion-annotated mental health (EmoMent) cor-
pus1 using Facebook posts extracted from two
South Asian countries - Sri Lanka and India. In
South Asia, due to the lack of awareness of symp-
toms of mental illnesses and its associated stigma,
people often do not seek professional help, result-
ing in many instances of mental disorders being
left undiagnosed (Arora et al., 2016). However,
since recently, these countries have demonstrated
a tendency to use social media, particularly Face-
book, to seek mental health help using private and
public groups (e.g., Psychology group in Sri Lanka,
Indian Psychology Association).

Depression and anxiety disorders are amongst
the most common mental disorders worldwide
(James et al., 2018; Black Dog Institute, 2020).
Therefore, our dataset includes de-identiﬁable Face-
book posts from individuals who have indicated a
diagnosis of depression or anxiety, the disorder-

1dataset and the code is available on request for research

purposes.

2
2
0
2

g
u
A
7
1

]
L
C
.
s
c
[

1
v
6
8
4
8
0
.
8
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
related issues they express including associated
emotions, and their help-seeking behaviours from
professionals and/or community. EmoMent con-
sists of 2802 posts (14845 sentences) extracted
from public Facebook groups dedicated to discuss
mental health concerns in Sri Lanka and India.
Three clinical psychology postgraduates were in-
volved in the data annotation process. Their task
was to read the entire post and assign one or more
labels from a given set of eight categories (e.g.,
mental illness, sadness, psychosomatic, irrelevant)
(Table 2). We have achieved ‘very good’ inter-
annotator agreement of 98.3% (i.e. % with two or
more rater-agreement) and "
"Language and Mental Health: Measures of Emotion Dynamics from Text as
  Linguistic Biosocial Markers","['Daniela Teodorescu', 'Tiffany Cheng', 'Alona Fyshe', 'Saif M. Mohammad']","Research in psychopathology has shown that, at an aggregate level, the
patterns of emotional change over time -- emotion dynamics -- are indicators of
one's mental health. One's patterns of emotion change have traditionally been
determined through self-reports of emotions; however, there are known issues
with accuracy, bias, and ease of data collection. Recent approaches to
determining emotion dynamics from one's everyday utterances addresses many of
these concerns, but it is not yet known whether these measures of utterance
emotion dynamics (UED) correlate with mental health diagnoses. Here, for the
first time, we study the relationship between tweet emotion dynamics and mental
health disorders. We find that each of the UED metrics studied varied by the
user's self-disclosed diagnosis. For example: average valence was significantly
higher (i.e., more positive text) in the control group compared to users with
ADHD, MDD, and PTSD. Valence variability was significantly lower in the control
group compared to ADHD, depression, bipolar disorder, MDD, PTSD, and OCD but
not PPD. Rise and recovery rates of valence also exhibited significant
differences from the control. This work provides important early evidence for
how linguistic cues pertaining to emotion dynamics can play a crucial role as
biosocial markers for mental illnesses and aid in the understanding, diagnosis,
and management of mental health disorders.",2023,http://arxiv.org/abs/2310.17369v2,http://arxiv.org/pdf/2310.17369v2,"Language and Mental Health:
Measures of Emotion Dynamics from Text as Linguistic Biosocial Markers
Daniela Teodorescu1,2∗, Tiffany Cheng3, Alona Fyshe1,4, Saif M. Mohammad5
1Dept. Computing Science, Alberta Machine Intelligence Institute (Amii), University of Alberta
2MaiNLP, Center for Information and Language Processing, LMU Munich, Germany
3Carleton University
4Dept. Psychology, University of Alberta
5National Research Council Canada
{dteodore,alona}@ualberta.ca, tiffany.cheng@carleton.ca, saif.mohammad@nrc-cnrc.gc.ca

Abstract

Research in psychopathology has shown that,
at an aggregate level, the patterns of emotional
change over time—emotion dynamics—are in-
dicators of one’s mental health. One’s pat-
terns of emotion change have traditionally been
determined through self-reports of emotions;
however, there are known issues with accu-
racy, bias, and ease of data collection. Recent
approaches to determining emotion dynamics
from one’s everyday utterances addresses many
of these concerns, but it is not yet known
whether these measures of utterance emotion
dynamics (UED) correlate with mental health
diagnoses. Here, for the first time, we study
the relationship between tweet emotion dynam-
ics and mental health disorders. We find that
each of the UED metrics studied varied by the
user’s self-disclosed diagnosis. For example:
average valence was significantly higher (i.e.,
more positive text) in the control group com-
pared to users with ADHD, MDD, and PTSD.
Valence variability was significantly lower in
the control group compared to ADHD, depres-
sion, bipolar disorder, MDD, PTSD, and OCD
but not PPD. Rise and recovery rates of valence
also exhibited significant differences from the
control. This work provides important early
evidence for how linguistic cues pertaining to
emotion dynamics can play a crucial role as
biosocial markers for mental illnesses and aid
in the understanding, diagnosis, and manage-
ment of mental health disorders.

1

Introduction

Language is inherently social—from the way in
which we say things, the expressions we use and
the things we choose to share, being impacted by
our social environment and lived experiences. As
our social environments have evolved over time,
language has evolved to better support our commu-
nication needs and collaborative societies. There-
fore, language is also variable, as the way in which

∗ Work done while at the University of Alberta.

we use it has adapted to cultures and communi-
ties around the world, and it is influenced by an
individual’s experiences.

Given the prominent role of language in human
evolution from hunters–gathers to collaborative so-
cieties, and the large extent to which we rely on
language today, it is not surprising that our mental
health impacts our language usage. Quantitative
features in language (e.g., aspects which can be
measured) have already been shown to indicate
and help clinicians monitor the progression of men-
tal health conditions (MHCs), acting as biomark-
ers. A linguistic biomarker is a language-based
measure that is associated with a disease outcome
or biology in general (Ballman, 2015; Gagliardi
and Tamburini, 2022; Lena, 2021). Some well-
known linguistic biomarkers include: the propor-
tion of pronouns (indicator of depression, Koops
et al. (2023)), syntax reduction (Anorexia Nervosa,
Cuteri et al. (2022)), certain lexical and syntactic
features (mild cognitive impairment and demen-
tia, Calzà et al. (2021); Gagliardi and Tamburini
(2021)), and semantic connectedness (schizophre-
nia, Corcoran et al. (2020). Also, the emotions
expressed in text have been shown to correlate with
mental health diagnosis. For example, more neg-
ative sentiment in text by individuals with depres-
sion (De Choudhury et al., 2013; Seabrook et al.,
2018; De Choudhury et al., 2021). Other work has
shown that suicide watch, anxiety, and self-harm
subreddits had noticeably lower negative sentiment
compared to other mental health subreddits such as
Autism and Asperger’s (Gkotsis et al., 2016).

While language can be a biomarker for mental
health, the substantial social nature of language
has implications. Notably, the tremendous vari-
ability in language use—especially across social
groups—means that we should be skeptical about
universal biomarkers; and instead realize that lin-
guistic biomarkers alone are not capable of pre-
dicting MHCs. A vast amount of contextual and

3
2
0
2

v
o
N
4

]
L
C
.
s
c
[

2
v
9
6
3
7
1
.
0
1
3
2
:
v
i
X
r
a

 
 
 
 
 
 
clinical information (often only available to an indi-
vidual’s physician) helps determine well-being, and
sometimes linguistic markers can aid the process.
Further, linguistic biomarkers are more likely to be
a stronger indicator among groups with commonal-
ities; for example, when applied to people from the
same region, culture, or medium of expression (e.g.,
social media platform). For example, social factors
such as parental socioeconomic status, neighbour-
hood, and institutio"
Modeling trajectories of mental health: challenges and opportunities,"['Lauren Erdman', 'Ekansh Sharma', 'Eva Unternahrer', 'Shantala Hari Dass', 'Kieran ODonnell', 'Sara Mostafavi', 'Rachel Edgar', 'Michael Kobor', 'Helene Gaudreau', 'Michael Meaney', 'Anna Goldenberg']","More than two thirds of mental health problems have their onset during
childhood or adolescence. Identifying children at risk for mental illness later
in life and predicting the type of illness is not easy. We set out to develop a
platform to define subtypes of childhood social-emotional development using
longitudinal, multifactorial trait-based measures. Subtypes discovered through
this study could ultimately advance psychiatric knowledge of the early
behavioural signs of mental illness. To this extent we have examined two types
of models: latent class mixture models and GP-based models. Our findings
indicate that while GP models come close in accuracy of predicting future
trajectories, LCMMs predict the trajectories as well in a fraction of the time.
Unfortunately, neither of the models are currently accurate enough to lead to
immediate clinical impact. The available data related to the development of
childhood mental health is often sparse with only a few time points measured
and require novel methods with improved efficiency and accuracy.",2016,http://arxiv.org/abs/1612.01055v1,http://arxiv.org/pdf/1612.01055v1,"Modeling trajectories of mental health: 
challenges and opportunities  

Lauren Erdman1, Ekansh Sharma1, Eva Unternährer2, Shantala Hari Dass2, 
Kieran O’Donnell2, Sara Mostafavi3, Rachel Edgar3, Michael Kobor3,  
Hélène Gaudreau4, Michael Meaney2, Anna Goldenberg1 
1University of Toronto Department of Science,  
2McGill University Ludmer Centre for Neuroinformatics and Mental Health,   
3University of British Columbia Centre for Molecular Medicine and Therapeutics  
4Douglas Mental Health University Institute 

Abstract 

More than two thirds of mental health problems have their onset during childhood 
or  adolescence.  Identifying  children  at  risk  for  mental  illness  later  in  life  and 
predicting the type of illness is not easy. We set out to develop a platform to define 
subtypes  of  childhood  social-emotional  development  using 
longitudinal, 
multifactorial trait-based measures. Subtypes discovered through this study could 
ultimately advance psychiatric knowledge of the early behavioral signs of mental 
illness. To this extent we have examined two types of models: latent class mixture 
models and GP-based models. Our findings indicate that while GP models come 
close in accuracy of predicting future trajectories, LCMMs predict the trajectories 
as well in a fraction of the time. Unfortunately, neither of the models are currently 
accurate enough to lead to immediate clinical impact. The available data related 
to the development of childhood mental health is  often  sparse  with only a  few 
time points  measured and require novel  methods  with improved efficiency and 
accuracy. 

In trod u cti on  

1 
Mental disorders constitute the largest contributor to the global burden of disease as measured using 
the disability-adjusted life years index [1]. The most common mental disorders, including attention 
deficit  hyperactive  disorder  and  major  depression  show  a  peak  age  of  onset  in  childhood  and 
adolescence thus derailing the quality of life and productivity of individuals over entire lifetimes. 
By identifying at risk children at an early age we have an opportunity to intervene and reduce the 
negative consequences of or prevent many such mental disorders. The challenge is in effectively 
identifying truly vulnerable children to be able to intervene in a timely manner. Current programs 
for  identifying  at  risk  children  are  constructed  on  evidence  linking  early  life  adversity,  such  as 
poverty or birth outcomes, and the risk for mental illness. These factors predict mental illness at the 
level  of  the  population,  but  are  ineffective  at  the  level  of  the  individual  due  to  the  considerable 
variability in outcomes: many children born early, small, or into poverty are healthy and productive. 

The goal of this work is to identify a model, using patients’ phenotypic time series data alone, that 
would both (i) discover underlying subtypes of individuals based on their disease trajectories as well 
as (ii) predict future phenotypic values on an individual basis. The ultimate goal is to use this model 
to inform targeted, and personalized interventions aimed at both reducing the severity of onset of 
these  disorders  and  the  negative  outcomes  that  accompany  them,  such  as  suicide  and  substance 
abuse. The difficulty in solving this task is that the longitudinal data usually available in existing 
cohorts is very short and irregularly measured. 

In the field of group-based disease trajectory modeling, there are two primary modeling directions 
stemming from the different fields of model development: those from the field of machine learning 

 
 
 
 
primarily  employing  Gaussian  (or  some  other)  stochastic  processes  and  those  from  the  field  of 
statistics/epidemiology  mainly  in  the  form  of  linear/non-linear  mixed  modeling  with  structured 
covariance between time-points [2]. We use each of these two paradigms in application to identify 
subtypes  and  predict  future  internalizing  behavior  (e.g.  fearfulness  and  social  withdrawal),  a 
phenotype  which is predictive of anxiety and depressive  disorders in adolescence and adulthood 
[3].  We used longitudinal data from the Maternal Adversity, Vulnerability and Neurodevelopment 
(MAVAN) project [4] to assess model performance. 

1 . 1  

R e l a t e d   L i t e r a t u re  

Gaussian processes (GPs) have become popular for modeling time-dependent phenomena owing to 
their  applicability  to  modeling  a  wide  variety  of  functions  and  their  ability  to  handle  overfitting 
more directly [5].The intuitive Gaussian output of a GP (providing both an average line of fit and a 
confidence  bound  around  this  line)  makes  results  interpretable  and  intuitive  across  fields  and 
computational  expertise  [6].  GPs  have  been  successfully  developed  for  group-based  trajectory 
modeling such as the Dirichlet Process-Gaussian Process (DP-GP) developed by Hensm"
"Security for People with Mental Illness in Telehealth Systems: A
  Proposal",['Helen Jiang'],"A mental health crisis is looming large, and needs to be addressed. But
across age groups, even just in the United States, more than 50% of people with
any mental illness (AMI) did not seek or receive any service or treatment. The
proliferation of telehealth and telepsychiatry tools and systems can help
address this crisis, but outside of traditional regulatory aspects on privacy,
e.g. Health Insurance Portability and Accountability Act (HIPPA), there does
not seem to be enough attention on the security needs, concerns, or user
experience of people with AMI using those telehealth systems. In this text, I
try to explore some priority security properties for telehealth systems used by
people with AMI for mental heath services (MHS). I will also suggest some key
steps in a proposed process for designing and building security mechanisms into
such systems, so that security is accessible and usable to patients with AMI,
and these systems can achieve their goals of ameliorate this mental health
crisis.",2020,http://arxiv.org/abs/2008.03406v1,http://arxiv.org/pdf/2008.03406v1,"0
2
0
2

g
u
A
8

]

Y
C
.
s
c
[

1
v
6
0
4
3
0
.
8
0
0
2
:
v
i
X
r
a

Security for People with Mental Illness in Telehealth Systems: A Proposal

Helen Jiang
Independent (afﬁliated with Georgia Institute of Technology)

Abstract

A mental health crisis is looming large, and needs to be ad-
dressed. But across age groups, even just in the United States,
more than 50% of people with any mental illness (AMI) did
not seek or receive any service or treatment [49]. The prolifer-
ation of telehealth and telepsychiatry tools and systems [8,12]
can help address this crisis, but outside of traditional regu-
latory aspects on privacy, e.g. Health Insurance Portability
and Accountability Act (HIPPA), there does not seem to be
enough attention on the security needs, concerns, or user ex-
perience of people with AMI using those telehealth systems.
In this text, I try to explore some priority security properties
for telehealth systems used by people with AMI for mental
heath services (MHS). I will also suggest some key steps in a
proposed process for designing and building security mech-
anisms into such systems, so that security is accessible and
usable to patients with AMI, and these systems can achieve
their goals of ameliorate this mental health crisis.f

1 Introduction

Mental health issues are prevalent around all of us, and the
scale is staggering. Within the United States alone, in 2017,
46.6 million adults had a mental illness, 49.5% of adolescents
had any mental disorder, and 10.6 million adults seriously
considered suicide [1, 49]. Estimates are that 50% of mental
illness begins by age 14, and 75% by 24, while suicide is the
third biggest cause of death for age group 10 – 24, among
whom 90% had underlying mental illness [9, 50]. Telehealth
and telepsychiatry tools and systems have been developed
with the hope to help address this crisis, and while they all
must comply to HIPPA, there is a missing dimension: psycho-
logically acceptable security to people with AMI.

The “psychological acceptability” principle is identiﬁed as
“usable” in 1975 [59], but it wasn’t until the 1990s, that “usable
security” started to get its due attention [52, 74]. Moreover,
the audience of “psychological acceptability” is open and
wide: to whom, or to what audience are the security measures

and mechanisms psychologically acceptable? What if the
psychological or mental state of the audience is impaired, or
the audience has mental disorders?

This question is open, wide, and more importantly, tricky.
While it is relatively easy to diagnose and notice cognitive im-
pairment and neurocognitive disorders as they manifest in do-
mains such as attention, recognition, and language [28,46,57],
the vast majority of people with mental illness keep function-
ing in daily lives [10]. What is even trickier, is that mental
disorder may eventually turn to affect cognition and behav-
iors, as Diagnostic and Statistical Manual of Mental Disorders
(DSM, latest edition DSM-5) deﬁnes a mental disorder as “...a
syndrome characterized by clinically signiﬁcant disturbance
in an individual’s cognition, emotion regulation, or behav-
iors...” [11]. How might we build security into telehealth
systems, which would be relied upon by many with mental
illness, who a diverse and complex, but under-served and
usually invisible user base? This is a question worth asking
and solving. In this work, I will propose some priority prop-
erties of security in telehealth systems used for MHS, and
suggest some key steps in a process when building usable
and secure telehealth systems for people with AMI. Here
I will adapt [56]’s deﬁnition of telehealth, to better suit the
MHS context. While it is still fundamentally ”the use of elec-
tronic information and telecommunication technologies to
support long-distance clinical health care etc.,” providers
of MHS via telehealth need not to be only human — they
can be automated, interactive agents such as social bots, e.g.
conversational agents (colloquially “chatbots”).

2 Related Work

For security and usable security, much has been written and
researched. However, even though “psychological accept-
ability” to users was proposed as a key principle for secu-
rity, it only started getting attention much later. Meanwhile,
security measures keep confusing users [2, 19, 60, 70, 74].
Moreover, the “psychological acceptability” principle is of-
ten doubted as incompatible with the goal of “security”

1

 
 
 
 
 
 
[13, 22, 51, 54, 61, 64, 73, 74], and usable security is still a
small community compared to other areas of security research.
Also, as [69] points out, usable security is designed with the
general population in mind, and may leave out speciﬁc vul-
nerable groups that are under-served. This leaves us not a
deep foundation to work with, when we consider building
psychologically acceptable security, for those whose mental
state may suffer from disorders or illness, and into systems
that many of them may rely on to get treatment a"
Data Augmentation for Mental Health Classification on Social Media,"['Gunjan Ansari', 'Muskan Garg', 'Chandni Saxena']","The mental disorder of online users is determined using social media posts.
The major challenge in this domain is to avail the ethical clearance for using
the user generated text on social media platforms. Academic re searchers
identified the problem of insufficient and unlabeled data for mental health
classification. To handle this issue, we have studied the effect of data
augmentation techniques on domain specific user generated text for mental
health classification. Among the existing well established data augmentation
techniques, we have identified Easy Data Augmentation (EDA), conditional BERT,
and Back Translation (BT) as the potential techniques for generating additional
text to improve the performance of classifiers. Further, three different
classifiers Random Forest (RF), Support Vector Machine (SVM) and Logistic
Regression (LR) are employed for analyzing the impact of data augmentation on
two publicly available social media datasets. The experiments mental results
show significant improvements in classifiers performance when trained on the
augmented data.",2021,http://arxiv.org/abs/2112.10064v1,http://arxiv.org/pdf/2112.10064v1,"Data Augmentation for Mental Health Classiﬁcation on Social Media

Gunjan Ansari
JSS Academy of Technical
Education, Noida, India
gunjanansari@jssaten.ac.in

Muskan Garg
Thapar Institute of
Engineering & Technology
Patiala, Punjab,
India
muskanphd@gmail.com

Chandni Saxena
The Chinese University
of Hong Kong, Shatin,
NT, Hong Kong
csaxena@cse.cuhk.edu.hk

1
2
0
2
c
e
D
9
1

]
L
C
.
s
c
[

1
v
4
6
0
0
1
.
2
1
1
2
:
v
i
X
r
a

Abstract

The mental disorder of online users is deter-
mined using social media posts. The ma-
jor challenge in this domain is to avail the
ethical clearance for using the user-generated
text on social media platforms. Academic re-
searchers identiﬁed the problem of insufﬁcient
and unlabeled data for mental health classiﬁ-
cation. To handle this issue, we have studied
the effect of data augmentation techniques on
domain-speciﬁc user-generated text for men-
tal health classiﬁcation. Among the exist-
ing well-established data augmentation tech-
niques, we have identiﬁed Easy Data Augmen-
tation (EDA), conditional BERT, and Back-
Translation (BT) as the potential techniques
for generating additional text to improve the
performance of classiﬁers. Further, three dif-
ferent classiﬁers- Random Forest (RF), Sup-
port Vector Machine (SVM) and Logistic Re-
gression (LR) are employed for analyzing the
impact of data augmentation on two publicly
available social media datasets. The experi-
mental results show signiﬁcant improvements
in classiﬁers’ performance when trained on the
augmented data.

1

Introduction

Recent studies over mental health classiﬁcation
(Salari et al., 2020; Garg, 2021; Biester et al., 2021)
convey that amid COVID-19 pandemic, the num-
ber of stress, anxiety and depression related mental
disorders have increased. As per the recent survey,
the rate of increase of mental disorders is more
than those of physical health impacts on the Chi-
nese population (Huang and Zhao, 2020). In this
context, the early detection of psychological dis-
orders is very important for good governance. It
is observed that more than 80% of the people who
commit suicide, disclose their intention to do so
on social media (Sawhney et al., 2021). Clinical
depression is the result of frequent tensions and

stress. Further, prevailing clinical depression for a
longer time period results in suicidal tendencies.

The information mining from social media helps
in identifying stressful and casual conversations
(Thelwall, 2017; Turcan and McKeown, 2019; Tur-
can et al., 2021). Many Machine Learning (ML)
algorithms are developed in literature using both
automatic and handcrafted features for classifying
Microblog. The problem of data sparsity is under-
explored for mental health studies on social media
due to the sensitivity of data (Wongkoblap et al.,
2017). Multiple ethical clearances are required for
new developments in mental health classiﬁcation.
To deal with this issue of data sparsity, we have
used data augmentation techniques to multiply the
training data (Turcan and McKeown, 2019; Haque
et al., 2021). The increase in training data may
help to improve the hyper-parameter learning of
textual features and thereby, reducing overﬁtting.
Data Augmentation is the method of increasing the
data diversity without collecting more data (Feng
et al., 2021). The idea behind the use of Data
Augmentation (DA) techniques is to understand
the improvements in training classiﬁers for mental
health detection on social media.

In this manuscript, the mental health classiﬁ-
cation is performed for two datasets to test the
scalability of data augmentation approaches for
mental healthcare domain. The classiﬁcation of ca-
sual and stressful conversations (Turcan and McK-
eown, 2019), and classifying depression and suici-
dal posts (Haque et al., 2021) on social media. We
select a rule based approach which preserves the
original label and diversiﬁes the text. To the best of
our knowledge, this is the ﬁrst attempt of stufﬁng
additional data for mental health classiﬁcation and
there is no such study in the existing literature. The
key contributions of this work are as follows:

• To determine the feasibility and the impor-

 
 
 
 
 
 
tance of data augmentation in the domain-
speciﬁc study of mental health classiﬁcation
to solve the problem of data sparsity.

• The empirical study for different classiﬁca-
tion algorithms show signiﬁcantly improved
F-measure.

Ethical Clearance: We use limited, sparse and
publicly available dataset for this study and so, no
ethical approval is required from the Institutional
Review Board (IRB) or elsewhere.

We organize rest of the manuscript in different
sections. Section 2 describes the historical per-
spective of data augmentation and mental health
classiﬁcation on social media. We discuss the data
augmentation methods and the architecture for ex-
perimental setups in Section 3. Section 4 elucidates
the experimental results and evaluation over the
proposed architecture of experimental setup wh"
"What Are You Anxious About? Examining Subjects of Anxiety during the
  COVID-19 Pandemic","['Lucia L. Chen', 'Steven R. Wilson', 'Sophie Lohmann', 'Daniela V. Negraia']","COVID-19 poses disproportionate mental health consequences to the public
during different phases of the pandemic. We use a computational approach to
capture the specific aspects that trigger an online community's anxiety about
the pandemic and investigate how these aspects change over time. First, we
identified nine subjects of anxiety (SOAs) in a sample of Reddit posts ($N$=86)
from r/COVID19\_support using thematic analysis. Then, we quantified Reddit
users' anxiety by training algorithms on a manually annotated sample ($N$=793)
to automatically label the SOAs in a larger chronological sample ($N$=6,535).
The nine SOAs align with items in various recently developed pandemic anxiety
measurement scales. We observed that Reddit users' concerns about health risks
remained high in the first eight months of the pandemic. These concerns
diminished dramatically despite the surge of cases occurring later. In general,
users' language disclosing the SOAs became less intense as the pandemic
progressed. However, worries about mental health and the future increased
steadily throughout the period covered in this study. People also tended to use
more intense language to describe mental health concerns than health risks or
death concerns. Our results suggest that this online group's mental health
condition does not necessarily improve despite COVID-19 gradually weakening as
a health threat due to appropriate countermeasures. Our system lays the
groundwork for population health and epidemiology scholars to examine aspects
that provoke pandemic anxiety in a timely fashion.",2022,http://arxiv.org/abs/2209.13595v1,http://arxiv.org/pdf/2209.13595v1,"What Are You Anxious About? Examining Subjects of Anxiety during the
COVID-19 Pandemic

Lucia L. Chen,1 Steven R. Wilson, 2 Sophie Lohmann 3 Daniela V. Negraia 3,4
1 Department of Health Policy, Stanford University, United States
2 School of Engineering and Computer Science, Oakland University, United States
3 Max Planck Institute for Demographic Research
4 Department of Sociology, Oxford University, United Kingdom
lucia.chen@stanford.edu, stevenwilson@oakland.edu, lohmann@demogr.mpg.de, negraia@demogr.mpg.de

Abstract

COVID-19 poses disproportionate mental health conse-
quences to the public during different phases of the pandemic.
We use a computational approach to capture the speciﬁc as-
pects that trigger an online community’s anxiety about the
pandemic and investigate how these aspects change over time.
First, we identiﬁed nine subjects of anxiety (SOAs) in a sam-
ple of Reddit posts (N =86) from r/COVID19 support using
thematic analysis. Then, we quantiﬁed Reddit users’ anxi-
ety by training algorithms on a manually annotated sample
(N =793) to automatically label the SOAs in a larger chrono-
logical sample (N =6,535). The nine SOAs align with items
in various recently developed pandemic anxiety measurement
scales. We observed that Reddit users’ concerns about health
risks remained high in the ﬁrst eight months of the pan-
demic. These concerns diminished dramatically despite the
surge of cases occurring later. In general, users’ language dis-
closing the SOAs became less intense as the pandemic pro-
gressed. However, worries about mental health and the future
increased steadily throughout the period covered in this study.
People also tended to use more intense language to describe
mental health concerns than health risks or death concerns.
Our results suggest that this online group’s mental health con-
dition does not necessarily improve despite COVID-19 grad-
ually weakening as a health threat due to appropriate coun-
termeasures. Our system lays the groundwork for popula-
tion health and epidemiology scholars to examine aspects that
provoke pandemic anxiety in a timely fashion.

Introduction
The novel Coronavirus Disease (COVID-19) pandemic has
created a global crisis. Unlike other recent pandemics (e.g.,
H1N1 or type-A inﬂuenza), the COVID-19 pandemic has re-
sulted in strict and extensive lockdown measures for large
swathes of the global population, such as complete lock-
downs, 14-day quarantine periods, closing of national bor-
ders, and disruption of international travel. A series of life
interruptions resulting from the COVID-19 pandemic are re-
lated to heightened anxiety and depression in many people
(Smith et al. 2020). In a 2020 study, over 80% of respon-
dents reported that their day-to-day thoughts were occupied
by topics related to the COVID-19 pandemic (Roy et al.

Copyright © 2021, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

2020). Sleep difﬁculties, extreme anxiety about becoming
infected with COVID-19, and distress caused by informa-
tion from social media were reported by 12.5%, 37.8%, and
36.4% of participants, respectively (Roy et al. 2020).

Anxiety is conceptualized as a multi-system response to
perceived risks, experienced as a feeling of unease, worry,
or fear (Wilkinson 2001). Experiencing occasional anxiety
about a situation is a normal part of life. However, prolonged
or frequent anxiety may lead to general anxiety disorders,
heightened depressive symptoms, reduction of sleep quality
(Huang and Zhao 2020), and other mental health risks. Psy-
chological studies often use scales to assess levels of anx-
iety. Studies that examine COVID-19 anxiety mainly fall
into two categories: those that treat anxiety as a clinical en-
tity with a focus on the symptoms (Ahorsu et al. 2020) and
those that examine the speciﬁc aspects of the pandemic that
trigger anxiety (McElroy et al. 2020; Taylor et al. 2020). Al-
though methodologies that use a survey approach with scale
measurements can provide detailed descriptions of individ-
ual respondents, their implementation is expensive and time-
consuming.

In an effort to collect data in a timely and cost-effective
manner, researchers have been exploring avenues to approx-
imate the anxiety of the public using proxy signals in social
media records (Guntuku et al. 2019). Our study does not aim
to replace the measurement using scales because some of the
behavioral, affective, and cognitive characteristics measured
with their items may rarely be reﬂected in the social me-
dia text. Rather, our automatic system may provide a proxy
value for the scientiﬁc and public health community to un-
derstand better how the public responds to large-scale health
threats promptly.

Our objective is to use data from Reddit to understand the
aspects that provoke people’s anxiety during early phases
of the pandemic and how these aspects have changed as
the pandemic has developed. Reddit is an online platform
in "
"Managing mental & psychological wellbeing amidst COVID-19 pandemic:
  Positive psychology interventions","['Maria Tresita Paul V.', 'N. Uma Devi']","COVID-19 pandemic has shaken the roots of healthcare facilities worldwide,
with the US being one of the most affected countries irrespective of being a
superpower. Along with the current pandemic, COVID-19 can cause a secondary
crisis of mental health pandemic if left unignored. Various studies from past
epidemics, financial turmoil and pandemic, especially SARS and MERS, have shown
a steep increase in mental and psychological issues like depression, low
quality of life, self-harm and suicidal tendencies among general populations.
The most venerable being the individuals infected and cured due to social
discrimination. The government is taking steps to contain and prevent further
infections of COVID-19. However, the mental and psychological wellbeing of
people is still left ignored in developing countries like India. There is a
significant gap in India concerning mental and psychological health still being
stigmatized and considered 'non-existent'. This study's effort is to highlight
the importance of mental and psychological health and to suggest interventions
based on positive psychology literature. These interventions can support the
wellbeing of people acting as a psychological first aid. Keywords: COVID-19,
Coronavirus, Pandemic, Mental wellbeing, Psychological Wellbeing, Positive
Psychology Interventions.
  KEYWORDS - COVID-19, Coronavirus, Pandemic, Wellbeing, Positive Psychology,
Interventions, PPI.",2021,http://arxiv.org/abs/2104.11726v3,http://arxiv.org/pdf/2104.11726v3,"THE American Journal of Humanities and Social Sciences Research (THE 
AJHSSR) 

2021 

E-ISSN: 2581-8868 
Volume-04, Issue-03, pp-121-131 
www.theajhssr.com 
Research Paper                                                                                                                      Open Access 

Managing mental & psychological wellbeing amidst COVID-19 
pandemic: Positive psychology interventions 

Maria Tresita Paul V.1

 & Uma Devi N.2 

1 & 2 Bharathiar School of Management and Entrepreneur Development  
(BSMED), Bharathiar University, Tamil Nadu, India. 
maria.tresi@gmail.com 

ABSTRACT 

COVID‐19 pandemic has shaken the roots of healthcare facilities worldwide, with the US being one of the most 
affected countries irrespective of being a superpower. Along with the current pandemic, COVID-19 can cause a 
secondary  crisis  of  mental  health  pandemic  if  left  unignored.  Various  studies  from  past  epidemics,  financial 
turmoil and pandemic, especially SARS and MERS, have shown a steep increase in mental and psychological 
issues like depression, low quality of life, self-harm and suicidal tendencies among general populations. The most 
venerable being the individuals infected and cured due to social discrimination. The government is taking steps 
to  contain  and  prevent  further  infections  of  COVID  19.  However,  the  mental  and  psychological  wellbeing  of 
people is still left ignored in developing countries like India. There is a significant gap in India concerning mental 
and psychological health still being stigmatized and considered 'non-existent'. This study's effort is to highlight 
the importance of mental and psychological health and to suggest interventions based on positive psychology 
literature. These interventions can support the wellbeing of people acting as a psychological first aid. 

KEYWORDS  - COVID-19, Coronavirus, Pandemic, Wellbeing, Positive Psychology, Interventions, PPI. 

I. 

INTRODUCTION 

China reported the first documented case of newly identified chronic respiratory illness COVID-19, on December 
16th, 2019, in Wuhan province. Unaware of the upcoming global catastrophe, by this time, the rest of the world 
was in a celebration mode preparing for the new year 2020. Diseased doctor 'Li Wenliang' was the whistleblower, 
who  alerted  about  this  suspicious  new  disease  novel  coronavirus  -  COVID-19  via  social  media.  The  Chinese 
government's numerous attempts to suppress this caught the attention of international media. By late December 
and  early  January  of  2020,    reports  of  confirmed  cases  of  COVID  19  diseases  spreading  outside  of  China  to 
countries like Americal, Italy, England & India, came to light affirming the human to human transition. With the 
global  news  covering  COVID-19,  came  enormous  pieces  of  information  causing  anxiety,  distress  and  fear 
worldwide among people, of this unknown new disease infecting and killing thousands worldwide (Wang et al. 
2020), especially the vulnerable and elderly (Centers for Disease Control and Prevention 2020). By January 2020, 
the World Health Organisation (WHO) announced COVID-19 epidemic outbreak, a public health emergency of 
international significance, and reported a high risk of COVID-19 spreading to other countries around the world. 
The COVID-19 virus is a zoonotic infection thought to have originated from pangolins, snakes and bats in wet 
markets of Wuhan (Ji et al. 2020). By January 2020 WHO confirmed the human-to-human transition of COVID 
19. In March 2020, the WHO assessed and declared coronavirus as a pandemic. Between March to June 2020, 
there is an exponential growth of coronavirus disease infected victims. Pandemic related containment measures 
worldwide as recommended by WHO are 'quarantine, social distancing, and self-isolation'.  

Recent  research  has  shown  that  a  long  period  of  'quarantine,  social  distancing,  and  self-isolation'  in  already 
uncertain situations like pandemic can harm mental and psychological wellbeing globally (Brooks et al., 2020; 
Dubey et al., 2020; Qui et al., 2020). The need  of mental wellbeing and stress coping of medical practitioners has 
become crucial area of study (Paul et al., 2021). Positive psychology has proven to heal and enhance the mental 
and psychological wellbeing of individuals (Seligman 2004; Seligman and Csikszentmihalyi  2014; Slade 2010; 
Vázquez et al., 2009).  
Positive psychology is explained as the scientific study of ""what makes life most worth living"" (Peterson, 2008), 
focusing on a) positive experiences, (e.g. joy, happiness, life satisfaction, inspiration and love); b) positive traits 

T H E A J H S S R   J o u r n a l                                 P a g e  | 121 

 
 
 
 
 
 
 
 
 
 
 
 
Managing mental & psychological wellbeing … 

and states (e.g. resilience, optimism, gratitude, hope, efficacy and compassion); c) positive institutions (applying 
positive principles with"
"Chatbots for Mental Health Support: Exploring the Impact of Emohaa on
  Reducing Mental Distress in China","['Sahand Sabour', 'Wen Zhang', 'Xiyao Xiao', 'Yuwei Zhang', 'Yinhe Zheng', 'Jiaxin Wen', 'Jialu Zhao', 'Minlie Huang']","The growing demand for mental health support has highlighted the importance
of conversational agents as human supporters worldwide and in China. These
agents could increase availability and reduce the relative costs of mental
health support. The provided support can be divided into two main types:
cognitive and emotional support. Existing work on this topic mainly focuses on
constructing agents that adopt Cognitive Behavioral Therapy (CBT) principles.
Such agents operate based on pre-defined templates and exercises to provide
cognitive support. However, research on emotional support using such agents is
limited. In addition, most of the constructed agents operate in English,
highlighting the importance of conducting such studies in China. In this study,
we analyze the effectiveness of Emohaa in reducing symptoms of mental distress.
Emohaa is a conversational agent that provides cognitive support through
CBT-based exercises and guided conversations. It also emotionally supports
users by enabling them to vent their desired emotional problems. The study
included 134 participants, split into three groups: Emohaa (CBT-based), Emohaa
(Full), and control. Experimental results demonstrated that compared to the
control group, participants who used Emohaa experienced considerably more
significant improvements in symptoms of mental distress. We also found that
adding the emotional support agent had a complementary effect on such
improvements, mainly depression and insomnia. Based on the obtained results and
participants' satisfaction with the platform, we concluded that Emohaa is a
practical and effective tool for reducing mental distress.",2022,http://arxiv.org/abs/2209.10183v1,http://arxiv.org/pdf/2209.10183v1,"Highlights

Chatbots for Mental Health Support: Exploring the Impact of Emohaa on Reducing Mental
Distress in China
Sahand Sabour,Wen Zhang,Xiyao Xiao,Yuwei Zhang,Yinhe Zheng,Jiaxin Wen,Jialu Zhao,Minlie Huang

• This study analyzes the eﬀectiveness, acceptability, and practicality of Emohaa, a Chinese conversational agent

for mental health support, in reducing mental health distress.

• Emohaa provides template-based intervention based on Cognitive Behavioral Therapy (CBT) principles. It also
provides emotional support by allowing users to discuss their desired topic freely and vent about their problems.

• Experimental results demonstrate that using Emohaa signiﬁcantly reduces symptoms of mental distress, namely

depression, anxiety, insomnia, and negative aﬀect.

• Our ﬁndings suggest that allowing participants to have open conversations with the agent and receiving emotional

support has a complementary eﬀect on the improvements.

• Based on the results, we conclude that Emohaa is a feasible and eﬀective tool for reducing mental distress.

2
2
0
2

p
e
S
1
2

]
L
C
.
s
c
[

1
v
3
8
1
0
1
.
9
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
Chatbots for Mental Health Support: Exploring the Impact of
Emohaa on Reducing Mental Distress in China⋆

Sahand Saboura, Wen Zhangb, Xiyao Xiaoc, Yuwei Zhangc, Yinhe Zhengc, Jiaxin Wena,
Jialu Zhaod,∗ and Minlie Huanga,c,∗

aThe CoAI Group, DCST, Institute for Artiﬁcial Intelligence, State Key Lab of Intelligent Technology and Systems, Beijing National Research
Center for Information Science and Technology, Tsinghua University, Beijing 100084, China
bDepartment of Psychology, Beijing Normal University, Beijing 100875, China
cBeijing Lingxin Intelligent Technology CO., Ltd,, Block D, Yousheng Building, Haidian District, Beijing 100083, China
dCenter for Counseling and Psychological Development Guidance Center, Tsinghua University, Beijing 100084, China

A R T I C L E I N F O

A B S T R A C T

Keywords:
Chatbot
Emotional Support
Artiﬁcial Intelligence
Conversational Agent
Mental Health Support
Cognitive Behavioral Therapy

The growing demand for mental health support has highlighted the importance of conversational
agents as human supporters worldwide and in China. These agents could increase availability
and reduce the relative costs of mental health support. The provided support can be divided into
two main types: cognitive and emotional support. Existing work on this topic mainly focuses
on constructing agents that adopt Cognitive Behavioral Therapy (CBT) principles. Such agents
operate based on pre-deﬁned templates and exercises to provide cognitive support. However,
research on emotional support using such agents is limited. In addition, most of the constructed
agents operate in English, highlighting the importance of conducting such studies in China. In
this study, we analyze the eﬀectiveness of Emohaa in reducing symptoms of mental distress.
Emohaa is a conversational agent that provides cognitive support through CBT-based exercises
and guided conversations. It also emotionally supports users by enabling them to vent their
desired emotional problems. The study included 134 participants, split into three groups: Emohaa
(CBT-based), Emohaa (Full), and control. Experimental results demonstrated that compared to
the control group, participants who used Emohaa experienced considerably more signiﬁcant
improvements in symptoms of mental distress. We also found that adding the emotional support
agent had a complementary eﬀect on such improvements, mainly depression and insomnia.
Based on the obtained results and participants’ satisfaction with the platform, we concluded
that Emohaa is a practical and eﬀective tool for reducing mental distress.

1. Introduction

Mental health is a prevalent issue in the modern world due to the increasing morbidity of mental diseases
(WHO, 2022). During the COVID-19 pandemic, depression, anxiety, and other mental health issues have increased
signiﬁcantly (Lakhan et al., 2020). Speciﬁcally, a review by Lakhan et al. (2020) highlighted a 20% and 35% rise in
depression and anxiety, respectively, for 113,285 individuals across 16 studies. Additionally, an international study
with a sample of 22,330 adults showed that about 17.4% of the participants met the criteria for a probable insomnia
disorder (Taylor et al., 2011). These mental health issues impact people’s daily lives, leading to social dysfunction
and risks of self-harm and suicide (Hanna and Strober, 2020). Due to the rapidly increasing demands, mental health
services worldwide face challenges regarding lack of professional training and stigmatization of mental illness. These
challenges can lead to low diagnosis accuracy and patient treatment delays (Lakhan et al., 2020).

Similarly, the prevalence of mental health diseases in China is increasing. According to the epidemiological survey
of mental disorders in China, the lifetime prevalence rate of mental disorders in adults, excluding senile dementia"
"Supporting Therapeutic Relationships and Communication about Mental
  Health","['David Coyle', 'Gavin Doherty']","Effective communication and strong therapeutic relationships are critical to
successful mental health interventions. For example, in 1957 Carl Rogers, a
pioneer of person-centred therapy, proposed that an empowering relationship
could, in and of itself, create the necessary and sufficient conditions for
positive therapeutic outcomes [1]. Whilst modern psychological theories no
longer favour an exclusive focus on relationships, positive relationships and
the dynamics of client-therapist communication remain cornerstones of mental
health intervention theories. A more recent meta-review concluded that across
all interventions models, irrespective of the theoretical approach, the quality
of the relationship between therapists and clients is the second leading
determinant of successful clinical outcomes [2]. Over the past ten years we
(David Coyle and Gavin Doherty) have designed and evaluated a wide range to
systems that provide support for psychological (or talk- based) mental health
interventions [3]. Here we briefly consider two recent examples. In each case
our aim was to enhance communication and reshape clinical practice in a manner
that empowers patients. gNats Island is a computer game that supports
face-to-face interventions for adolescents [4]. MindBalance is an online
treatment programme for adults experiencing difficulties with depression [5].",2013,http://arxiv.org/abs/1307.3164v1,http://arxiv.org/pdf/1307.3164v1,"Supporting Therapeutic Relationships and 
Communication about Mental Health

David Coyle 

Gavin Doherty 

Interaction and Graphics Group, 

School of Computer Science      

Dept. of Computer Science, 

and Statistics, 

University of Bristol, 

Bristol BS8 1UB, UK 

Trinity College Dublin, 

College Green,  

david.coyle@bristol.ac.uk  

Dublin 2, Ireland 

gavin.doherty@cs.tcd.ie  

Keywords 
Mental health; client-therapist relationships; 
communication; face-to-face and remote interventions 

ACM Classification Keywords 
H.5.m [Information Interfaces and Presentation]: Miscellaneous – 

interdisciplinary design, mental health 

Copyright is held by the author/owner(s).  
ACM CHI 2013 April 28, 2013, Paris, France.  

Introduction and background 
Effective communication and strong therapeutic 
relationships are critical to successful mental health 
interventions. For example, in 1957 Carl Rogers, a 
pioneer of person-centred therapy, proposed that an 
empowering relationship could, in and of itself, create 
“the necessary and sufficient conditions” for positive 
therapeutic outcomes [1]. Whilst modern psychological 
theories no longer favour an exclusive focus on 
relationships, positive relationships and the dynamics of 
client-therapist communication remain cornerstones of 
mental health intervention theories. A more recent 
meta-review concluded that across all interventions 
models, irrespective of the theoretical approach, the 
quality of the relationship between therapists and 
clients is the second leading determinant of successful 
clinical outcomes [2]. 

Over the past ten years we (David Coyle and Gavin 
Doherty) have designed and evaluated a wide range to 
systems that provide support for psychological (or talk-
based) mental health interventions [3]. Here we briefly 
consider two recent examples. In each case our aim 
was to enhance communication and reshape clinical 
practice in a manner that empowers patients. gNats 
Island is a computer game that supports face-to-face 
interventions for adolescents [4]. MindBalance is an 
online treatment programme for adults experiencing 
difficulties with depression [5]. 

 
 
 
 
 
 
 
 
 
 
 
 
 
Face-to-face communication: gNats Island 
Adolescents experiencing mental health difficulties 
often react confrontationally, or not at all, to direct 
conversations with a therapist. When therapists work 
with younger children, play therapy often provides an 
effective way of engaging, indirectly, in therapeutic 
processes. However adolescents can also react 
negatively to traditional play therapy if they feel they 
are being treated as children. 

gNats Island is a desktop computer game that aims to 
address this imbalance. It implements key aspects of 
Cognitive Behavioural Therapy (CBT) and provides an 
age appropriate, face-to-face intervention for 
adolescents aged 10-15. The game provides an overall 
narrative in which players visit a tropical island and 
meet a team of wild life explorers. Characters introduce 
mental health concepts using spoken conversation, 
animations, videos and questions regarding the player’s 
own situation. Concrete metaphors are used to explain 
abstract CBT concepts. For example negative automatic 
thoughts, a key concept in CBT, are presented as little 
creatures called gNats that can sting people, causing 
negative thinking. Through a series of in-game 
conversations players learn new strategies for 
identifying and challenging negative thoughts. 
Metaphors such as catching, trapping and swatting 
gNats are used to describe this process. 

In sessions a therapist and adolescent sit together at a 
computer. Rather than talking face-to-face with the 
adolescent, the therapist acts as a partner in their 
exploration of the game world. As such gNats Island 
represents a substantial reshaping of the traditional 
therapeutic interaction. It was intended that 
conversations with game characters would provide a 
context for more detailed conversations between the 

adolescent and therapist. Further, it was predicted that 
the game would help to reduce the difficulties many 
adolescents experience with face-to-face interventions 
and assist in creating a client-centred, fun and 
experiential process. 

Therapists who used gNats Island with adolescents 
were very positive about the way in which the game 
changed the dynamics of the therapeutic interaction. 
They highlighted both specific factors (e.g. eye contact) 
and the general role of the game as a mediating factor: 

“I thought it was really good from an eye contact point 
of view, he doesn’t like making a lot of eye contact, so 
having the screen to focus in on was perfect.”  

“It was almost like a transitional object or an external 
kind of mediating factor, so that I suppose the sessions 
were less directed, less challenging ... so the child 
found it easier to engage through the medium of the 
game.” 

Clinicians also felt the game had a beneficial impact on 
the client-th"
"Heart rate and its variability as an indicator of mental health in male
  prisoners","['Christian Gold', 'Jörg Assmus']","Heart rate (HR) and its variability (HRV) has been proposed as a marker for
depressive symptoms and other aspects of mental health. However, the real
correlation between them is presently uncertain, as previous studies have
generally been conducted on the basis of small samples. In a sample of 113
adult male prisoners, we analyzed correlations between five measures of HR/HRV
and five psychological measures of mental health aspects (depression, state and
trait anxiety, and social relationships). We used Nadaraya-Watson
non-parametric regression in both directions and age-stratified Spearman
correlation to detect possible relations. Despite strong correlations among
HR/HRV measures and among psychological measures, correlations between HR/HRV
and psychological measures were low and non-significant for the overall sample.
However, we found an age dependency, suggesting some correlations in younger
people (HR with STAI-State, r = 0.39; with HADS-Anxiety, r = 0.52; both p <
.005). Overall, the general utility of HR/HRV as a marker for mental health
across populations remains unclear. Future research should address age and
other potential confounders more consistently.",2015,http://arxiv.org/abs/1501.05842v1,http://arxiv.org/pdf/1501.05842v1,"Heart rate and its variability as an indicator of mental health in 
male prisoners 

HRV and mental health 

Christian Gold1,2, Jörg Assmus1,3 
1 GAMUT, Uni Research Health, Uni Research, Bergen, Norway 
2 Grieg Academy Department of Music, University of Bergen, Norway 
3 Centre for Clinical Research, Haukeland University Hospital, Bergen, Norway 

Correspondence 
Christian Gold 
GAMUT – The Grieg Academy Music Therapy Research Centre 
Uni Research Health 
Uni Research 
Lars Hilles gt. 3 
5015 Bergen 
Norway 
Phone +47-97501757 
Email: christian.gold@uni.no 

Abstract 
Heart rate (HR) and its variability (HRV) has been proposed as a marker for depressive 
symptoms and other aspects of mental health. However, the real correlation between them is 
presently uncertain, as previous studies have generally been conducted on the basis of small 
samples. In a sample of 113 adult male prisoners, we analyzed correlations between five 
measures of HR/HRV and five psychological measures of mental health aspects (depression, 
state and trait anxiety, and social relationships). We used Nadaraya-Watson non-parametric 
regression in both directions and age-stratified Spearman correlation to detect possible 
relations. Despite strong correlations among HR/HRV measures and among psychological 
measures, correlations between HR/HRV and psychological measures were low and non-
significant for the overall sample. However, we found an age dependency, suggesting some 
correlations in younger people (HR with STAI-State, r = 0.39; with HADS-Anxiety, r = 0.52; 
both p < .005). Overall, the general utility of HR/HRV as a marker for mental health across 
populations remains unclear. Future research should address age and other potential 
confounders more consistently.  

Keywords 
biomarkers, surrogate endpoints, clinical endpoints, depression, anxiety, social relationships, 
heart rate variability, confounding, age 

i. Introduction 
In evidence-based mental health care, it is important, but not always straightforward, to 
choose the best measures to assess outcomes. Already selecting the right domain can be 
challenging – for example, one has to choose between ‘positive’ or ‘negative’ outcome 
domains (e.g., symptoms or functioning), and between proximal (direct) or distal 
(downstream) outcomes, all to reflect best what the intervention can do and what clients and 
providers need or request (1). In addition, choosing the right data source for a given domain is 
more than a technicality. A relatively recent challenge in this context is the choice between 
traditional psychological assessments (i.e., either self-report or assessor-based, often using 

1 

 
 
 
 
 
 
 
 
HRV and mental health 

questionnaires) versus newer neurophysiological measures. Neurophysiological assessments 
rely on technological tools for measuring some indicator of brain activity. If successful, such 
measures may provide a more objective basis for judging someone’s mental health, as they 
are less susceptible to purposeful distortions and biases than traditional psychological 
assessments. In addition, they might also help to understand links between mental and somatic 
processes. However, in contrast to questionnaire-based methods, physiological indicators are 
usually ‘found’ rather than developed for the purpose. They are therefore reflective of a 
variety of factors, including many that may be unrelated to the domain of interest and that will 
complicate the use of these measures by acting as noise or confounding variables (2). For 
example, a recent study showed almost no correlation between encephalographic markers for 
depression/anxiety and psychological assessments of these domains (3). However, many 
recent studies have used or suggested physiological indicators of mental health as outcomes, 
either alongside or instead of psychological assessments (4-11). 

Heart rate variability (HRV) is one such marker. As a potential biomarker, it is “important not 
so much for what it tells us about the state of the heart as much as it is important for what it 
tells us about the state of the brain” (12). HRV is influenced by various influences from the 
brain, including both the sympathetic as well as the parasympathetic nervous system. Simply 
put, sympathetic input increases the heart rate (in response to stressors, to facilitate ‘fight or 
flight’ behaviors), and parasympathetic input decreases it (to enable relaxation, to facilitate 
‘rest and digest’ behaviors). High HRV might therefore indicate that both systems work well 
and are in balance; the individual is able to respond and adapt to stressful situations as well as 
to relax. HRV has therefore been suggested as a potential biomarker for numerous aspects of 
mental health: It could be a “marker of stress and health” (12), or of “stress and resilience” (p. 
751). It has also been suggested to reflect the “link between emotional states and dispositions 
such as depression, anxiety, anger and hostil"
"Explainable Multi-class Classification of the CAMH COVID-19 Mental
  Health Data","['YuanZheng Hu', 'Marina Sokolova']","Application of Machine Learning algorithms to the medical domain is an
emerging trend that helps to advance medical knowledge. At the same time, there
is a significant a lack of explainable studies that promote informed,
transparent, and interpretable use of Machine Learning algorithms. In this
paper, we present explainable multi-class classification of the Covid-19 mental
health data. In Machine Learning study, we aim to find the potential factors to
influence a personal mental health during the Covid-19 pandemic. We found that
Random Forest (RF) and Gradient Boosting (GB) have scored the highest accuracy
of 68.08% and 68.19% respectively, with LIME prediction accuracy 65.5% for RF
and 61.8% for GB. We then compare a Post-hoc system (Local Interpretable
Model-Agnostic Explanations, or LIME) and an Ante-hoc system (Gini Importance)
in their ability to explain the obtained Machine Learning results. To the best
of these authors knowledge, our study is the first explainable Machine Learning
study of the mental health data collected during Covid-19 pandemics.",2021,http://arxiv.org/abs/2105.13430v1,http://arxiv.org/pdf/2105.13430v1,"Explainable Multi-class Classification of  
the CAMH COVID-19 Mental Health Data  

YuanZheng Hu 
EECS, University of Ottawa 

bhu078@uottawa.ca 

Marina Sokolova 
IBDA@Dalhousie University and  
University of Ottawa 
sokolova@uottawa.ca 

Abstract  
Application of Machine Learning algorithms to the medical domain is an emerging trend that helps to 
advance medical knowledge.  At the same time, there is a significant a lack of explainable studies that 
promote informed, transparent, and interpretable use of Machine Learning algorithms.   In this paper, 
we present explainable multi-class classification of the Covid-19 mental health data.  In Machine 
Learning study, we aim to find the potential factors to influence a person’s mental health during the 
Covid-19 pandemic. We found that Random Forest (RF) and Gradient Boosting (GB) have scored the 
highest accuracy of 68.08% and 68.19% respectively, with LIME prediction accuracy 65.5% for RF and 
61.8% for GB.  We then compare a Post-hoc system (Local Interpretable Model-Agnostic Explanations, or 
LIME) and an Ante-hoc system (Gini Importance) in their ability to explain the obtained Machine 
Learning results.  To the best of these authors’ knowledge, our study is the first explainable Machine 
Learning study of the mental health data collected during Covid-19 pandemics. 

Introduction  
Machine Learning algorithms applied to the medical domain is an emerging trend that helps to advance 
medical studies.  Machine Learning (ML) and Deep Learning (DL) algorithms are often deployed to 
analyse large and diverse data sets when a timely response is essential. Classifications of medical images 
in respect to the COVID-19 diagnosis (Mohamadou et al, 2020), the Covid-19 forecasting model by 
Google Cloud and Harvard Global Health Institute help the frontline medicine.  At the same time, 
reported classification accuracy and predicted infections, hospitalizations, expected deaths tell only a 
part of the story if the studies use a black box approach where the algorithms’ internal factors are 
treated as either unknown or beyond interpretation.   The black box approach impends successful 
implementation and reproducibility of ML and DL studies that depend on a detailed and systematic 
analysis of the models, learning functions involved, meta-parameter influence on the obtained results, 
among others. 

In this work, we demonstrate how post-hoc and ante-hoc explanations enrich ML studies.  Multi-class 
classification of the Covid-19 Mental Health National Survey1 data serves as the ML base of our work.   
The dataset is extracted from a series of six surveys conducted in Canada during May – December 2020. 
The surveys aimed to investigate mental health during the pandemic in Canada.    Our goal is to find out 
the potential factors to influence a person’s mental health during the Covid-19 pandemic. 

1 https://www.camh.ca/en/health-info/mental-health-and-covid-19/covid-19-national-survey 

1 

 
 
 
 
We classify the surveys’ participants into one of the six categories, where each category corresponds to 
a survey.  The survey questions are the data features; the participant answers are feature values.  We 
use six algorithms (Gradient Boosting, Random Forest, Decision Tree, SVM, Logistic Regression, Naïve 
Bayes).   We apply a post-hoc system LIME (Holzinger et al, 2017) to explain the predictions of the six 
Machine Learning algorithms. After we train our dataset using the six models (Gradient Boosting, 
Random Forest, Decision Tree, SVM, Logistic Regression, Naïve Bayes), we use an ante-hoc system Gini 
Importance to analyze two Machine Learning models that achieve the best results (Gradient Boosting ad 
Random Forest).    

We present a comprehensive analysis of the LIME prediction accuracy for Random Forest and Gradient 
Boosting and compute LIME probability estimates for the top most predictions for the six ML classifiers. 
We compare LIME and Gini Importance results by using the explainability fact sheet (Sokol and Flach, 
2020). The fact sheet lists functional requirements, operational requirements, usability, safety, and 
validation as key aspects of explainability. We show that LIME and Gini Importance are similar in 
operational requirements and differ in functional requirements. 

Our explanation results show that consumption of alcohol and use of cannabis have a strong positive 
impact on determining the periods of the pandemic.  This result helps to get insights into the general 
public’s mental health during the Covid-19.  At the same time, it delivers an important information to 
decision makers about usage of the recreational drugs in times of crises.  

To the best of these authors’ knowledge, our study is the first explainable Machine Learning study of 
mental health data collected during Covid-19 pandemics.   Our study fills the void in post-hoc and ante-
hoc explanations of multi-class classification of mental health data and comparison of post-hoc "
"Alexa Depression and Anxiety Self-tests: A Preliminary Analysis of User
  Experience and Trust","['Juan C. Quiroz', 'Tristan Bongolan', 'Kiran Ijaz']","Mental health resources available via websites and mobile apps provide
support such as advice, journaling, and elements from cognitive behavioral
therapy. The proliferation of spoken conversational agents, such as Alexa,
Siri, and Google Home, has led to an increasing interest in developing mental
health apps for these devices. We present the pilot study outcomes of an Alexa
Skill that allows users to conduct depression and anxiety self-tests. Ten
participants were given access to the Alexa Skill for two-weeks, followed by an
online evaluation of the Skill's usability and trust. Our preliminary
evaluation suggests that participants trusted the Skill and scored the
usability and user experience as average. Usage of the Skill was low, with most
participants using the Skill only once. In view of work-in-progress, we also
present a discussion of implementation and study design challenges to guide the
current literature on designing spoken conversational agents for mental health
applications.",2020,http://arxiv.org/abs/2008.03892v1,http://arxiv.org/pdf/2008.03892v1,"0
2
0
2

g
u
A
0
1

]

C
H
.
s
c
[

1
v
2
9
8
3
0
.
8
0
0
2
:
v
i
X
r
a

Alexa Depression and Anxiety Self-tests: A Preliminary Analysis
of User Experience and Trust

Juan C. Quiroz
Centre for Big Data Research in
Health, UNSW
Australian Institute of Health
Innovation, Macquarie University
Sydney, Australia
juan.quiroz@unsw.edu.au

Tristan Bongolan
Macquarie University
Sydney, Australia
tbongolan@hotmail.com

Kiran Ijaz
Australian Institute of Health
Innovation, Macquarie University
Sydney, Australia
kiran.ijaz@mq.edu.au

ABSTRACT
Mental health resources available via websites and mobile apps
provide support such as advice, journaling, and elements from
cognitive behavioral therapy. The proliferation of spoken conver-
sational agents, such as Alexa, Siri, and Google Home, has led to
an increasing interest in developing mental health apps for these
devices. We present the pilot study outcomes of an Alexa Skill
that allows users to conduct depression and anxiety self-tests. Ten
participants were given access to the Alexa Skill for two-weeks,
followed by an online evaluation of the Skill’s usability and trust.
Our preliminary evaluation suggests that participants trusted the
Skill and scored the usability and user experience as average. Usage
of the Skill was low, with most participants using the Skill only
once. In view of work-in-progress, we also present a discussion of
implementation and study design challenges to guide the current
literature on designing spoken conversational agents for mental
health applications.

CCS CONCEPTS
• Human-centered computing → Sound-based input / out-
put.

KEYWORDS
mental health, conversational agent, depression, anxiety, Alexa

ACM Reference Format:
Juan C. Quiroz, Tristan Bongolan, and Kiran Ijaz. 2020. Alexa Depression
and Anxiety Self-tests: A Preliminary Analysis of User Experience and Trust.
In Adjunct Proceedings of the 2020 ACM International Joint Conference on
Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM Inter-
national Symposium on Wearable Computers (UbiComp/ISWC ’20 Adjunct),
September 12–16, 2020, Virtual Event, Mexico. ACM, New York, NY, USA,
3 pages. https://doi.org/10.1145/3410530.3414374

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
UbiComp/ISWC ’20 Adjunct, September 12–16, 2020, Virtual Event, Mexico
© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-8076-8/20/09. . . $15.00
https://doi.org/10.1145/3410530.3414374

1 INTRODUCTION
Mental health problems are a growing global challenge affecting
people of all different backgrounds, ages, and socioeconomic sta-
tus [19]. To tackle this challenge, mental health resources are in-
creasingly available online and via mobile apps [8, 12, 14]. The
proliferation of conversational agents has made them attractive for
health applications [11] and mental health [18]. Notable chatbots
that monitor mood and use aspects of CBT to help users deal with
anxiety and depression include Woebot [17] and TESS [4].

The advancements and rapid adoption of spoken conversational
agents, such as Siri and Alexa, make them attractive as a channel
for providing mental health resources to users [13]. Spoken conver-
sational agents interact with users via spoken natural language. For
mental health applications, this requires users to vocalize responses
about their mental health status, which is different than typing
responses to a chatbot or on a website. One study explained that
some people are more likely to have truthful interactions about
their mental health with technology than wth mental health pro-
fessionals [16].

This paper presents work-in-progress findings of an Alexa Skill
we developed that performs depression and anxiety self-tests. Cur-
rent Alexa Skills focus on guiding, educating, and helping users
manage mental health issues. Some Alexa Skills examples include
management for anxiety and stress through advice sessions (Anti
Anxiety, Anxiety Stress), assisting people with depression by pro-
viding tasks to boost their mood (Mental Health Day Manager),
management advice and education for children and teenagers deal-
ing anger, stress, anxiety, and depression (Mental Health Spies),
and targeted exercises depending on the situation (work, studies,
life) causing the user stress (Mindscape). One study used Alexa to
monitor a user’s mental health behaviors and symptoms, requiring
users to self-report data on sleep, mood, and acti"
"Participatory Design for Mental Health Data Visualization on a Social
  Robot","['Raida Karim', 'Edgar Lopez', 'Elin A. Björling', 'Maya Cakmak']","The intersection of data visualization and human-robot interaction (HRI) is a
burgeoning field. Understanding, communicating, and processing different kinds
of data for creating versatile visualizations can benefit HRI. Conversely,
expressing different kinds of data generated from HRI through effective
visualizations can provide interesting insights. Our work adds to the
literature of this growing domain. In this paper, we present our exploratory
work on visualizing mental health data on a social robot. Particularly, we
discuss development of mental health data visualizations using a participatory
design (PD) approach. As a first step with mental health data visualization on
a social robot, this work paves the way for relevant further work and using
social robots as data visualization tools.",2022,http://arxiv.org/abs/2210.06469v1,http://arxiv.org/pdf/2210.06469v1,"2
2
0
2

g
u
A
0
2

]

C
H
.
s
c
[

1
v
9
6
4
6
0
.
0
1
2
2
:
v
i
X
r
a

Participatory Design for Mental Health Data
Visualization on a Social Robot

Raida Karim
University of Washington
Seattle, Washington, United States
rk1997@cs.washington.edu

Elin A. Bj¨orling
University of Washington
Seattle, Washington, United States
bjorling@uw.edu

Edgar Lopez
University of Washington
Seattle, Washington, United States
lopeze7@uw.edu

Maya Cakmak
University of Washington
Seattle, Washington, United States
mcakmak@cs.washington.edu

Abstract—The intersection of data visualization and human-
robot interaction (HRI) is a burgeoning ﬁeld. Understanding,
communicating, and processing different kinds of data for
creating versatile visualizations can beneﬁt HRI. Conversely,
expressing different kinds of data generated from HRI through
effective visualizations can provide interesting insights. Our work
adds to the literature of this growing domain. In this paper, we
present our exploratory work on visualizing mental health data
on a social robot. Particularly, we discuss development of mental
health data visualizations using a participatory design (PD)
approach. As a ﬁrst step with mental health data visualization
on a social robot, this work paves the way for relevant further
work and using social robots as data visualization tools.

Index Terms—Participatory design, mental health, community,

data visualization, social robots, human-robot interaction

I. INTRODUCTION AND BACKGROUND
Despite many opportunities for collaborative research in
data visualization and HRI, not much work has been con-
tributed to this intersection [6]. Some existing works of this
area include visualizing data of children’s touch patterns on
a social robot [5]. Contributing to this promising domain’s
literature, we worked on developing visualizations of mental
health data for a social robot. Social robots have been used
to support mental health in various ways such as to help
children with autism improve on their social skills [1]. They
have been used to help older adults by reducing feelings of
loneliness [3], and other populations. However, existing work
only shows support for mental health through social robots by
responding interactively to human activity to help them learn
relevant skills. No work has shown the use of social robots
as a means of visualizing mental health data. Therefore, our
work is novel or ﬁrst of its kind.

II. A SOCIAL ROBOT & MENTAL HEALTH DATA
We detail here the procedure of collecting and visualizing

mental health data in these two respective stages:

A. Data Collection

We conducted a ﬁve-weekdays HRI study in an American
university campus with a total of ﬁfty-ﬁve (n=55) participants
sharing their in-the-moment mood and stress levels with a so-

cial robot. Our previous work [2] showed using an emoji likert
scale can enhance coherence and accessibility in portraying
different levels of mood or stress data, which is what we used.
The users’ shared data were stored in a secured ﬁrebase 1.

B. Data Visualization

We developed data visualization software with the updated
static data visualization template from [2] in our social robot’s
software platform. These visualizations are shown in Fig. 1,
and were implemented in JavaScript using AnyChart library
2. When the visualization program is run on the robot,
mood/stress data from ﬁrebase is sent to visualization software
and data visualizations are created in real-time.

III. DISCUSSION
Mental health data visualizations with a social robot can
potentially improve mental health [2]. To the best of our
knowledge, this is the ﬁrst work rendering mental health data
visualizations on a social robot seeking to alleviate mental
health issues among users. Although this work has been con-
ducted with data collected from people of a university campus,
collecting and visualizing other community’s data can inform
about distinct mental health needs of each community. Moving
forward, we plan to expand this work to other community
spaces such as high school, and public library. As mentioned
earlier, PD method was used to ﬁnalize design of data visual-
izations [2]. PD helped us to get inputs from the community
members in designing, developing and reﬁning the features of
the robot-rendered data visualizations for mental well-being.
We have been using PD in our work for more than two years.
We choose to use PD methodology, because PD considers the
intended users’ and stakeholders’ participation throughout the
design process and can result in well-informed and usability-
tested features of these data visualizations rendered by a social
robot. This can eventually help ensure the success of such
robotic technologies in supporting mental health. In [2], we
used qualitative analysis method to derive common themes in

1Firebase: https://ﬁrebase.google.com/
2AnyChart: https://www.anychart.com/

 
 
 
 
 
 
Fig. 1. A line chart visualizing mood data (left) and a color-coded pie chart visualizing "
"An empirical comparison of machine learning models for student's mental
  health illness assessment","['Prathamesh Muzumdar', 'Ganga Prasad Basyal', 'Piyush Vyas']","Student's mental health problems have been explored previously in higher
education literature in various contexts including empirical work involving
quantitative and qualitative methods. Nevertheless, comparatively few research
could be found, aiming for computational methods that learn information
directly from data without relying on set parameters for a predetermined
equation as an analytical method. This study aims to investigate the
performance of Machine learning (ML) models used in higher education. ML models
considered are Naive Bayes, Support Vector Machine, K-Nearest Neighbor,
Logistic regression, Stochastic Gradient Descent, Decision Tree, Random Forest,
XGBoost (Extreme Gradient Boosting Decision Tree), and NGBoost (Natural)
algorithm. Considering the factors of mental health illness among students, we
follow three phases of data processing: segmentation, feature extraction, and
classification. We evaluate these ML models against classification performance
metrics such as accuracy, precision, recall, F1 score, and predicted run time.
The empirical analysis includes two contributions: 1. It examines the
performance of various ML models on a survey-based educational dataset,
inferring a significant classification performance by a tree-based XGBoost
algorithm; 2. It explores the feature importance [variables] from the datasets
to infer the significant importance of social support, learning environment,
and childhood adversities on a student's mental health illness.",2022,http://arxiv.org/abs/2202.13495v1,http://arxiv.org/pdf/2202.13495v1,"Asian Journal of Computer and Information Systems (ISSN: 2321 – 5658) 
Volume 10 – Issue 1, February 2022 

An Empirical Comparison of Machine Learning Models for 
Student’s Mental Health Illness Assessment 

Prathamesh Muzumdar1, Ganga Prasad Basyal2, Piyush Vyas3 

1College of Business, The University of Texas at Arlington, Texas, USA 
Email: prathameshmegh.muzumdar [AT] mavs.uta.edu 

2Business and Natural Sciences Department, College of Business and Natural Sciences  
Black Hills State University, Spearfish, South Dakota, USA 
Email: gangaprasad.basyal [AT] bhsu.edu 

3College of Business and Information Systems, Dakota State University 
Madison, South Dakota, USA 
Email: piyush.vyas [AT] trojans.dsu.edu 

_________________________________________________________________________________________________ 

ABSTRACT---  Student’s  mental  health  problems  have  been  explored  previously  in  higher  education  literature  in 
various contexts including empirical work involving quantitative and qualitative methods. Nevertheless, comparatively 
few  research  could  be  found,  aiming  for  computational  methods  that  learn  information  directly  from  data  without 
relying  on  set  parameters  for  a  predetermined  equation as  an  analytical method.  This  study  aims  to  investigate  the 
performance  of  Machine  learning  (ML)  models  used  in  higher  education.  ML  models  considered  are  Naïve  Bayes, 
Support  Vector  Machine,  K-Nearest  Neighbor,  Logistic  Regression,  Stochastic  Gradient  Descent,  Decision  Tree, 
Random Forest, XGBoost (Extreme Gradient Boosting Decision Tree), and NGBoost (Natural) algorithm. Considering 
the factors of mental health illness among students, we follow three phases of data processing: segmentation, feature 
extraction,  and  classification.  We  evaluate  these  ML  models  against  classification  performance  metrics  such  as 
accuracy, precision, recall, F1 score, and predicted run time. The empirical analysis includes two contributions: 1. It 
examines  the  performance  of  various  ML  models  on  a  survey-based  educational  dataset,  inferring  a  significant 
classification performance by a tree-based XGBoost algorithm; 2. It explores the feature importance [variables] from 
the datasets to infer the significant importance of social support, learning environment, and childhood adversities on a 
student’s mental health illness. 

Keywords--- Student’s mental health illness, Machine learning, Feature importance 

1.  INTRODUCTION 

The World Health Organization [WHO] has indicated that mental illness affects nearly half of the population worldwide 
[3]. The ubiquity of mental illness is associated with considerable impairment in cognitive skills [13], with the combination 
of anxiety and affective disorders being the most common forms of disability among sufferers  [20]. Mental illness is as 
prevalent among college students as others, and the illness appears to be increasing in number and severity [24]. When 
researchers study such illness, college students are the most neglected population, though students are not immune to the 
sufferings and disability associated with such illness. Mental health problems are very common among students and are 
highly  prevalent  in  college  students  [14].  This  is  mainly  because  attending  college  requires  a  student  to  overcome 
challenging times,  which is uncommon in settings like community college and high school  [26]. College students start 
college  after  completing  high  school,  typically  depend  upon  parents  for  financial  support  for  few  years  till  they  start 
working part-time [1]. These students not only face stress related to academic load but also have to face the task of taking 
on more adult-like responsibilities at a younger age. Mental health problems among college students represent a growing 
concern as a large number of students enter their adulthood and this stage is considered an important period of life [24]. 
The  developmentally  challenging  transition  to  adulthood  and  untreated  mental  illness  leads  to  crucial  implications  for 
academic success, productivity, social and personal relationships, and substance abuse [29]. 

College tenure represents the time in many people’s lives when their main activities relating to career and social life 
are  integrated  with  their  surroundings.  University  campuses  are  responsible  to  develop,  disseminate,  and  evaluate  best 
practices to ensure a better experience for students [15]. Therefore, colleges offer the best opportunity to address student’s 
mental health problems among late adolescents and young adults [13]. A robust base of research is necessary to deeply 
understand this phenomenon and investigate the antecedents of student’s mental health problems. In that regard, machine 
learning models and data mining techniques are efficient methods in extracting features and classifying educatio"
Temperature and Mental Health: Evidence from Helpline Calls,['Benedikt Janzen'],"This paper studies the short-term effects of ambient temperature on mental
health using data on nearly half a million helpline calls in Germany.
Leveraging location-based routing of helpline calls and random day-to-day
weather fluctuations, I find a negative effect of temperature extremes on
mental health as revealed by an increase in the demand for telephone counseling
services. On days with an average temperature above 25{\deg}C (77{\deg}F) and
below 0{\deg}C (32{\deg}F), call volume is 3.4 and 5.1 percent higher,
respectively, than on mid-temperature days. Mechanism analysis reveals
pronounced adverse effects of cold temperatures on social and psychological
well-being and of hot temperatures on psychological well-being and violence.
More broadly, the findings of this work contribute to our understanding of how
changing climatic conditions will affect population mental health and
associated social costs in the near future.",2022,http://arxiv.org/abs/2207.04992v2,http://arxiv.org/pdf/2207.04992v2,"Temperature and Mental Health: Evidence from
Helpline Calls∗

Benedikt Janzen†

First version: July 2022
This version: November 2022

Abstract

This paper studies the short-term eﬀects of ambient temperature on mental health

using data on nearly half a million helpline calls in Germany. Leveraging location-

based routing of helpline calls and random day-to-day weather ﬂuctuations, I ﬁnd a

negative eﬀect of temperature extremes on mental health as revealed by an increase in

the demand for telephone counseling services. On days with an average temperature
above 25◦C (77◦F) and below 0◦C (32◦F), call volume is 3.4 and 5.1 percent higher,
respectively, than on mid-temperature days. Mechanism analysis reveals pronounced

adverse eﬀects of cold temperatures on social and psychological well-being and of hot

temperatures on psychological well-being and violence. More broadly, the ﬁndings of

this work contribute to our understanding of how changing climatic conditions will

aﬀect population mental health and associated social costs in the near future.

Keywords: Climate Change, Weather, Well-being

JEL Codes: I1, I31, Q5, Q54

2
2
0
2

v
o
N
5
1

]

N
G
.
n
o
c
e
[

2
v
2
9
9
4
0
.
7
0
2
2
:
v
i
X
r
a

∗I am thankful for helpful comments from Ludovica Gazze, Jamie Mullins, Alessandro Palma, Patrick
Bigler, as well as conference and seminar participants at the AERE Summer Conference, the EAERE Annual
Conference, the ESPE Annual Conference, the IAERE Annual Conference, and the VfS Environmental and
Resource Economics Junior Workshop. I am grateful to my supervisor Doina Radulescu for her excellent
and continuous guidance. I am particularly indebted to Ludger Storch and TelefonSeelsorge for providing
the necessary data. The author has no conﬂict of interest in any part and did not receive any funding for
this work. All remaining errors are my own.

†University of Bern, KPM Center for Public Management and OCCR Oeschger Centre for Climate Change

Research; Email: benedikt.janzen@kpm.unibe.ch

 
 
 
 
 
 
1

Introduction

Mental disorders aﬀect nearly one billion people worldwide, accounting for ﬁve percent of
the total global burden of disease (Ferrari et al., 2022). The World Health Organization
(2012) expects that by the end of the decade mental illness will be the leading cause of
disease burden worldwide, up from 13th in 1990. For those aﬀected, mental illnesses such as
depression are associated with high individual costs, as they reduce labor force participation
and entail large earning penalties (B¨utikofer et al., 2020; Biasi et al., 2021). Globally, the
World Economic Forum estimates that the socioeconomic cost of mental disorders was $2.5
trillion in 2010, and it is expected to more than double by 2030 (Bloom et al., 2011). Because
of uncertainty in potential risk factors for human health, which include climate variability
and trends (McMichael et al., 2006), and given an increase in global surface temperatures
through at least mid-century (IPCC, 2021) projected costs are likely to be an underestimate.

Despite their large share of the global burden of disease and in the face of climate change,
there is limited causal evidence on the impact of temperature extremes on mental health
(Berry et al., 2018). Where existing work has explored the causal eﬀects of temperature
on mental distress, it has focused on suicidality (Burke et al., 2018; Carleton, 2017), health
care utilization (Mullins & White, 2019), and self-reported mental health (Obradovich et
al., 2018). However, these measures have limitations that ultimately make it diﬃcult to
infer the impact of temperature on mental health from them alone (Romanello et al., 2021;
Obradovich & Minor, 2022) as they either focus on rare and extreme or clinical outcomes1,
or represent subjective measures of mental health that might suﬀer from systematic bias
(e.g., Jahedi & M´endez, 2014).

This paper studies the short-term eﬀects of ambient temperature on mental distress using
administrative records from the largest general telephone counseling service in Germany,
consisting of 485,274 individual calls received at 55 sites nationwide between November 2018
and March 2020. The data contains the timestamp, processing location, call topics, and
caller characteristics for each call. Telephone helplines provide free, low-threshold, anony-
mous2 counseling services for people with unmet mental health needs. Although not a
direct measure of psychiatric disorders, the use of helpline data oﬀers many advantages in-

1Mental health stigma can discourage people from seeking professional help (Bharadwaj et al., 2017). In
addition, access to evidence-based treatment remains inadequate even in high-income countries (Demytte-
naere et al., 2004; World Health Organization, 2012).

2In Germany, anonymous and unobservable access to telephone counseling services is even guaranteed
by federal law (§99 Abs. 2 Telecommunications Act (TKG)), which prohibits telecommunication service
provi"
Exploring Mental Health Communications among Instagram Coaches,"['Ehsan-Ul Haq', 'Lik-Hang Lee', 'Gareth Tyson', 'Reza Hadi Mogavi', 'Tristan Braud', 'Pan Hui']","There has been a significant expansion in the use of online social networks
(OSNs) to support people experiencing mental health issues. This paper studies
the role of Instagram influencers who specialize in coaching people with mental
health issues. Using a dataset of 97k posts, we characterize such users'
linguistic and behavioural features. We explore how these observations impact
audience engagement (as measured by likes). We show that the support provided
by these accounts varies based on their self-declared professional identities.
For instance, Instagram accounts that declare themselves as Authors offer less
support than accounts that label themselves as Coach. We show that increasing
information support in general communication positively affects user
engagement. However, the effect of vocabulary on engagement is not consistent
across the Instagram account types. Our findings shed light on this
understudied topic and guide how mental health practitioners can improve
outreach.",2022,http://arxiv.org/abs/2211.06013v1,http://arxiv.org/pdf/2211.06013v1,"2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)

Exploring Mental Health Communications among
Instagram Coaches

Ehsan-Ul Haq∗, Lik-Hang Lee†, Gareth Tyson§, Reza Hadi Mogavi∗, Tristan Braud∗, and Pan Hui∗‡§
∗Hong Kong University of Science and Technology, HKSAR
†Korea Advanced Institute of Science and Technology
‡University of Helsinki, Helsinki
§Hong Kong University of Science and Technology, Guangzhou

Email: {euhaq,rhadimogavi}@connect.ust.hk

likhang.lee@kaist.ac.kr

{gtyson,braudt,panhui}@ust.hk

2
2
0
2

v
o
N
1
1

]
I
S
.
s
c
[

1
v
3
1
0
6
0
.
1
1
2
2
:
v
i
X
r
a

Abstract—There has been a signiﬁcant expansion in the use
of online social networks (OSNs) to support people experiencing
mental health issues. This paper studies the role of Instagram
inﬂuencers who specialize in coaching people with mental health
issues. Using a dataset of 97k posts, we characterize such
users’ linguistic and behavioural features. We explore how these
observations impact audience engagement (as measured by likes).
We show that the support provided by these accounts varies
based on their self-declared professional identities. For instance,
Instagram accounts that declare themselves as Authors offer less
support than accounts that label themselves as a Coach. We
show that increasing information support in general communi-
cation positively affects user engagement. However, the effect of
vocabulary on engagement is not consistent across the Instagram
account types. Our ﬁndings shed light on this understudied topic
and guide how mental health practitioners can improve outreach.

Index Terms—social networks, mental health, Instagram, in-

ﬂuencers

I. INTRODUCTION

The US government reports that one in ﬁve Americans are
facing a mental health problem [1]. Similar statistics have been
reported in other regions [2]. Mental health issues can have
devastating consequences, yet such issues are often considered
taboo.1 This can result in a reluctance to seek help from
professionals, especially since some societies do not encourage
discussions on mental health issues. In such cases, the use
of information and communication technologies (ICT) can
be an important asset in helping people. Researchers have
studied Online Social Networks’ (OSNs) role in the support
and prediction of mental health issues [3], [4]. Social media
has also led to the emergence of mental health ‘inﬂuencers’,
i.e., OSN proﬁles that focus on offering mental health advice.
Such accounts frequently post advice and interact with their
audience in an attempt to promote well-being.

Despite this, there is a paucity of (quantiﬁed) knowledge
about how these users operate and impact others. Considering
the critical role these accounts can play in people’s lives, we
argue that it is vital to study them. We take two social science
theories as motivating factors for our research. First, we look

1https://www.swissre.com/risk-knowledge/risk-perspectives-blog/world-

mental-health-day-preventing-breaking-taboos.html
IEEE/ACM ASONAM 2022, November 10-13, 2022
978-1-6654-5661-6/22/$31.00 © 2022 IEEE

at these accounts from the identity perspective. Professional
identity helps individuals deﬁne and express their role as a
professional and social entity [5], [6]. Moreover, individuals
with professional roles often enjoy trust from the wider
society [7]. This leads us to reason that while the goal of
these accounts is to promote mental health, their professional
identity can be used to characterize such accounts. Thus,
taking this self-declared identity as our comparative scale to
study their communications.
Second, we look at

the psychological characteristics of
the language used. The language used for mental health
support has an effect on patient health [8], [9]. The analysis
of language related to mental health is widely carried out
using the psychological characterization of vocabulary and
quantifying the level of support [10], more particularly in
the context of Information and Emotion Support
that can
have practical outcomes [11]. In our work, we analyze the
communication based on the level of Information and Emotion
Support provided by mental health inﬂuencers. We note that
while these online communications largely remain one-way
in contrast to an actual therapy session, the primary goal of
health inﬂuencers is to promote well-being. Hence, the role of
language remains important.

This paper presents the ﬁrst analysis of how mental health
inﬂuencers use Instagram. We choose Instagram because of
the growing anecdotal evidence of the importance it plays in
this ﬁeld.2 In addition to the characterization of the language,
and support provided by these accounts, we further quantify
the effect of these attributes on user engagement. Speciﬁcally,
we ask two research questions:

• RQ1: Is there any difference in the language across
accounts based on their identity? More particularly, what
are the levels of
information and emoti"
"Quantifying the Effect of Socio-Economic Predictors and Built
  Environment on Mental Health Events in Little Rock, AR","['Alfieri Ek', 'Samantha Robinson', 'Grant Drawve', 'Jyotishka Datta']","Proper allocation of law enforcement resources remains a critical issue in
crime prediction and prevention that operates by characterizing spatially
aggregated crime activities and a multitude of predictor variables of interest.
Despite the critical nature of proper resource allocation for mental health
incidents, there has been little progress in statistical modeling of the
geo-spatial nature of mental health events in Little Rock, Arkansas. In this
article, we provide insights into the spatial nature of mental health data from
Little Rock, Arkansas between 2015 and 2018, under a supervised spatial
modeling framework while extending the popular risk terrain modeling (Caplan et
al., 2011, 2015; Drawve, 2016) approach. We provide evidence of spatial
clustering and identify the important features influencing such heterogeneity
via a spatially informed hierarchy of generalized linear models, spatial
regression models and a tree based method, viz., Poisson regression, spatial
Durbin error model, Manski model and Random Forest. The insights obtained from
these different models are presented here along with their relative predictive
performances. The inferential tools developed here can be used in a broad
variety of spatial modeling contexts and have the potential to aid both law
enforcement agencies and the city in properly allocating resources.",2022,http://arxiv.org/abs/2212.05486v1,http://arxiv.org/pdf/2212.05486v1,"2
2
0
2

c
e
D
1
1

]
P
A

.
t
a
t
s
[

1
v
6
8
4
5
0
.
2
1
2
2
:
v
i
X
r
a

Quantifying the Effect of Socio-Economic Predictors and Built
Environment on Mental Health Events in Little Rock, AR *

Alﬁeri Ek
Department of Mathematical Sciences, University of Arkansas - Fayetteville
and
Samantha Robinson
Department of Mathematical Sciences, University of Arkansas - Fayetteville
and
Grant Drawve
Department of Sociology and Criminology, University of Arkansas - Fayetteville
and
Jyotishka Datta †
Department of Statistics, Virginia Polytechnic Institute and State University

December 13, 2022

Abstract

Proper allocation of law enforcement resources remains a critical issue in crime prediction
and prevention that operates by characterizing spatially aggregated crime activities and a
multitude of predictor variables of interest. Despite the critical nature of proper resource
allocation for mental health incidents, there has been little progress in statistical modeling of the
geo-spatial nature of mental health events in Little Rock, Arkansas. In this article, we provide
insights into the spatial nature of mental health data from Little Rock, Arkansas between 2015
and 2018, under a supervised spatial modeling framework while extending the popular risk
terrain modeling (Caplan et al., 2011, 2015; Drawve, 2016) approach. We provide evidence
of spatial clustering and identify the important features inﬂuencing such heterogeneity via a
spatially informed hierarchy of generalized linear models, spatial regression models and a tree
based method, viz., Poisson regression, spatial Durbin error model, Manski model and Random
Forest. The insights obtained from these different models are presented here along with their
relative predictive performances. The inferential tools developed here can be used in a broad
variety of spatial modeling contexts and have the potential to aid both law enforcement agencies
and the city in properly allocating resources.

1 Introduction

Over the last two decades, law enforcement agencies are relying more and more on statistical tools
to build an objective criminal justice system, leading to a meteoric rise of “predictive policing”,
loosely deﬁned as “the application of analytical techniques - particularly quantitative techniques - to
identify likely targets for police intervention and prevent crime or solve past crimes by making statistical

*This study is a continuation of work presented in the ﬁrst author’s MS thesis and is a work-in-progress draft.
†Corresponding author

1

 
 
 
 
 
 
predictions” (Perry et al., 2013). The proposed algorithms and methods attempt to uncover and
exploit different aspects of crime activities data. For example, Gotway & Stroup (1997) use a spatial
generalized linear model, that has been extended both by considering the temporal pattern as well
as a non-linear modeling approach using generalized additive modeling in ST-GAM or LST-GAM
(Wang & Brown, 2012). In a series of papers, Mohler et al. (2011, 2013, 2015) propose a self-exciting
point process model that treats near-repeat nature of crimes (Townsley et al., 2000) as aftershocks
of an earthquake. This is the main driving force behind the popular crime forecasting software
called PredPol (https://predpol.com/) that has been since adopted by many policing agencies
throughout the US.

Apart from increasing the accuracy of prediction of future crime, it is also important to understand
which geographical factors signiﬁcantly contribute to crime. Such knowledge can inform a plan
for allocating resources or making policy changes to either counteract the effect of a ‘risky’ place
or increase the intensity or presence of a ‘protective’ place. This is also closely related to the goal
of ensuring that a prediction rule does not suffer from algorithmic or systemic biases. This is
particularly important, as with the increase in complexity and use of such data-based tools, there
is growing concern and additional effort devoted to reducing the racial disparities in predictive
policing, while producing dynamic and real-time forecasts and insights about spatio-temporal
crime activities. For example, using a combination of demographically representative synthetic
data and survey data on drug use, Lum & Isaac (2016) point out that predictive policing estimates
based on biased policing records often accentuate the racial bias instead of removing it. A natural
solution seems to be the risk terrain modeling (RTM) framework of Caplan et al. (2011), that uses a
simple but interpretable approach. In RTM, a separate map layer is created for each predictor, that
are then combined to produce a composite map where contribution or importance of each factor
can be evaluated in a model-based way.

We start with a brief review of the existing statistical methodology behind the most common crime
forecasting tools.

1.1 Literature Review

Self-exciting Point Process: One of the popular statistical approaches to modeling criminal activi-
ties "
"Exploring Hybrid and Ensemble Models for Multiclass Prediction of Mental
  Health Status on Social Media","['Sourabh Zanwar', 'Daniel Wiechmann', 'Yu Qiao', 'Elma Kerz']","In recent years, there has been a surge of interest in research on automatic
mental health detection (MHD) from social media data leveraging advances in
natural language processing and machine learning techniques. While significant
progress has been achieved in this interdisciplinary research area, the vast
majority of work has treated MHD as a binary classification task. The
multiclass classification setup is, however, essential if we are to uncover the
subtle differences among the statistical patterns of language use associated
with particular mental health conditions. Here, we report on experiments aimed
at predicting six conditions (anxiety, attention deficit hyperactivity
disorder, bipolar disorder, post-traumatic stress disorder, depression, and
psychological stress) from Reddit social media posts. We explore and compare
the performance of hybrid and ensemble models leveraging transformer-based
architectures (BERT and RoBERTa) and BiLSTM neural networks trained on
within-text distributions of a diverse set of linguistic features. This set
encompasses measures of syntactic complexity, lexical sophistication and
diversity, readability, and register-specific ngram frequencies, as well as
sentiment and emotion lexicons. In addition, we conduct feature ablation
experiments to investigate which types of features are most indicative of
particular mental health conditions.",2022,http://arxiv.org/abs/2212.09839v1,http://arxiv.org/pdf/2212.09839v1,"Exploring Hybrid and Ensemble Models for Multiclass Prediction of
Mental Health Status on Social Media

Sourabh Zanwar
RWTH Aachen University
sourabh.zanwar@rwth-aachen.de

Daniel Wiechmann
University of Amsterdam
d.wiechmann@uva.nl

Yu Qiao
RWTH Aachen University
yu.qiao@rwth-aachen.de

Elma Kerz
RWTH Aachen University
elma.kerz@ifaar.rwth-aachen.de

Abstract

In recent years, there has been a surge of in-
terest in research on automatic mental health
detection (MHD) from social media data lever-
aging advances in natural language processing
and machine learning techniques. While sig-
niﬁcant progress has been achieved in this in-
terdisciplinary research area, the vast major-
ity of work has treated MHD as a binary clas-
siﬁcation task. The multiclass classiﬁcation
setup is, however, essential if we are to un-
cover the subtle differences among the statis-
tical patterns of language use associated with
particular mental health conditions. Here, we
report on experiments aimed at predicting six
conditions (anxiety, attention deﬁcit hyperac-
tivity disorder, bipolar disorder, post-traumatic
stress disorder, depression, and psychological
stress) from Reddit social media posts. We ex-
plore and compare the performance of hybrid
and ensemble models leveraging transformer-
based architectures (BERT and RoBERTa) and
BiLSTM neural networks trained on within-
text distributions of a diverse set of linguis-
tic features. This set encompasses measures
of syntactic complexity, lexical sophistication
and diversity, readability, and register-speciﬁc
ngram frequencies, as well as sentiment and
emotion lexicons. In addition, we conduct fea-
ture ablation experiments to investigate which
types of features are most indicative of partic-
ular mental health conditions.

1

Introduction

Mental health is a major challenge in healthcare
and in our modern societies at large, as evidenced
by the topic’s inclusion in the United Nations’ 17
Sustainable Development Goals. The World Health
Organization estimates that 970 million people
worldwide suffer from mental health issues, the
most common being anxiety and depressive disor-
ders1. The problem is compounded by the fact that

1https://www.who.int/news-room/fact-sheets/

detail/mental-disorders

the rate of undiagnosed mental disorders has been
estimated to be as high as 45% (La Vonne et al.,
2012). The societal impact of mental health disor-
ders requires prevention and intervention strategies
focused primarily on screening and early diagnosis.
In keeping with the WHO Mental Health Action
Plan (Saxena et al., 2013), natural language pro-
cessing and machine learning can make an impor-
tant contribution to gathering more comprehensive
information and knowledge about mental illness.
In particular, an increasing use of social media plat-
forms by individuals is generating large amounts
of high-quality behavioral and textual data that can
support the development of computational solu-
tions for the study of mental disorders. An emerg-
ing, interdisciplinary ﬁeld of research at the in-
tersections of computational linguistics, health in-
formatics and artiﬁcial intelligence now leverages
natural language processing techniques to analyze
such data to develop models for early detection of
various mental health conditions.

Systematic reviews of this research show that
the vast majority of the existing work has focused
primarily on automatic identiﬁcation of speciﬁc
disorders, with depression and anxiety being the
most commonly studied target conditions (Calvo
et al., 2017; Chancellor and De Choudhury, 2020;
Zhang et al., 2022). As a result, existing work has
focused on developing binary classiﬁers that aim
to distinguish between individuals with a particular
mental illness and control users.

The current work addresses the more complex
problem of distinguishing between multiple men-
tal states, which is essential if we are to uncover
the subtle differences among the statistical pat-
terns of language use associated with particular
disorders. Speciﬁcally, in this paper we make the
following contributions to the existing literature
on health text mining based on social media data:
(1) We frame the MHC detection tasks as a multi-
class prediction task aimed to determine to what

2
2
0
2
c
e
D
9
1

]
L
C
.
s
c
[

1
v
9
3
8
9
0
.
2
1
2
2
:
v
i
X
r
a

 
 
 
 
 
 
extent six mental health conditions (anxiety, atten-
tion deﬁcit hyperactivity disorder, bipolar disorder,
post-traumatic stress disorder, depression, and psy-
chological stress) can be predicted on the basis of
social media posts from Reddit. (2) We explore
and compare the performance of hybrid and ensem-
ble models leveraging transformer-based architec-
tures (BERT and RoBERTa) and BiLSTM neural
networks trained on within-text distributions of a
diverse set of linguistic features. (3) We conduct
feature ablation experiments to investigate which
types of features are most indicative of particular
mental health conditions.

This pap"
Deep Learning Mental Health Dialogue System,"['Lennart Brocki', 'George C. Dyer', 'Anna Gładka', 'Neo Christopher Chung']","Mental health counseling remains a major challenge in modern society due to
cost, stigma, fear, and unavailability. We posit that generative artificial
intelligence (AI) models designed for mental health counseling could help
improve outcomes by lowering barriers to access. To this end, we have developed
a deep learning (DL) dialogue system called Serena. The system consists of a
core generative model and post-processing algorithms. The core generative model
is a 2.7 billion parameter Seq2Seq Transformer fine-tuned on thousands of
transcripts of person-centered-therapy (PCT) sessions. The series of
post-processing algorithms detects contradictions, improves coherency, and
removes repetitive answers. Serena is implemented and deployed on
\url{https://serena.chat}, which currently offers limited free services. While
the dialogue system is capable of responding in a qualitatively empathetic and
engaging manner, occasionally it displays hallucination and long-term
incoherence. Overall, we demonstrate that a deep learning mental health
dialogue system has the potential to provide a low-cost and effective
complement to traditional human counselors with less barriers to access.",2023,http://arxiv.org/abs/2301.09412v1,http://arxiv.org/pdf/2301.09412v1,"6th International Workshop on Dialog Systems (IWDS)
10th IEEE International Conference on Big Data and Smart Computing (BigComp)

Deep Learning Mental Health Dialogue System

Lennart Brocki
Institute of Informatics
University of Warsaw
Warsaw, Poland
brocki.lennart@gmail.com

George C. Dyer
Demiteris
Wrocław, Poland
georgecdyer@gmail.com

Anna Gładka
Psychiatry Department
Wrocław Medical University
Wrocław, Poland
agladka@gmail.com

Neo Christopher Chung
Institute of Informatics
University of Warsaw
Warsaw, Poland
nchchung@gmail.com

3
2
0
2

n
a
J

3
2

]
L
C
.
s
c
[

1
v
2
1
4
9
0
.
1
0
3
2
:
v
i
X
r
a

Abstract—Mental health counseling remains a major challenge
in modern society due to cost, stigma, fear, and unavailability. We
posit that generative artiﬁcial intelligence (AI) models designed
for mental health counseling could help improve outcomes by
lowering barriers to access. To this end, we have developed a
deep learning (DL) dialogue system called Serena. The system
consists of a core generative model and post-processing algo-
rithms. The core generative model is a 2.7 billion parameter
Seq2Seq Transformer [26] ﬁne-tuned on thousands of transcripts
of person-centered-therapy (PCT) sessions. The series of post-
processing algorithms detects contradictions, improves coherency,
and removes repetitive answers. Serena is implemented and
deployed on https://serena.chat, which currently offers limited
free services. While the dialogue system is capable of responding
in a qualitatively empathetic and engaging manner, occasionally
it displays hallucination and long-term incoherence. Overall, we
demonstrate that a deep learning mental health dialogue system
has the potential to provide a low-cost and effective complement
to traditional human counselors with less barriers to access.

Index Terms—Deep Learning, Artiﬁcial Intelligence, Trans-

formers, Mental Health, Chatbot, Dialogue System

I. INTRODUCTION

The lack of widespread access to mental health counseling
remains one of the biggest challenges in the world. It
is
estimated that 658 million people in the world suffer from
some form of psychological distress and this number grew by
50% in the last 30 years [4]. Yet only 35% percent of people
with mental health disorders receive mental health treatment
[3], and less than 25% percent have ever “seen someone” [7].
Psychological counseling and therapy are helpful in treating
anxiety, depression, obsessive compulsive disorder, personality
disorders, eating disorders and a plethora of other conditions
[14]. Around 48% of people experiencing a mental health
crisis reported that talking with friends was helpful, however
56% of them ended up handling their problems alone [6].
We propose that a virtual mental health counselor based on
generative deep learning models could substantially improve
mental health outcomes for many user proﬁles. In this paper
we will present our design and implementation of a deep
learning dialogue system for psychological counseling.

Generative deep learning (DL) models may provide an
answer to a simple yet
tenacious question: how can we
make mental health counseling more accessible? To effectively
tackle the problem, we ﬁrst need to consider why most people
cannot or do not want to access mental health counseling.
The most obvious cause is the prohibitive cost of the type

Fig. 1. Overview of the Serena dialogue system. A large generative model
outputs candidate responses conditioned on a user prompt and three smaller,
more specialized NLP models are used to reject unsuitable responses.

of regular, in-person counseling that is proven to be the most
beneﬁcial [11]. A similar obstacle is time. Those people who
earn enough money to afford quality counseling may not,
as a result, have enough time to dedicate to the process,
which in addition to the actual sessions, requires scheduling,
commuting, arranging for the care of children, etc. Finally, we
have fear of counseling and perceived stigma [22].

We designed such a DL-based dialogue system called Ser-
ena as a system that addresses as many of these factors as pos-
sible, with an emphasis on ﬁlling the gaps left by traditional,
in-person counseling. Stated differently, the proposed system is
not designed as a replacement for traditional therapy. Rather,
we conceive it as: 1) a fallback for those who are strictly
unable to engage in traditional therapy because of money or
time; 2) a catalyst for helping people warm up to the idea of
sharing their thoughts through the process of dialogue, which
may result in them in setting up in-person sessions; 3) a tool
for identifying therapy needs and measuring engagement with
a virtual counseling model across a wide demographic, with
the goal of improving quality and access to mental health
resources globally.

II. RELATED WORK

Broadly speaking, dialogue systems (a.k.a. chatbots) can
be divided into two groups: those that primarily use artiﬁcial
intelligence or generative processes on the one han"
"Curriculum-guided Abstractive Summarization for Mental Health Online
  Posts","['Sajad Sotudeh', 'Nazli Goharian', 'Hanieh Deilamsalehy', 'Franck Dernoncourt']","Automatically generating short summaries from users' online mental health
posts could save counselors' reading time and reduce their fatigue so that they
can provide timely responses to those seeking help for improving their mental
state. Recent Transformers-based summarization models have presented a
promising approach to abstractive summarization. They go beyond sentence
selection and extractive strategies to deal with more complicated tasks such as
novel word generation and sentence paraphrasing. Nonetheless, these models have
a prominent shortcoming; their training strategy is not quite efficient, which
restricts the model's performance. In this paper, we include a curriculum
learning approach to reweigh the training samples, bringing about an efficient
learning procedure. We apply our model on extreme summarization dataset of
MentSum posts -- a dataset of mental health related posts from Reddit social
media. Compared to the state-of-the-art model, our proposed method makes
substantial gains in terms of Rouge and Bertscore evaluation metrics, yielding
3.5% (Rouge-1), 10.4% (Rouge-2), and 4.7% (Rouge-L), 1.5% (Bertscore) relative
improvements.",2023,http://arxiv.org/abs/2302.00954v1,http://arxiv.org/pdf/2302.00954v1,"Curriculum-guided Abstractive Summarization
for Mental Health Online Posts

Sajad Sotudeh 1*, Nazli Goharian1, Hanieh Deilamsalehy2, and Franck Dernoncourt2

1IRLab, Georgetown University
{sajad,nazli}@ir.cs.georgetown.edu
2Adobe Research
{deilamsa,franck.dernoncourt}@adobe.com

Abstract

Automatically generating short summaries
from users’ online mental health posts could
save counselors’ reading time and reduce their
fatigue so that they can provide timely re-
sponses to those seeking help for improv-
ing their mental state. Recent Transformers-
based summarization models have presented
a promising approach to abstractive summa-
rization. They go beyond sentence selection
and extractive strategies to deal with more
complicated tasks such as novel word gener-
ation and sentence paraphrasing. Nonethe-
less, these models have a prominent shortcom-
ing;
their training strategy is not quite efﬁ-
cient, which restricts the model’s performance.
In this paper, we include a curriculum learn-
ing approach to reweigh the training samples,
bringing about an efﬁcient learning procedure.
We apply our model on extreme summariza-
tion dataset of MENTSUM posts —a dataset
of mental health related posts from Reddit so-
cial media. Compared to the state-of-the-art
model, our proposed method makes substan-
tial gains in terms of ROUGE and BERTSCORE
evaluation metrics, yielding 3.5% (ROUGE-
1), 10.4% (ROUGE-2), and 4.7% (ROUGE-L),
1.5% (BERTSCORE) relative improvements.

1

Introduction

Summarization of mental health online posts is an
emerging task that aims to summarize users’ posts
who are seeking help to enhance their mental state
in online networks such as Reddit 1 and Reachout 2.
The post might address several issues of the user’s
concerns or simply be an elaboration on the user’s
mental and emotional situation. With user prefer-
ence, each user-written post can be accompanied
by a succinct summary (known as TL;DR 3), con-

* Work partially done during the internship at Adobe

Research.

1https://www.reddit.com/
2https://au.reachout.com/
3 TL;DR is the abbreviation of “Too Long, Didn’t Read”.
We use “TL;DR” and “summary” exchangeably in this paper.

densing major points of the user post. This TL;DR
summary is deemed to urge the counselors for a
faster read of the user’s posted content before read-
ing the post in its entirety; hence, counsellors can
provide responses promptly. Herein, we aim to im-
prove state-of-the-art results reported in (Sotudeh,
Goharian, and Young, 2022) for this task.

Large-scale deep neural models are often hard
leaning on intricate heuristic set-ups,
to train,
which can be time-consuming and expensive to
tune (Gong et al., 2019; Chen et al., 2021). This is
especially the case for the Transformers-based sum-
marizers, which have been shown to consistently
outperform the RNN networks when rigorously
tuned (Popel and Bojar, 2018), but also require
heuristics such as specialized learning rates and
large-batch training (Platanios et al., 2019). In this
paper, we attempt to overcome the mentioned prob-
lem on BART (Lewis et al., 2020) Transformers-
based summarizer by introducing a Curriculum
Learning (CL) strategy (Bengio et al., 2009) for
training the summarization model, leading to im-
proved convergence time, and performance.

Inspired by humans’ teaching style, curriculum
learning suggests moving the teaching process
from easier samples to more difﬁcult ones and dates
back to the nineties (Elman, 1993). The driving
idea behind this approach is that networks can ac-
complish better task learning when the training
instances are exposed to the network in a speciﬁc
and certain order, from easier samples to more dif-
ﬁcult ones (Chang et al., 2021). In the context of
neural networks, this process can be thought of as a
technique that makes the network robust to getting
stuck at local optima, which is more likely in the
early stages of the training process. Given the men-
tioned challenge of summarization networks, we
utilize the SUPERLOSS (Castells et al., 2020) func-
tion that falls into the family of conﬁdence-aware
curriculum learning techniques, introducing a new
parameter called conﬁdence (i.e., σ) to the network.

3
2
0
2

b
e
F
2

]
L
C
.
s
c
[

1
v
4
5
9
0
0
.
2
0
3
2
:
v
i
X
r
a

 
 
 
 
 
 
We validate our model on MENTSUM (Sotudeh,
Goharian, and Young, 2022) dataset, containing
over 24k instances mined from 43 mental health
related communities on Reddit social media. Our
experimental results show the efﬁcacy of applying
curriculum learning objectives on BART summa-
rizer, achieving a new state-of-the-art performance.

2 Related Work

While majority of works in mental health research
have focused on studying users’ behavioral patterns
through classiﬁcation and prediction tasks (Choud-
hury et al., 2013; Resnik et al., 2013; Coppersmith
et al., 2014; Yates et al., 2017; Cohan et al., 2017,
2018; MacAvaney et al., 2018), summarization of
online mental health posts has been recently made
via"
Evaluation of ChatGPT for NLP-based Mental Health Applications,['Bishal Lamichhane'],"Large language models (LLM) have been successful in several natural language
understanding tasks and could be relevant for natural language processing
(NLP)-based mental health application research. In this work, we report the
performance of LLM-based ChatGPT (with gpt-3.5-turbo backend) in three
text-based mental health classification tasks: stress detection (2-class
classification), depression detection (2-class classification), and suicidality
detection (5-class classification). We obtained annotated social media posts
for the three classification tasks from public datasets. Then ChatGPT API
classified the social media posts with an input prompt for classification. We
obtained F1 scores of 0.73, 0.86, and 0.37 for stress detection, depression
detection, and suicidality detection, respectively. A baseline model that
always predicted the dominant class resulted in F1 scores of 0.35, 0.60, and
0.19. The zero-shot classification accuracy obtained with ChatGPT indicates a
potential use of language models for mental health classification tasks.",2023,http://arxiv.org/abs/2303.15727v1,http://arxiv.org/pdf/2303.15727v1,"Evaluation of ChatGPT for NLP-based Mental
Health Applications

Bishal Lamichhane,
lamichhane.bishal@gmail.com

1

3
2
0
2

r
a

M
8
2

]
L
C
.
s
c
[

1
v
7
2
7
5
1
.
3
0
3
2
:
v
i
X
r
a

Abstract—Large language models (LLM) have been successful
in several natural language understanding tasks and could be rel-
evant for natural language processing (NLP)-based mental health
application research. In this work, we report the performance
of LLM-based ChatGPT (with gpt-3.5-turbo backend) in three
text-based mental health classiﬁcation tasks: stress detection (2-
class classiﬁcation), depression detection (2-class classiﬁcation),
and suicidality detection (5-class classiﬁcation). We obtained
annotated social media posts for the three classiﬁcation tasks
from public datasets. Then ChatGPT API classiﬁed the social
media posts with an input prompt for classiﬁcation. We obtained
F1 scores of 0.73, 0.86, and 0.37 for stress detection, depression
detection, and suicidality detection, respectively. A baseline model
that always predicted the dominant class resulted in F1 scores
of 0.35, 0.60, and 0.19. The zero-shot classiﬁcation accuracy
obtained with ChatGPT indicates a potential use of language
models for mental health classiﬁcation tasks.

Index Terms—ChatGPT, mental health, natural language pro-

cessing, stress, depression, suicidality

I. INTRODUCTION

Mental health illnesses are widely prevalent. More than one
billion people worldwide are estimated to be suffering from
mental illnesses [1]. In the US, one in ﬁve individuals has men-
tal health issues every year [2]. Proper management of mental
health with timely diagnosis,
intervention, and monitoring
requires measuring mental health. Since most mental health ill-
nesses have bio-psycho-social origins, research on measuring
mental health has considered obtaining bio-behavioral signals
to detect the mental health state of the individual. Social media
posts could be a source to detect the mental health state of an
individual. One’s mental health state could be reﬂected in the
sentiments or linguistic contents of their social media posts.
Accordingly, previous works have demonstrated mental health
state detection based on the analysis of users’ social media
posts [3], [4], [5].

Mental health state detection from texts such as social
media posts requires natural language processing (NLP) to
infer the sentiment and content shared in the text. Recently,
large language models (LLM) have shown unprecedented
success in natural language understanding. LLMs are neural
networks based on the transformer architecture [6] trained in
a self-supervised setting with a large text corpus, followed by
ﬁne-tuning in supervised and reinforcement learning settings.
ChatGPT is a popular LLM-based chat application/assistant
that has been receiving a lot of public attention. ChatGPT as
a conversation agent demonstrates its capability to understand
the text and respond accordingly. Though several limitations
of ChatGPT and LLMs, in general, are acknowledged, these

models have shown to be good generalized models across
different applications. The applications of the GPT-4 model,
the latest LLM model from OpenAI, in several areas such
as programming and mathematics were demonstrated by the
authors in [7]. Similarly, the authors in [8] demonstrated
GPT-4’s capability in the medical domain for answering
USMLE (United States Medical Licensing Examination) and
MultMedQA dataset [9] questions.

One application area for LLM could be in mental health,
given the model’s capability for language understanding. Dif-
ferent application scenarios could arise for LLM’s use in a
mental health context. As a user interacts more with LLMs,
the
sometimes even sharing their thoughts and concerns,
posts shared with LLMs could provide a better view of the
person’s mental health compared to social media posts. The
LLMs could adapt to respond based on the person’s mental
health state or even provide interventions, e.g., by suggesting
to seek medical care. LLM’s language understanding could
also be used as a backend in many front-end mental health
applications. Much effort today is focused on building custom
machine-learning models for mental health detection tasks
based on texts and other modalities. As the LLMs get more
intelligent, it is not inconceivable that these LLMs become a
defacto backend for all language understanding tasks such as
in mental health applications

Given the current capability of ChatGPT as one of the most
popular LLM-based chat applications, in this work, we evalu-
ated ChatGPT’s zero-shot classiﬁcation performance in three
mental health application tasks: stress detection, depression
detection, and suicidality detection tasks based on user’s social
media posts. We used publicly available labeled datasets for
our evaluations.

A. Dataset

II. METHOD

1) Stress Detection Dataset: We evaluated ChatGPT’s abil-
ity to detect stressed states using the labeled stress detection
dataset available "
"Demo Alleviate: Demonstrating Artificial Intelligence Enabled Virtual
  Assistance for Telehealth: The Mental Health Case","['Kaushik Roy', 'Vedant Khandelwal', 'Raxit Goswami', 'Nathan Dolbir', 'Jinendra Malekar', 'Amit Sheth']","After the pandemic, artificial intelligence (AI) powered support for mental
health care has become increasingly important. The breadth and complexity of
significant challenges required to provide adequate care involve: (a)
Personalized patient understanding, (b) Safety-constrained and medically
validated chatbot patient interactions, and (c) Support for continued
feedback-based refinements in design using chatbot-patient interactions. We
propose Alleviate, a chatbot designed to assist patients suffering from mental
health challenges with personalized care and assist clinicians with
understanding their patients better. Alleviate draws from an array of publicly
available clinically valid mental-health texts and databases, allowing
Alleviate to make medically sound and informed decisions. In addition,
Alleviate's modular design and explainable decision-making lends itself to
robust and continued feedback-based refinements to its design. In this paper,
we explain the different modules of Alleviate and submit a short video
demonstrating Alleviate's capabilities to help patients and clinicians
understand each other better to facilitate optimal care strategies.",2023,http://arxiv.org/abs/2304.00025v1,http://arxiv.org/pdf/2304.00025v1,"3
2
0
2

r
a

M
1
3

]
L
C
.
s
c
[

1
v
5
2
0
0
0
.
4
0
3
2
:
v
i
X
r
a

Demo Alleviate: Demonstrating Artiﬁcial Intelligence Enabled Virtual Assistance
for Telehealth: The Mental Health Case

Kaushik Roy, Vedant Khandelwal, Raxit Goswami, Nathan Dolbir, Jinendra Malekar, Amit Sheth
Artiﬁcial Intelligence Institute, University of South Carolina
Columbia, South Carolina (Zip - 29208)
{kaushikr, vedant, rgoswami, ndolbir}@email.sc.edu, jmalekar@mailbox.sc.edu, amit@sc.edu

Abstract

After the pandemic, artiﬁcial intelligence (AI) powered sup-
port for mental health care has become increasingly im-
portant. The breadth and complexity of signiﬁcant chal-
lenges required to provide adequate care involve: (a) Per-
sonalized patient understanding, (b) Safety-constrained and
medically validated chatbot patient interactions, and (c) Sup-
port for continued feedback-based reﬁnements in design us-
ing chatbot-patient interactions. We propose Alleviate, a chat-
bot designed to assist patients suffering from mental health
challenges with personalized care and assist clinicians with
understanding their patients better. Alleviate draws from an
array of publicly available clinically valid mental-health texts
and databases, allowing Alleviate to make medically sound
and informed decisions. In addition, Alleviate’s modular de-
sign and explainable decision-making lends itself to robust
and continued feedback-based reﬁnements to its design. In
this paper, we explain the different modules of Alleviate and
submit a short video demonstrating Alleviate’s capabilities to
help patients and clinicians understand each other better to
facilitate optimal care strategies.

Introduction
The current pandemic has over-extended mental healthcare
systems and caused striking increases in mental health clin-
ical services(WHO 2022; WCVB 2020). With the severe
shortage of mental health clinicians coupled with a decrease
in in-person visits at health care facilities, AI-powered chat-
bots offer a promising solution in helping patients miti-
gate mental health symptoms early on through active self-
care for effective prevention and intervention. The current
standard of chatbots provides script-based screening tasks
(e.g., reminding, scheduling) that assist patients with mental
health self-management through chatbot-patient interactions
for their daily self-care(Jaimini et al. 2018).

Enabling more advanced capabilities in chatbots raises
challenging core algorithmic issues on: (a) Personalized
patient understanding, (b) Safety-constrained and medi-
cally validated chatbot-patient interactions, and (c) support
for continued feedback-based reﬁnements in design using
chatbot-patient and chatbot-clinician interactions.

We propose Alleviate, a chatbot designed to assist patients
suffering from mental health challenges with personalized

Copyright © 2023, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

care. Alleviate represents personalized patient knowledge as
a graph that integrates knowledge from an array of clinically
valid mental-health texts and databases with patient-speciﬁc
information derived from provider notes and patient-chatbot
interactions (see Figure 1 (a))(Cameron et al. 2015; Roy
et al. 2021a; Rawte et al. 2022; Lokala et al. 2021; Gaur
et al. 2021). Furthermore, alleviate operates in strict confor-
mance with medically established guidelines ensuring safe
interactions with the patient. The breadth and depth of med-
ical knowledge consolidated in the knowledge graph enable
Alleviate to make medically sound and informed decisions
(see Figure 1 (b))(Roy et al. 2022; Sheth et al. 2022; Gupta
et al. 2022). In addition, Alleviate’s modular design and ex-
plainable reinforcement learning algorithms allow continued
development and reﬁnement using user and clinician feed-
back (see Figure 1 (c))(Roy et al. 2021b). We explain the
inner workings of the Alleviate functions:

• Safe

and Explainable Medication Reminder

and

Troubleshooting.
• Patient Appraisal
Recommendations.

on Adherence

to Medical

• Behavior Detection Requiring Emergency Human

Intervention.

. The functions cover Alleviate’s aim to assist care providers
with safe and explainable personalized patient care.

Safe and Explainable Medication Reminder
and Troubleshooting
Alleviate extracts personalized patient information from
provider notes and past patient interactions using ¡sub-
ject, predicate, object¿ triple extraction techniques to boot-
strap the patient knowledge graph. Further, Alleviate inte-
grates patient information with mental health information
from knowledge bases by connecting the entities and re-
lationships in the initialized patient knowledge graph with
similar entities in the knowledge bases. Computing dense
representation-based distances are used to determine simi-
lar entities. Finally, alleviate resolves connection conﬂicts
during integration using clinician-speciﬁed guidelines for
conﬂict resolution. Fi"
Amity -- A Hybrid Mental Health Application,"['Srija Santhanam', 'Kavipriya P', 'Balamurugan MS', 'Manoj Kumar Rajagopal']","Wellness in trivial terms combines physical, social, and mental wellbeing.
While mental health is neglected, long-term success in a person life is mostly
determined by his psychological health and contentment. For a person in
distress, professional mental health services are quite expensive, unpopular,
and invite a lot of hesitation. Hence, it would be effective to use an Android
application that can offer day to day therapeutic assistance, meditation
sessions, and guidance since it can cater to a massive community instantly. In
this paper, we propose a mobile and web application AMITY with a chat group and
chatbot created using a machine learning approach. We have also built a dataset
to train the chatbot model that we propose in this paper. We briefly introduce
the dataset and the machine learning model in section 3. In section 4, we
include the architecture and the development details of the Hybrid application.
Next, we present our results on usability and the efficiency of the idea we
propose.",2023,http://arxiv.org/abs/2305.11871v1,http://arxiv.org/pdf/2305.11871v1,"AMITY - A HYBRID MENTAL HEALTH APPLICATION

Srija Santhanam , Kavipriya P , Balamurugan MS

School of Electronics Engineering , Vellore Institute of Technology , Chennai , India

ABSTRACT.

Wellness in trivial terms combines physical, social, and mental well-being. While mental health
is generally neglected,
long-term success in a person’s life is mostly determined by his
psychological health and contentment. For a person in distress, professional mental health
services are quite expensive, unpopular, and invite a lot of hesitation. Hence, It would be
effective to use an Android application that can offer day-to-day therapeutic assistance,
meditation sessions, and guidance since it can cater to a massive community instantly. In this
paper, we propose a mobile and web application-AMITY with a chat group and chatbot created
using a machine learning approach. We have also built a dataset to train the chatbot model that
we propose in this paper. We briefly introduce the dataset and the machine learning model in
section 3. In section 4, we include the architecture and the development details of the Hybrid
application. Next, we present our results on usability and the efficiency of the idea we propose.

INTRODUCTION

Emotional well-being stands equal to physical well-being and plays a vital role in creating
positive relationships, giving back to the community, and feeling accepted in groups. Positive
mental health can help us deal with stress, adapt to changes, make difficult decisions, and
manage emotions.

Mental health has become a rising concern over the past decade, especially after a pandemic
that scaled worldwide and terrorized lakhs of people in their homes. In 2020, the Centers for
Disease Control and Prevention in the United States found that there was a 31% increase in the
number of people with mental health disorders from the previous year due to COVID-19.
Alarmingly, about 381 suicides happen every day in India according to National Crime Records
Bureau(2019).

Around 10% of the population of India in 2015-2016 was found to need Counseling services out
of which only 28% received treatment. Also, mental health issues are shunned and ostracized
since there is not much awareness propagated. There is an inadequacy in the number of mental
health professionals and the percentage of funds allocated by the Government of India is
minimal. Consequently, psychological therapy is expensive in India and people in turn solicit
help from conventional
Institutions such as religious establishments, cultural practices, or
immediate friends and family.

The vast majority do not
treat mental health problems until their effects become severe.
Professional help is not immediate. A significant fraction might also find it difficult to share their

problems with another individual face to face. It is said that 1 in 4 people have mental health
problems in their lifetime. Supply does not meet the demands here. Hence, a vast platform such
as an Android application surely is a benefit. A multitude of mental health applications exist
offering breathing and meditation practices, sleep stories, and mindfulness exercises. There is
this app called ‘WoeBot’ offering cognitive behavioral therapy exercises to induce sleep. Another
application ‘BetterHelp’ connects users with therapists online and the MoodFit app tracks the
mood of the user on a day-to-day basis with which required exercises are suggested. Generally,
people need to talk or let out their emotions to someone on an immediate basis to relieve stress,
anxiety, or frustration. The problem is that there would not be many that may listen and
empathize. Our solution involves a group chat feature that helps people with similar problems
connect, talk and help each other out anytime and anywhere which is lacking in the majority of
the apps out there.

Emotional Artificial Intelligence uses machine learning to detect and respond to the emotions of
humans with technologies such as Computer Vision and Natural Language Processing. Facial
Recognition algorithms are used for detecting expressions, while chatbots enable conversations
with users based on their mood that could be tracked from their messages. Hence, helping
people who are depressed will be made easier and cheaper with Artificial Intelligence. We
include an NLP-based chatbot in our application that offers quick therapeutic assistance to the
users based on their input. We also suggest diet and exercise plans as an additional feature.
Users would also be able to call therapists if they need a professional to talk to.

2.RELATED WORKS

There are a few psychotherapeutic approaches used for mental wellness. Cognitive Behavioral
Therapy (CBT). Dialectical Behavior Therapy (DBT), Acceptance and Commitment Therapy
(ACT), Psychodynamic Therapy, Interpersonal Therapy (IPT), Eye Movement Desensitization
and Reprocessing (EMDR), and Mindfulness-Based Therapies, are some of
the major
psychotherapeutic approaches used. Among the above ther"
Rethinking Large Language Models in Mental Health Applications,"['Shaoxiong Ji', 'Tianlin Zhang', 'Kailai Yang', 'Sophia Ananiadou', 'Erik Cambria']","Large Language Models (LLMs) have become valuable assets in mental health,
showing promise in both classification tasks and counseling applications. This
paper offers a perspective on using LLMs in mental health applications. It
discusses the instability of generative models for prediction and the potential
for generating hallucinatory outputs, underscoring the need for ongoing audits
and evaluations to maintain their reliability and dependability. The paper also
distinguishes between the often interchangeable terms ``explainability'' and
``interpretability'', advocating for developing inherently interpretable
methods instead of relying on potentially hallucinated self-explanations
generated by LLMs. Despite the advancements in LLMs, human counselors'
empathetic understanding, nuanced interpretation, and contextual awareness
remain irreplaceable in the sensitive and complex realm of mental health
counseling. The use of LLMs should be approached with a judicious and
considerate mindset, viewing them as tools that complement human expertise
rather than seeking to replace it.",2023,http://arxiv.org/abs/2311.11267v2,http://arxiv.org/pdf/2311.11267v2,"3
2
0
2
c
e
D
7
1

]
L
C
.
s
c
[

2
v
7
6
2
1
1
.
1
1
3
2
:
v
i
X
r
a

Rethinking Large Language Models
in Mental Health Applications

Shaoxiong Ji †, Tianlin Zhang ⋆, Kailai Yang ⋆, Sophia Ananiadou ⋆, and Erik
Cambria α

†

University of Helsinki, Finland
⋆ The University of Manchester, UK
αNanyang Technological University, Singapore
Email: shaoxiong.ji@helsinki.fi; {kailai.yang,tianlin.zhang}@postgrad.manchester.ac.uk;,
sophia.ananiadou@manchester.ac.uk, cambria@ntu.edu.sg

Abstract

Large Language Models (LLMs) have become valuable assets in mental health, showing promise
in both classification tasks and counseling applications. This paper offers a perspective on using
LLMs in mental health applications. It discusses the instability of generative models for predic-
tion and the potential for generating hallucinatory outputs, underscoring the need for ongoing au-
dits and evaluations to maintain their reliability and dependability. The paper also distinguishes
between the often interchangeable terms “explainability” and “interpretability”, advocating for
developing inherently interpretable methods instead of relying on potentially hallucinated self-
explanations generated by LLMs. Despite the advancements in LLMs, human counselors’ em-
pathetic understanding, nuanced interpretation, and contextual awareness remain irreplaceable
in the sensitive and complex realm of mental health counseling. The use of LLMs should be ap-
proached with a judicious and considerate mindset, viewing them as tools that complement human
expertise rather than seeking to replace it.

1 Introduction

Mental health is important and has been studied by natural language processing (NLP) using text
(e.g., social posts and doctor-patient conversations) as the data sources, leading to the development
of automatic methods for various applications, including early detection of mental disorders [49]
and mental health counseling [1]. Researchers have employed techniques, ranging from traditional
feature engineering to automatic feature learning, such as convolutional neural networks, recurrent
neural networks, and transformer networks, for mental illness detection and classification [49]. Re-
cent advances utilize pretrained language models (PLMs). PLMs trained with the masked language
modeling objective have become popular for training classification models in this domain. Domain-
specific continual pre-training has also undergone intensive development to acquire domain knowl-
edge with representative discriminative models including PsychBERT [41], MentalBERT [18], PHS-
BERT [31], and MentalLongformer [19]. A recent shift as in Figure 1 has occurred towards prompt
learning, where generative large language models (LLMs) such as SmileChat [33], Psy-LLM [22],
Mental-LLM [46], MentalLLaMA [48], ChatCounselor [26], and MindWatch [4], are used to gen-
erate predictions or counseling based on input prompts related to mental health conditions. This
shift signifies a growing interest in leveraging generative LLMs and prompt learning for mental
health-related tasks. However, one question looms large: is this a mere hype? This paper delves into
the recent developments and concerns surrounding the use of LLMs for early prediction of mental
health conditions, generating explanations for mental health conditions, and generating responses
in mental health counseling.

The landscape of large language models has undergone substantial transformation in recent
years. Current LLMs boast hundreds of billions of parameters, a stark contrast to the relatively
modest sizes seen in the early 2010s, typically ranging from millions to tens of millions of pa-
rameters. Notably, models such as BERT, with 110 million parameters, and GPT-2, with 1.5 billion

1

 
 
 
 
 
 
Figure 1: A paradigm shift in NLP for mental health applications from masked language models
such as BERT to generative language models such as GPT and LLaMA. Images of BERT, GPT, LLaMA
are generated by Midjourney AI Art Generator.

parameters, which were once considered large, now fall into the category of medium-sized language
models by standards at the time of writing. It is important to note that the size of language models is
not the only factor determining their performance. Other factors, such as model architecture, train-
ing data, and fine-tuning, also play significant roles in their capabilities. This growth in model size
reflects the ongoing evolution of AI language models. This paper focuses on the recent use of gen-
erative LLMs in mental health applications. For the purpose of this paper, the term “LLMs” refers
to generative models trained with the causal language modeling objective, often called next-word
prediction in a simpler term.

Our paper offers perspectives on rethinking large language models in the context of mental
healthcare. When using generation to predict mental health conditions based on a prompt and
post, it is worth noting that the generation-as-prediction process can "
PsyChat: A Client-Centric Dialogue System for Mental Health Support,"['Huachuan Qiu', 'Anqi Li', 'Lizhi Ma', 'Zhenzhong Lan']","Dialogue systems are increasingly integrated into mental health support to
help clients facilitate exploration, gain insight, take action, and ultimately
heal themselves. A practical and user-friendly dialogue system should be
client-centric, focusing on the client's behaviors. However, existing dialogue
systems publicly available for mental health support often concentrate solely
on the counselor's strategies rather than the behaviors expressed by clients.
This can lead to unreasonable or inappropriate counseling strategies and
corresponding responses generated by the dialogue system. To address this
issue, we propose PsyChat, a client-centric dialogue system that provides
psychological support through online chat. The client-centric dialogue system
comprises five modules: client behavior recognition, counselor strategy
selection, input packer, response generator, and response selection. Both
automatic and human evaluations demonstrate the effectiveness and practicality
of our proposed dialogue system for real-life mental health support.
Furthermore, the case study demonstrates that the dialogue system can predict
the client's behaviors, select appropriate counselor strategies, and generate
accurate and suitable responses.",2023,http://arxiv.org/abs/2312.04262v2,http://arxiv.org/pdf/2312.04262v2,"PsyChat: A Client-Centric Dialogue System for
Mental Health Support

Huachuan Qiu1,2, Anqi Li1,2, Lizhi Ma2, Zhenzhong Lan2,†
1Zhejiang University, Hangzhou, China
2School of Engineering, Westlake University, Hangzhou, China
{qiuhuachuan, lanzhenzhong}@westlake.edu.cn

4
2
0
2

r
a

M
0
2

]
L
C
.
s
c
[

2
v
2
6
2
4
0
.
2
1
3
2
:
v
i
X
r
a

Abstract—Dialogue systems are increasingly integrated into
mental health support
to help clients facilitate exploration,
gain insight, take action, and ultimately heal themselves. A
practical and user-friendly dialogue system should be client-
centric, focusing on the client’s behaviors. However, existing
dialogue systems publicly available for mental health support
often concentrate solely on the counselor’s strategies rather than
the behaviors expressed by clients. This can lead to unreason-
able or inappropriate counseling strategies and corresponding
responses generated by the dialogue system. To address this
issue, we propose PsyChat, a client-centric dialogue system that
provides psychological support through online chat. The client-
centric dialogue system comprises five modules: client behavior
recognition, counselor strategy selection, input packer, response
generator, and response selection. Both automatic and human
evaluations demonstrate the effectiveness and practicality of our
proposed dialogue system for real-life mental health support. Fur-
thermore, the case study demonstrates that the dialogue system
can predict the client’s behaviors, select appropriate counselor
strategies, and generate accurate and suitable responses.

Index Terms—dialogue system, client-centric, mental health
support, client behavior recognition, counselor strategy selection

I. INTRODUCTION

Mental health [1] is a growing concern in our fast-paced and
digitally connected world. However, traditional mental health
support services often face challenges related to accessibility,
affordability, and stigma. Additionally, face-to-face interviews
with counselors are constrained by time and space. Therefore,
many individuals are hesitant to seek help due to these barriers,
leaving their mental well-being at risk. With the increasing
demand for mental health support, there is a pressing need for
innovative approaches to effectively meet this demand.

Dialogue systems are increasingly integrated into mental
health support to assist clients in exploring, gaining insight,
taking action, and ultimately facilitating self-healing [2]. A
practical and user-friendly dialogue system should be client-
centric, focusing on clients’ behaviors. However, existing
dialogue systems [3]–[5] for mental health support often
concentrate solely on counselors’ strategies, frequently over-
looking the behaviors expressed by clients. This tendency
leads to unreasonable or inappropriate counseling strategies
and corresponding responses produced by the dialogue system.
More specifically, a practical and user-friendly dialogue sys-
tem should prioritize considering clients’ states. Therefore, it

Fig. 1. An illustration depicting how a counselor tailors strategies in response
to the behaviors exhibited by the client.

should adjust its strategies based on clients’ current behaviors,
mimicking human counselors, as illustrated in Figure 1.

In light of this, we introduce PsyChat, a client-centric
dialogue system designed to provide psychological support
through online chat. The client-centric dialogue system con-
sists of five modules: client behavior recognition, counselor
strategy selection, input packer, response generator, and re-
sponse selection. The response generation module is intention-
ally fine-tuned using synthetic and real-life dialogue datasets.
The primary contributions of this paper are as follows:

• To the best of our knowledge, we are the first to propose a
client-centric dialogue system for mental health support,
with a priority on considering the client’s behaviors.
• We optimize collaboration among modules by conducting
extensive experiments to identify the optimal model for
each. These selected models are then integrated to form
a cohesive dialogue system dedicated to mental health.
• Automatic and human evaluations demonstrate the ef-
fectiveness and practicality of our developed dialogue
system. Finally, we release our code and model1 to
facilitate research in mental health support.

II. RELATED WORK

While the development of integrated dialogue systems for
mental health support remains unexplored, we offer a summary

† Corresponding Author.

1https://github.com/qiuhuachuan/PsyChat

( Negative – Sarcastic Answer )You always provide me with encouragement and support, and it feels a bit like you're just going through the motions. Any practical advice you can offer?Counselor( Supporting – Restatement )You mentioned struggling with procrastination.( Supporting – Affirmation and Reassurance )It's impressive that you're aware of this tendency.( Positive – Confirming )I really appreciate your underst"
The Role of Likes: How Online Feedback Impacts Users' Mental Health,"['Angelina Voggenreiter', 'Sophie Brandt', 'Fabian Putterer', 'Andreas Frings', 'Juergen Pfeffer']","Social media usage has been shown to have both positive and negative
consequences for users' mental health. Several studies indicated that peer
feedback plays an important role in the relationship between social media use
and mental health. In this research, we analyse the impact of receiving online
feedback on users' emotional experience, social connectedness and self-esteem.
In an experimental study, we let users interact with others on a Facebook-like
system over the course of a week while controlling for the amount of positive
reactions they receive from their peers. We find that experiencing little to no
reaction from others does not only elicit negative emotions and stress amongst
users, but also induces low levels of self-esteem. In contrast, receiving much
positive online feedback, evokes feelings of social connectedness and reduces
overall loneliness. On a societal level, our study can help to better
understand the mechanisms through which social media use impacts mental health
in a positive or negative way. On a methodological level, we provide a new
open-source tool for designing and conducting social media experiments.",2023,http://arxiv.org/abs/2312.11914v1,http://arxiv.org/pdf/2312.11914v1,"3
2
0
2
c
e
D
9
1

]

Y
C
.
s
c
[

1
v
4
1
9
1
1
.
2
1
3
2
:
v
i
X
r
a

The Role of Likes: How Online Feedback Impacts Users’ Mental
Health

Angelina Voggenreiter*1
0000-0001-6597-3514

Sophie Brandt*
0009-0003-6999-5106

Fabian Putterer*
0009-0009-9310-3634

Andreas Frings*
0009-0009-4993-0384

J¨urgen Pfeffer*
0000-0002-1677-150X

*School of Social Sciences and Technology, Technical University of Munich
1angelina.voggenreiter@tum.de

Abstract

1

Introduction

Social media usage has been shown to have both
positive and negative consequences for users’ mental
health. Several studies indicated that peer feedback
plays an important role in the relationship between
social media use and mental health. In this research,
we analyse the impact of receiving online feedback
on users’ emotional experience, social connectedness
and self-esteem.
In an experimental study, we let
users interact with others on a Facebook-like system
over the course of a week while controlling for the
amount of positive reactions they receive from their
peers. We find that experiencing little to no reaction
from others does not only elicit negative emotions and
stress amongst users, but also induces low levels of
self-esteem. In contrast, receiving much positive on-
line feedback, evokes feelings of social connectedness
and reduces overall loneliness. On a societal level,
our study can help to better understand the mecha-
nisms through which social media use impacts mental
health in a positive or negative way. On a method-
ological level, we provide a new open-source tool for
designing and conducting social media experiments.

Keywords
self-
social media, Facebook,
esteem, social status, ostracism, rejection, exclusion

likes,

Worldwide, more than 4.5 billion people use social
media platforms, such as Facebook, Twitter or In-
stagram. This number is expected to rise in the fol-
lowing years, with an estimated 5.85 billion users by
2027 [6]. Based on the sheer amount of people ac-
tively participating in such online spaces, it is impor-
tant to understand the impact social media can have
on their users.

On the one hand, social media offers tremendous
possibilities to improve people’s mental health: So-
cial media has been shown to provide distinct social
support and connectedness, which can be associated
with better mental health outcomes [15].

Especially when looking at marginalized groups
such as the LGBTQIA+ community, social media
can serve as a place to find friends and social sup-
port. For example, LGBTQIA+ youth is more likely
than non-LGBTQIA+ youth to report having friends
exclusively known online, who are further described
as more supportive than their in-person friendships,
proving how the internet can serve as a safe space for
receiving both social and emotional encouragement
[21]. By investigating the online behaviour of uni-
versity students an overall positive indirect impact
of social media use on psychological well-being was

1

 
 
 
 
 
 
found. The effect was mainly derived from its posi-
tive effect on bonding and bridging social capital, im-
plying that the use of social media allows students to
continue their close relationships during events such
as a pandemic. Further, social media was shown to
improve trust and promote the establishing of social
connections. Finally, it was found that students can
use social media platforms to receive emotional sup-
port and increase their potential to mobilize others or
build social networks, leading to social belongingness
[11].

On the other hand, social media use has also
been associated with numerous mental health issues,
such as anxiety, depression, loneliness, poor quality
of sleep, thoughts of self-harm and suicide, and in-
creased levels of psychological distress [14].

Coyne et al.

[2] performed an eight-year longi-
tudinal study to analyse the effects of social media
use on adolescents’ mental health. Based on an-
nual surveys, they found that, although there were
no within-subjects relationships between social me-
dia usage time and mental health consequences, par-
ticipants who spent more time on social media had a
higher chance of experiencing anxiety and depression,
compared to others [2].

Further investigation into social networks and their
relationship to student mental health showed that
symptoms of poor mental health, especially depres-
sion, increased with a roll-out of Facebook at the col-
lege. For students predicted to be most susceptible to
mental illness, the introduction of Facebook led to an
increased uptake of mental healthcare services. Addi-
tionally, the likelihood to report a negative impact of
poor mental health on their academic performance
increased [1]. Another study looking specifically at
adolescents showed higher usage of social media and
higher emotional investment in social media leads to
a poorer quality of sleep, higher levels of anxiety and
depression, and lower self-esteem [20].

However, the mechanisms in which social media
migh"
"Mental Workload Estimation with Electroencephalogram Signals by
  Combining Multi-Space Deep Models","['Hong-Hai Nguyen', 'Ngumimi Karen Iyortsuun', 'Seungwon Kim', 'Hyung-Jeong Yang', 'Soo-Hyung Kim']","The human brain remains continuously active, whether an individual is working
or at rest. Mental activity is a daily process, and if the brain becomes
excessively active, known as overload, it can adversely affect human health.
Recently, advancements in early prediction of mental health conditions have
emerged, aiming to prevent serious consequences and enhance the overall quality
of life. Consequently, the estimation of mental status has garnered significant
attention from diverse researchers due to its potential benefits. While various
signals are employed to assess mental state, the electroencephalogram,
containing extensive information about the brain, is widely utilized by
researchers. In this paper, we categorize mental workload into three states
(low, middle, and high) and estimate a continuum of mental workload levels. Our
method leverages information from multiple spatial dimensions to achieve
optimal results in mental estimation. For the time domain approach, we employ
Temporal Convolutional Networks. In the frequency domain, we introduce a novel
architecture based on combining residual blocks, termed the Multi-Dimensional
Residual Block. The integration of these two domains yields significant results
compared to individual estimates in each domain. Our approach achieved a 74.98%
accuracy in the three-class classification, surpassing the provided data
results at 69.00%. Specially, our method demonstrates efficacy in estimating
continuous levels, evidenced by a corresponding Concordance Correlation
Coefficient (CCC) result of 0.629. The combination of time and frequency domain
analysis in our approach highlights the exciting potential to improve
healthcare applications in the future.",2023,http://arxiv.org/abs/2308.02409v2,http://arxiv.org/pdf/2308.02409v2,"4
2
0
2

r
a

M
2
1

]
P
S
.
s
s
e
e
[

2
v
9
0
4
2
0
.
8
0
3
2
:
v
i
X
r
a

MENTAL WORKLOAD ESTIMATION WITH

ELECTROENCEPHALOGRAM SIGNALS BY COMBINING

MULTI-SPACE DEEP MODELS

Hong-Hai Nguyen, Ngumimi Karen Iyortsuun, Seungwon Kim, Hyung-Jeong Yang, and Soo-Hyung Kim ∗

Artificial Intelligence Convergence, Chonnam National University, Gwangju, 61186, South Korea

honghaik14@gmail.com; kareniyortsuun@gmail.com; Seungwon.Kim@jnu.ac.kr; hjyang@jnu.ac.kr; shkim@jnu.ac.kr.

ABSTRACT

The human brain remains continuously active, whether an individual is working or at rest. Mental

activity is a daily process, and if the brain becomes excessively active, known as overload, it

can adversely affect human health. Recently, advancements in early prediction of mental health

conditions have emerged, aiming to prevent serious consequences and enhance the overall quality of

life. Consequently, the estimation of mental status has garnered significant attention from diverse

researchers due to its potential benefits. While various signals are employed to assess mental state,

the electroencephalogram, containing extensive information about the brain, is widely utilized by

researchers. In this paper, we categorize mental workload into three states (low, middle, and high) and

estimate a continuum of mental workload levels. Our method leverages information from multiple

spatial dimensions to achieve optimal results in mental estimation. For the time domain approach,

we employ Temporal Convolutional Networks. In the frequency domain, we introduce a novel

architecture based on combining residual blocks, termed the Multi-Dimensional Residual Block. The

integration of these two domains yields significant results compared to individual estimates in each

domain. Our approach achieved a 74.98% accuracy in the three-class classification, surpassing the

provided data results at 69.00%. Specially, our method demonstrates efficacy in estimating continuous

levels, evidenced by a corresponding Concordance Correlation Coefficient (CCC) result of 0.629.

The combination of time and frequency domain analysis in our approach highlights the exciting

potential to improve healthcare applications in the future.

Keywords Electroencephalogram · Mental Workload · Temporal Convolutional Networks · Time-Frequency domains

∗Corresponding author: Soo-Hyung Kim

 
 
 
 
 
 
Mental Workload Estimation with Electroencephalogram Signals by Combining Multi-Space Deep Models

1

Introduction

Mental workload (MWL) refers to brain activities, which are the number of resources in the human brain. The level

of the resource can be changed when the human is thinking or performing a task [1]. Because the mental workload

resource of a person is limited, the ability to process a lot of information at once will be limited [2, 3]. Humans will be

bored if they do easy work when their MWL is low and their MWL is high when they do complicated tasks. However, a

high MWL is not suitable for their health [4] and can impair their abilities for memory, communication, activity, etc. For

jobs with high MWL, such as doctors, soldiers and pilots, the brain sometimes has serious accidents [5]. Furthermore,

understanding how the human brain works in daily activities and tasks is an essential area of neuroergonomics research.

Therefore, the MWL estimation helps to observe and help people at work and evaluate their work system, which can

be improved in the future [6]. Because the EEG signal is a recording of the biological activities of individual brain

cells or a subset of brain cells transmitted directly or indirectly through the cerebral cortex and scalp. EEG signals that

record brain activities reflect physiological and pathological functions of the hemisphere or of the whole brain related

to clinical symptoms, supplementing diagnosis and monitoring treatment, called a clinical electroencephalogram. By

providing a reliable EEG can contribute to predicting and preventing work-related risks. Diagnostic applications in

MWL estimation can be created to address various real-world issues in healthcare, education, and smart traffic, among

others [7, 8].

Three metrics were used to measure MWL, namely subject, performance, and physiological measures [6, 9–11]. The

traditional method to measure the context is through a set of various questions, such as the Aeronautics and Space

Administration Task Load Index (NASA-TLX) [12] or Assessment Technique (SWAT) [13]. Performance measurement

involves measuring the person’s performance during the task with an increasing workload. Both subject and performance

measures are taken after the task is completed, making them prone to bias. On the contrary, physiological measurements

can continuously record information about the workload and do not affect the performance of the main task. Therefore,

physiological signals can be used to evaluate the effectiveness of mental workload.

Physiological measurement uses a variet"
"Engagement Patterns of Peer-to-Peer Interactions on Mental Health
  Platforms","['Ashish Sharma', 'Monojit Choudhury', 'Tim Althoff', 'Amit Sharma']","Mental illness is a global health problem, but access to mental healthcare
resources remain poor worldwide. Online peer-to-peer support platforms attempt
to alleviate this fundamental gap by enabling those who struggle with mental
illness to provide and receive social support from their peers. However,
successful social support requires users to engage with each other and failures
may have serious consequences for users in need. Our understanding of
engagement patterns on mental health platforms is limited but critical to
inform the role, limitations, and design of these platforms. Here, we present a
large-scale analysis of engagement patterns of 35 million posts on two popular
online mental health platforms, TalkLife and Reddit. Leveraging communication
models in human-computer interaction and communication theory, we
operationalize a set of four engagement indicators based on attention and
interaction. We then propose a generative model to jointly model these
indicators of engagement, the output of which is synthesized into a novel set
of eleven distinct, interpretable patterns. We demonstrate that this framework
of engagement patterns enables informative evaluations and analysis of online
support platforms. Specifically, we find that mutual back-and-forth
interactions are associated with significantly higher user retention rates on
TalkLife. Such back-and-forth interactions, in turn, are associated with early
response times and the sentiment of posts.",2020,http://arxiv.org/abs/2004.04999v1,http://arxiv.org/pdf/2004.04999v1,"Engagement Patterns of Peer-to-Peer Interactions on Mental Health Platforms

Ashish Sharma1∗ Monojit Choudhury2 Tim Althoff1 Amit Sharma2
1Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, USA
2Microsoft Research, Bangalore, India
1{ashshar,althoff}@cs.washington.edu 2{monojitc,amshar}@microsoft.com

0
2
0
2

r
p
A
0
1

]
I
S
.
s
c
[

1
v
9
9
9
4
0
.
4
0
0
2
:
v
i
X
r
a

Abstract

Mental illness is a global health problem, but access to men-
tal healthcare resources remain poor worldwide. Online peer-
to-peer support platforms attempt to alleviate this fundamen-
tal gap by enabling those who struggle with mental illness
to provide and receive social support from their peers. How-
ever, successful social support requires users to engage with
each other and failures may have serious consequences for
users in need. Our understanding of engagement patterns on
mental health platforms is limited but critical to inform the
role, limitations, and design of these platforms. Here, we
present a large-scale analysis of engagement patterns of 35
million posts on two popular online mental health platforms,
TALKLIFE and REDDIT. Leveraging communication models
in human-computer interaction and communication theory,
we operationalize a set of four engagement indicators based
on attention and interaction. We then propose a generative
model to jointly model these indicators of engagement, the
output of which is synthesized into a novel set of eleven dis-
tinct, interpretable patterns. We demonstrate that this frame-
work of engagement patterns enables informative evaluations
and analysis of online support platforms. Speciﬁcally, we ﬁnd
that mutual back-and-forth interactions are associated with
signiﬁcantly higher user retention rates on TALKLIFE. Such
back-and-forth interactions, in turn, are associated with early
response times and the sentiment of posts.

1

Introduction

Mental illness is an alarming global health issue with ad-
verse social and economic consequences. Mental illness
and related behavioral health problems contribute 13% to
the global burden of disease, more than cardiovascular dis-
eases and cancer (Collins et al. 2011). Still, access to men-
tal health care is poor worldwide. Most low-income and
middle-income countries have less than one psychiatrist per
100,000 individuals (Rathod et al. 2017). Even in high-
income countries like the United States, 60% of counties do
not have a single psychiatrist (New-American-Economy Re-
search, 2019).

∗This work was done when the author was a Research Fellow

at Microsoft Research, India.
Copyright c(cid:13) 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

Research suggests that for people in distress, connecting
and interacting with peers can be helpful in coping with
mental illness, enhancing mental well-being and developing
social integration (Davidson et al. 1999). This form of so-
cial support (Kaplan, Cassel, and Gore 1977) through peers
can be provided online which has stimulated the design and
development of online mental health support platforms.

In recent years, several low-cost and easy-to-access peer-
to-peer support platforms, such as TALKLIFE & 7Cups1,
have provided new pathways for seeking social support and
dealing with mental health challenges. These platforms al-
low interactions between support seekers and peers in a
thread-like setting; it starts with a user writing a support
seeking post which elicits responses from peers and subse-
quent interactions between the users. Online platforms have
multiple advantages over traditional face-to-face supportive
methods: they enable asynchronous conversations by de-
sign; they are unrestricted by time, space and geographic
boundaries; and they facilitate anonymous disclosures which
can be helpful in dealing with the major challenge of stigma
associated with mental illness (White and Dorman 2001).

However, for these platforms to be successful at facili-
tating peer-to-peer support, users need to interact and en-
gage. A user who wants to seek support on the platform
(henceforth referred to as seeker) needs to interact with a
peer who is willing to provide support (henceforth referred
as peer-supporter). For example, on TALKLIFE, one third
of support-seeking posts by users do not receive any re-
sponses at all. Receiving no response or having limited en-
gagement with peers can have serious consequences on a
mental health platform with vulnerable users, a number of
whom are at risk for self-harm or suicide. Also, as indi-
cated in prior literature, engagement between users is key
for ensuring favorable outcomes on these platforms (Van
Uden-Kraan et al. 2011), including overcoming cognitive
distortion, effective distraction, and empathy (Taylor 2011;
Mayshak et al. 2017).

Prior work on engagement between users on support plat-
forms have focused on ﬁnding its correlations with several
user and platform related char"
