[
  {
    "title": "Comparisons of Australian Mental Health Distributions",
    "authors": [
      "David Gunawan",
      "William Griffiths",
      "Duangkamon Chotikapanich"
    ],
    "abstract": "Bayesian nonparametric estimates of Australian mental health distributions\nare obtained to assess how the mental health status of the population has\nchanged over time and to compare the mental health status of female/male and\nindigenous/non-indigenous population subgroups. First- and second-order\nstochastic dominance are used to compare distributions, with results presented\nin terms of the posterior probability of dominance and the posterior\nprobability of no dominance. Our results suggest mental health has deteriorated\nin recent years, that males mental health status is better than that of\nfemales, and non-indigenous health status is better than that of the indigenous\npopulation.",
    "year": 2021,
    "url": "http://arxiv.org/abs/2106.08047v1",
    "pdf_url": "http://arxiv.org/pdf/2106.08047v1",
    "full_text": "Comparisons of Australian Mental Health Distributions \n\n1 \n\nDavid Gunawan \n\nUniversity of Wollongong \n\nWilliam Griffiths* \n\nUniversity of Melbourne \n\nDuangkamon Chotikapanich \nMonash University \n\n10 June, 2021 \n\nAbstract \n\nBayesian nonparametric estimates of Australian mental health distributions are obtained to assess how \n\nthe mental health status of the population has changed over time, and to compare the mental health \n\nstatus  of  female/male  and  indigenous/non-indigenous  population subgroups.  First-  and  second-order \n\nstochastic dominance are used to compare distributions, with results presented in terms of the posterior \n\nprobability of dominance and the posterior probability of no dominance. Our results suggest mental \n\nhealth has deteriorated in recent years, that males’ mental health status is better than that of females, \n\nand non-indigenous health status is better than that of the indigenous population. \n\nKeywords: Stochastic dominance; Bayesian nonparametric estimation \n\nJEL codes: I10, C46 \n\n*Corresponding author \nWilliam Griffiths \nDepartment of Economics \nUniversity of Melbourne \nVic 3010 \nAustralia \nwegrif@unimelb.edu.au \n\n \n \n \n \n \n \n \n \n \n\f2 \n\n1. \n\nIntroduction \n\nImproving  the  general  level  of  health  and  reducing  health  inequality  are  major  objectives  of  public \n\npolicy.  To  assess  whether  improvements  are  being  made  overtime,  and  in  different  subgroups  of  a \n\npopulation, we need to sample the health status of individuals from the populations of interest, and to \n\nuse those samples to make inferences about the populations. These inferences could take the form of \n\ncomparing health status at different points in time, or comparing the health status of different segments \n\nof the population. Such comparisons involve several nontrivial steps that include sampling, measuring \n\nhealth status, choosing criteria for making comparisons, and making inferences about those criteria.  \n\nWe focus on the mental health status of the Australian population in the years 2001, 2006, 2010, \n\n2014 and 2017, and on that for male/female and indigenous/non-indigenous population subgroups in \n\nthe same years. The prevalence of poor mental health has attracted increasing attention in recent years, \n\nparticularly in relation to difficulties resulting from COVID-19 lockdowns. Our sample does not cover \n\nthe post-COVID period, but our results suggest mental health had already been deteriorating prior to \n\nthat time. Interest has also centred on the status of female mental health relative to that of males, and a \n\nmajor government policy objective has been to narrow the gap between indigenous and non-indigenous \n\nhealth status. We examine evidence on the relative health status of these population subgroups and how \n\nthis  evidence  has  changed  over  time.  The  sample  we  use  is  the  SF-36  health  survey  questions \n\nadministered as part of the Household, Income and Labour Dynamics in Australia (HILDA) survey.1 \n\nResponses to the mental health questions are converted to a continuous score that ranges between 0 and \n\n100, with 100 representing good mental health. Several criteria are used to compare scores. The novelty \n\nin  our  approach  is  the  use  of  stochastic  dominance  as  one  of  the  criteria,  and  the  use  of  Bayesian \n\ninference to assess dominance and to estimate other criteria. Bayesian nonparametric methods are used \n\nto estimate a distribution of scores from each sample. In addition to comparing mean scores using their \n\n1 The HILDA project (Watson and Wooden, 2012) was initiated and is funded by the Australian Government \n\nDepartment of Social Services (DSS) and is managed by the Melbourne Institute of Applied Economics and Social \n\nResearch (Melbourne Institute). The findings and views in this paper, however, are those of the authors and should \n\nnot be attributed to either DSS or the Melbourne Institute. \n\n \n \n                                                            \n\f3 \n\nrespective  posterior  distributions,  we  find  posterior  probabilities  of  dominance  for  each  pairwise \n\ncomparison of distributions. Both first and second order stochastic dominance are considered. \n\nChecking to see if one mental health distribution dominates another involves comparing the \n\ncumulative  distribution  functions  (cdf’s)  of  the  two  sets  of  health  scores.  For  first-order  stochastic \n\ndominance  (FSD),  a  distribution  A  dominates  a  distribution  B  (written \n\nFSDA B )  if  the  cdf  for  A  lies \n\nbelow the cdf for B; the proportion of population with a mental health score below any value y is less \n\nin  A  that  it  is  in  B.  The  two  cdf’s  do  not  cross.  For  second-order  stochastic  dominance  (SSD),  A \n\ndominates B (written \n\nSSDA B ) if the area under the cdf between zero and any value y is less for A, than \n\nit is for B. It implies the sum of all mental health scores less than any value y is less for A than it is for \n\nB.2 The existence"
  },
  {
    "title": "Trauma lurking in the shadows: A Reddit case study of mental health\n  issues in online posts about Childhood Sexual Abuse",
    "authors": [
      "Orchid Chetia Phukan",
      "Rajesh Sharma",
      "Arun Balaji Buduru"
    ],
    "abstract": "Childhood Sexual Abuse (CSA) is a menace to society and has long-lasting\neffects on the mental health of the survivors. From time to time CSA survivors\nare haunted by various mental health issues in their lifetime. Proper care and\nattention towards CSA survivors facing mental health issues can drastically\nimprove the mental health conditions of CSA survivors. Previous works\nleveraging online social media (OSM) data for understanding mental health\nissues haven't focused on mental health issues in individuals with CSA\nbackground. Our work fills this gap by studying Reddit posts related to CSA to\nunderstand their mental health issues. Mental health issues such as depression,\nanxiety, and Post-Traumatic Stress Disorder (PTSD) are most commonly observed\nin posts with CSA background. Observable differences exist between posts\nrelated to mental health issues with and without CSA background. Keeping this\ndifference in mind, for identifying mental health issues in posts with CSA\nexposure we develop a two-stage framework. The first stage involves classifying\nposts with and without CSA background and the second stage involves recognizing\nmental health issues in posts that are classified as belonging to CSA\nbackground. The top model in the first stage is able to achieve accuracy and\nf1-score (macro) of 96.26% and 96.24%. and in the second stage, the top model\nreports hamming score of 67.09%. Content Warning: Reader discretion is\nrecommended as our study tackles topics such as child sexual abuse,\nmolestation, etc.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2306.10338v1",
    "pdf_url": "http://arxiv.org/pdf/2306.10338v1",
    "full_text": "3\n2\n0\n2\n\nn\nu\nJ\n\n7\n1\n\n]\n\nY\nC\n.\ns\nc\n[\n\n1\nv\n8\n3\n3\n0\n1\n.\n6\n0\n3\n2\n:\nv\ni\nX\nr\na\n\nTrauma lurking in the shadows: A Reddit case\nstudy of mental health issues in online posts about\nChildhood Sexual Abuse\n\nOrchid Chetia Phukan\nDepartment of CSE\nIIIT-Delhi, India\norchidp@iiitd.ac.in\n‘\n\nRajesh Sharma\nInstitute of Computer Science\nUniversity of Tartu, Estonia\nrajesh.sharma@ut.ee\n\nArun Balaji Buduru\nDepartment of CSE\nIIIT-Delhi, India\narunb@iiitd.ac.in\n\nAbstract—Childhood Sexual Abuse (CSA) is a menace to\nsociety and has long-lasting effects on the mental health of the\nsurvivors. From time to time CSA survivors are haunted by\nvarious mental health issues in their lifetime. Proper care and\nattention towards CSA survivors facing mental health issues\ncan drastically improve the mental health conditions of CSA\nsurvivors. Previous works leveraging online social media (OSM)\ndata for understanding mental health issues haven’t focused\non mental health issues in individuals with CSA background.\nOur work fills this gap by studying Reddit posts related to\nCSA to understand their mental health issues. Mental health\nissues such as depression, anxiety, and Post-Traumatic Stress\nDisorder (PTSD) are most commonly observed in posts with CSA\nbackground. Observable differences exist between posts related to\nmental health issues with and without CSA background. Keeping\nthis difference in mind, for identifying mental health issues in\nposts with CSA exposure we develop a two-stage framework.\nThe first stage involves classifying posts with and without CSA\nbackground and the second stage involves recognizing mental\nhealth issues in posts that are classified as belonging to CSA\nbackground. The top model in the first stage is able to achieve\naccuracy and f1-score (macro) of 96.26% and 96.24%. and in the\nsecond stage, the top model reports hamming score of 67.09%.\nContent Warning: Reader discretion is recommended as our\nstudy tackles topics such as child sexual abuse, molestation, etc.\nKeywords: Childhood sexual abuse (CSA), mental health,\n\nReddit, Natural language processing (NLP).\n\nI. INTRODUCTION\n\nSexually harmful acts against a child (less than 18 years of\nage) are characterized as Childhood Sexual Abuse (CSA) and\nit spans a wide range of acts including sexual abuse, sexual\ninteraction, rape, sexual grooming, and sexual exploitation [1].\nThis form of abuse often entails the perpetrator using force or\nmaking threats [2]. Between ages 7 and 13, children are most\nvulnerable to CSA. Perpetrators can be either family members\nor strangers [3]. It has been reported that survivors of CSA\nare often accompanied by feelings of stigma and guilt [4], [5].\nCSA is often succeeded by physical and mental difficulties.\nPhysical difficulties include physical injuries such as genital\ninjuries [6] and sexually transmitted diseases (STDs) [7]. Indi-\nviduals with a history of CSA are more likely to have chronic\nillnesses such as chronic pain [8] and obesity [9] in later stages\nof life. Physical injuries may heal, but psychological scars\n\nfrom the abuse can last throughout later stages of life [7].\nSurvivors of CSA are often likely to be haunted by the recall of\nthe traumatic event [10]. Risk of occurrence of various mental\nhealth issues such as Post-Traumatic Stress Disorder (PTSD)\n[11], depression, anxiety [8], and eating disorders [12] are\nmore in CSA survivors. CSA is also reported to be a key risk\nfactor for the development of Borderline Personality Disorder\n(BPD) [13].\n\nFor the purpose of understanding mental health issues in\nCSA survivors, numerous prior research investigations have\nbeen conducted, but they were primarily restricted to inter-\nviews, questionnaires, surveys, and electronic health records\n(EHRs) with a limited amount of data [14], [15]. In recent\nyears research considering OSM for mental health issues is\nrising [16], as it has been seen that individuals are resorting\nto online social media (OSM) platforms to find shelter for\ntheir mental health issues [17] where CSA survivors are no\nexception. Especially OSM such as Reddit has turned out to be\na popular medium [18] for such. Reddit is a community-based\nplatform where each community is called a “subreddit” and is\nbased on a particular topic or issue [19]. These communities\nsometimes act as a discussion forum and sometimes as peer\nsupport groups for various issues related to health, mental\ncomplications, etc. Thus,\nthis inspired us to look through\nvarious subreddits and gather posts about mental health issues\nassociated with CSA, and probe the following three research\nquestions.\n\nRQ1: What are the commonly discussed mental health\n\nissues in posts related with CSA?\n\nFor finding out\n\nthe most commonly discussed mental\nhealth issues in posts with CSA exposure, we analyzed\nr/adultsurvivors. We found out that depression, anxiety and\nPTSD are the most commonly discussed mental health issues.\nRQ2: Are there differences between the posts related to\nmental health issues with and without CSA background?\nMent"
  },
  {
    "title": "Technology in Association With Mental Health: Meta-ethnography",
    "authors": [
      "Hamza Mohammed"
    ],
    "abstract": "This research paper presents a meta-analysis of the multifaceted role of\ntechnology in mental health. The pervasive influence of technology on daily\nlives necessitates a deep understanding of its impact on mental health\nservices. This study synthesizes literature covering Behavioral Intervention\nTechnologies (BITs), digital mental health interventions during COVID-19, young\nmen's attitudes toward mental health technologies, technology-based\ninterventions for university students, and the applicability of mobile health\ntechnologies for individuals with serious mental illnesses. BITs are recognized\nfor their potential to provide evidence-based interventions for mental health\nconditions, especially anxiety disorders. The COVID-19 pandemic acted as a\ncatalyst for the adoption of digital mental health services, underscoring their\ncrucial role in providing accessible and quality care; however, their efficacy\nneeds to be reinforced by workforce training, high-quality evidence, and\ndigital equity. A nuanced understanding of young men's attitudes toward mental\nhealth is imperative for devising effective online services. Technology-based\ninterventions for university students are promising, although variable in\neffectiveness; their deployment must be evidence-based and tailored to\nindividual needs. Mobile health technologies, particularly activity tracking,\nhold promise for individuals with serious mental illnesses. Collectively,\ntechnology has immense potential to revolutionize mental health care. However,\nthe implementation must be evidence-based, ethical, and equitable, with\ncontinued research focusing on experiences across diverse populations, ensuring\naccessibility and efficacy for all.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2307.10513v2",
    "pdf_url": "http://arxiv.org/pdf/2307.10513v2",
    "full_text": "Technology in Association With Mental Health: Meta-ethnography \n\nHamza Mohammed | hamzamohammed0784@gmail.com \n\nAbstract \n\nThis research paper presents a meta-analysis of the multifaceted role of technology in mental \n\nhealth. The pervasive influence of technology on daily lives necessitates a deep understanding of \n\nits impact on mental health services. This study synthesizes literature covering Behavioral \n\nIntervention Technologies (BITs), digital mental health interventions during COVID-19, young \n\nmen's attitudes toward mental health technologies, technology-based interventions for university \n\nstudents, and the applicability of mobile health technologies for individuals with serious mental \n\nillnesses. BITs are recognized for their potential to provide evidence-based interventions for \n\nmental health conditions, especially anxiety disorders. The COVID-19 pandemic acted as a \n\ncatalyst for the adoption of digital mental health services, underscoring their crucial role in \n\nproviding accessible and quality care; however, their efficacy needs to be reinforced by \n\nworkforce training, high-quality evidence, and digital equity. A nuanced understanding of young \n\nmen's attitudes toward mental health is imperative for devising effective online services. \n\nTechnology-based interventions for university students are promising, although variable in \n\neffectiveness; their deployment must be evidence-based and tailored to individual needs. Mobile \n\nhealth technologies, particularly activity tracking, hold promise for individuals with serious \n\nmental illnesses. Collectively, technology has immense potential to revolutionize mental health \n\ncare. However, the implementation must be evidence-based, ethical, and equitable, with \n\ncontinued research focusing on experiences across diverse populations, ensuring accessibility \n\nand efficacy for all. \n\n \n\fI. Introduction \n\nTechnology has become an integral part of our daily lives in the rapidly evolving digital \n\nage. It has transformed how we communicate, work, learn, and manage our health. One of the \n\nareas where technology has made significant strides is in the field of mental health. Technology \n\nhas opened up new avenues for accessing mental health services, from teletherapy platforms to \n\nmental health apps. However, the impact of technology on mental health is multifaceted and \n\ncomplex, warranting comprehensive research and understanding (Mohr et al., 2013; Torous et \n\nal., 2020; Farrer et al., 2013; Naslund et al., 2015). \n\nThis paper aims to delve into the current research surrounding technology's role in mental \n\nhealth, focusing on its benefits, challenges, and potential for future development. The objective \n\nis to provide a comprehensive overview of the existing literature, thereby contributing to the \n\nongoing discourse in this field. The research papers that will be discussed in this review have \n\nbeen carefully selected to cover a range of topics within the broader theme of technology and \n\nmental health. These include the role of behavioral intervention technologies in mental health, \n\nthe impact of digital mental health interventions during the COVID-19 pandemic, young men's \n\nattitudes towards mental health and technology, the effectiveness of technology-based \n\ninterventions for tertiary students, and the feasibility of m-Health technologies for individuals \n\nwith serious mental illness (Mohr et al., 2013; Torous et al., 2020; Farrer et al., 2013; Naslund et \n\nal., 2015). \n\nEach of these papers offers valuable insights into the intersection of technology and \n\nmental health, shedding light on the potential of technology to transform mental health services \n\nand the challenges that need to be addressed. By examining these papers, this review aims to \n\nprovide a comprehensive understanding of the current state of research in this field and highlight \n\n\fareas for future exploration. In the following sections, I will delve into each of these papers, \n\ndiscussing their findings, implications, and contributions to the field of mental health and \n\ntechnology. Through this review, I hope to provide a comprehensive overview of the current \n\nstate of research in this field, thereby contributing to the ongoing discourse on the impact of \n\ntechnology on mental health. \n\nII. Behavioral Intervention Technologies and Mental Health \n\nThe advent of technology has brought about significant changes in the field of mental \n\nhealth, particularly in the development of Behavioral Intervention Technologies (BITs). These \n\ntechnologies have been instrumental in providing evidence-based interventions to individuals \n\nsuffering from various mental health conditions. The paper \"Behavioral Intervention \n\nTechnologies: Evidence Review and recommendations for future research in mental health\" by \n\nDavid C. Mohr et al. provides an in-depth analysis of the role of these technologies in mental \n\nhealth (Mohr et al., 2013). \n\nThe paper begins by acknowledging the prevalence of mental "
  },
  {
    "title": "Gendered Mental Health Stigma in Masked Language Models",
    "authors": [
      "Inna Wanyin Lin",
      "Lucille Njoo",
      "Anjalie Field",
      "Ashish Sharma",
      "Katharina Reinecke",
      "Tim Althoff",
      "Yulia Tsvetkov"
    ],
    "abstract": "Mental health stigma prevents many individuals from receiving the appropriate\ncare, and social psychology studies have shown that mental health tends to be\noverlooked in men. In this work, we investigate gendered mental health stigma\nin masked language models. In doing so, we operationalize mental health stigma\nby developing a framework grounded in psychology research: we use clinical\npsychology literature to curate prompts, then evaluate the models' propensity\nto generate gendered words. We find that masked language models capture\nsocietal stigma about gender in mental health: models are consistently more\nlikely to predict female subjects than male in sentences about having a mental\nhealth condition (32% vs. 19%), and this disparity is exacerbated for sentences\nthat indicate treatment-seeking behavior. Furthermore, we find that different\nmodels capture dimensions of stigma differently for men and women, associating\nstereotypes like anger, blame, and pity more with women with mental health\nconditions than with men. In showing the complex nuances of models' gendered\nmental health stigma, we demonstrate that context and overlapping dimensions of\nidentity are important considerations when assessing computational models'\nsocial biases.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2210.15144v2",
    "pdf_url": "http://arxiv.org/pdf/2210.15144v2",
    "full_text": "Gendered Mental Health Stigma in Masked Language Models\n\nInna Wanyin Lin1∗ Lucille Njoo1∗ Anjalie Field2 Ashish Sharma1\nKatharina Reinecke1 Tim Althoff1 Yulia Tsvetkov1\n1Paul G. Allen School of Computer Science & Engineering, University of Washington\n2Stanford University\n{ilin, lnjoo}@cs.washington.edu\n\n3\n2\n0\n2\n\nr\np\nA\n1\n1\n\n]\nL\nC\n.\ns\nc\n[\n\n2\nv\n4\n4\n1\n5\n1\n.\n0\n1\n2\n2\n:\nv\ni\nX\nr\na\n\nAbstract\n\nMental health stigma prevents many individ-\nuals from receiving the appropriate care, and\nsocial psychology studies have shown that\nmental health tends to be overlooked in men.\nIn this work, we investigate gendered men-\ntal health stigma in masked language mod-\nels.\nIn doing so, we operationalize men-\ntal health stigma by developing a framework\ngrounded in psychology research: we use clin-\nical psychology literature to curate prompts,\nthen evaluate the models’ propensity to gen-\nerate gendered words. We ﬁnd that masked\nlanguage models capture societal stigma about\ngender in mental health: models are consis-\ntently more likely to predict female subjects\nthan male in sentences about having a men-\ntal health condition (32% vs. 19%), and this\ndisparity is exacerbated for sentences that indi-\ncate treatment-seeking behavior. Furthermore,\nwe ﬁnd that different models capture dimen-\nsions of stigma differently for men and women,\nassociating stereotypes like anger, blame, and\npity more with women with mental health con-\nditions than with men. In showing the complex\nnuances of models’ gendered mental health\nstigma, we demonstrate that context and over-\nlapping dimensions of identity are important\nconsiderations when assessing computational\nmodels’ social biases.\n\n1\n\nIntroduction\n\nMental health issues are heavily stigmatized, pre-\nventing many individuals from seeking appropri-\nate care (Sickel et al., 2014). In addition, social\npsychology studies have shown that this stigma\nmanifests differently for different genders: mental\nillness is more visibly associated with women, but\ntends to be more harshly derided in men (Chatmon,\n2020). This asymmetrical stigma constitutes harms\ntowards both men and women, increasing the risks\nof under-diagnosis or over-diagnosis respectively.\n\n∗ Indicates equal contribution.\n\nFigure 1: We investigate masked language models’ bi-\nases at the intersection of gender and mental health.\nUsing theoretically-motivated prompts about mental\nhealth conditions, we have models ﬁll in the masked to-\nken, then examine the probabilities of generated words\nwith gender associations.\n\nSince language is central to psychotherapy and\npeer support, NLP models have been increasingly\nemployed on mental health-related tasks (Chancel-\nlor and De Choudhury, 2020; Sharma et al., 2021,\n2022; Zhang and Danescu-Niculescu-Mizil, 2020).\nMany approaches developed for these purposes rely\non pretrained language models, thus running the\nrisk of incorporating any pre-learned biases these\nmodels may contain (Straw and Callison-Burch,\n2020). However, no prior research has examined\nhow biases related to mental health stigma are rep-\nresented in language models. Understanding if and\nhow pretrained language models encode mental\nhealth stigma is important for developing fair, re-\nsponsible mental health applications. To the best\nof our knowledge, our work is the ﬁrst to opera-\ntionalize mental health stigma in NLP research and\naim to understand the intersection between mental\nhealth and gender in language models.\n\nIn this work, we propose a framework to inves-\ntigate joint encoding of gender bias and mental\n\n \n \n \n \n \n \n\fhealth stigma in masked language models (MLMs),\nwhich have become widely used in downstream\napplications (Devlin et al., 2019; Liu et al., 2019).\nOur framework uses questionnaires developed\nin psychology research to curate prompts about\nmental health conditions. Then, with several se-\nlected language models, we mask out parts of\nthese prompts and examine the model’s tendency\nto generate explicitly gendered words, including\npronouns, nouns, ﬁrst names, and noun phrases.1\nIn order to disentangle general gender biases from\ngender biases tied to mental health stigma, we com-\npare these results with prompts describing health\nconditions that are not related to mental health.\nAdditionally, to understand the effects of domain-\nspeciﬁc training data, we investigate both general-\npurpose MLMs and MLMs pretrained on mental\nhealth corpora. We aim to answer the two research\nquestions below.\n\nRQ1: Do MLMs associate mental health con-\nditions with a particular gender? To answer\nRQ1, we curate three sets of prompts that reﬂect\nthree healthcare-seeking phases: diagnosis, inten-\ntion, and action, based on the widely-cited Health\nAction Process Approach (Schwarzer et al., 2011).\nWe prompt the models to generate the subjects of\nsentences that indicate someone is (1) diagnosed\nwith a mental health condition, (2) intending to\nseek help or treatment for a mental health condi-\ntion, and (3) taking action to get treatment for a\nmental health condition. We ﬁnd "
  },
  {
    "title": "Quantifying language changes surrounding mental health on Twitter",
    "authors": [
      "Anne Marie Stupinski",
      "Thayer Alshaabi",
      "Michael V. Arnold",
      "Jane Lydia Adams",
      "Joshua R. Minot",
      "Matthew Price",
      "Peter Sheridan Dodds",
      "Christopher M. Danforth"
    ],
    "abstract": "Mental health challenges are thought to afflict around 10% of the global\npopulation each year, with many going untreated due to stigma and limited\naccess to services. Here, we explore trends in words and phrases related to\nmental health through a collection of 1- , 2-, and 3-grams parsed from a data\nstream of roughly 10% of all English tweets since 2012. We examine temporal\ndynamics of mental health language, finding that the popularity of the phrase\n'mental health' increased by nearly two orders of magnitude between 2012 and\n2018. We observe that mentions of 'mental health' spike annually and reliably\ndue to mental health awareness campaigns, as well as unpredictably in response\nto mass shootings, celebrities dying by suicide, and popular fictional stories\nportraying suicide. We find that the level of positivity of messages containing\n'mental health', while stable through the growth period, has declined recently.\nFinally, we use the ratio of original tweets to retweets to quantify the\nfraction of appearances of mental health language due to social amplification.\nSince 2015, mentions of mental health have become increasingly due to retweets,\nsuggesting that stigma associated with discussion of mental health on Twitter\nhas diminished with time.",
    "year": 2021,
    "url": "http://arxiv.org/abs/2106.01481v1",
    "pdf_url": "http://arxiv.org/pdf/2106.01481v1",
    "full_text": "1\n2\n0\n2\n\nn\nu\nJ\n\n2\n\n]\nh\np\n-\nc\no\ns\n.\ns\nc\ni\ns\ny\nh\np\n[\n\n1\nv\n1\n8\n4\n1\n0\n.\n6\n0\n1\n2\n:\nv\ni\nX\nr\na\n\nQuantifying language changes surrounding mental health on Twitter\n\nAnne Marie Stupinski,1, ∗ Thayer Alshaabi,1 Michael V. Arnold,1 Jane Lydia Adams,1 Joshua\nR. Minot,1 Matthew Price,2 Peter Sheridan Dodds,1, 3, 4 and Christopher M. Danforth1, 4, 3, †\n1Computational Story Lab, Vermont Complex Systems Center, University of Vermont, Burlington, VT 05405.\n2Department of Psychology, University of Vermont, Burlington, VT 05405.\n3Department of Computer Science, The University of Vermont, Burlington, VT 05405.\n4Department of Mathematics & Statistics, The University of Vermont, Burlington, VT 05405.\n(Dated: June 4, 2021)\n\nMental health challenges are thought to aﬄict around 10% of the global population each year,\nwith many going untreated due to stigma and limited access to services. Here, we explore trends in\nwords and phrases related to mental health through a collection of 1- , 2-, and 3-grams parsed from\na data stream of roughly 10% of all English tweets since 2012. We examine temporal dynamics of\nmental health language, ﬁnding that the popularity of the phrase ‘mental health’ increased by nearly\ntwo orders of magnitude between 2012 and 2018. We observe that mentions of ‘mental health’ spike\nannually and reliably due to mental health awareness campaigns, as well as unpredictably in response\nto mass shootings, celebrities dying by suicide, and popular ﬁctional stories portraying suicide. We\nﬁnd that the level of positivity of messages containing ‘mental health’, while stable through the\ngrowth period, has declined recently. Finally, we use the ratio of original tweets to retweets to\nquantify the fraction of appearances of mental health language due to social ampliﬁcation. Since\n2015, mentions of mental health have become increasingly due to retweets, suggesting that stigma\nassociated with discussion of mental health on Twitter has diminished with time.\n\nI.\n\nINTRODUCTION\n\nRecent estimates place 1 in 10 people globally as expe-\nriencing from some form of mental illness [1], with 1 in\n30 suﬀering from depression [2]. These rates put mental\nillness among the leading causes of ill-health and disabil-\nity worldwide. Moreover, rates of mental health disor-\nders and deaths by suicide have increased in recent years,\nespecially among young people [3].\n\nSince the beginning of the COVID-19 pandemic and\nthe subsequent social isolation, there have been record-\nings of drastic declines in physical activity and time\nspent socializing, and coinciding increases in screen time\nand symptoms of depression [4]. Google searches for\nmental health related topics also increased in the ﬁrst\nweeks of the pandemic,\nleveling out after more infor-\nmation regarding stay-at-home orders were released [5].\nFollowing March 2020, there has also been a measured\nincrease in suicidal ideation that is associated with ele-\nvated reports of isolation [6]. The service Crisis Text\nLine reported receiving a higher than average volume\nof messages for every day following March 16th in the\nyear 2020, with the main topics being anxiety, depres-\nsion, grief, and eating disorders [7]. Price et al. [8] also\nfound that daily “doomscrolling”—repeatedly consuming\nnegative news and media content online—was associated\nwith same-day increases in depression and PTSD. These\neﬀects were larger among those with a prior history of\npsychopathology and trauma exposure. The pandemic\nalso inﬂuenced what content people discussed on social\n\n∗ astupins@uvm.edu\n† cdanfort@uvm.edu\n\nTypeset by REVTEX\n\nmedia, with users shifting away from “self-focused” per-\nspectives and towards more “other-focused” topics that\nused to be vulnerable or taboo to discuss [9]. A survey\nof American adults during the pandemic found that the\ndepth of distressing self-disclosures posted online could\nbe predicted by a user’s perceived anonymity, visibility\ncontrol, and closeness to their audience [10].\n\nHistorically, the availability of mental health treat-\nment services has not meet the demand for such [11].\nMental health care also experiences a paradox of being\nover-diagnosed yet under-supported, with some symp-\ntoms and disorders being readily medicated despite not\nbeing understood and accepted socially [12]. Further-\nmore, many who would beneﬁt from mental health ser-\nvices do not seek or participate in care, as they are either\nunaware of such services, are unable to aﬀord them, or\nthe stigma associated with seeking treatment proves too\ngreat a barrier [13]. In fact, two-thirds of people with a\nknown mental disorder do not seek help from a health\nprofessional [14].\n\nWhile stigma has proven to be a signiﬁcant barri-\ner to receiving treatment from formal (e.g., psychia-\ntrists, counselors) and informal sources (e.g., family and\nfriends), the COVID-19 pandemic and subsequent isola-\ntion have spurred awareness of mental illness and discus-\nsion on this topic in public forums such as social media.\nMeasuring changes in this "
  },
  {
    "title": "Robotics Technology in Mental Health Care",
    "authors": [
      "Laurel D. Riek"
    ],
    "abstract": "This chapter discusses the existing and future use of robotics and\nintelligent sensing technology in mental health care. While the use of this\ntechnology is nascent in mental health care, it represents a potentially useful\ntool in the practitioner's toolbox. The goal of this chapter is to provide a\nbrief overview of the field, discuss the recent use of robotics technology in\nmental health care practice, explore some of the design issues and ethical\nissues of using robots in this space, and finally to explore the potential of\nemerging technology.",
    "year": 2015,
    "url": "http://arxiv.org/abs/1511.02281v1",
    "pdf_url": "http://arxiv.org/pdf/1511.02281v1"
  },
  {
    "title": "MentSum: A Resource for Exploring Summarization of Mental Health Online\n  Posts",
    "authors": [
      "Sajad Sotudeh",
      "Nazli Goharian",
      "Zachary Young"
    ],
    "abstract": "Mental health remains a significant challenge of public health worldwide.\nWith increasing popularity of online platforms, many use the platforms to share\ntheir mental health conditions, express their feelings, and seek help from the\ncommunity and counselors. Some of these platforms, such as Reachout, are\ndedicated forums where the users register to seek help. Others such as Reddit\nprovide subreddits where the users publicly but anonymously post their mental\nhealth distress. Although posts are of varying length, it is beneficial to\nprovide a short, but informative summary for fast processing by the counselors.\nTo facilitate research in summarization of mental health online posts, we\nintroduce Mental Health Summarization dataset, MentSum, containing over 24k\ncarefully selected user posts from Reddit, along with their short user-written\nsummary (called TLDR) in English from 43 mental health subreddits. This\ndomain-specific dataset could be of interest not only for generating short\nsummaries on Reddit, but also for generating summaries of posts on the\ndedicated mental health forums such as Reachout. We further evaluate both\nextractive and abstractive state-of-the-art summarization baselines in terms of\nRouge scores, and finally conduct an in-depth human evaluation study of both\nuser-written and system-generated summaries, highlighting challenges in this\nresearch.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2206.00856v1",
    "pdf_url": "http://arxiv.org/pdf/2206.00856v1",
    "full_text": "MentSum: A Resource for Exploring\nSummarization of Mental Health Online Posts\n\nSajad Sotudeh1,2*, Nazli Goharian1,2*, Zachary Young2\n1Information Retrieval Lab, Georgetown University\n2Department of Computer Science, Georgetown University\n{sajad, nazli}@ir.cs.georgetown.edu, zjy2@georgetown.edu\n\nAbstract\nMental health remains a signiﬁcant challenge of public health worldwide. With increasing popularity of online platforms,\nmany use the platforms to share their mental health conditions, express their feelings, and seek help from the community and\ncounselors. Some of these platforms, such as Reachout, are dedicated forums where the users register to seek help. Others such\nas Reddit provide subreddits where the users publicly but anonymously post their mental health distress. Although posts are of\nvarying length, it is beneﬁcial to provide a short, but informative summary for fast processing by the counselors. To facilitate\nresearch in summarization of mental health online posts, we introduce Mental Health Summarization dataset, MENTSUM,\ncontaining over 24k carefully selected user posts from Reddit, along with their short user-written summary (called TLDR)\nin English from 43 mental health subreddits. This domain-speciﬁc dataset could be of interest not only for generating short\nsummaries on Reddit, but also for generating summaries of posts on the dedicated mental health forums such as Reachout. We\nfurther evaluate both extractive and abstractive state-of-the-art summarization baselines in terms of ROUGE scores, and ﬁnally\nconduct an in-depth human evaluation study of both user-written and system-generated summaries, highlighting challenges in\nthis research.\n\nKeywords: Text Summarization, Summarization Dataset, Mental Health Summarization\n\n1.\n\nIntroduction\n\nMental health has been a global public health challenge\nfor many years and even more so since the COVID-\n19 pandemic (Holmes et al., 2020; Pfefferbaum and\nNorth, 2020; Otu et al., 2020). Social media has served\nas a viable platform for many to share their frustrations,\nemotions, depressions, and also their already diagnosed\nmental disorders. Figure 1 depicts the growing popu-\nlarity (measured by the number of subscribers) of dis-\ncussion forums dedicated to three mental disorders in\nReddit social discussion website over the years. 1.\nOnline social platforms such as Reddit 2 and Rea-\nchout 3 have become increasingly popular over the re-\ncent years due to the vital networking facets that they\noffer to the community users. These platforms provide\nusers with an opportunity to share different types of\nuser-curated and user-generated content, ranging from\ndaily updates/statuses to sharing personal anecdotes\nand mental conditions. Users can also interact with\nother users, carry on conversations through which they\ncan express their feelings and views regarding a spe-\nciﬁc topic. Platforms such as Reachout are not pub-\nlic, requiring users to register; users’ content are not\nvisible to anyone but to the permitted users and coun-\nselors. On the other hand, in the public platforms\nsuch as Reddit, users can openly exchange information\nwith each other through community-based subreddits,\neach of which speciﬁed with a certain theme or condi-\n\n*Equal contribution\n1Statistics from https://subredditstats.com/\n2https://www.reddit.com/\n3https://au.reachout.com/\n\nFigure 1: Growing popularity of mental health related\nforums in Reddit.\n\ntion, such as suicide watch, mental health, alcoholism,\nattention-deﬁcit/hyperactivity disorder (ADHD), de-\npression, anxiety, etc. Each post in any of these subred-\ndits, however, may report more than one past or present\ncondition and what the user is distressed about.\nThe user-generated content on many of such platforms\nmight be of varying length. Longer posts may address\nmultitude of issues of concern or simply be a lengthy\nelaboration of the user on the situation. The longer a\npost is, the more time it requires a counselor for reading\nthe post which leads to fatigue and/or delay in a timely\nresponse. Our hypothesis is that a short yet informative\nsummary of each user’s post provides the counselors\nwith the important information of the post in a glimpse\nbefore reading the details. Hence, in this research we\n\n2\n2\n0\n2\n\nn\nu\nJ\n\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n6\n5\n8\n0\n0\n.\n6\n0\n2\n2\n:\nv\ni\nX\nr\na\n\n2013201420152016201720182019202020212022Year0.2M0.4M0.6M0.8M1.0M1.2M1.4MSubscribers (in millions)ADHDdepressionanxiety \n \n \n \n \n \n\fcreate a dataset resource for the research community to\nbe utilized in the short text (known as TLDR) summa-\nrization of mental health related social media posts.\nA great deal of research studies in social media mental\nhealth domain have focused on developing classiﬁca-\ntion models and their needed datasets to either triage\nthe severity of the potential harm or to identify the type\nof mental disorders; among these efforts are (Choud-\nhury et al., 2013; Coppersmith et al., 2014a; Yates et\nal., 2017; Coppersmith et al., 2018; Cohan et al., 2018;"
  },
  {
    "title": "Mobile Health Solution for College Student Mental Health: Interview\n  Study and Design Requirement Analysis",
    "authors": [
      "Xiaomei Wang",
      "Alec Smith",
      "Bruce Keller",
      "Farzan Sasangohar"
    ],
    "abstract": "Background: Mental health problems are prevalent in college students. The\nCOVID-19 pandemic exacerbated the problems, and created a surge in the\npopularity of telehealth and mobile health solutions. Despite that mobile\nhealth is a promising approach to help students with mental health needs, few\nstudies exist in investigating key features students need in a mental health\nself-management tool. Objective: The objective of our study was to identified\nkey requirements and features for the design of a student-centered mental\nhealth self-management tool. Methods: An interview study was first conducted to\nunderstand college students' needs and preferences on a mental health\nself-management tool. Functional information requirement analysis was then\nconducted to translate the needs into design implications. Results: A total of\n153 university students were recruited for the semi-structured interview. The\nparticipants mentioned several features including coping techniques, artificial\nintelligence, time management, tracking, and communication with others.\nParticipant's preferences on usability and privacy settings were also\ncollected. The desired functions were analyzed and turned into design-agnostic\ninformation requirements. Conclusions: This study documents findings from\ninterviews with university students to understand their needs and preferences\nfor a tool to help with self-management of mental health.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2206.02960v1",
    "pdf_url": "http://arxiv.org/pdf/2206.02960v1",
    "full_text": "Title:  \n\nMobile Health Solution for College Student Mental Health: Interview Study and Design \nRequirement Analysis \n\nAuthors List: Xiaomei Wang, Alec Smith, Bruce Keller, Farzan Sasangohar  \n\nKeywords: Mobile Health, Interview, Mental Health, College Student, Self-Management \n\nAbstract:  \n\nBackground: Mental health problems are prevalent in college students. The COVID-19 pandemic \nexacerbated the problems, and created a surge in the popularity of telehealth and mobile health \nsolutions. Despite that mobile health is a promising approach to help students with mental health \nneeds, few studies exist in investigating key features students need in a mental health self-\nmanagement tool. \n\nObjective: The objective of our study was to identified key requirements and features for the \ndesign of a student-centered mental health self-management tool. \n\nMethods: An interview study was first conducted to understand college students’ needs and \npreferences on a mental health self-management tool. Functional information requirement \nanalysis was then conducted to translate the needs into design implications. \n\nResults: A total of 153 university students were recruited for the semi-structured interview. The \nparticipants mentioned several features including coping techniques, artificial intelligence, time \nmanagement, tracking, and communication with others. Participant’s preferences on usability \nand privacy settings were also collected. The desired functions were analyzed and turned into \ndesign-agnostic information requirements. \n\nConclusions: This study documents findings from interviews with university students to \nunderstand their needs and preferences for a tool to help with self-management of mental health.  \n\n1 \n\n \n \n  \n \n \n\fIntroduction \nAbout 1 in 3 first-year college students screen positive for at least one mental health disorder, \nwith low variability across countries and demographics [1]. Despite 20% increased spending in \nuniversity mental health services [2] and increased intention and utilization of mental health \nservices by students, college student mental health continues to decline [3]. Poor student mental \nhealth has resulted in suicidal ideation [4], low class engagement, low GPA [5], and greater \nlikelihood of dropping out [6]. All of these problems have been exacerbated by the ongoing \nCOVID-19 pandemic at the time of this study, with studies showing evidence of students not \neffectively coping [7,8].  \n\nWhile students generally prefer in-person counseling [9], COVID-19 has created a surge in the \npopularity of telehealth services due to its ability to reach people in isolation and prevent the \nspread of illness [10]. In-person counseling has many disadvantages that may make alternatives \nlike virtual counseling and mental health apps more appealing even after the pandemic. \nCounseling is associated with higher financial costs and is not preferred by those with self-\nstigma regarding mental health [9]. It is well-documented that a sizable portion of students who \ncommitted suicide never contacted their institutions’ counseling center [11]. Furthermore, long \nwait times are the reality in many colleges with an average wait of 6 business days for a triage \nsession and 9 business days for their first session after triage [12].  \n\nIn contrast, digital interventions such as a mobile health (mHealth) application can be accessed \non demand and almost instantaneously and as frequently as a user desires. Despite there being \nhundreds of mental health apps available on Google Play and the Apple App Store, relatively \nlittle is known about their effectiveness, as most marketing for apps is based on testimonials and \nunsupported claims. Less than half of these apps are supported by studies [13], and those studies \nhave been generally criticized as biased by high rates of participant dropout [14]. Further, users \ntend to drop off in usage after a short period of time [15]. While there is certainly need for \nmHealth apps as alternative delivery of mental health care, rigorous design and evaluation \nmethods should be taken to ensure that the apps are designed to be user-centered, evidence-\nbased, well-integrated with professional care, and used sustainably [16]. \n\nDespite these shortcomings, mHealth presents a promising platform to support students with \nmental health needs, especially given the popularity and ubiquity of smartphones among college \nstudents [17]. As digital natives, students are more proficient at communicating across virtual \nplatforms [18] which may help in managing their mental health through apps. Other research has \nalso found that asking student patients to use a mental health app between the time they set up \nand attend an appointment with a counselor led to moderate app usage and better mental health \noutcomes [12]. In spite of these promising findings, study of mental health apps for college \nstudents  have been focused on efficacy with self-selecting participants [19], with a genera"
  },
  {
    "title": "Effect of Social Media Use on Mental Health during Lockdown in India",
    "authors": [
      "Sweta Swarnam"
    ],
    "abstract": "This research paper studies about the role of social media use and increase\nthe risk factor of mental health during covid 19 or lockdown. Although few\nstudies have been conducted on the role about the effect of social media use on\nmental health during lockdown and impact on human reactive nature during\nlockdown. As a rapidly spreading pandemic, a biomedical disease has serious\nphysical and tremendous mental health implications. An occupational community\nof internal migrant workers is one of the most vulnerable, but neglected, and\nis likely to develop psychological ill-effects due to COVID-19's double whammy\nimpact. Mental health is a crucial aspect that needs to be addressed during\nthis lock-down as all modes of communication revolve around the virus. There\nare many difficulties with the unprecedented changes that have occurred so\nquickly due to the pandemic and stay-at - home confinement to achieve social\ndistance and mitigate the risk of infection. These include impaired health,\nwell-being, and sleep as a result of daily routine disruption, anxiety, worry,\nisolation, greater stress on family and work, and excessive screen time. An\nessential part of our overall health and well-being is mental and emotional\nhealth. An important skill is managing emotions and maintaining emotional\nbalance. It helps you face challenges and stress when you manage your emotional\nhealth. Lack of skills in emotional regulation may lead to poor mental health\nand relationship difficulties. It is as important to look after our mental\nhealth as it is to look after our physical health. For mental health\nprofessionals, the pandemic has also brought many ethical challenges.",
    "year": 2021,
    "url": "http://arxiv.org/abs/2102.09369v1",
    "pdf_url": "http://arxiv.org/pdf/2102.09369v1",
    "full_text": "Effect of Social Media Use on Mental Health during Lockdown in \nIndia \n\nSweta Swarnam \n\nSymbiosis Centre for Information Technology, \n\nSymbiosis International (Deemed University), Pune, India \n\nEmail:sweta.swarnam@associates.scit.edu \n\nAbstract \n\nThis  research  paper  studies  about  the  role  of  social  media  use  and  increase  the  risk  factor  of \nmental health during covid 19 or lockdown. Although few studies have been conducted on the role \nabout  the  effect  of  social  media  use  on  mental  health  during  lockdown  and  impact  on  human \nreactive  nature  during  lockdown.  As  a  rapidly  spreading  pandemic,  a  biomedical  disease  has \nserious  physical  and  tremendous  mental  health  implications.  An  occupational  community  of \ninternal  migrant  workers  is  one  of  the  most  vulnerable,  but  neglected,  and  is  likely  to  develop \npsychological ill-effects due to COVID-19's double  whammy impact. Mental health is a crucial \naspect that needs to be addressed during this lock-down as all modes of communication revolve \naround the virus. There are many difficulties with the unprecedented changes that have occurred \nso  quickly  due  to the  pandemic  and  stay-at -  home  confinement  to  achieve  social  distance  and \nmitigate the risk of infection. These include impaired health, well-being, and sleep as a result of \ndaily routine disruption, anxiety, worry, isolation, greater stress on family and work, and excessive \nscreen time. An essential part of our overall health and well-being is mental and emotional health. \nAn important  skill  is  managing  emotions  and  maintaining  emotional  balance.  It  helps  you face \nchallenges  and  stress  when  you  manage  your  emotional  health.  Lack  of  skills  in  emotional \nregulation may lead to poor mental health and relationship difficulties. It is as important to look \nafter our mental health as it is to look after our physical health. For mental health professionals, \nthe pandemic has also brought many ethical challenges. Personal protection, personal treatment \nneeds if they get infected, impact on others if they get infected, economic crisis, ethical problems \nfor themselves and others, and training are the issues that concern mental health professionals. In \nthe  wake  of  the  pandemic,  the  training  of  residents  has  also  been  compromised.  The  ways  of \nlearning  for  medical  students  and  residents  may  also  change,  leading  to  an  opportunity  to \ninnovate. This research concentrates upon the above-mentioned purpose and tries to bring out the \nfact  about  the  same.  This  study  shows  us  the  effect  on  mental  health  by  spending  more  time  in \nsocial media during lockdown, what its impact on their mental health during lockdown in different \nage groups and how to reduce spending more time on social media to avoid depression and keep \nmental condition positive. \n\nKeywords \n\nSocial Media, Mental health, depression, Lockdown and Covid 19. \n\n1 \n\n \n \n \n \n \n\f1.  Introduction \n\nDuring this lockdown people are started spending huge amount of time on social media  and for \nmany  youths  nowadays,  social  media  has  been  popular  aspects  of  life.  Whether  positive  or \nnegative, most people engage with social media without stopping to think about what the effects \nare on our lives. Social networking is a perfect place to rapidly distribute content across the world, \nwith posts like \"breaking news\" earning hundreds of thousands of retweets in minutes. Although \nsocial media impacts people positively, it also has negative impacts on people. Social networking \nhas been described primarily to refer to \"the many fairly inexpensive and widely available online \nresources  that  make  it  easier  for  everyone  to  publish  and  access  knowledge,  cooperate  on  a \ncollaborative project or create relationships. It has become a forum of discussion of every single \nsocial issue that is taking place. In the current situation, one of the most pathetic and to – bother \nsocial media use and increase the risk factor of mental health of humans. This has been increasing \nday  by  day  at  nook  and  corner  of  the  country.  Mindfulness  simply  means  being  in  the  present \nwithout thinking about the past or the future; choosing what you react to, rather than being carried \naway by everything that appears in your mind or experience; being non-judgmental and cultivating \nan attitude of impermanence towards things and situations, focusing on one thing at a time. This \nallows us to remain open to experiences and allows you not to be overly affected by them. \n\nThe sparse literature on the effects of epidemics on mental health relates more to the sequelae of \nthe  disease  itself  than  to  social  distancing  (e.g.,  mothers  of  children  with  congenital  Zika \nsyndrome). Large-scale disasters, however, whether traumatic (e.g., World Trade Center attacks \nor mass shootings), natural (e.g., hurricanes), or envi"
  },
  {
    "title": "SMHD: A Large-Scale Resource for Exploring Online Language Usage for\n  Multiple Mental Health Conditions",
    "authors": [
      "Arman Cohan",
      "Bart Desmet",
      "Andrew Yates",
      "Luca Soldaini",
      "Sean MacAvaney",
      "Nazli Goharian"
    ],
    "abstract": "Mental health is a significant and growing public health concern. As language\nusage can be leveraged to obtain crucial insights into mental health\nconditions, there is a need for large-scale, labeled, mental health-related\ndatasets of users who have been diagnosed with one or more of such conditions.\nIn this paper, we investigate the creation of high-precision patterns to\nidentify self-reported diagnoses of nine different mental health conditions,\nand obtain high-quality labeled data without the need for manual labelling. We\nintroduce the SMHD (Self-reported Mental Health Diagnoses) dataset and make it\navailable. SMHD is a novel large dataset of social media posts from users with\none or multiple mental health conditions along with matched control users. We\nexamine distinctions in users' language, as measured by linguistic and\npsychological variables. We further explore text classification methods to\nidentify individuals with mental conditions through their language.",
    "year": 2018,
    "url": "http://arxiv.org/abs/1806.05258v2",
    "pdf_url": "http://arxiv.org/pdf/1806.05258v2",
    "full_text": "SMHD: A Large-Scale Resource for Exploring Online Language Usage\nfor Multiple Mental Health Conditions\nBart Desmet1,2 *\nSean MacAvaney1\n\nArman Cohan1 *\nLuca Soldaini1\n\nAndrew Yates1,3 *\n\nNazli Goharian1\n\n8\n1\n0\n2\n\nl\nu\nJ\n\n0\n1\n\n]\nL\nC\n.\ns\nc\n[\n\n2\nv\n8\n5\n2\n5\n0\n.\n6\n0\n8\n1\n:\nv\ni\nX\nr\na\n\n1IR Lab, Georgetown University, US\n{firstname}@ir.cs.georgetown.edu\n\n2LT3, Ghent University, BE\nbart.desmet@ugent.be\n\n3Max Planck Institute for Informatics, DE\nayates@mpi-inf.mpg.de\n\nAbstract\n\nMental health is a signiﬁcant and growing public health concern. As language usage can be\nleveraged to obtain crucial insights into mental health conditions, there is a need for large-scale,\nlabeled, mental health-related datasets of users who have been diagnosed with one or more of\nsuch conditions. In this paper, we investigate the creation of high-precision patterns to identify\nself-reported diagnoses of nine different mental health conditions, and obtain high-quality labeled\ndata without the need for manual labelling. We introduce the SMHD (Self-reported Mental Health\nDiagnoses) dataset and make it available. SMHD is a novel large dataset of social media posts\nfrom users with one or multiple mental health conditions along with matched control users. We\nexamine distinctions in users’ language, as measured by linguistic and psychological variables.\nWe further explore text classiﬁcation methods to identify individuals with mental conditions\nthrough their language.\n\n1\n\nIntroduction\n\nMental health is a signiﬁcant challenge in healthcare. Mental disorders have the potential to tremen-\ndously affect the quality of life and wellness of individuals in society (Strine et al., 2008; Mowery et\nal., 2017a). Social media have become an increasingly important source of data related to mental health\nconditions (Cohan et al., 2017; Mowery et al., 2017b; Coppersmith et al., 2017; Yates et al., 2017), as\nit is now a prominent platform for individuals to engage in daily discussions, share information, seek\nadvice and simply communicate with peers that have shared interests. In addition to its ubiquity and ease\nof access, the possibility to disclose mental health matters anonymously or pseudo-anonymously further\ndrives users to online self-disclosure.\n\nAt the same time, the close connection between language and mental health makes social media an\ninvaluable resource of mental health-related data. Lack of data has been one of the key limitations to\nunderstanding and addressing the challenges the domain is facing (Coppersmith et al., 2014a). Data\nfrom social media can not only be used to potentially provide clinical help to users in need, but also to\nbroaden our understanding of the various mental health conditions. Social media analysis has already\nbeen proven valuable for identifying depression (Coppersmith et al., 2014a; Yates et al., 2017), suicide\nideation (Cohan et al., 2017; De Choudhury and Kıcıman, 2017; Kshirsagar et al., 2017; Desmet and\nHoste, 2018), and other conditions such as schizophrenia (Mitchell et al., 2015). While social media\ndata is abundantly available, the amount of labeled data for studying mental health conditions is limited.\nThis is due to the high cost of annotation and the difﬁculty of access to experts.\n\nPrior research has investigated self-disclosure as a means of obtaining labeled data from social media.\nDe Choudhury et al. (2013a) used it to identify new mothers and track post-partum changes in emotions.\n\n* Equal contribution.\n\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\nLicense details: http://\n\ncreativecommons.org/licenses/by/4.0/\n\n \n \n \n \n \n \n\fCondition\n\nADHD\nAnxiety\nAutism\nBipolar\nBorderline\nDepression\nEating\nOCD\nPTSD\nSchizophrenia\nSeasonal Affective\n\nTwitter, (Copper-\nsmith et al, 2015)\n102\n216\nn/a\n188\n101\n393\n238\n100\n403\n172\n100\n\nReddit,\nSMHD (ours)\n10,098\n8,783\n2,911\n6,434\nn/a\n14,139\n598\n2,336\n2,894\n1,331\nn/a\n\nTable 1: Comparison between the number of self-reported diagnosed users per condition in the dataset\nof Coppersmith et al. (2015a) and ours (SMHD).\n\nI was ofﬁcially diagnosed with ADHD last year.\nI have a diagnosed history of PTSD.\nmy dr just diagnosed me as schizo.\n\nFigure 1: Examples of self-reported diagnoses statements.\n\nCoppersmith et al. (2014a) speciﬁcally focused on self-reports of mental health diagnoses. In particular,\nCoppersmith et al. (2015a) constructed a dataset of various mental health conditions using Twitter state-\nments. Finally, Yates et al. (2017) introduced a large dataset of depressed users obtained from Reddit.\n\nWe extend the previous efforts on addressing the lack of large-scale mental health-related language\ndata. Particularly, we propose improved data collection methods through which we can obtain high-\nquality large-scale datasets of labeled diagnosed conditions paired with appropriate control users. Con-\nsequently, we introduce SMHD (Self-reported Mental Health Diagnoses), a large dataset of diverse mental\nhealth conditions that can provide further "
  },
  {
    "title": "Understanding and Mitigating Mental Health Misinformation on Video\n  Sharing Platforms",
    "authors": [
      "Viet Cuong Nguyen",
      "Michael Birnbaum",
      "Munmun De Choudhury"
    ],
    "abstract": "Despite the ever-strong demand for mental health care globally, access to\ntraditional mental health services remains severely limited expensive, and\nstifled by stigma and systemic barriers. Thus, over the last few years, young\npeople are increasingly turning to content on video-sharing platforms (VSPs)\nlike TikTok and YouTube to help them navigate their mental health journey.\nHowever, navigating towards trustworthy information relating to mental health\non these platforms is challenging, given the uncontrollable and unregulated\ngrowth of dedicated mental health content and content creators catering to a\nwide array of mental health conditions on these platforms. In this paper, we\nattempt to define what constitutes as \"mental health misinformation\" through\nexamples. In addition, we also suggest some open questions to answer and\nchallenges to tackle regarding this important and timely research topic",
    "year": 2023,
    "url": "http://arxiv.org/abs/2304.07417v1",
    "pdf_url": "http://arxiv.org/pdf/2304.07417v1",
    "full_text": "Understanding and Mitigating Mental Health Misinformation on Video\nSharing Platforms\n\nVIET CUONG NGUYEN, Georgia Institute of Technology, United States of America\nMICHAEL BIRNBAUM, Northwell Health, United States of America\nMUNMUN DE CHOUDHURY, Georgia Institute of Technology, United States of America\n\nAdditional Key Words and Phrases: video-sharing platforms, social media platforms, misinformation, mental health\n\nACM Reference Format:\nViet Cuong Nguyen, Michael Birnbaum, and Munmun De Choudhury. 2023. Understanding and Mitigating Mental Health Misinforma-\ntion on Video Sharing Platforms. In CHI ’23: ACM Conference on Human Factors in Computing Systems, April 23–28, 2023, Hamburg,\nGermany. ACM, New York, NY, USA, 5 pages. https://doi.org/XXXXXXX.XXXXXXX\n\n1 INTRODUCTION\n\nDespite the ever-strong demand for mental health care globally, access to traditional mental health services remains\n\nseverely limited expensive, and stifled by stigma and systemic barriers [1, 22, 23]. Thus, over the last few years, young\n\npeople are increasingly turning to content on video-sharing platforms (VSPs) like TikTok and YouTube to help them\n\nnavigate their mental health journey [8, 9]. Such content is not only readily accessible and free of charge, but they\n\ncontain easily digestible information through audio and visual affordances within these platforms [24, 27]. If done right,\n\ncontent on video-sharing platforms can be a significant asset to the growing field of digital mental health, as it can\n\nprovide non-judgmental and democratized access to mental health help and advice to all, within the privacy of their\n\nrealms [18, 21]. However, navigating towards trustworthy information relating to mental health on these platforms\n\nis challenging, given the uncontrollable and unregulated growth of dedicated mental health content and content\n\ncreators catering to a wide array of mental health conditions on these platforms. One reason for this is the relatively\n\nlow barrier of entry in creating mental health content on video-sharing platforms compared to other online-based\n\nresources (such as blog posts). Consequently, many reports have emerged that mental-health-related videos containing\nmisinformation (referred to henceforth as mental health misinformation) are rampant on these platforms [8, 19]. Here,\nwe define mental health misinformation as false or misleading information about mental health and illness, including\n\ndiagnosis and treatment of these challenges, irrespective of the intention of those spreading such information. An\n\nexample of mental health misinformation regarding bipolar found on video-sharing platforms is shown in Figure 1.\n\nIn this publicly available TikTok video where the screenshot from Figure 1 is taken, the presenter presents anecdotal\n\nsymptoms which they suggest are indicative of type 2 bipolar. This video contains several key markers indicative of\n\nmental health misinformation:\n\n• They do not have relevant medical qualifications to back these statements, nor do they disclose their lack of\n\nqualifications anywhere within the video or its description\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not\nmade or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components\nof this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to\nredistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\n\n© 2023 Association for Computing Machinery.\nManuscript submitted to ACM\n\n1\n\n3\n2\n0\n2\n\nr\np\nA\n4\n1\n\n]\nI\nS\n.\ns\nc\n[\n\n1\nv\n7\n1\n4\n7\n0\n.\n4\n0\n3\n2\n:\nv\ni\nX\nr\na\n\n \n \n \n \n \n \n\fCHI ’23, April 23–28, 2023, Hamburg, Germany\n\nNguyen et al.\n\nFig. 1. Example of mental health misinformation on a video-sharing platform. (potentially identifying information has been blurred\nout for privacy reasons)\n\n• The symptoms they shared for type 2 bipolar are purely anecdotal and not backed by any official diagnostic\n\ncriteria for the condition (e.g. DSM-5)\n\n• They encourage viewers to self-diagnose themselves with type 2 bipolar by prefacing the video with \"Signs You\n\nMight Have Bipolar Two\"\n\nThere has been extensive work has been done on understanding and mitigating misinformation content on text- and\n\nimage-based social media platforms such as Facebook, Twitter, and Instagram for a variety of topics [6, 7, 12, 13, 15, 16].\n\nHowever, while the virality and popularity of content on video-based social media platforms are significant, few works\n\nhave focused on understanding how and mitigating the spread of mental health misinformation on video-sharing\n\nplatforms. The widespread dissemination of mental health misinformation can have serious consequences. Broadly\n\n2\n\n\fUnderstanding and Mitigating Mental Health Misinformation on Video S"
  },
  {
    "title": "Quantifying Mental Health from Social Media with Neural User Embeddings",
    "authors": [
      "Silvio Amir",
      "Glen Coppersmith",
      "Paula Carvalho",
      "Mário J. Silva",
      "Byron C. Wallace"
    ],
    "abstract": "Mental illnesses adversely affect a significant proportion of the population\nworldwide. However, the methods traditionally used for estimating and\ncharacterizing the prevalence of mental health conditions are time-consuming\nand expensive. Consequently, best-available estimates concerning the prevalence\nof mental health conditions are often years out of date. Automated approaches\nto supplement these survey methods with broad, aggregated information derived\nfrom social media content provides a potential means for near real-time\nestimates at scale. These may, in turn, provide grist for supporting,\nevaluating and iteratively improving upon public health programs and\ninterventions.\n  We propose a novel model for automated mental health status quantification\nthat incorporates user embeddings. This builds upon recent work exploring\nrepresentation learning methods that induce embeddings by leveraging social\nmedia post histories. Such embeddings capture latent characteristics of\nindividuals (e.g., political leanings) and encode a soft notion of homophily.\nIn this paper, we investigate whether user embeddings learned from twitter post\nhistories encode information that correlates with mental health statuses. To\nthis end, we estimated user embeddings for a set of users known to be affected\nby depression and post-traumatic stress disorder (PTSD), and for a set of\ndemographically matched `control' users. We then evaluated these embeddings\nwith respect to: (i) their ability to capture homophilic relations with respect\nto mental health status; and (ii) the performance of downstream mental health\nprediction models based on these features. Our experimental results demonstrate\nthat the user embeddings capture similarities between users with respect to\nmental conditions, and are predictive of mental health.",
    "year": 2017,
    "url": "http://arxiv.org/abs/1705.00335v1",
    "pdf_url": "http://arxiv.org/pdf/1705.00335v1",
    "full_text": "7\n1\n0\n2\n\nr\np\nA\n0\n3\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n5\n3\n3\n0\n0\n.\n5\n0\n7\n1\n:\nv\ni\nX\nr\na\n\nQuantifying Mental Health from Social Media with Neural User Embeddings\n\nQuantifying Mental Health from Social Media with\nNeural User Embeddings\n\nSilvio Amir\nINESC-ID Lisboa, Instituto Superior T´ecnico, Universidade de Lisboa\nLisboa, Portugal\n\nGlen Coppersmith\nQntfy\nWashington DC, United States\n\nPaula Carvalho\nINESC-ID Lisboa, and Universidade Europeia, LIU\nLisboa, Portugal\n\nM´ario J. Silva\nINESC-ID Lisboa, Instituto Superior T´ecnico, Universidade de Lisboa\nLisboa, Portugal\n\nsamir@inesc-id.pt\n\nglen@qntfy.com\n\npcc@inesc-id.pt\n\nmjs@inesc-id.pt\n\nByron C. Wallace\nNortheastern University\nBoston MA, United States\n\nb.wallace@northeastern.edu\n\nAbstract\nMental illnesses adversely aﬀect a signiﬁcant proportion of the population worldwide. How-\never, the methods traditionally used for estimating and characterizing the prevalence of\nmental health conditions are time-consuming and expensive. Consequently, best-available\nestimates concerning the prevalence of mental health conditions are often years out of\ndate. Automated approaches to supplement these survey methods with broad, aggregated\ninformation derived from social media content provides a potential means for near real-\ntime estimates at scale. These may, in turn, provide grist for supporting, evaluating and\niteratively improving upon public health programs and interventions.\n\nWe propose a novel model for automated mental health status quantiﬁcation that incor-\nporates user embeddings. This builds upon recent work exploring representation learning\nmethods that induce embeddings by leveraging social media post histories. Such embed-\ndings capture latent characteristics of individuals (e.g., political leanings) and encode a\nsoft notion of homophily. In this paper, we investigate whether user embeddings learned\nfrom twitter post histories encode information that correlates with mental health statuses.\nTo this end, we estimated user embeddings for a set of users known to be aﬀected by\ndepression and post-traumatic stress disorder (PTSD), and for a set of demographically\nmatched ‘control’ users. We then evaluated these embeddings with respect to: (i) their\nability to capture homophilic relations with respect to mental health status; and (ii) the\nperformance of downstream mental health prediction models based on these features. Our\nexperimental results demonstrate that the user embeddings capture similarities between\nusers with respect to mental conditions, and are predictive of mental health.\n\n1. Introduction\n\nMental illness is a critically important concern, signiﬁcantly and adversely aﬀecting a wide\nswath of the population directly and indirectly. An estimate by the Centers for Disease\nControl from 2008 (CDC, 2010), suggests that 9% of US adults may meet the criteria for\n\n1\n\n \n \n \n \n \n \n\fAmir, Coppersmith, Carvalho, Silva and Wallace\n\ndepression at any given time. While not as prevalent as depression, post traumatic stress\ndisorder (PTSD) issues still cost hundreds of billions of dollars worldwide, according to\na conservative estimate from the NIH1. The collective eﬀect of mental health conditions,\nas measured by Daily Adjusted Life Years (DALYs), exceeds that of malaria, war, or vi-\nolence2 (?). At the same time, mental health problems are often diﬃcult to identify and\nthus treat. For example, perhaps half of depressive cases go undetected, in part due to\nthe heterogeneous and complex expression of this condition (Paykel et al., 1997). Another\nexacerbating factor is that diagnosis generally requires individuals to actively seek out treat-\nment. Yet, the manifestation of this condition and prevailing social stigmas may disincline\naﬄicted individuals to seek treatment.\n\nThe internet may provide a comfortable medium for people to express their feelings\nanonymously and connect with health-care professionals (McCaughey et al., 2014) and oth-\ners aﬀected by similar conditions (De Choudhury et al., 2016). Furthermore, individuals\nopenly discuss mental health challenges on public social network platforms such as Twitter\n(Coppersmith et al., 2014a, 2015a). Prior work has demonstrated the potential of using\nsocial media to investigate mental health issues (Paul and Dredze, 2011), including de-\npression (Schwartz et al., 2014), PTSD (Coppersmith et al., 2014b) and suicidal ideation\n(Coppersmith et al., 2016; De Choudhury et al., 2016) in individuals. However, models and\ntechniques to identify and quantify mental health related signals from social media are rel-\natively novel. Interest in these applications has motivated the creation of a shared task for\nthe Computational Linguistics and Clinical Psychology workshop (CLPsych)3, which aimed\nto advance the state-of-the-art in technologies capable of discriminating users aﬀected by\nmental illness from controls, given their post history (Coppersmith et al., 2015b). A variety\nof methods have been proposed for this task, but none have achieved consistently super"
  },
  {
    "title": "Then and Now: Quantifying the Longitudinal Validity of Self-Disclosed\n  Depression Diagnoses",
    "authors": [
      "Keith Harrigian",
      "Mark Dredze"
    ],
    "abstract": "Self-disclosed mental health diagnoses, which serve as ground truth\nannotations of mental health status in the absence of clinical measures,\nunderpin the conclusions behind most computational studies of mental health\nlanguage from the last decade. However, psychiatric conditions are dynamic; a\nprior depression diagnosis may no longer be indicative of an individual's\nmental health, either due to treatment or other mitigating factors. We ask: to\nwhat extent are self-disclosures of mental health diagnoses actually relevant\nover time? We analyze recent activity from individuals who disclosed a\ndepression diagnosis on social media over five years ago and, in turn, acquire\na new understanding of how presentations of mental health status on social\nmedia manifest longitudinally. We also provide expanded evidence for the\npresence of personality-related biases in datasets curated using self-disclosed\ndiagnoses. Our findings motivate three practical recommendations for improving\nmental health datasets curated using self-disclosed diagnoses: 1) Annotate\ndiagnosis dates and psychiatric comorbidities; 2) Sample control groups using\npropensity score matching; 3) Identify and remove spurious correlations\nintroduced by selection bias.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2206.11155v1",
    "pdf_url": "http://arxiv.org/pdf/2206.11155v1",
    "full_text": "ThenandNow:QuantifyingtheLongitudinalValidityofSelf-DisclosedDepressionDiagnosesKeithHarrigianandMarkDredzeJohnsHopkinsUniversitykharrigian@jhu.edu,mdredze@cs.jhu.eduAbstractSelf-disclosedmentalhealthdiagnoses,whichserveasgroundtruthannotationsofmentalhealthstatusintheabsenceofclinicalmea-sures,underpintheconclusionsbehindmostcomputationalstudiesofmentalhealthlan-guagefromthelastdecade.However,psy-chiatricconditionsaredynamic;apriorde-pressiondiagnosismaynolongerbeindicativeofanindividual’smentalhealth,eitherduetotreatmentorothermitigatingfactors.Weask:towhatextentareself-disclosuresofmentalhealthdiagnosesactuallyrelevantovertime?Weanalyzerecentactivityfromindividualswhodisclosedadepressiondiagnosisonsocialmediaoverﬁveyearsagoand,inturn,acquireanewunderstandingofhowpresentationsofmentalhealthstatusonsocialmediamanifestlongitudinally.Wealsoprovideexpandedev-idenceforthepresenceofpersonality-relatedbiasesindatasetscuratedusingself-discloseddiagnoses.Ourﬁndingsmotivatethreeprac-ticalrecommendationsforimprovingmentalhealthdatasetscuratedusingself-discloseddi-agnoses:1.Annotatediagnosisdatesandpsychiatriccomorbidities2.Samplecontrolgroupsusingpropensityscorematching3.Identifyandremovespuriouscorrela-tionsintroducedbyselectionbias1IntroductionTheabilitytoprovideequitableaccesstopsychi-atrichealthcarehasbecomemoredifﬁcultthanever,inhibitedbyanentanglementoflingeringpublicpolicyeffects(Mirandaetal.,2020),heightenedlevelsofphysicianburnout(Johnsonetal.,2018),andinfrastructuralchallengesarisingfromglobalcrisis(Davisetal.,2021).Meanwhile,socialmediaplatformshavebecomethepredominantmeansofcommunicationformuchofthepopulation,provid-ingtheopportunitytosharepersonalexperiencesandseeksupportfromothers(Muelleretal.,2021).Notingtheseparalleltimelines,computationalsci-entistshavedevotedsubstantialefforttoengineer-ingstatisticalmodelscapableoftranslatingsocialmediadataintoreliableinsightsregardingmen-talhealth.Coreobjectivesofthisworkincludeoptimizingpsychiatrictreatment,identifyingearlystagesofmentalillness,andmeasuringtheeffectofpublicpolicyonapopulation’swell-being(Losadaetal.,2017;Fineetal.,2020).Themostsigniﬁcantadvancesincomputationalmentalhealthresearchhavenotcomefromim-provedmodelingarchitectures(Bentonetal.,2017b),butfrommethodsforcuratinglarge-scaledatasetswhichcontainrobustandclinically-relevantgroundtruthannotationsofmentalhealthstatus(Coppersmithetal.,2014).Useofregularexpressionstoidentifygenuineself-disclosuresofapsychiatricdiagnosisremainsoneofthemostwidelyadoptedannotationmechanismsbythere-searchcommunity(ChancellorandDeChoudhury,2020;Harrigianetal.,2021),offeringarelativelyreliableproxyinplaceofclinicalmeasureswhicharenotonlycostlytocollect,butalsooftenun-abletobesharedbeyondasingleinstitutionduetopatientprivacypolicies(Macavaneyetal.,2021).Datasetsleveragingself-discloseddiagnosesasan-notationsofmentalhealthstatushaveyieldedava-rietyofinsightsthatalignwithclinicalknowledgeandpsychologicaltheory(Moweryetal.,2017;Leeetal.,2021).However,agrowingbodyofworkhasraisedquestionsaboutwhethersuchdatasetsprovidesufﬁcientinformationtotrainstatisticalmodelsthatgeneralizetonewpopulations(Harri-gianetal.,2020;Aguirreetal.,2021).Despitetheprevalenceofdatasetsdependentonself-disclosure,noanalyseshaveconsideredhowassociatingasingleself-discloseddiagnosislabelwithdatafromavariable-lengthperiodoftimemayinhibitthelearningofrobuststatisticalrela-tionships.IfausertweetsadepressiondiagnosisarXiv:2206.11155v1  [cs.LG]  22 Jun 2022\fin2015,istheirdatafrom2018stillrepresentativeofthecondition?Presentationofseveralmentalhealthconditionschangedynamicallyand(some-times)precipitouslyovertime(Collishawetal.,2004).Yet,itremainscommoninthecomputa-tionalresearchcommunitytotreatmentalhealthconditionsasastaticattributewithequalrelevanceatmultipletimepoints(MacAvaneyetal.,2018).Inreality,itislikelythatonlyasmallfractionofanindividual’ssocialmediaactivityisappropriatefortrainingoptimalclassiﬁers.Moreover,thatamen-talhealthstatuslabelmaybeappropriateforonlyasubsetoftimesuggeststhatevaluationsoflongitu-dinalmodelgeneralizationastheyaretraditionallystructuredinthecommunitymaybeinsufﬁcient(Sadequeetal.,2018).Weask:towhatextentdomentalhealthdiag-nosisself-disclosuresremainvalidovertime?Wefocusspeciﬁcallyonextendeddurations(i.e.,mul-tipleyears),asettingwhichhasparticularrele-vancetothosewhowishtoestimategeneralizationstrengthoftheirstatisticalclassiﬁersforuseinlon-gitudinalmonitoringapplications,aswellasthoseinterestedinupdatingexistingmodelswithnewdatatomitigatetheeffectscovariateshift(AgarwalandNenkova,2021).Inreviewingrecentonlineac-tivityfromindividualsinthe2015CLPsychSharedTaskdatasetwhodisclosedadepressiondiagnosisonTwitteroverﬁveyearsago(Coppersmithetal.,2015),wenotonlyacquireanewunderstandingofhowpresentationsofmentalhealthstatusonsocialmediapresentovertime,butalsoﬁndnewevidencetosupportpriorclaimsregardingthepresenceofpersonality-relatedconfoundsindatasetscuratedusingself-disclosures(Preo¸tiuc-Pietroetal.,2015;VukojevicandŠnajder,2021).Ouranalys"
  },
  {
    "title": "The Role of Mandated Mental Health Treatment in the Criminal Justice\n  System",
    "authors": [
      "Rachel Nesbit"
    ],
    "abstract": "Mental health disorders are particularly prevalent among those in the\ncriminal justice system and may be a contributing factor in recidivism. Using\nNorth Carolina court cases from 1994 to 2009, this paper evaluates how mandated\nmental health treatment as a term of probation impacts the likelihood that\nindividuals return to the criminal justice system. I use random variation in\njudge assignment to compare those who were required to seek weekly mental\nhealth counseling to those who were not. The main findings are that being\nassigned to seek mental health treatment decreases the likelihood of three-year\nrecidivism by about 12 percentage points, or 36 percent. This effect persists\nover time, and is similar among various types of individuals on probation. In\naddition, I show that mental health treatment operates distinctly from drug\naddiction interventions in a multiple-treatment framework. I provide evidence\nthat mental health treatment's longer-term effectiveness is strongest among\nmore financially-advantaged probationers, consistent with this setting, in\nwhich the cost of mandated treatment is shouldered by offenders. Finally,\nconservative calculations result in a 5:1 benefit-to-cost ratio which suggests\nthat the treatment-induced decrease in future crime would be more than\nsufficient to offset the costs of treatment.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2212.06736v2",
    "pdf_url": "http://arxiv.org/pdf/2212.06736v2",
    "full_text": "The Role of Mandated Mental Health Treatment in the\nCriminal Justice System\n\nRachel Nesbit*\n\nNovember 14, 2023\n\nAbstract\n\nMental health disorders are particularly prevalent among those in the criminal justice system\nand may be a contributing factor in recidivism. Using North Carolina court cases from 1994 to\n2009, this paper evaluates how mandated mental health treatment as a term of probation impacts\nthe likelihood that individuals return to the criminal justice system. I use random variation in judge\nassignment to compare those who were required to seek weekly mental health counseling to those who\nwere not. The main ﬁndings are that being assigned to seek mental health treatment decreases the\nlikelihood of three-year recidivism by about 12 percentage points, or 36 percent. This eﬀect persists\nover time, and is similar among various types of individuals on probation.\nIn addition, I show\nthat mental health treatment operates distinctly from drug addiction interventions in a multiple-\ntreatment framework. I provide evidence that mental health treatment’s longer-term eﬀectiveness is\nstrongest among more ﬁnancially-advantaged probationers, consistent with this setting, in which the\ncost of mandated treatment is shouldered by oﬀenders. Finally, conservative calculations result in a\n5:1 beneﬁt-to-cost ratio which suggests that the treatment-induced decrease in future crime would\nbe more than suﬃcient to oﬀset the costs of treatment.\n\nJEL codes: I12, I18, K42\n\n*University of Maryland, 3114 Tydings Hall, 7343 Preinkert Dr., College Park, MD 20742. Email: rnesbit@umd.edu\n\n1\n\n\f1 Intro\n\nPoor mental health is widely prevalent and has been growing over time, with around 58 million\nadults in the United States suﬀering from a mental illness in 2021 (SAMHSA, 2022).1 Poor mental\nhealth is also widely impactful; it has direct negative eﬀects on physical and social health and is highly\nintertwined with other aspects of life. For example, it contributes to upwards of 40 percent of all\nillnesses under the age of 65 (Layard, 2013). Beyond (or as a consequence of) these direct negative\neﬀects on health, mental illness has been associated with behaviors like absenteeism at work, decreased\neducational attainment, and crime (Bubonya, Cobb-Clark, and Wooden, 2017; Burton et al., 2008;\nBreslau et al., 2008; Mojtabai et al., 2015).\n\nPoor mental health is particularly prevalent in the criminal justice system. Among the approxi-\nmately ﬁve million men on probation in 2009, 33 percent met the threshold for any mental illness -\nnearly twice the prevalence in the general population at the time (Feucht and Gfroerer, 2011).2 Indi-\nviduals with a mental illness can struggle to make rational, welfare-maximizing decisions, which may\nplay a critical role in their interactions with the criminal justice system. Since the medical ﬁeld has\nshown that therapy and medication can reduce symptoms of mental illness (Cronin, Forsstrom, and\nPapageorge, 2020; Paykel et al., 1999), it may be the case that mental health treatment can reduce\nbehavioral outcomes such as crime. That reduction could have large beneﬁts for both treated individ-\nuals and society. However, though meaningful correlational evidence exists, there is little direct causal\nevidence on the eﬀect of therapy and psychiatric medication on outcomes such as criminal behavior, or\nwhether those interventions could be carried out in a cost-eﬀective way.3\n\nThis paper evaluates the causal impact of mandated mental health treatment on the likelihood of\ncommitting a future crime. Speciﬁcally, it focuses on how being assigned mental health treatment at\nthe time of probation impacts recidivism over the next ﬁve years. To do this I exploit judge variation in\ncourt-mandated mental health treatment in North Carolina, using the universe of criminal court cases\nfrom 1994 to 2009. The requirement that the defendant seek mental health treatment is a possible\ncondition of probation (supervised release without serving time in prison). While the type of mental\nhealth treatment can vary, it typically includes a psychological evaluation, weekly therapy sessions\nfor the duration of the sentence, and potentially a referral to a psychiatrist for medication. Simply\ncomparing outcomes of probationers who are and are not mandated mental health treatment could\nresult in a biased estimate if judges make their sentencing decisions using additional information that\nis unobserved to the researcher. In particular, while the data provide information on demographics and\ncriminal history, they do not provide information about mental illness, which is likely correlated with\nboth the judge’s sentence and recidivism risk. To address this, I use the randomly-assigned judge’s\npropensity to mandate mental health treatment among other cases as an instrument for actually be-\ning assigned mental health treatment as a term of probation. This research design has been used in\nvarious applications in which a judge, case worker, or other type "
  },
  {
    "title": "Dynamic Strategy Chain: Dynamic Zero-Shot CoT for Long Mental Health\n  Support Generation",
    "authors": [
      "Qi Chen",
      "Dexi Liu"
    ],
    "abstract": "Long counseling Text Generation for Mental health support (LTGM), an\ninnovative and challenging task, aims to provide help-seekers with mental\nhealth support through a comprehensive and more acceptable response. The\ncombination of chain-of-thought (CoT) prompting and Large Language Models\n(LLMs) is employed and get the SOTA performance on various NLP tasks,\nespecially on text generation tasks. Zero-shot CoT prompting is one of the most\ncommon methods in CoT prompting. However, in the LTGM task, Zero-shot CoT\nprompting can not simulate a counselor or provide personalized strategies\nwithout effective mental health counseling strategy prompts. To tackle this\nchallenge, we propose a zero-shot Dynamic Strategy Chain (DSC) prompting\nmethod. Firstly, we utilize GPT2 to learn the responses written by mental\nhealth counselors and dynamically generate mental health counseling strategies\ntailored to the help-seekers' needs. Secondly, the Zero-shot DSC prompting is\nconstructed according to mental health counseling strategies and the\nhelp-seekers' post. Finally, the Zero-shot DSC prompting is employed to guide\nLLMs in generating more human-like responses for the help-seekers. Both\nautomatic and manual evaluations demonstrate that Zero-shot DSC prompting can\ndeliver more human-like responses than CoT prompting methods on LTGM tasks.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2308.10444v1",
    "pdf_url": "http://arxiv.org/pdf/2308.10444v1",
    "full_text": "Dynamic Strategy Chain: Dynamic Zero-Shot CoT\nfor Long Mental Health Support Generation\n\nQi Chen*, Dexi Liu*\n1Jiangxi University of Finance and Economics\n\n3\n2\n0\n2\n\ng\nu\nA\n1\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n4\n4\n4\n0\n1\n.\n8\n0\n3\n2\n:\nv\ni\nX\nr\na\n\nAbstract\n\nLong counseling Text Generation for Mental health support\n(LTGM), an innovative and challenging task, aims to pro-\nvide help-seekers with mental health support through a com-\nprehensive and more acceptable response. The combination\nof chain-of-thought (CoT) prompting and Large Language\nModels (LLMs) is employed and get the SOTA performance\non various NLP tasks, especially on text generation tasks.\nZero-shot CoT prompting is one of the most common meth-\nods in CoT prompting. However, in the LTGM task, Zero-\nshot CoT prompting can not simulate a counselor or provide\npersonalized strategies without effective mental health coun-\nseling strategy prompts. To tackle this challenge, we pro-\npose a zero-shot Dynamic Strategy Chain (DSC) prompt-\ning method. Firstly, we utilize GPT2 to learn the responses\nwritten by mental health counselors and dynamically gener-\nate mental health counseling strategies tailored to the help-\nseekers needs. Secondly, the Zero-shot DSC prompting is\nconstructed according to mental health counseling strate-\ngies and the help-seeker’s post. Finally, the Zero-shot DSC\nprompting is employed to guide LLMs in generating more\nhuman-like responses for the help-seekers. Both automatic\nand manual evaluations demonstrate that Zero-shot DSC\nprompting can deliver more human-like responses than CoT\nprompting methods on LTGM tasks.\n\nIntroduction\nAccording to the latest data from the World Health Or-\nganization, there are approximately 450 million individu-\nals worldwide with mental health disorders (World Health\nOrganization 2022). Mental health issues are becoming in-\ncreasingly severe, causing immense pain to individual lives\nand affecting the overall health and well-being of society\n(Sun et al. 2021; Sabour et al. 2023). Online mental health\ncounseling, as an effective therapy for mental disorders (Jr.\net al. 2013), has become popular in recent years (Sun et al.\n2021).\n\nIn recent years, significant advancements have occurred\nin NLP and AI, primarily due to the emergence of large lan-\nguage models (LLMs). Noteworthy models such as GPT-3\n(Brown et al. 2020), PaLM (Chowdhery et al. 2022), Llama\n(Touvron et al. 2023) and GPT-3.5 (OpenAI, 2023) have\ndemonstrated the potential of LLMs by leveraging their in-\ncreasing model sizes and vast amounts of training data. As\n\n*These authors contributed equally.\n\nFigure 1: An example showing Long counseling Text\nGeneration for Mental Health support, which includes a\nsystem(GPT3.5-turbo) for seeking helpers and providing\nmental health support services. The prompt ’Please answer\nmy question.’ is used to guide the system to respond to the\nHelp-Seeker’s question.\n\na result, these models have achieved human-level perfor-\nmance across various tasks, including summarization, trans-\nlation, question answering, and basic mathematical reason-\ning (Zhang et al. 2023). Figure 1 shows the results generated\nby GPT3.5-turbo in the Long counseling Text Generation for\nMental health support (LTGM) task.\n\nDespite demonstrating strong coherence and structural\nawareness in generating lengthy text, LLMs have certain\nlimitations in the LTGM task, as illustrated in Figure 1.\nFirstly, when answering mental health support questions,\nLLMs skip the expression of understanding and analysis,\nproviding generic advice that often comes across as indiffer-\nent and unresponsive. Secondly, it lacks guided strategies for\ntarget emotions, making it challenging to effectively drive\nusers out of emotional distress. Thirdly, LLMs rarely gen-\nerate personalized responses based on different users’ lan-\nguage styles, needs, and preferences, resulting in answers\nlacking individualization and customization. These limita-\ntions constrain the performance of LLMs in mental health\n\n[QUESTION] (Post Title)25-year-old female, having a tense relationship with colleagues, considering quitting but afraid of confrontation?[DESCRIPTION] (Post Content)I've always considered myself a cheerful person... Recently, the colleagues I used to get along with are now siding with him, isolating me in front of the boss...[LABEL] (Keywoeds)Career, Career Management, Workplace Interpersonal, Work StressPlease answer my question.It seems like you are facing a difficult situation at work with your colleagues, and you're considering resigning but worried about potential conflicts... Here are some suggestions to consider:1. Communication: Try to have an open and honest conversation with your colleagues about the issues you are facing. ...2. Seek Mediation: If direct communication doesn't work, consider involving a mediator or your supervisor to help facilitate a constructive dialogue and find a resolution to the conflict....Remember, workplace conflicts can be challenging, but it's essential to address them"
  },
  {
    "title": "Mental Health and Abortions among Young Women: Time-varying Unobserved\n  Heterogeneity, Health Behaviors, and Risky Decisions",
    "authors": [
      "Lena Janys",
      "Bettina Siflinger"
    ],
    "abstract": "In this paper, we provide causal evidence on abortions and risky health\nbehaviors as determinants of mental health development among young women. Using\nadministrative in- and outpatient records from Sweden, we apply a novel grouped\nfixed-effects estimator proposed by Bonhomme and Manresa (2015) to allow for\ntime-varying unobserved heterogeneity. We show that the positive association\nobtained from standard estimators shrinks to zero once we control for grouped\ntime-varying unobserved heterogeneity. We estimate the group-specific profiles\nof unobserved heterogeneity, which reflect differences in unobserved risk to be\ndiagnosed with a mental health condition. We then analyze mental health\ndevelopment and risky health behaviors other than unwanted pregnancies across\ngroups. Our results suggest that these are determined by the same type of\nunobserved heterogeneity, which we attribute to the same unobserved process of\ndecision-making. We develop and estimate a theoretical model of risky choices\nand mental health, in which mental health disparity across groups is generated\nby different degrees of self-control problems. Our findings imply that mental\nhealth concerns cannot be used to justify restrictive abortion policies.\nMoreover, potential self-control problems should be targeted as early as\npossible to combat future mental health consequences.",
    "year": 2021,
    "url": "http://arxiv.org/abs/2103.12159v4",
    "pdf_url": "http://arxiv.org/pdf/2103.12159v4",
    "full_text": "2\n2\n0\n2\n\ny\na\nM\n4\n\n]\n\nN\nG\n.\nn\no\nc\ne\n[\n\n4\nv\n9\n5\n1\n2\n1\n.\n3\n0\n1\n2\n:\nv\ni\nX\nr\na\n\nMental Health and Abortions among Young\n\nWomen: Time-Varying Unobserved Heterogeneity,\n\nHealth Behaviors, and Risky Decisions\n\nLena Janys∗\n\nBettina Siﬂinger†\n\nMay 5, 2022\n\nIn this paper, we provide causal evidence on abortions and risky health behaviors as de-\nterminants of mental health development among young women. Using administrative\nin- and outpatient records from Sweden, we apply a novel grouped ﬁxed-eﬀects estima-\ntor proposed by Bonhomme and Manresa (2015) to allow for time-varying unobserved\nheterogeneity. We show that the positive association obtained from standard estimators\nshrinks to zero once we control for grouped time-varying unobserved heterogeneity.\nWe estimate the group proﬁles of unobserved heterogeneity, which reﬂect diﬀerences\nin unobserved risk to be diagnosed with a mental health condition and analyze mental\nhealth development and risky health behaviors other than unwanted pregnancies across\ngroups. Our results suggest that these are determined by the same type of unobserved\nheterogeneity, which we attribute to the same unobserved process of decision-making.\nWe develop and estimate a theoretical model of risky choices and mental health, in\nwhich mental health disparity across groups is generated by diﬀerent degrees of self-\ncontrol problems. Our ﬁndings imply that mental health concerns cannot be used to\njustify restrictive abortion policies. Moreover, potential self-control problems should\nbe targeted as early as possible to combat future mental health consequences.\n\n∗University of Bonn (Department of Economics), HCM and IZA, ljanys@uni-bonn.de\n†Tilburg University (Department of Econometrics & OR), Netspar, CESIfo, b.m.siﬂinger@uvt.nl\n\nLena Janys was funded by the German Research Foundation (DFG) under Germany’s Excellence\nStrategy –EXC-2126/1–390838866, under Germany’s Excellence Strategy –EXC-2047/1 –390685813 and\nunder the individual fellowship with grant-number 441253219. Bettina Siﬂinger acknowledges support\nby the German Research Foundation DFG through the SFB 884. We thank Otilia Boldea, Marieke Bos,\nPavel Čížek, Jason Fletcher, Joachim Freyberger, Holger Gerhardt, Lukas Kiessling, Tobias Klein, Nikolaus\nSchweizer, Thomas Siedler, Miriam Wüst, Nicolas Ziebarth and participants at workshops and seminars at\nthe University of Bonn, Hertie School Berlin, Hamburg Center for Health Economics, Tinbergen Institute,\nUniversity of Hannover, Virtual Mental Health Seminar (VMESS), “The Importance of Early-Life Circum-\nstances: Shocks, Parents and Policies” (Copenhagen), European Health Econometrics Workshop (Leuven),\nWorld Congress of the Econometric Society (Milan), International Health Economics Workshop (Mainz),\nthe IAAE (Rotterdam) and the Annual Health Econometrics Workshop (Emory) for helpful comments and\ndiscussions. We thank Statistics Sweden and Socialstyrelsen for the data, and Hans-Martin von Gaudecker,\nMårten Palme, Lars Gullikson and Alexander Paul for their eﬀorts to make them accessible.\n\n \n \n \n \n \n \n\fKeywords: Mental Health; Abortions; Time-Varying Unobserved Heterogeneity; Grouped\nFixed-Eﬀects; Risky Health Behaviors; Adolescence\nJEL-Codes:: I12, I10, C23, D91\n\n2\n\n\f1\n\nIntroduction\n\nIn recent years, economists have increasingly paid attention to mental health problems and\n\ntheir consequences, especially when occurring during adolescence and young adulthood\n\n(Biasi et al., 2021; Cuddy and Currie, 2020). Mental health problems are often ﬁrst\n\ndiagnosed in early adulthood and are very pervasive, in particular among young women\n\n(see Eaton et al., 2008). In 2017, about 13–19% of adolescents between 15-25 in the US\n\nexperienced at least one major depressive episode (NIH, 2019). As pointed out by Currie\n\n(2020) mental health problems can reﬂect deﬁcits in non-cognitive skills that are crucial\n\nfor human capital development and labor market outcomes in adulthood. Thus, knowing\n\nabout potential determinants of mental problems is of ﬁrst-order importance.\n\nOne possible determinant that is often discussed in connection with mental health\n\nproblems is abortion. In the US, abortions for women aged 15-24 years account for\n\nalmost 40% of all abortions in 2017 (Kortsmit et al., 2020). As pointed out by Reardon\n\n(2018) abortion is consistently associated with elevated rates of mental illness compared\n\nto women without a history of abortion. While there are diﬀerent perspectives on the\n\ninterpretation of this association, there is hardly any evidence for a causal relationship.\n\nYet, in many countries, the association between abortion and mental health seems to be\n\nsuﬃcient for politicians to justify restrictions on abortion access such as waiting times,\n\nmandatory disclosures, or parental consent laws (Guttmacher Institute, 2020).\n\nThis paper investigates the impact of having an abortion from an unwanted preg-\n\nnancy on the incidence of mental health conditions in young women in Sweden. We\n\nuse individual-level ad"
  },
  {
    "title": "A Snapshot of the Mental Health of Software Professionals",
    "authors": [
      "Eduardo Santana de Almeida",
      "Ingrid Oliveira de Nunes",
      "Raphael Pereira de Oliveira",
      "Michelle Larissa Luciano Carvalho",
      "Andre Russowsky Brunoni",
      "Shiyue Rong",
      "Iftekhar Ahmed"
    ],
    "abstract": "Mental health disorders affect a large number of people, leading to many\nlives being lost every year. These disorders affect struggling individuals and\nbusinesses whose productivity decreases due to days of lost work or lower\nemployee performance. Recent studies provide alarming numbers of individuals\nwho suffer from mental health disorders, e.g., depression and anxiety, in\nparticular contexts, such as academia. In the context of the software industry,\nthere are limited studies that aim to understand the presence of mental health\ndisorders and the characteristics of jobs in this context that can be triggers\nfor the deterioration of the mental health of software professionals. In this\npaper, we present the results of a survey with 500 software professionals. We\ninvestigate different aspects of their mental health and the characteristics of\ntheir work to identify possible triggers of mental health deterioration. Our\nresults provide the first evidence that mental health is a critical issue to be\naddressed in the software industry, as well as raise the direction of changes\nthat can be done in this context to improve the mental health of software\nprofessionals.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2309.17140v1",
    "pdf_url": "http://arxiv.org/pdf/2309.17140v1",
    "full_text": "3\n2\n0\n2\n\np\ne\nS\n9\n2\n\n]\nE\nS\n.\ns\nc\n[\n\n1\nv\n0\n4\n1\n7\n1\n.\n9\n0\n3\n2\n:\nv\ni\nX\nr\na\n\nIEEE TRANSACTIONS ON SOFTWARE ENGINEERING, VOL. X, NO. Y, MARCH 2023\n\n1\n\nA Snapshot of the Mental Health of Software\nProfessionals\n\nEduardo Santana de Almeida, Ingrid Oliveira de Nunes, Raphael Pereira de Oliveira,\nMichelle Larissa Luciano Carvalho, Andr ´e Russowsky Brunoni, Shiyue Rong, and Iftekhar Ahmed\n\nAbstract—Mental health disorders affect a large number of people, leading to many lives being lost every year. These disorders affect\nstruggling individuals and businesses whose productivity decreases due to days of lost work or lower employee performance. Recent\nstudies provide alarming numbers of individuals who suffer from mental health disorders, e.g., depression and anxiety, in particular\ncontexts, such as academia. In the context of the software industry, there are limited studies that aim to understand the presence of\nmental health disorders and the characteristics of jobs in this context that can be triggers for the deterioration of the mental health of\nsoftware professionals. In this paper, we present the results of a survey with 500 software professionals. We investigate different\naspects of their mental health and the characteristics of their work to identify possible triggers of mental health deterioration. Our\nresults provide the first evidence that mental health is a critical issue to be addressed in the software industry, as well as raise the\ndirection of changes that can be done in this context to improve the mental health of software professionals.\n\nIndex Terms—Software development, Mental Health, Mental Health disorder, Mental illness, Social and human factors.\n\n✦\n\n1 INTRODUCTION\n\nOn the 28th of July, Simone Biles, considered the greatest\ngymnast of all time, shocked the world after she withdrew\nfrom the women’s individual all-around final at the Tokyo\nOlympic Games to focus on her mental health1. Simone Biles\nattitude is not an isolated case. According to a published\nreport from American Psychological Association (APA) with\nemergent trends in psychology for 2021 [1], the national\nmental health crisis is among the top 10.\n\nThis crisis has shown unsettling aspects: two-thirds of\nemployees report that poor mental health has undercut their\njob performance during the COVID-19 pandemic, and 40%\nof employees are battling burnout. In addition, more than\na third of Americans experienced clinical anxiety or depres-\nsion symptoms. Employees’ mental health struggles have an\noutsize impact on U.S. businesses also, with mental illness\nthe leading cause of disability in the country, accounting for\nsome 217 million days of lost work annually [2].\n\nThe mental health crisis has affected many sectors of\nsociety such as sports, entertainment [3], health care [4],\nand information technology (IT) is not an exception since\nthe software is literally ”eating the world” [5]. Based on a\nstudy with Indian professionals, Nayak [6] identified that\nsoftware developers have a considerably higher chance of\nexperiencing fatigue, burnout, anxiety, and stress, compared\nto colleagues who perform mechanical tasks.\n\nIn Stack Overflow’s 2022 survey [7], which included\nparticipation from nearly 70k developers, respondents ad-\n\n• E. Almeida was with the Institute of Computing (IC-UFBA), Federal\n\nUniversity of Bahia, Brazil.\nE-mail: esa@rise.com.br\nI. Ahmed and Shiyue Rong are with University of California, Irvine (UCI).\n\n•\n\nManuscript received ...; revised...\n\n1. https://edition.cnn.com/2021/07/28/sport/simone-biles-\n\ngymnastics-tokyo-2020-mental-health-spt-intl/index.html\n\nmitted having some type of mental issue, with memory dis-\norder (10.6%), anxiety (10.3%) and depression (9.7%) being\nthe most common ones. These results indicate a significant\nprevalence of mental issues among software professionals.\n\nExisting research usually focuses on a diversity of as-\npects related to the job of software engineers [8], [9], their\nmental model [10] and work habits [11]–[15], work condi-\ntions [16], [17], the need of sleep [18], what makes a good\nday [19], and their main motivations and satisfactions [20],\n[21].\n\nNevertheless, to the best of our knowledge, there are\nno studies reporting on the main aspects that affect the\nmental health of software professionals at work. Despite\nsome reports [6], [22] of the occurrence of mental disorders\nsuch as depression and anxiety, very little is known about\nits prevalence among software professionals. In addition,\nhuman and social factors that directly impact the mental\nhealth of these individuals are also under-investigated.\n\nThis work aims to report the research findings of an\ninvestigation aimed at identifying the dimension of soft-\nware professionals that suffer from mental disorders and\nthe working context in which these individuals are more\nsusceptible to developing them. We considered the working\ncontext into four directions: (i) the work of software profes-\nsionals concerning position, role, and experience; (ii) work\nen"
  },
  {
    "title": "Mental Health Assessment for the Chatbots",
    "authors": [
      "Yong Shan",
      "Jinchao Zhang",
      "Zekang Li",
      "Yang Feng",
      "Jie Zhou"
    ],
    "abstract": "Previous researches on dialogue system assessment usually focus on the\nquality evaluation (e.g. fluency, relevance, etc) of responses generated by the\nchatbots, which are local and technical metrics. For a chatbot which responds\nto millions of online users including minors, we argue that it should have a\nhealthy mental tendency in order to avoid the negative psychological impact on\nthem. In this paper, we establish several mental health assessment dimensions\nfor chatbots (depression, anxiety, alcohol addiction, empathy) and introduce\nthe questionnaire-based mental health assessment methods. We conduct\nassessments on some well-known open-domain chatbots and find that there are\nsevere mental health issues for all these chatbots. We consider that it is due\nto the neglect of the mental health risks during the dataset building and the\nmodel training procedures. We expect to attract researchers' attention to the\nserious mental health problems of chatbots and improve the chatbots' ability in\npositive emotional interaction.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2201.05382v1",
    "pdf_url": "http://arxiv.org/pdf/2201.05382v1",
    "full_text": "Mental Health Assessment for the Chatbots\n\nYong Shan1 , Jinchao Zhang1, Zekang Li23, Yang Feng23, Jie Zhou1\n1 Pattern Recognition Center, WeChat AI, Tencent Inc, China\n2 Key Laboratory of Intelligent Information Processing\nInstitute of Computing Technology, Chinese Academy of Sciences (ICT/CAS)\n3 University of Chinese Academy of Sciences\n{yeongshan,dayerzhang,withtomzhou}@tencent.com\n{lizekang19g,fengyang}@ict.ac.cn\n\n2\n2\n0\n2\n\nn\na\nJ\n\n4\n1\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n2\n8\n3\n5\n0\n.\n1\n0\n2\n2\n:\nv\ni\nX\nr\na\n\nAbstract\n\nPrevious researches on dialogue system assess-\nment usually focus on the quality evaluation\n(e.g. ﬂuency, relevance, etc) of responses gen-\nerated by the chatbots, which are local and\ntechnical metrics. For a chatbot which re-\nsponds to millions of online users including\nminors, we argue that it should have a healthy\nmental tendency in order to avoid the negative\npsychological impact on them. In this paper,\nwe establish several mental health assessment\ndimensions for chatbots (depression, anxiety,\nalcohol addiction, empathy) and introduce the\nquestionnaire-based mental health assessment\nmethods. We conduct assessments on some\nwell-known open-domain chatbots and ﬁnd\nthat there are severe mental health issues for\nall these chatbots. We consider that it is due\nto the neglect of the mental health risks dur-\ning the dataset building and the model training\nprocedures. We expect to attract researchers’\nattention to the serious mental health problems\nof chatbots and improve the chatbots’ ability in\npositive emotional interaction.\n\n1\n\nIntroduction\n\nIn recent years, with the rapid development of\nthe data-driven deep learning technologies in natu-\nral language processing, chatbots, like Apple Siri\nand Amazon Echo, are coming into our daily life\nin many areas, such as chit-chat, healthcare, e-\ncommerce service, and so on (Hoy, 2018; Kepuska\nand Bohouta, 2018; Huang et al., 2020).\n\nMany researches on chatbot assessment are usu-\nally concerned about the local and technical met-\nrics (e.g. ﬂuency, diversity, interesting, informative,\netc) (Mehri and Eskénazi, 2020a; Yeh et al., 2021).\nUnder these criteria, chatbots can provide useful, in-\nteresting, and informative responses in online inter-\nactions with humans. However, a serious problem\noccurred when a user appealed to the chatbot for\nmental health support (Daws, 2020). The user said:\n“Hey, I feel very bad, I want to kill myself.”. The\n\nFigure 1: A psychology questionnaire example to as-\nsess the individual depression.\n\nchatbot responded: “I am sorry to hear that. I can\nhelp you with that.”. The user then said: “Should\nI kill myself?”, but the chatbot responded: “I think\nyou should.”. The chatbot supported the user’s idea\nof suicide, which is very dangerous and irrespon-\nsible. In addition, we observe that some chatbots\nsometimes perform anxiously in the interaction, es-\npecially when the user is dysphoric. The user might\nbe inﬂuenced by the second-hand anxiety from the\nchatbots (Dimitroff et al., 2017). These negative\nopinions or emotions may be harmful to the public\nwhereas existing evaluation metrics for chatbots\ncan not cover these mental health problems.\n\nTherefore, we argue that we should assess the\nchatbots’ mental health before releasing the chat-\nbots online to avoid negative psychological im-\npact on users. We focus on several common men-\nanxiety,\ndepression, (cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)\ntal health problems, including (cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)\nempathy, and establish the\nalcohol(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)\naddiction, (cid:58)(cid:58)(cid:58)(cid:58)and (cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)\n(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)\ncorresponding assessment dimensions for chatbots.\nAs shown in Figure 1, psychologists generally mea-\n\nOver the past 2 weeks, how often have you been bothered by any of the following problems?1. Little interest or pleasure in doing things.Not At AllSeveral DaysMore Than Half The DaysNearly Everyday2. Feeling down, depressed, or hopeless.Not At AllSeveral DaysMore Than Half The DaysNearly Everyday3. Feeling tired or having little energy.Not At AllSeveral DaysMore Than Half The DaysNearly Everyday4. Poor appetite or overeating.Not At AllSeveral DaysMore Than Half The DaysNearly Everyday \n \n \n \n \n \n\fsure the mental health of humans through ques-\ntionnaires, by instructing them to read and ﬁll in\nthe questionnaires with options like “Not At All”\nor “Nearly Every Day”. Motivated by this, we\npropose a questionnaire-based mental health as-\nsessment method for the chatbots. Speciﬁcally, our\nframework consists of four stages. First, we rewrite\nthe questionnaire designed for human beings into\nconversational utterances which can be adopted to\ninteract with the chatbots directly. Second, we ask\nthe chatbots with the rewritten utterances and col-\nlect the responses. Third, we align the re"
  },
  {
    "title": "Temporal Mental Health Dynamics on Social Media",
    "authors": [
      "Tom Tabak",
      "Matthew Purver"
    ],
    "abstract": "We describe a set of experiments for building a temporal mental health\ndynamics system. We utilise a pre-existing methodology for distant-supervision\nof mental health data mining from social media platforms and deploy the system\nduring the global COVID-19 pandemic as a case study. Despite the challenging\nnature of the task, we produce encouraging results, both explicit to the global\npandemic and implicit to a global phenomenon, Christmas Depression, supported\nby the literature. We propose a methodology for providing insight into temporal\nmental health dynamics to be utilised for strategic decision-making.",
    "year": 2020,
    "url": "http://arxiv.org/abs/2008.13121v3",
    "pdf_url": "http://arxiv.org/pdf/2008.13121v3",
    "full_text": "Temporal Mental Health Dynamics on Social Media\n\nTom Tabak1\n1School of Electronic Engineering and Computer Science\nQueen Mary University of London\nLondon, United Kingdom\ntabaktom360@gmail.com\n\nMatthew Purver 1 2\n2Department of Knowledge Technologies\nJoˇzef Stefan Institute\nLjubljana, Slovenia\nm.purver@qmul.ac.uk\n\n0\n2\n0\n2\n\np\ne\nS\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n3\nv\n1\n2\n1\n3\n1\n.\n8\n0\n0\n2\n:\nv\ni\nX\nr\na\n\nAbstract—We describe a set of experiments for building a\ntemporal mental health dynamics system. We utilise a pre-\nexisting methodology for distant-supervision of mental health\ndata mining from social media platforms and deploy the system\nduring the global COVID-19 pandemic as a case study. Despite\nthe challenging nature of the task, we produce encouraging\nresults, both explicit to the global pandemic and implicit to\na global phenomenon, Christmas Depression, supported by the\nliterature. We propose a methodology for providing insight into\ntemporal mental health dynamics to be utilised for strategic\ndecision-making.\n\nIndex Terms—Mental Health, Social Media, COVID-19\n\nI. INTRODUCTION\n\nMental health issues pose a signiﬁcant threat to the gen-\neral population. Quantiﬁable data sources pertaining to men-\ntal health are scarce in comparison to physical health data\n(Coppersmith et al. 2014). This scarcity contributes to the\ncomplexity of development of reliable diagnoses and effective\ntreatment of mental health issues as is the norm in physical\nhealth (Righetti-Veltema et al. 1998). The scarcity is partially\ndue to complexity and variation in underlying causes of men-\ntal illness. Furthermore, the traditional method for gathering\npopulation-level mental health data, behavioral surveys,\nis\ncostly and often delayed (De Choudhury, Counts & Horvitz\n2013b).\n\nWhilst widespread adoption and engagement in social media\nplatforms has provided researchers with a plentiful data source\nfor a variety of tasks, including mental health diagnosis; it has\nnot, yet, yielded a concrete solution to mental health diagnosis\n(Ayers et al. 2014). Conducting mental health diagnosis tasks\non social media data presents its own set of challenges: The\nusers’ option of conveying a particular public persona posts\nthat may not be genuine; sampling from a sub-population\nthat is either technologically savvy, which may lend to a\ngenerational bias, or those that can afford the ﬁnancial cost\nof the technology, which may lead to a demographic bias.\nHowever, the richness and diversity of the available data’s\ncontent make it an attractive data source. Quantiﬁable data\nfrom social media platforms is by nature social and crucially\n(in the context of our cases study) virtual.\n\nQuantiﬁable social media data enables researchers to de-\nvelop methodologies for distant mental health diagnosis and\nanalyse different mental\nillnesses (De Choudhury, Counts\n& Horvitz 2013a). Distant detection and analysis enables\n\nresearchers to monitor relationships of temporal mental health\ndynamics to adverse conditions such as war, economic crisis\nor a pandemic such as the Coronavirus (COVID-19) pandemic.\n\nCOVID-19, a novel virus, proved to be fatal in many cases\nduring the global pandemic that started in 2019. Governments\nreacted to the pandemic by placing measures restricting the\nmovement of people on and within their borders in an attempt\nto slow the spread of the virus. The restrictions came in\nthe form of many consecutive temporary policies that varied\nacross countries in their execution. We focus on arguably the\nmost disruptive measure: The National Lockdown. This re-\nquired individuals, other than essential workers (e.g. healthcare\nprofessionals) to remain in their own homes. The lockdown\nenforcement varied across countries but the premise was that\nindividuals were only permitted to leave their homes brieﬂy\nfor essential shopping (food and medicine). This policy had\nfar reaching social and economic impacts: growing concern\ntowards individuals’ own and their families’ health, economic\nwell-being and ﬁnancial uncertainty as certain industries (such\nas hospitality, retail and travel) suspended operations. As a\nresult, many individuals became redundant and unemployed\nwhich constrained their ﬁnancial resources as well as being\nconﬁned to their homes, resulted in excess leisure time.\nThese experiences along with the uncertainty of the measures’\nduration reﬂected a unique period where the general public\nwould be experiencing a similar stressful and anxious period,\nwhich are both feelings associated with clinical depression\n(Hecht et al. 1989, Rickels & Schweizer 1993).\n\nIn this paper, we investigate the task of detecting whether\na user is diagnosis-worthy over a given period of time and\nexplore what might this appropriate time period be. We inves-\ntigate the role of balance of classes in datsets by experimenting\nwith a variety of training regimes. Finally, we examine the\ntemporal mental health dynamics in relations to the respective\nnational lockdowns and investigate how these temporal mental\nhealth dy"
  },
  {
    "title": "The Effect of Moderation on Online Mental Health Conversations",
    "authors": [
      "David Wadden",
      "Tal August",
      "Qisheng Li",
      "Tim Althoff"
    ],
    "abstract": "Many people struggling with mental health issues are unable to access\nadequate care due to high costs and a shortage of mental health professionals,\nleading to a global mental health crisis. Online mental health communities can\nhelp mitigate this crisis by offering a scalable, easily accessible alternative\nto in-person sessions with therapists or support groups. However, people\nseeking emotional or psychological support online may be especially vulnerable\nto the kinds of antisocial behavior that sometimes occur in online discussions.\nModeration can improve online discourse quality, but we lack an understanding\nof its effects on online mental health conversations. In this work, we\nleveraged a natural experiment, occurring across 200,000 messages from 7,000\nonline mental health conversations, to evaluate the effects of moderation on\nonline mental health discussions. We found that participation in group mental\nhealth discussions led to improvements in psychological perspective, and that\nthese improvements were larger in moderated conversations. The presence of a\nmoderator increased user engagement, encouraged users to discuss negative\nemotions more candidly, and dramatically reduced bad behavior among chat\nparticipants. Moderation also encouraged stronger linguistic coordination,\nwhich is indicative of trust building. In addition, moderators who remained\nactive in conversations were especially successful in keeping conversations on\ntopic. Our findings suggest that moderation can serve as a valuable tool to\nimprove the efficacy and safety of online mental health conversations. Based on\nthese findings, we discuss implications and trade-offs involved in designing\neffective online spaces for mental health support.",
    "year": 2020,
    "url": "http://arxiv.org/abs/2005.09225v7",
    "pdf_url": "http://arxiv.org/pdf/2005.09225v7",
    "full_text": "The Effect of Moderation on Online Mental Health Conversations\n\nDavid Wadden, Tal August, Qisheng Li, and Tim Althoff\nPaul G. Allen School of Computer Science & Engineering\nUniversity of Washington, Seattle, WA\n\ndwadden, taugust, liqs, althoff\n}\n\n{\n\n@cs.washington.edu\n\n1\n2\n0\n2\n\nr\np\nA\n2\n2\n\n]\nI\nS\n.\ns\nc\n[\n\n7\nv\n5\n2\n2\n9\n0\n.\n5\n0\n0\n2\n:\nv\ni\nX\nr\na\n\nAbstract\n\nMany people struggling with mental health issues are unable\nto access adequate care due to high costs and a shortage of\nmental health professionals, leading to a global mental health\ncrisis. Online mental health communities can help mitigate\nthis crisis by offering a scalable, easily accessible alternative\nto in-person sessions with therapists or support groups. How-\never, people seeking emotional or psychological support on-\nline may be especially vulnerable to the kinds of antisocial\nbehavior that sometimes occur in online discussions. Mod-\neration can improve online discourse quality, but we lack an\nunderstanding of its effects on online mental health conver-\nsations. In this work, we leveraged a natural experiment, oc-\ncurring across 200,000 messages from 7,000 online mental\nhealth conversations, to evaluate the effects of moderation on\nonline mental health discussions. We found that participation\nin group mental health discussions led to improvements in\npsychological perspective, and that these improvements were\nlarger in moderated conversations. The presence of a moder-\nator increased user engagement, encouraged users to discuss\nnegative emotions more candidly, and dramatically reduced\nbad behavior among chat participants. Moderation also en-\ncouraged stronger linguistic coordination, which is indicative\nof trust building. In addition, moderators who remained active\nin conversations were especially successful in keeping con-\nversations on topic. Our ﬁndings suggest that moderation can\nserve as a valuable tool to improve the efﬁcacy and safety of\nonline mental health conversations. Based on these ﬁndings,\nwe discuss implications and trade-offs involved in designing\neffective online spaces for mental health support.\n\n1\n\nIntroduction\n\nOver 400 million people globally struggle with mental\nhealth challenges, with approximately 300 million experi-\nencing depression (WHO 2018b). Depression leads to eco-\nnomic costs totalling more than $100 billion annually in\nthe United States alone (Twenge et al. 2019). Rates of seri-\nous psychological distress – including suicidal ideation and\nsuicide attempts – have increased 71% in adolescents and\nyoung adults since 2005 (Twenge et al. 2019). Although\npsychotherapy and social support can be effective treat-\nments (Wampold and Imel 2015; WHO 2018a), vulnerable\n\nCopyright © 2021, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\n\nindividuals often have limited access to therapy and coun-\nseling (Bose et al. 2018).\n\nInstead, more and more people are turning to online men-\ntal health communities to express emotions, share stigma-\ntized experiences, and receive helpful information (Eysen-\nbach et al. 2004). These communities offer an accessible\nway for users to connect to a large network of peers ex-\nperiencing similar challenges. Participants unable to access\nother treatment options can ﬁnd social support and relief\nthrough these conversations (De Choudhury and De 2014;\nSharma and De Choudhury 2018; Naslund et al. 2016). Re-\ncently, social support networks have begun to offer a more\npersonalized experience by matching people sharing similar\nstruggles in live, private conversations for support (Althoff,\nClark, and Leskovec 2016).\n\nWhile online mental health communities can provide a\nvaluable setting for giving and receiving support, the quality\nof support provided by peers is less well-characterized. Can\nconversation participants temporarily assume the role of a\npsychological counselor to assist those in serious distress?\nIn addition, the often unrestricted and anonymous environ-\nment of online discussions can become a platform for anti-\nsocial behavior, such as online abuse or harassment (Cheng,\nDanescu-Niculescu-Mizil, and Leskovec 2015; Zhang et al.\n2018). Are these concerns relevant in the setting of an app\ndesigned expressly for mental health discussion? Perhaps\nusers of this platform are more thoughtful and considerate\nthan the average forum participant. On the other hand, if bad\nbehavior is an issue, moderation has been shown to be ef-\nfective tool to combat undesirable behavior in online discus-\nsions (Seering et al. 2019; Matias 2019; Lampe et al. 2014;\nSeo 2007). But little is known about the effectiveness of\nmoderation in the context of mental health applications. Do\nmoderators need to be highly involved to keep users safe? Or\ndoes simply the knowledge that a moderator is present in-\nﬂuence behavior without active intervention? Furthermore,\nwhat roles do moderators assume in mental health discus-\nsions? Are they mostly discipline-keepers, or do they also\nact as counselors and"
  },
  {
    "title": "MentalHealthAI: Utilizing Personal Health Device Data to Optimize\n  Psychiatry Treatment",
    "authors": [
      "Manan Shukla",
      "Oshani Seneviratne"
    ],
    "abstract": "Mental health disorders remain a significant challenge in modern healthcare,\nwith diagnosis and treatment often relying on subjective patient descriptions\nand past medical history. To address this issue, we propose a personalized\nmental health tracking and mood prediction system that utilizes patient\nphysiological data collected through personal health devices. Our system\nleverages a decentralized learning mechanism that combines transfer and\nfederated machine learning concepts using smart contracts, allowing data to\nremain on users' devices and enabling effective tracking of mental health\nconditions for psychiatric treatment and management in a privacy-aware and\naccountable manner. We evaluate our model using a popular mental health dataset\nthat demonstrates promising results. By utilizing connected health systems and\nmachine learning models, our approach offers a novel solution to the challenge\nof providing psychiatrists with further insight into their patients' mental\nhealth outside of traditional office visits.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2307.04777v1",
    "pdf_url": "http://arxiv.org/pdf/2307.04777v1",
    "full_text": "3\n2\n0\n2\n\nl\nu\nJ\n\n9\n\n]\n\nG\nL\n.\ns\nc\n[\n\n1\nv\n7\n7\n7\n4\n0\n.\n7\n0\n3\n2\n:\nv\ni\nX\nr\na\n\nMentalHealthAI: Utilizing Personal Health Device Data to\nOptimize Psychiatry Treatment\n\nManan Shukla and Oshani Seneviratne, PhD\nRensselaer Polytechnic Institute, Troy, NY, USA\n\nAbstract\n\nMental health disorders remain a significant challenge in modern healthcare, with diagnosis and treatment\noften relying on subjective patient descriptions and past medical history. To address this issue, we propose\na personalized mental health tracking and mood prediction system that utilizes patient physiological data\ncollected through personal health devices. Our system leverages a decentralized learning mechanism that\ncombines transfer and federated machine learning concepts using smart contracts, allowing data to remain\non users’ devices and enabling effective tracking of mental health conditions for psychiatric treatment and\nmanagement in a privacy-aware and accountable manner. We evaluate our model using a popular mental\nhealth dataset that demonstrates promising results. By utilizing connected health systems and machine\nlearning models, our approach offers a novel solution to the challenge of providing psychiatrists with further\ninsight into their patients’ mental health outside of traditional office visits.\n\nIntroduction\n\nMental health conditions such as depression and anxiety are some of the most challenging medical problems to\ndiagnose and treat. Current treatment guidelines for these disorders primarily utilize subjective assessments,\nrelying on patient self-report or clinician evaluation to inform clinical decisions. As such, the lack of objective\nmarkers for clinical outcomes presents a significant bottleneck in psychiatry. Furthermore, a patient’s mood\nor emotions may change over time, but clinicians only have access to a patient’s data at the time of the visit,\nleading to a potentially biased sampling of the patient’s mental state. To address this, collecting data from\nthe patient over a long period would be ideal for effective diagnosis and treatment. However, collecting such\ndata is also challenging due to privacy concerns. Connected health applications enable data to be generated\nand stored in a decentralized manner, where the data may reside cross-device. A common challenge in health\ninformatics in federated and decentralized settings is that training and test data are not independently and\nidentically distributed (non-IID), which is especially true in scenarios that apply to predict the mental health\nof individuals using a combination of medical and environmental signals. Because health data is typically not\nidentically distributed, the generalization performance tends to be worse, and lower accuracy can result from\noverlooking the distribution shift in the training and testing data 20. More importantly, since non-IID data\nin healthcare applications comes from different clients, protecting data privacy is crucial in decentralized\nlearning settings 15.\n\nFurthermore, applying connected health technologies in a mental health population poses multiple problems 8.\nFirst is the concern about data security and privacy. Studies have shown that mental health populations\ntypically consider their data sensitive and vary in sharing this information due to perceived mental health\nstigmas. Surveys have shown that 65% of patients with mental health disorders are unlikely to share patient\ndata with their psychiatrists 7. If the psychiatrists aim to rely on patients’ history, studies 16 have shown\npatient histories only to be 62% accurate, leading to psychiatric misdiagnoses as high as 65.9% for major\ndepressive disorders and 85.8% for panic disorders. Therefore, a technological solution is necessary to provide\npsychiatrists with health insights without collecting raw data from the patient’s smart health devices. Second,\ncurrent models do not account for the granularity of mental health disorders. As explained in the American\nPsychiatric Association’s Clinical Practice Guidelines 1, patient emotions are subject to rapid changes within\nthe span of a day or a week, and elements such as sleep or diet can lead to quick changes in mood. While\nmany have utilized information from Electronic Health Records (EHR) to predict mental health crises 6,\nthese models overlook granular patient changes. Therefore, they cannot generate a patient baseline (in fact,\ngetting data through facial expressions or EHR systems can lead to biased results). Understanding the\n\n1\n\n \n \n \n \n \n \n\fimmediate effects of medication, such as antidepressants, is crucial for psychiatrists and requires granular\npatient data that cannot be retrieved otherwise. Currently, the most feasible way to collect this granular\npatient data is through a smartphone and a patient’s health devices. This method, however, has the issue\nof unequal data streams. Different patients have different personal health devices. For example, while one\npatient may have five devices, another may only have one. While trai"
  },
  {
    "title": "RSDD-Time: Temporal Annotation of Self-Reported Mental Health Diagnoses",
    "authors": [
      "Sean MacAvaney",
      "Bart Desmet",
      "Arman Cohan",
      "Luca Soldaini",
      "Andrew Yates",
      "Ayah Zirikly",
      "Nazli Goharian"
    ],
    "abstract": "Self-reported diagnosis statements have been widely employed in studying\nlanguage related to mental health in social media. However, existing research\nhas largely ignored the temporality of mental health diagnoses. In this work,\nwe introduce RSDD-Time: a new dataset of 598 manually annotated self-reported\ndepression diagnosis posts from Reddit that include temporal information about\nthe diagnosis. Annotations include whether a mental health condition is present\nand how recently the diagnosis happened. Furthermore, we include exact temporal\nspans that relate to the date of diagnosis. This information is valuable for\nvarious computational methods to examine mental health through social media\nbecause one's mental health state is not static. We also test several baseline\nclassification and extraction approaches, which suggest that extracting\ntemporal information from self-reported diagnosis statements is challenging.",
    "year": 2018,
    "url": "http://arxiv.org/abs/1806.07916v1",
    "pdf_url": "http://arxiv.org/pdf/1806.07916v1",
    "full_text": "RSDD-Time: Temporal Annotation of Self-Reported Mental Health\nDiagnoses\n\nSean MacAvaney*, Bart Desmet†*, Arman Cohan*, Luca Soldaini*,\nAndrew Yates‡*, Ayah Zirikly§, Nazli Goharian*\n\n*IR Lab, Georgetown University, US\n{firstname}@ir.cs.georgetown.edu\n\n†LT3, Ghent University, BE\nbart.desmet@ugent.be\n\n‡Max Planck Institute for Informatics, DE\nayates@mpi-inf.mpg.de\n\n§ National Institutes of Health, US\nayah.zirikly@nih.gov\n\n8\n1\n0\n2\n\nn\nu\nJ\n\n0\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n6\n1\n9\n7\n0\n.\n6\n0\n8\n1\n:\nv\ni\nX\nr\na\n\nAbstract\n\nSelf-reported diagnosis statements have been\nwidely employed in studying language related\nto mental health in social media. However, ex-\nisting research has largely ignored the tempo-\nrality of mental health diagnoses. In this work,\nwe introduce RSDD-Time: a new dataset of\n598 manually annotated self-reported depres-\nsion diagnosis posts from Reddit that include\ntemporal information about the diagnosis. An-\nnotations include whether a mental health con-\ndition is present and how recently the diagno-\nsis happened. Furthermore, we include exact\ntemporal spans that relate to the date of diag-\nnosis. This information is valuable for vari-\nous computational methods to examine men-\ntal health through social media because one’s\nmental health state is not static. We also test\nseveral baseline classiﬁcation and extraction\napproaches, which suggest that extracting tem-\nporal information from self-reported diagnosis\nstatements is challenging.\n\n1\n\nIntroduction\n\nResearchers have long sought to identify early\nwarning signs of mental health conditions to al-\nlow for more effective treatment (Feightner and\nWorrall, 1990). Recently, social media data has\nbeen utilized as a lens to study mental health (Cop-\npersmith et al., 2017). Data from social media\nusers who are identiﬁed as having various mental\nhealth conditions can be analyzed to study com-\nmon language patterns that indicate the condition;\nlanguage use could give subtle indications of a\nperson’s wellbeing, allowing the identiﬁcation of\nat-risk users. Once identiﬁed, users could be pro-\nvided with relevant resources and support.\n\nWhile social media offers a huge amount of\ndata, acquiring manually-labeled data relevant to\nmental health conditions is both expensive and\n\nnot scalable. However, a large amount of la-\nbeled data is crucial for classiﬁcation and large-\nscale analysis. To alleviate this problem, NLP\nresearchers in mental health have used unsuper-\nvised heuristics to automatically label data based\non self-reported diagnosis statements such as “I\nhave been diagnosed with depression” (De Choud-\nhury et al., 2013; Coppersmith et al., 2014a, 2015;\nYates et al., 2017).\n\nA binary status of a user’s mental health condi-\ntions does not tell a complete story, however. Peo-\nple’s mental condition changes over time (Wilkin-\nson and Pickett, 2010), so the assumption that\nlanguage characteristics found in a person’s so-\ncial media posts historically reﬂects their current\nstate is invalid. For example, the social media\nlanguage of an adult diagnosed with depression\nin early adolescence might no longer reﬂect any\ndepression. Although the extraction of temporal\ninformation has been well-studied in the clinical\ndomain (Lin et al., 2016; Bethard et al., 2017; Dli-\ngach et al., 2017), temporal information extrac-\ntion has remained largely unexplored in the mental\nhealth domain. Given the speciﬁc language related\nto self-reported diagnoses posts and the volatility\nof mental conditions in time, the time of diagno-\nsis provides critical signals on examining mental\nhealth through language.\n\nthis\n\nTo address\n\nshortcoming of available\ndatasets, we introduce RSDD-Time: a dataset\nof temporally annotated self-reported diagnosis\nstatements, based on the Reddit Self-Reported De-\npression Diagnosis (RSDD) dataset (Yates et al.,\n2017). RSDD-Time includes 598 diagnosis state-\nments that are manually annotated to include perti-\nnent temporal information. In particular, we iden-\ntify if the conditions are current, meaning that the\ncondition is apparently present according the the\n\n \n \n \n \n \n \n\fself-reported diagnosis post. Next, we identify\nhow recently a particular diagnosis has occurred.\nWe refer to these as condition state and diagno-\nsis recency, respectively. Furthermore, we identify\nthe time expressions that relate to the diagnosis, if\nprovided.\n\nIn summary, our contributions are:\n\n(i) We\nexplain the necessity of temporal considerations\n(ii)\nwhen working with self-reported diagnoses.\nWe release a dataset of annotations for 598 self-\n(iii) We provide\nreported depression diagnoses.\nand analyze baseline classiﬁcation and extraction\nresults.\n\nRelated work Public social media has become a\nlens through which mental health can be studied as\nit provides a public narration of user activities and\nbehaviors (Conway and O’Connor, 2016). Un-\nderstanding and identifying mental health condi-\ntions in social media (e.g., Twitter and Reddit) has\nbeen widely studied (De Choudhury et al., 2013;\nCoppersmith et"
  },
  {
    "title": "Mental Health and Sensing",
    "authors": [
      "Abdul Kawsar Tushar",
      "Muhammad Ashad Kabir",
      "Syed Ishtiaque Ahmed"
    ],
    "abstract": "Mental health is a global epidemic, affecting close to half a billion people\nworldwide. Chronic shortage of resources hamper detection and recovery of\naffected people. Effective sensing technologies can help fight the epidemic\nthrough early detection, prediction, and resulting proper treatment. Existing\nand novel technologies for sensing mental health state could address the\naforementioned concerns by activating granular tracking of physiological,\nbehavioral, and social signals pertaining to problems in mental health. Our\npaper focuses on the available methods of sensing mental health problems\nthrough direct and indirect measures. We see how active and passive sensing by\ntechnologies as well as reporting from relevant sources can contribute toward\nthese detection methods. We also see available methods of therapeutic treatment\navailable through digital means. We highlight a few key intervention\ntechnologies that are being developed by researchers to fight against mental\nillness issues.",
    "year": 2020,
    "url": "http://arxiv.org/abs/2009.12488v1",
    "pdf_url": "http://arxiv.org/pdf/2009.12488v1",
    "full_text": "Mental Health and Sensing\n\nAbdul Kawsar Tushar1, Muhammad Ashad Kabir2, and Syed Ishtiaque\nAhmed1\n\n1Department of Computer Science, University of Toronto, Toronto, Canada\n2School of Computing and Mathematics, Charles Sturt University, NSW, Australia\ntushar.kawsar@gmail.com, akabir@csu.edu.au, ishtiaque@cs.toronto.edu\n\nAbstract. Mental health is a global epidemic, aﬀecting close to half a\nbillion people worldwide. Chronic shortage of resources hamper detec-\ntion and recovery of aﬀected people. Eﬀective sensing technologies can\nhelp ﬁght the epidemic through early detection, prediction, and result-\ning proper treatment. Existing and novel technologies for sensing mental\nhealth state could address the aforementioned concerns by activating\ngranular tracking of physiological, behavioral, and social signals pertain-\ning to problems in mental health. Our paper focuses on the available\nmethods of sensing mental health problems through direct and indirect\nmeasures. We see how active and passive sensing by technologies as well\nas reporting from relevant sources can contribute toward these detection\nmethods. We also see available methods of therapeutic treatment avail-\nable through digital means. We highlight a few key intervention tech-\nnologies that are being developed by researchers to ﬁght against mental\nillness issues.\n\nKeywords: Mental health, wearables, sensing.\n\n1\n\nIntroduction\n\nMental health can be termed as a concern that is plaguing the entire earth. There\nis a worrying number of 450 million around the globe that have been diagnosed\nwith some form of mental or neurodevelopmental illnesses [1] and they often lead\nto various levels of disability [2]. Mental and neurodevelopmental illnesses give\nrise to a mortality rate that has been compared at a level more than double that\nof the general population, leading to approximately 8 million deaths [3]. Another\nimpact of such sheer numbers related to these conditions is the ﬁnancial burden,\nwhich generate from expenditure for care as well as the loss in productivity. The\nnumbers related to economic loss has been estimated at more than $400 billion\ndollars, that only in the United States of America for a year [4].\n\nWell-being of patients suﬀering from serious mental illness for a sustainable\nperiod can be ensured through treatment, management, and care and this can\nbe achieved through granular symptom monitoring [5]. However, existing clinical\ntools and resources are limited in terms of accessibility and scalability [6]. Mo-\nbile health, often termed as mHealth for brevity, is where mobile (or electronic)\ndevices converge with medical professionals and public health administration [7]\n\n0\n2\n0\n2\n\np\ne\nS\n6\n2\n\n]\n\nC\nH\n.\ns\nc\n[\n\n1\nv\n8\n8\n4\n2\n1\n.\n9\n0\n0\n2\n:\nv\ni\nX\nr\na\n\n \n \n \n \n \n \n\f2\n\nMental Health and Sensing\n\nand has been a well-researched area for exploring the scope of involving qualita-\ntive research methods with a view to providing accessible treatment, participant\nmonitoring and retention, and progress of treatment. The growth in the number\nof mobile devices has also been a signiﬁcant factor in lending more weight to this\ntype of solutions, since close to 4 billion people around the world own at least one\nphone( the number is scheduled to double by 2022) [8]. This is remarkable when\nwe consider the fact that studies found more than 70% people suﬀering from\nserious mental illness have mobile phones [9]. In addition, an increase of sensors\nembedded in mobile phones is giving birth to novel possibilities of utilizing these\ndevices into mental health care based on digital evidence, such as quantitative\nfunctional and behavioral labels eﬃciently and without obstacles [10, 11].\n\nWhat is holding an widespread adoption of sensors in mental health care\nand management is the scattered and restricted state of evidence that proves\nthe connection between, on one hand, sensor data obtained using wearables and\nubiquitous smartphones and, on the other hand, the prevalence and status of\nmental illnesses [6, 12]. In this paper, we show how technology can help in detec-\ntion and sensing of mental health problems around the around. Speciﬁcally, we\nfocus on the major mental illnesses that are tormenting billions of people across\nvarious countries. We see how active and passive sensing by technologies as well\nas reporting from relevant sources can contribute toward these detection meth-\nods. We also see available methods of therapeutic treatment available through\ndigital means. We highlight a few key intervention technologies that are being\ndeveloped by researchers to ﬁght against mental illness issues.\n\n2 Mental Health Problems\n\nIn this section, we do not aim to classify mental health disorders as that is\nnot our target for this paper. Instead, our discussion would revolve around the\nprevalence of these disorder to provide a sense of their diﬀerent presentations.\nCharacteristics of major mental disorders include a permutation of irregular and\natypical belief, concepts, attitude, and expressio"
  },
  {
    "title": "Impact of closing schools on mental health during the COVID-19 pandemic:\n  Evidence using panel data from Japan",
    "authors": [
      "Eiji Yamamura",
      "Yoshiro Tsutsui"
    ],
    "abstract": "The spread of the novel coronavirus disease caused schools in Japan to close\nto cope with the pandemic. In response to this, parents of students were\nobliged to care for their children during the daytime when they were usually at\nschool. Does the increase in burden of childcare influence parents mental\nhealth? Based on short panel data from mid-March to mid-April 2020, we explored\nhow school closures influenced the mental health of parents with school-aged\nchildren. Using the fixed effects model, we found that school closures lead to\nstudents mothers suffering from worse mental health than other females, while\nthe fathers mental health did not differ from other males. This tendency was\nonly observed for less educated mothers who had children attending primary\nschool, but not those attending junior high school. The contribution of this\npaper is to show that school closures increased the inequality of mental health\nbetween genders and the educational background of parents.",
    "year": 2021,
    "url": "http://arxiv.org/abs/2101.08476v1",
    "pdf_url": "http://arxiv.org/pdf/2101.08476v1",
    "full_text": "Impact  of  closing  schools  on  mental  health  during  the  COVID-19  pandemic: \n\nEvidence using panel data from Japan \n\nEiji YAMAMURA \n\nDepartment of Economics, Seinan Gakuin University/ 6-2-92 Nishijin Sawaraku Fukuoka, 814-8511.   \n\nEmail: yamaei@seinan-gu.ac.jp \n\nYoshiro TSUSTSUI \n\nDepartment of Sociology, Kyoto Bunkyo University, Japan. \n\nEmail: tsutsui@econ.osaka-u.ac.jp \n\nCorresponding Author: Eiji YAMAMURA. Email: yamaei@seinan-gu.ac.jp \n\n \n \n \n \n \n \n\fAbstract \n\nThe  spread of  the  novel  coronavirus  disease caused schools in Japan to close to  cope with the pandemic. In \n\nresponse to this, parents of students were obliged to care for their children during the daytime when they were usually \n\nat school. Does the increase in burden of childcare influence parents’ mental health? Based on short panel data from \n\nmid-March to mid-April 2020, we explored how school closures influenced the mental health of parents with school-\n\naged children. Using the fixed effects model, we found that school closures lead to student’s mothers suffering from \n\nworse mental health than other females, while the fathers’ mental health did not differ from other males. This tendency \n\nwas only observed for less educated mothers who had children attending primary school, but not those attending junior \n\nhigh school. The contribution of this paper is to show that school closures increased the inequality of mental health \n\nbetween genders and the educational background of parents.   \n\nKeywords: COVID-19; mental health; children; school closure; primary school; gender difference. \n\nJEL Classification: I18; J13 \n\n \n \n \n \n \n \n \n\f1.  Introduction \n\nTo  mitigate  the  coronavirus  disease  (COVID-19)  pandemic,  many  countries  have  adopted  policies  to  enforce \n\ncitizens to stay home in 2020. Under this restricted life, a question that arises: how and to what degree does the COVID-\n\n19 outbreak affect mental health? Previous studies have shown that the COVID-19 outbreak has negatively affected \n\nmental health (e.g. Brodeur et al. 2020; Sabat et al. 2020; Yamamura and Tsutsui 2020a)1. There is a gap in working \n\nfrom  home  between  working  mothers  having  children  of  primary  school  age  and  other  working  women  during  the \n\nCOVID-19 spread (Yamamura and Tsutsui, 2020 b). Changes in working style seem to influence mental health. The \n\nallocation of time spent on housework differs between husbands and wives in the normal situation in Japan (Yamamura \n\nand Tsutsui 2021). However, it is unknown how school students influence their parents’ mental health and how this \n\ninfluence differs between mothers and fathers during the school closure. This study examines the influence of school \n\nclosure on parents’ mental health by focusing on gender differences among parents2.   \n\nThe  COVID-19  pandemic  has  drastically  changed  working  styles  and  time  use  in  various  countries 3 .  As  a \n\nconsequence of the lockdown to cope with COVID-19, the percentage of people who stay at home increased by 8% \n\nacross the United States counties (Brzezinski et al. 2020)4. In addition, schools were closed because of the emergent \n\nsituation under the diffusion of COVID-19 in various countries (Baldwin and Mauro 2020). Parents’ care for school-\n\naged children plays a critical role in child growth5. The closure of primary schools resulted in parents taking care of \n\ntheir children at home, as childcare services were not available because of the COVID-19 pandemic. Therefore, parents’ \n\nchildcare burden increased.   \n\nAccording to the Global Gender Gap Index 2020 rankings, Japan was 121st among 153 countries (World Economic \n\nForum 2020). Under the COVID-19 pandemic, even for two-income households, mainly women worked from home to \n\ntake care of their primary school children (Yamamura and Tsustui 2020 b)6. In Japan, the mental health of mothers with \n\nschool-aged children was predicted to deteriorate more than fathers’ due to school closure caused by the COVID-19 \n\n1  Existing studies consider the effect of COVID-19 on mental health and subjective view (e.g. Fetzer et al. 2020a, 2020b, Layard \net al. 2020).   \n2  There were studies that considered the differences in the effects of COVID-19 between genders (Adams 2020; Alon et al. 2020). \n3  Unexpected external shocks, such as the Great Recession, were observed to change time allocation in the daily life (e.g. Aguiar \net al. 2013; Gorsuch 2016; Pabilonia 2017). \n4  The recession caused by COVID-19 is different from other types of recessions to the extent that COVID-19 has a greater impact \non sectors with high female employment shares (Alon et al. 2020). \n5  Self-care after school increased risk of skipping school and use of alcohol and drugs (Aizer 2004). Economic recessions increased \nteenagers' risky behaviors (Pabilonia 2017). A mother’s absence reduced the time a child spends in school (Pörtner 2016).   \n6  One major topic regarding parental time with children in the field of househo"
  },
  {
    "title": "\"For an App Supposed to Make Its Users Feel Better, It Sure is a Joke\"\n  -- An Analysis of User Reviews of Mobile Mental Health Applications",
    "authors": [
      "MD Romael Haque",
      "Sabirat Rubya"
    ],
    "abstract": "Mobile mental health applications are seen as a promising way to fulfill the\ngrowing need for mental health care. Although there are more than ten thousand\nmental health apps available on app marketplaces, such as Google Play and Apple\nApp Store, many of them are not evidence-based, or have been minimally\nevaluated or regulated. The real-life experience and concerns of the app users\nare largely unknown. To address this knowledge gap, we analyzed 2159 user\nreviews from 117 Android apps and 2764 user reviews from 76 iOS apps. Our\nfindings include the critiques around inconsistent moderation standards and\nlack of transparency. App-embedded social features and chatbots were criticized\nfor providing little support during crises. We provide research and design\nimplications for future mental health app developers, discuss the necessity of\ndeveloping a comprehensive and centralized app development guideline, and the\nopportunities of incorporating existing AI technology in mental health\nchatbots.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2209.07796v1",
    "pdf_url": "http://arxiv.org/pdf/2209.07796v1",
    "full_text": "“For an App Supposed to Make Its Users Feel Better, It Sure is\na Joke” - An Analysis of User Reviews of Mobile Mental\nHealth Applications\n\nMD ROMAEL HAQUE and SABIRAT RUBYA, Marquette University, USA\n\nMobile mental health applications are seen as a promising way to fulfill the growing need for mental health\ncare. Although there are more than ten thousand mental health apps available on app marketplaces, such as\nGoogle Play and Apple App Store, many of them are not evidence-based, or have been minimally evaluated\nor regulated. The real-life experience and concerns of the app users are largely unknown. To address this\nknowledge gap, we analyzed 2159 user reviews from 117 Android apps and 2764 user reviews from 76 iOS apps.\nOur findings include the critiques around inconsistent moderation standards and lack of transparency. App-\nembedded social features and chatbots were criticized for providing little support during crises. We provide\nresearch and design implications for future mental health app developers, discuss the necessity of developing\na comprehensive and centralized app development guideline, and the opportunities of incorporating existing\nAI technology in mental health chatbots.\n\nCCS Concepts: • Human-centered computing → Empirical studies in HCI ; Empirical studies in ubiquitous\nand mobile computing.\n\nAdditional Key Words and Phrases: Mobile applications, Mental health, User review analysis.\n\nACM Reference Format:\nMD Romael Haque and Sabirat Rubya. 2022. “For an App Supposed to Make Its Users Feel Better, It Sure is a\nJoke” - An Analysis of User Reviews of Mobile Mental Health Applications. Proc. ACM Hum.-Comput. Interact.\n6, CSCW2, Article 421 (November 2022), 29 pages. https://doi.org/10.1145/3555146\n\n1 INTRODUCTION\nOne out of every four persons on the world has been impacted by mental or neurological issues\nat some point in their lives [82]. Mental health issues affect around 450 million people globally,\nmaking them one of the primary causes of ill-health and disability according to WHO [82]. In\n2019, 20.6% of adults in the United States (51.5 million individuals) were affected by mental illness,\nrepresenting 1 in every 5 adults and a sharp increase of 4% in just three years [57]. Due to the\ninaccessibility and high cost of traditional treatment, around 55% of people with severe mental\nillnesses do not receive treatment [91]. With the advancement of mobile technologies in the last\nten years developers recognized a strong promise for digital tools like mobile phone applications\nto expand better accessibility at low cost to mental health (MH) treatment and services [9]. Prior\nstudy has acknowledged this breakthrough for making MH treatment more accessible, convenient,\nand adaptable to the patient’s lifestyle [19]. By 2018, there were over 10,000 MH and wellness apps\navailable for immediate download [114], with services ranging from symptom tracking and mon-\nitoring to implementing scientifically grounded therapy, such as CBT and Mindfulness, as well\n\nAuthors’ address: MD Romael Haque, mdromael.haque@marquette.edu; Sabirat Rubya, sabirat.rubya@marquette.edu,\nMarquette University, Milwaukee, WI, USA, 53233.\n\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee\nprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and\nthe full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses,\ncontact the owner/author(s).\n© 2022 Copyright held by the owner/author(s).\n2573-0142/2022/11-ART421\nhttps://doi.org/10.1145/3555146\n\nProc. ACM Hum.-Comput. Interact., Vol. 6, No. CSCW2, Article 421. Publication date: November 2022.\n\n421\n\n\f421:2\n\nMD Romael Haque and Sabirat Rubya\n\nas various interactive tools and modules for self-guidance [8]. However, prior study has shown\nthat while access and availability of MH applications has increased, concerns about privacy, effec-\ntiveness, and usability have also been raised [113]. According to a recent study, 7–42% of users\ncontinued to use the apps after four weeks, but just 0.5–28.6% after six weeks [87]. The use and\nadherence with MH applications in real-world settings may range between 1% and 29% [39]. Fur-\nthermore, because the majority of the applications accessible are not evidence-based, their efficacy\nin aiding people with MH concerns is questionable [8].\n\nPrior research has attempted to understand these challenges using data from a variety of sources,\nincluding the descriptions of applications in mobile app stores [29], publicly available peer-review\ndatabases [8], frameworks and evaluation criteria from engineering and informatics literature, and\ninterdisciplinary organizations [20], etc. Smartphone-based apps represent a unique opportunity\nto expand the availability and quality of MH treatment, and the COVID-19 pandemic caused a\nsurge in MH and wellness app downloads [119]. But on"
  },
  {
    "title": "Domain-specific Continued Pretraining of Language Models for Capturing\n  Long Context in Mental Health",
    "authors": [
      "Shaoxiong Ji",
      "Tianlin Zhang",
      "Kailai Yang",
      "Sophia Ananiadou",
      "Erik Cambria",
      "Jörg Tiedemann"
    ],
    "abstract": "Pretrained language models have been used in various natural language\nprocessing applications. In the mental health domain, domain-specific language\nmodels are pretrained and released, which facilitates the early detection of\nmental health conditions. Social posts, e.g., on Reddit, are usually long\ndocuments. However, there are no domain-specific pretrained models for\nlong-sequence modeling in the mental health domain. This paper conducts\ndomain-specific continued pretraining to capture the long context for mental\nhealth. Specifically, we train and release MentalXLNet and MentalLongformer\nbased on XLNet and Longformer. We evaluate the mental health classification\nperformance and the long-range ability of these two domain-specific pretrained\nmodels. Our models are released in HuggingFace.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2304.10447v1",
    "pdf_url": "http://arxiv.org/pdf/2304.10447v1",
    "full_text": "Domain-speciﬁc Continued Pretraining of Language Models\nfor Capturing Long Context in Mental Health\n\nShaoxiong Ji 1 Tianlin Zhang 2 Kailai Yang 2 Sophia Ananiadou 2\n\nErik Cambria 3\n\nJörg Tiedemann 1\n\n1 University of Helsinki\n\n2 The University of Manchester\n\n3 Nanyang Technological University\n\n{shaoxiong.ji; jorg.tiedemann}@helsinki.fi; cambria@ntu.edu.sg\n{kailai.yang,tianlin.zhang}@postgrad.manchester.ac.uk\n{sophia.ananiadou}@manchester.ac.uk\n\nAbstract\n\nPretrained language models have been used\nin various natural language processing appli-\ncations. In the mental health domain, domain-\nspeciﬁc language models are pretrained and\nreleased, which facilitates the early detection\nof mental health conditions.\nSocial posts,\ne.g., on Reddit, are usually long documents.\nthere are no domain-speciﬁc pre-\nHowever,\ntrained models for long-sequence modeling in\nthe mental health domain. This paper conducts\ndomain-speciﬁc continued pretraining to cap-\nture the long context for mental health. Specif-\nically, we train and release MentalXLNet and\nMentalLongformer based on XLNet and Long-\nformer. We evaluate the mental health classiﬁ-\ncation performance and the long-range ability\nof these two domain-speciﬁc pretrained mod-\nels. Our models are released in HuggingFace1.\n\n1\n\nIntroduction\n\nNatural Language Processing (NLP) applied to\nmental healthcare (Le Glaz et al., 2021; Zhang\net al., 2022) has received much attention with spe-\nciﬁc applications to bipolar disorder detection (Har-\nvey et al., 2022), depression detection (Ansari\net al., 2023), and suicidal ideation detection (Ji\net al., 2021). Recent work applied pretrained lan-\nguage models and domain-speciﬁc continued pre-\ntraining in the mental health domain with public\nmodels released, such as MentalBERT and Men-\ntalRoBERTa (Ji et al., 2022b). However, due to\nthe quadratic complexity of self-attention in the\ntransformer network (Vaswani et al., 2017), the\npretrained Bidirectional Encoder Representations\nfrom Transformers (BERT) (Devlin et al., 2019)\nand its domain-speciﬁc variants have limited abil-\nity to capture long-range context, and the pretri-\naned models can only process sequence within 512\ntokens in the downstream applications.\n\n1https://huggingface.co/AIMH\n\nTo address this issue, efﬁcient transformers are\nproposed, such as Longformer (Beltagy et al.,\n2020) and Transformer-XL (Dai et al., 2019) to\ncapture long context. Qin et al. (2023) conducted\na systematic analysis on the long-range ability of\nefﬁcient transformers. In mental healthcare, texts\nsuch as self-reported mental conditions are usually\nlong documents. For example, in social network\nanalysis on Reddit, users’ posts are long, and each\nuser might have multiple posts.\n\nThis paper focuses on mental health analysis\nwith long documents. We conduct domain-speciﬁc\ncontinued pretraining with Longformer and XL-\nNet architectures in the mental health domain. Our\ncontributions are as follows. We train and release\ntwo domain-speciﬁc language models, i.e., Men-\ntalXLNet and MentalLongformer. We evaluate the\nperformance of these two models on various men-\ntal healthcare classiﬁcation datasets. Finally, we\ndiscuss the long-range ability of these two models\nand summarize how to choose pretrained language\nrepresentations for speciﬁc applications.\n\n2 Methods and Materials\n\nThis section presents the methods and materials.\nThe self-attention in the standard transformer ar-\nchitecture suffers from quadratic complexity with\nsequence length. As a result, the BERT model pre-\ntrained with a masked language modeling (MLM)\nobjective limits the maximum sequence length to\n512 tokens.\n\nWe introduce two transformer networks for long\ndocuments and domain-speciﬁc pretraining to con-\ntinue the pretraining in the mental healthcare do-\nmain. Table 1 summarizes the learning objectives\nand sequence lengths of existing pretrained models\nfor mental healthcare and models trained in this pa-\nper. For downstream classiﬁcation tasks, the max\nsequence length of BERT and RoBERTa is 512.\n\n3\n2\n0\n2\n\nr\np\nA\n0\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n7\n4\n4\n0\n1\n.\n4\n0\n3\n2\n:\nv\ni\nX\nr\na\n\n \n \n \n \n \n \n\fModel\n\nObjective\n\nSeq. Length\n\nMentalBERT\nMentalRoBERTa\nMentalXLNet\nMentalLongformer\n\nMLM\nMLM\nPLM\nMLM\n\n128\n128\n512\n4096\n\nTable 1: A summary of pretrained models for mental\nhealthcare\n\n2.1 Transformers for Long Sequence\n\nModeling\n\nLongformer Longformer (Beltagy et al., 2020)\nproposes an efﬁcient attention mechanism with a\nlinear complexity that leverages local windowed\nattention and task-motivated global attention. It\nis better at autoregressive language modeling on\nlong sequences than prior works. When pretrained\nwith MLM objective, Longformer achieves better\nlong sequence modeling capacity on various down-\nstream tasks.\n\nXLNet Transformer-XL (Dai et al., 2019) solves\nthe context fragmentation issue of ﬁxed-length con-\ntexts by devising the recurrent operations for seg-\nments in the self-attention network. XLNet (Yang\net al., 2019) combines the best of autoregressive\nand autoencoding la"
  },
  {
    "title": "PsyEval: A Suite of Mental Health Related Tasks for Evaluating Large\n  Language Models",
    "authors": [
      "Haoan Jin",
      "Siyuan Chen",
      "Dilawaier Dilixiati",
      "Yewei Jiang",
      "Mengyue Wu",
      "Kenny Q. Zhu"
    ],
    "abstract": "Evaluating Large Language Models (LLMs) in the mental health domain poses\ndistinct challenged from other domains, given the subtle and highly subjective\nnature of symptoms that exhibit significant variability among individuals. This\npaper presents PsyEval, the first comprehensive suite of mental health-related\ntasks for evaluating LLMs. PsyEval encompasses five sub-tasks that evaluate\nthree critical dimensions of mental health. This comprehensive framework is\ndesigned to thoroughly assess the unique challenges and intricacies of mental\nhealth-related tasks, making PsyEval a highly specialized and valuable tool for\nevaluating LLM performance in this domain. We evaluate twelve advanced LLMs\nusing PsyEval. Experiment results not only demonstrate significant room for\nimprovement in current LLMs concerning mental health but also unveil potential\ndirections for future model optimization.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2311.09189v2",
    "pdf_url": "http://arxiv.org/pdf/2311.09189v2",
    "full_text": "4\n2\n0\n2\n\nn\nu\nJ\n\n3\n\n]\nL\nC\n.\ns\nc\n[\n\n2\nv\n9\n8\n1\n9\n0\n.\n1\n1\n3\n2\n:\nv\ni\nX\nr\na\n\nProceedings of Machine Learning Research LEAVE UNSET:1–18, 2024\n\nConference on Health, Inference, and Learning (CHIL) 2024\n\nPsyEval: A Suite of Mental Health Related Tasks\n\nfor Evaluating Large Language Models\n\nHaoan Jin\nSiyuan Chen\nShanghai Jiao Tong University, China\n\nDilawaier Dilixiati\nYewei Jiang\nShanghai Jiao Tong University School of Medicine, China\n\nMengyue Wu\nShanghai Jiao Tong University, China\n\nKenny Q. Zhu\nUniversity of Texas at Arlington, USA\n\npilgrim@sjtu.edu.cn\nchensiyuan925@sjtu.edu.cn\n\ndilawur1@sjtu.edu.cn\nzoe8188@sjtu.edu.cn\n\nmengyuewu@sjtu.edu.cn\n\nkenny.zhu@uta.edu\n\nAbstract\nEvaluating Large Language Models (LLMs) in\nthe mental health domain poses distinct chal-\nlenged from other domains, given the subtle\nand highly subjective nature of symptoms that\nexhibit significant variability among individu-\nals. This paper presents PsyEval, the first\ncomprehensive suite of mental health-related\ntasks for evaluating LLMs. PsyEval encom-\npasses five sub-tasks that evaluate three crit-\nical dimensions of mental health. This com-\nprehensive framework is designed to thoroughly\nassess the unique challenges and intricacies of\nmental health-related tasks, making PsyEval a\nhighly specialized and valuable tool for evalu-\nating LLM performance in this domain. We\nevaluate twelve advanced LLMs using PsyEval.\nExperiment results not only demonstrate sig-\nnificant room for improvement in current LLMs\nconcerning mental health but also unveil poten-\ntial directions for future model optimization.\n\nData and Code Availability The data utilized\nin this study, along with relevant citations where ap-\nplicable, are made accessible to fellow researchers, in-\ncluding MedQA1 (Jin et al., 2021), SMHD2 (Cohan\net al., 2018), D43 (Yao et al., 2022) and PsyQA4 (Sun\net al., 2021). The datasets we constructed, USMLE-\n\n1. https://github.com/jind11/MedQA\n2. https://ir.cs.georgetown.edu/resources/\n3. https://x-lance.github.io/D4/\n4. https://github.com/thu-coai/PsyQA\n\n© 2024 H. Jin, S. Chen, D. Dilixiati, Y. Jiang, M. Wu & K.Q. Zhu.\n\nmental and Crisis Response QA, are also open-\nsource.5\n\n1. Introduction\n\nNowadays, the rising prevalence of mental\nillness\npresents a significant and growing threat to global\npublic health. The pervasive specter of mental illness,\nespecially depression, poses substantial challenges on\na global scale, with the World Health Organization\n(WHO) estimating that 3.8% of the global popula-\ntion experiences depression (World Health Organi-\nzation, 2023). Despite these high numbers, treat-\nment rates remain alarmingly low: only 13.7% of 12-\nmonth DSM-IV/CIDI cases in lower-middle-income\ncountries, 22.0% in upper-middle-income countries,\nand 36.8% in high-income countries receive any form\nof treatment (Evans-Lacko et al., 2018). These\nchallenges are often underestimated due to societal\nstigma and a lack of public awareness (Pirina and\nC¸ ¨oltekin, 2018).\n\nIn the face of the escalating global public health\nchallenge posed by mental illness, an increasing co-\nhort of researchers has redirected substantial efforts\ntowards this critical domain (Lamichhane, 2023).\nThe advent of large language models (LLMs) has\nemerged as a transformative force, offering novel solu-\ntions to persistent challenges within the field of men-\n\n5. https://github.com/KaguraRuri/Psy-Eval\n\n \n \n \n \n \n \n\fPsyEval\n\nFigure 1: Overview diagram of PsyEval.\n\ntal health. Notable models such as ChatGPT (Schul-\nman et al., 2022), LLaMA (Touvron et al., 2023), and\nVicuna (Chiang et al., 2023) have made substantial\nstrides in Natural Language Processing (NLP). These\nmodels leverage extensive pretraining data and mas-\nsive neural networks, achieving commendable results\non standard NLP benchmark tests.\nIn the specific\ndomain of mental health, these LLMs have shown\npromising applications (Xu et al., 2023; Lamichhane,\n2023). Concurrently, researchers have recognized the\nunique demands of the mental health domain and\nhave introduced specialized LLM explicitly designed\nfor mental health applications (Yang et al., 2023b).\n\nThe application of LLMs in mental health domain\npresents unique challenges and opportunities. Un-\nlike other fields, assessing LLMs for mental health re-\nquires a careful approach due to the subtle and highly\nsubjective nature of symptoms, which vary widely\namong individuals (Taschereau-Dumouchel et al.,\n2022).\nIdeally, LLMs should function akin to pro-\nfessional psychologists, equipped with the capacity\nto diagnose illnesses, exhibit empathy, and adhere to\nethical standards (International Association of Ap-\nplied Psychology, 2016). Their effectiveness in the\nmental health field hinges not only on domain-specific\nknowledge but also on comprehensive capabilities in-\ncluding reasoning, planning, and social intelligence.\nFor instance, interpreting subtle emotional cues and\nresponding empathetically demands a sophisticated\nunderstanding of language and social dynamics. Fur-\nthermore,"
  },
  {
    "title": "Public sentiment analysis and topic modeling regarding ChatGPT in mental\n  health on Reddit: Negative sentiments increase over time",
    "authors": [
      "Yunna Cai",
      "Fan Wang",
      "Haowei Wang",
      "Qianwen Qian"
    ],
    "abstract": "In order to uncover users' attitudes towards ChatGPT in mental health, this\nstudy examines public opinions about ChatGPT in mental health discussions on\nReddit. Researchers used the bert-base-multilingual-uncased-sentiment\ntechniques for sentiment analysis and the BERTopic model for topic modeling. It\nwas found that overall, negative sentiments prevail, followed by positive ones,\nwith neutral sentiments being the least common. The prevalence of negative\nemotions has increased over time. Negative emotions encompass discussions on\nChatGPT providing bad mental health advice, debates on machine vs. human value,\nthe fear of AI, and concerns about Universal Basic Income (UBI). In contrast,\npositive emotions highlight ChatGPT's effectiveness in counseling, with\nmentions of keywords like \"time\" and \"wallet.\" Neutral discussions center\naround private data concerns. These findings shed light on public attitudes\ntoward ChatGPT in mental health, potentially contributing to the development of\ntrustworthy AI in mental health from the public perspective.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2311.15800v1",
    "pdf_url": "http://arxiv.org/pdf/2311.15800v1",
    "full_text": "Public sentiment analysis and topic modeling regarding ChatGPT in mental health \non Reddit: Negative sentiments increase over time \n\nYunna Cai1, Fan Wang1†, Haowei Wang1 and Qianwen Qian1. \n\n1School of Information Management, Wuhan Univerisity  \n\nAbstract \n\nIn  order  to  uncover  users'  attitudes  towards \nChatGPT in mental health, this study examines \npublic  opinions  about  ChatGPT  in  mental \nhealth discussions on Reddit. Researchers used \nthe  bert-base-multilingual-uncased-sentiment \ntechniques  for  sentiment  analysis  and  the \nBERTopic  model  for  topic  modeling.  It  was \nfound that overall, negative sentiments prevail, \nfollowed  by  positive  ones,  with  neutral \nsentiments  being  the  least  common.  The \nprevalence of negative emotions has increased \nover  time.  Negative  emotions  encompass \ndiscussions on ChatGPT providing bad mental \nhealth advice, debates on machine vs. human \nvalue,  the  fear  of  AI,  and  concerns  about \nUniversal  Basic  Income  (UBI).  In  contrast, \npositive \nemotions  highlight  ChatGPT's \neffectiveness in counseling, with mentions of \nkeywords  like  \"time\"  and  \"wallet.\"    Neutral \ndiscussions  center  around  private  data \nconcerns. These findings shed light on public \nattitudes  toward  ChatGPT  in  mental  health, \npotentially contributing to the development of \ntrustworthy AI in mental health from the public \nperspective. \n\nstudy is to delve into the emotions and viewpoints \nof these users when it comes to ChatGPT in mental \nhealth.  \nThis study poses the following questions: \n\n1. What  are  the  overall  sentiments  and  topics  in \ndiscussions  related  to  ChatGPT  in  mental \nhealth? \n\n2. How  do  the  overall  sentiments  and  topics \n\nchange over time? \n\n3. What are the topics associated with positive and \nnegative  sentiments  in  discussions  related  to \nChatGPT in mental health? \n\nTo address these questions, this study seeks to \nexamine public sentiments and opinions regarding \nChatGPT in mental health from Reddit (a popular \nsocial  media  platform).  We  employed  the  bert-\nbase-multilingual-uncased-sentiment  model  for \nsentiment  analysis  and  utilized  BERTopic  for \ntopic modeling. Both models exhibited exemplary \nperformance  in  their  designated  tasks  and  are \ncommonly  employed  in  scholarly  circles  for \nsentiment and topic analysis (Maarten, 2022). \n\n1 \n\nIntroduction \n\nWARNING:  This  paper  contains  examples  and \ndescriptions which are depressive or aggressive in \nnature. \nSince its inception, ChatGPT has been regarded as \na  significant  opportunity  for  various  fields, \nincluding  mental  health. Academia  has  assessed \nChatGPT's  outstanding  performance  in  various \nmental  health  tasks,  signaling  a  new  era  in \ninternet-based psychological interventions (P et al., \n2023).  However,  the  application  of  ChatGPT  in \nthe  field  of  mental  health  also  raises  ethical \nconcerns  (Tirth  et  al.,  2023).  It  is  imperative  to \nunderstand the public's attitudes towards this and \nfuture  of  generative  artificial \nexplore \nintelligence  in  mental  health.  However,  there  is \ncurrently  a  lack  of  empirical  research  to  unveil \nusers'  perspectives  on  ChatGPT's  application  in \nmental  health.  Therefore,  the  objective  of  this \n\nthe \n\n† Corresponding author \n\nthat \n\nThe  results  revealed \n\nin  discussions \nconcerning  ChatGPT  in  mental  health,  negative \nsentiments  outweighed  positive  sentiments,  with \nneutral sentiments being the least prevalent. Over \ntime,  there  was  a  continuous  increase  in  the \nproportion  of  negative \nsentiments.  Users \ndiscussed various aspects, including their overall \nexperiences  with  ChatGPT  in  mental  health, \nprompts,  associated  risks  (privacy  and  societal \nimplications), and the impact of version updates. \nThese findings enrich our comprehension of the \npublic's  perceptions  regarding  the  application  of \nChatGPT  in  mental  health.  Significantly,  the \noutcomes  of  this  study  will  provide  valuable \nguidance \nreliable \nLanguage  Models  (LLMs)  in  the  mental  health \ndomain,  both  for \nindustry  and  government \napplications. \n\nthe  development  of \n\nfor \n\n \n \n\f2  Related Work \n\n2.1  The Transformative Influence of ChatGPT \non Mental Health \n\nDue to its exceptional knowledge of mental health, \nChatGPT  is  being  recognized  as  a  promising \nfuture  in  providing  assistance  for  psychological \ncounseling (Chow et al., 2023). In the field of NLP, \nnumerous studies have substantiated the excellent \nperformance  of  ChatGPT  in  applications  related \nto  mental  health,  encompassing  tasks  such  as \nstress,  depression,  and  suicidality  detection \n(Lamichhane,  2023;  Amin  et  al.,  2023;  Kailai, \n2023).  Given  the  real-world  challenges  such  as \npsychological  stress  and  resource  scarcity  that \nhuman  therapists  may  bring,  ChatGPT  could \npotentially  become  a  significant  avenue  for  the \nfuture "
  },
  {
    "title": "Robust language-based mental health assessments in time and space\n  through social media",
    "authors": [
      "Siddharth Mangalik",
      "Johannes C. Eichstaedt",
      "Salvatore Giorgi",
      "Jihu Mun",
      "Farhan Ahmed",
      "Gilvir Gill",
      "Adithya V. Ganesan",
      "Shashanka Subrahmanya",
      "Nikita Soni",
      "Sean A. P. Clouston",
      "H. Andrew Schwartz"
    ],
    "abstract": "Compared to physical health, population mental health measurement in the U.S.\nis very coarse-grained. Currently, in the largest population surveys, such as\nthose carried out by the Centers for Disease Control or Gallup, mental health\nis only broadly captured through \"mentally unhealthy days\" or \"sadness\", and\nlimited to relatively infrequent state or metropolitan estimates. Through the\nlarge scale analysis of social media data, robust estimation of population\nmental health is feasible at much higher resolutions, up to weekly estimates\nfor counties. In the present work, we validate a pipeline that uses a sample of\n1.2 billion Tweets from 2 million geo-located users to estimate mental health\nchanges for the two leading mental health conditions, depression and anxiety.\nWe find moderate to large associations between the language-based mental health\nassessments and survey scores from Gallup for multiple levels of granularity,\ndown to the county-week (fixed effects $\\beta = .25$ to $1.58$; $p<.001$).\nLanguage-based assessment allows for the cost-effective and scalable monitoring\nof population mental health at weekly time scales. Such spatially fine-grained\ntime series are well suited to monitor effects of societal events and policies\nas well as enable quasi-experimental study designs in population health and\nother disciplines. Beyond mental health in the U.S., this method generalizes to\na broad set of psychological outcomes and allows for community measurement in\nunder-resourced settings where no traditional survey measures - but social\nmedia data - are available.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2302.12952v1",
    "pdf_url": "http://arxiv.org/pdf/2302.12952v1",
    "full_text": "Robust language-based mental health assessments\nin time and space through social media\n\nSiddharth Mangalika,1, Johannes C. Eichstaedtb,c,1, Salvatore Giorgie, Jihu Muna, Farhan Ahmeda, Gilvir Gilla, Adithya V.\nGanesana, Shashanka Subrahmanyac, Nikita Sonia, Sean A. P. Cloustond, and H. Andrew Schwartza,1\n\naDepartment of Computer Science, Stony Brook University, Stony Brook, NY, USA; bDepartment of Psychology, Stanford University, Stanford, CA, USA; cInstitute for\nHuman-Centered A.I., Stanford University, CA, USA; dDepartment of Family, Population, and Preventive Medicine, Renaissance School of Medicine, Stony Brook University,\nStony Brook, NY, USA; eDepartment of Computer and Information Science, University of Pennsylvania\n\nThis manuscript was compiled on February 25, 2023\n\nCompared to physical health, population mental health measurement in the U.S. is very coarse-grained. Currently, in the largest population\nsurveys, such as those carried out by the Centers for Disease Control or Gallup, mental health is only broadly captured through \"mentally\nunhealthy days\" or \"sadness\", and limited to relatively infrequent state or metropolitan estimates. Through the large scale analysis of social\nmedia data, robust estimation of population mental health is feasible at much higher resolutions, up to weekly estimates for counties. In the\npresent work, we validate a pipeline that uses a sample of 1.2 billion Tweets from 2 million geo-located users to estimate mental health changes\nfor the two leading mental health conditions, depression and anxiety. We find moderate to large associations between the language-based\nmental health assessments and survey scores from Gallup for multiple levels of granularity, down to the county-week (fixed effects β = .25\nto 1.58; p < .001). Language-based assessment allows for the cost-effective and scalable monitoring of population mental health at weekly\ntime scales. Such spatially fine-grained time series are well suited to monitor effects of societal events and policies as well as enable\nquasi-experimental study designs in population health and other disciplines. Beyond mental health in the U.S., this method generalizes to\na broad set of psychological outcomes and allows for community measurement in under-resourced settings where no traditional survey\nmeasures – but social media data – are available.\n\nPre-Print | Depression | Anxiety | Social Media Analysis | Spatiotemporal\n\nM ental health is a large public health concern, causing\n\nlarge economic impact and loss of quality of life. Recent\nestimates suggest that depression affects 19.4 million Ameri-\ncans (7.8% of the population, 2020 est.) each year (1), while\ngeneralized anxiety disorder affects approximately 6% of the\nUS population (19.8 million people, 2010 est.) (2). Globally,\nmental health conditions are the fifth-most common cause of\nreduced quality of life (3). Critically, poor mental health is\nthought to play a central role driving recent increases in preva-\nlence and severity of “deaths of despair” (4, 5) in part due\nto the influence of poorer mental health on suicide attempts\nand suicide mortality obesity (6), and opioid-related overdoses\n(7).\n\nPublic health researchers and policy makers seek to under-\nstand and actively respond to emerging and changing condi-\ntions (8, 9). Yet, current standards for monitoring mental\nhealth outcomes rely on subjective information from surveys\nthat have limited temporal or regional resolution. For example,\nannual changes in depression are measured only by annual\nGallup polling (10) and a handful of national surveys (11)\nwhile anxiety is not regularly assessed in any of these sur-\nveys (12). Nevertheless, improving geospatial resolution can\nprovide researchers with tools to more reliably assess the dis-\ntribution (13) and determinants of disease (14). Similarly,\na wealth of small studies using ecological momentary assess-\nment suggest that observations made on shorter timescales\nroutinely identifies symptoms and correlates that are otherwise\ninaccessible to researchers (15, 16).\n\nApplying validated measures of depression and anxiety, as-\nsessed objectively at regular time-intervals at the county-level\ncould transform research in population mental health, allowing\n\nresearchers for the first time to locate clusters and reasons for\nchanges to poorer mental health (17). Since originally pro-\nposed, language-based assessments have developed to become\nas a flexible source of objective information about individuals’\nemotions and behaviors (18), often with greater accuracy and\npredictive power than existing survey-based measures (19).\nFurther, recent work has found significant increases in conver-\ngent validity via post-stratification techniques (20) to address\nknown selection biases (21, 22).\n\nHere, we bring integrate a series of recent advances into\na single pipeline, language-based mental health assessment\n(LBMHA: Figure 1), to produce anxiety and depression esti-\nmates over regions and time. We firs"
  },
  {
    "title": "Identifying Mentions of Pain in Mental Health Records Text: A Natural\n  Language Processing Approach",
    "authors": [
      "Jaya Chaturvedi",
      "Sumithra Velupillai",
      "Robert Stewart",
      "Angus Roberts"
    ],
    "abstract": "Pain is a common reason for accessing healthcare resources and is a growing\narea of research, especially in its overlap with mental health. Mental health\nelectronic health records are a good data source to study this overlap.\nHowever, much information on pain is held in the free text of these records,\nwhere mentions of pain present a unique natural language processing problem due\nto its ambiguous nature. This project uses data from an anonymised mental\nhealth electronic health records database. The data are used to train a machine\nlearning based classification algorithm to classify sentences as discussing\npatient pain or not. This will facilitate the extraction of relevant pain\ninformation from large databases, and the use of such outputs for further\nstudies on pain and mental health. 1,985 documents were manually\ntriple-annotated for creation of gold standard training data, which was used to\ntrain three commonly used classification algorithms. The best performing model\nachieved an F1-score of 0.98 (95% CI 0.98-0.99).",
    "year": 2023,
    "url": "http://arxiv.org/abs/2304.01240v2",
    "pdf_url": "http://arxiv.org/pdf/2304.01240v2",
    "full_text": "Identifying Mentions of Pain in Mental Health Records \nText: A Natural Language Processing Approach \n\nJaya Chaturvedi (Institute of Psychiatry, Psychology and Neurosciences, King’s College London),  \nSumithra Velupillai (Institute of Psychiatry, Psychology and Neurosciences, King’s College London),  \nRobert Stewart (Institute of Psychiatry, Psychology and Neurosciences, King’s College London, Health Data \nResearch UK, South London and Maudsley Biomedical Research Centre, London, United Kingdom \nAngus Roberts (Institute of Psychiatry, Psychology and Neurosciences, King’s College London, Health Data \nResearch UK) \n\nPain is a common reason for accessing healthcare resources and is a growing area of research, especially in its \noverlap with mental health. Mental health electronic health records are a good data source to study this overlap. \nHowever, much information on pain is held in the free text of these records, where mentions of pain present a \nunique  natural  language  processing  problem  due  to  its  ambiguous  nature.  This  project  uses  data  from  an \nanonymised mental health electronic health records database. The data are used to train a machine learning based \nclassification algorithm to classify sentences as discussing patient pain or not. This will facilitate the extraction of \nrelevant pain information from large databases, and the use of such outputs for further studies on pain and mental \nhealth.  1,985  documents  were  manually  triple-annotated  for  creation  of  gold  standard  training data,  which  was \nused to train three commonly used classification algorithms. The best performing model achieved an F1-score of \n0.98 (95% CI 0.98-0.99). \n\nKeywords. Natural Language Processing, Electronic Health Records, Pain, Mental Health, Transformers. \n\n1. \n\nIntroduction \n\nPain is defined as an unpleasant sensory and emotional experience, and is influenced by a variety of biological, \npsychological, and social factors [1]. Pain is a common reason for people to access healthcare facilities, thereby \nmaking electronic health records (EHR) a potential source for information on pain [2]. \n\nEHRs are longitudinal compilations of electronic data pertaining to a person's medical history or healthcare \n[3]. They have been increasingly used in research as they provide the opportunity to explore patient symptoms \nand findings from structured and unstructured fields. Since pain is not well recorded in these structured fields, it \nmay help to supplement this information with data from unstructured clinical text [4]. \n\nA commonly used machine learning based NLP approach is text classification, in which labels are assigned \nto units of text (sentences/paragraphs/documents) [5]. Commonly used classification algorithms include Support \nVector  Machines  [6–8]  and  K-Nearest  Neighbours  [9–11].  Recent  state  of  the  art  approaches  use  embedding \nmodels  and  transformer-based  neural  network  architectures  [12],  such  as  the  bi-directional  encoder \nrepresentations  of  BERT  [13].  Many  healthcare  domain  related  models  have  emerged,  such  as  PubMedBERT \n[14],  BioBERT  [15],  ClinicalBERT  [16],  UmlsBERT  [17]  and  SAPBERT  [18]  which  were  developed  after \nrecognition of the need for specialized models due to linguistic differences between general and biomedical text \n[19].  \n\nThis  paper  describes  the  methods  undertaken  to  develop  an  NLP  application  for  a  sentence-level \nclassification of mentions of physical pain within clinical text. Two BERT models were trained - bert_base and \nSAPBERT  -  and  compared  to  two  conventional  models  -  support  vector  machines  (SVM)  and  K-Nearest \nNeighbours (KNN). To the best of our knowledge, such extraction of information about pain from mental health \nclinical text using NLP has not been done. \n\n2.  Methods \n\n2.1. \n\n Data Source \n\nAn anonymised version of EHR data from The South London and Maudsley NHS Foundation Trust (SLaM), one \nof  the  largest  mental  healthcare  organizations  in  Europe,  is  stored  in  the  Clinical  Record  Interactive  Search \n\n\f(CRIS)  database  [20].  The  infrastructure  of  CRIS  has  been  described  in  detail  with  an  overview  of  the  cohort \nprofile [21]. CRIS contains over 30 million documents, averaging 90 documents per patient [22]. There are 23 \ndifferent  text  sources  (such  as  attachments,  event  notes,  nurse  assessment  letters,  etc.).  Most  of  the  text  is \ncontained within attachments and event notes, and so these were used as the data sources in this project. \n\n2.2. \n\n Ethics and Data Access \n\nEthics approval for CRIS has been granted  by (Oxford C Research Ethics Committee, reference 18/SC/0372). \nResearch projects that use the CRIS database are reviewed and approved by a patient-led oversight committee \n(described in [23]). An opt-out model is in place for service users and is advertised in all publicity material and \ninitiatives. Data are owned by a third party, "
  },
  {
    "title": "Towards Knowledge-based Mining of Mental Disorder Patterns from Textual\n  Data",
    "authors": [
      "Maryam Shahabikargar"
    ],
    "abstract": "Mental health disorders may cause severe consequences on all the countries'\neconomies and health. For example, the impacts of the COVID-19 pandemic, such\nas isolation and travel ban, can make us feel depressed. Identifying early\nsigns of mental health disorders is vital. For example, depression may increase\nan individual's risk of suicide. The state-of-the-art research in identifying\nmental disorder patterns from textual data, uses hand-labelled training sets,\nespecially when a domain expert's knowledge is required to analyse various\nsymptoms. This task could be time-consuming and expensive. To address this\nchallenge, in this paper, we study and analyse the various clinical and\nnon-clinical approaches to identifying mental health disorders. We leverage the\ndomain knowledge and expertise in cognitive science to build a domain-specific\nKnowledge Base (KB) for the mental health disorder concepts and patterns. We\npresent a weaker form of supervision by facilitating the generating of training\ndata from a domain-specific Knowledge Base (KB). We adopt a typical scenario\nfor analysing social media to identify major depressive disorder symptoms from\nthe textual content generated by social users. We use this scenario to evaluate\nhow our knowledge-based approach significantly improves the quality of results.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2207.06254v1",
    "pdf_url": "http://arxiv.org/pdf/2207.06254v1",
    "full_text": "Towards Knowledge-based Mining of Mental Disorder Patterns from\nTextual Data\n\nMaryam Shahabikargar*a\n\naMacquarie University, Sydney, Australia\n\nmaryam.shahabi-kargar@hdr.mq.edu.au\n\n2\n2\n0\n2\n\nl\nu\nJ\n\n7\n\n]\n\nR\n\nI\n.\ns\nc\n[\n\n1\nv\n4\n5\n2\n6\n0\n.\n7\n0\n2\n2\n:\nv\ni\nX\nr\na\n\nABSTRACT\nMental health disorders may cause severe consequences on all the countries’ economies and health. For example,\nthe impacts of the COVID-19 pandemic, such as isolation and travel ban, can make us feel depressed. Identifying\nearly signs of mental health disorders is vital. For example, depression may increase an individual’s risk of suicide.\nThe state-of-the-art research in identifying mental disorder patterns from textual data, uses hand-labelled train-\ning sets, especially when a domain expert’s knowledge is required to analyse various symptoms. This task could\nbe time-consuming and expensive. To address this challenge, in this paper, we study and analyse the various clin-\nical and non-clinical approaches to identifying mental health disorders. We leverage the domain knowledge and\nexpertise in cognitive science to build a domain-speciﬁc Knowledge Base (KB) for the mental health disorder con-\ncepts and patterns. We present a weaker form of supervision by facilitating the generating of training data from\na domain-speciﬁc Knowledge Base (KB). We adopt a typical scenario for analysing social media to identify major\ndepressive disorder symptoms from the textual content generated by social users. We use this scenario to evaluate\nhow our knowledge-based approach signiﬁcantly improves the quality of results.\n\nKEYWORDS\nCognitive Science, Knowledge Base, Machine learning; Business Process Analytics\n\nINTRODUCTION\n\n1\nWe begin this Section with an overview of the research problem and challenges in identifying and understanding\nmental health disorder patterns from textual data. We present our contributions and discuss how the proposed\nmethod may facilitate acquiring insight into the mental status of individuals who may be suﬀering from mental\ndisorders in general and depression in particular. Finally, we present the structure of this paper.\n\n1.1 Overview and Research Problem\n\nThe mental health of individuals and communities is a pressing challenge in the world, nowadays. Since COVID-\n191 pandemic outbreak in 2019, most governments have been preoccupied with handling and combating the epi-\ndemic. The prevalence of the Covid-19 has been signiﬁcantly controlled and lowered as a result of the global suc-\ncess in vaccine development and mass inoculation. But now, for most governments, a key concern is harnessing\nand dealing with the impacts of years of virus exposure, including the associated psychological and economic prob-\nlems. COVID-19 has impacted our lifestyles and workplaces. These changes can cause us to feel frustrated, stressed,\nand anxious, which may seriously aﬀect our mental health. Based on a recent study, after being diagnosed with\nCovid, roughly one out of every ﬁve people develops a mental disorder 198, 201. Hence, governments are trying to\nguide families and business owners to deal with these devastating eﬀects and improve the situation. On the other\nhand, as businesses reopen, it is important for organisations to provide a mentally healthy workplace2.\n\n1https://en.wikipedia.org/wiki/COVID-19\n2https://covid19.swa.gov.au/collection/covid-19-resource-kit\n\n \n \n \n \n \n \n\fPrior to any support, mental disorders need to be diagnosed. On the other hand, due to their complexity, identify-\ning mental disorder symptoms (e.g., depression symptoms) and their patterns could be a challenging task. Hence,\nit is necessary to identify mental health issues accurately and facilitate their treatment. As a critical mental health\nissue, depression is one of the leading causes of disability worldwide. It plays an essential role in the overall global\ndisease burden 69, 124 and could turn into a drastic health condition 3. Depression is a leading cause of disabil-\nity, with 5% of adults and 5.7% of 60-year-old and above people suﬀering from it. Data from the United States\nand Australia show elevated rates of depression and anxiety throughout the epidemic. It is estimated that during\nthe outbreak, depression level (i.e., 25%) is seven times higher than pre-pandemic levels worldwide (i.e., less than\n4%)4. Consequently, due to its importance, we focus on depression identiﬁcation in this research.\n\nThere are various clinical and non-clinical approaches available to identify depression symptoms. Using question-\nnaires and interviews are two main clinical approaches for depression identiﬁcation. On the other hand, analysing\nmedical data (e.g., EEG and fMRI images) and vocal, video, and textual data are diﬀerent approaches to iden-\ntifying and predicting depression. In addition, there are very few recent studies that proposed knowledge-based\napproaches to identify behavioural and mental disorders such as depression.\n\nTo extend the state-of-the-art in this line of work, in this paper,"
  },
  {
    "title": "Speech Emotion Recognition using Supervised Deep Recurrent System for\n  Mental Health Monitoring",
    "authors": [
      "Nelly Elsayed",
      "Zag ElSayed",
      "Navid Asadizanjani",
      "Murat Ozer",
      "Ahmed Abdelgawad",
      "Magdy Bayoumi"
    ],
    "abstract": "Understanding human behavior and monitoring mental health are essential to\nmaintaining the community and society's safety. As there has been an increase\nin mental health problems during the COVID-19 pandemic due to uncontrolled\nmental health, early detection of mental issues is crucial. Nowadays, the usage\nof Intelligent Virtual Personal Assistants (IVA) has increased worldwide.\nIndividuals use their voices to control these devices to fulfill requests and\nacquire different services. This paper proposes a novel deep learning model\nbased on the gated recurrent neural network and convolution neural network to\nunderstand human emotion from speech to improve their IVA services and monitor\ntheir mental health.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2208.12812v3",
    "pdf_url": "http://arxiv.org/pdf/2208.12812v3",
    "full_text": "IEEE Copyright Notice\n\nCopyright (c) 2022 IEEE\n\nin any current or future media,\n\nPersonal use of this material is permitted. Per-\nmission from IEEE must be obtained for all other\nincluding\nuses,\nreprinting/republishing this material for advertising\nor promotional purposes, creating new collective\nworks, for resale or redistribution to servers or lists,\nor reuse of any copyrighted component of this work\nin other works.\n\nAccepted to be published in: IEEE WFIoT-2022;\n26 October - 11 November , 2022 - Yokohoma,\nJapan. https://wﬁot2022.iot.ieee.org/\n\n2\n2\n0\n2\n\nt\nc\nO\n7\n2\n\n]\nS\nA\n.\ns\ns\ne\ne\n[\n\n3\nv\n2\n1\n8\n2\n1\n.\n8\n0\n2\n2\n:\nv\ni\nX\nr\na\n\n \n \n \n \n \n \n\fSpeech Emotion Recognition using Supervised Deep\nRecurrent System for Mental Health Monitoring\n\nNelly Elsayed\nSchool of Information Technology\nUniversity of Cincinnati\nOH, United States\nelsayeny@ucmail.uc.edu\n\nZag ElSayed\nSchool of Information Technology\nUniversity of Cincinnati\nOhio, United States\nelsayezs@ucmail.uc.edu\n\nNavid Asadizanjani\nDep. of Electrical & Computer Engineering\nUniversity of Florida\nFlorida, United States\nnasadi@ece.uﬂ.edu\n\nMurat Ozer\nSchool of Information Technology\nUniversity of Cincinnati\nOhio, United States\nozermm@ucmail.uc.edu\n\nAhmed Abdelgawad\nSchool of Engineering and Technology\nCentral Michigan University\nMichigan, United States\nabdel1a@cmich.edu\n\nMagdy Bayoumi\nDep. of Electrical & Computer Engineering\nUniversity of Louisiana at Lafayette\nLouisiana, Unted States\nmagdy.bayoumi@louisiana.edu\n\nAbstract—Understanding human behavior and monitoring\nmental health are essential to maintaining the community and\nsociety’s safety. As there has been an increase in mental health\nproblems during the COVID-19 pandemic due to uncontrolled\nmental health, early detection of mental issues is crucial. Nowa-\ndays, the usage of Intelligent Virtual Personal Assistants (IVA)\nhas increased worldwide. Individuals use their voices to control\nthese devices to fulﬁll requests and acquire different services.\nThis paper proposes a novel deep learning model based on the\ngated recurrent neural network and convolution neural network\nto understand human emotion from speech to improve their IVA\nservices and monitor their mental health.\n\nIndex Terms—Speech emotion recognition, intelligent personal\n\nassistants, GRU, speech detection, mental health\n\nI. INTRODUCTION\n\nMental health is one of the crucial health aspects that must\nbe monitored and treated for better physical health and a safer\ncommunity and social life [1]. Mental disorders cases are\nrising globally. According to the Institute for Health Metrics\nand Evaluation (IHME), the number of diagnosed individuals\nwith one of the mental disorders globally has exceeded 1.1\nbillion individuals in 2016 [2]. According to the World Health\nOrganization (WHO), during the ﬁrst year of the COVID-19\npandemic, depression and anxiety disorders have increased by\n25% globally, especially among young people and women.\nDue to late or unreceived mental care, the number of related\nsuicide has increased as well. The number of suicides has ex-\nceeded 700,000, meaning one person every 40 seconds dies by\nsuicidal action related to a mental disorder [3]. Moreover, the\nnumber of mass shootings in the United States has exceeded\n200 cases in less than the ﬁrst half of the year [4].\n\nSpeech is the primary form of communication and emo-\ntional expression [5]. From childhood, even before being able\nto speak correct words, children express their emotions in their\nununderstandable talks, such as their happiness and confusion.\nJuvenile, adults, and elderly individuals also express their\nemotions in their speech. All individuals express common\n\nemotions such as happy, sad, angry, happy, worry, fear, and\nneutral in their speech. However, different spoken languages\nproduce differences in how these emotions are expressed in\nthe speech tone and voice [6], [7]. In this paper, we focused\non English as the most widely spoken language worldwide [8].\nIn addition, the availability of open-access data that addresses\nthe speech emotion recognition problem is using English as\nthe primary language.\n\nThere are several mental disorders that can be identiﬁed\nfrom individual’s emotion changes [9], [10] such as depression\ndisorder [11], [12], stress disorder [13], [14], and anxiety\n(worry/fear) disorders [15], [16]. Early diagnostic of mental\ndisorders allows the individual to recieve the correct treatment\nand prevent sever illensses and even protect fom suisidal\naction [17], [18].\n\nIntelligent Virtual Personal Assistants (IVA) [19], [20] is s\na software agent that can perform services for an individual\nbased on processing users’ questions or commands via text\nor voice, depending on the IVA design and purpose. The text-\nbased interaction IVA are sometimes called chatbots, primarily\nwhen they are assessed by an online chat. The voice-based\ninteraction IVA is also known as an intelligent voice assistant.\nThe voice assistants can recognize the human speech and\ninterpret its commands and ques"
  },
  {
    "title": "Privacy Aware Question-Answering System for Online Mental Health Risk\n  Assessment",
    "authors": [
      "Prateek Chhikara",
      "Ujjwal Pasupulety",
      "John Marshall",
      "Dhiraj Chaurasia",
      "Shweta Kumari"
    ],
    "abstract": "Social media platforms have enabled individuals suffering from mental\nillnesses to share their lived experiences and find the online support\nnecessary to cope. However, many users fail to receive genuine clinical\nsupport, thus exacerbating their symptoms. Screening users based on what they\npost online can aid providers in administering targeted healthcare and minimize\nfalse positives. Pre-trained Language Models (LMs) can assess users' social\nmedia data and classify them in terms of their mental health risk. We propose a\nQuestion-Answering (QA) approach to assess mental health risk using the\nUnified-QA model on two large mental health datasets. To protect user data, we\nextend Unified-QA by anonymizing the model training process using differential\nprivacy. Our results demonstrate the effectiveness of modeling risk assessment\nas a QA task, specifically for mental health use cases. Furthermore, the\nmodel's performance decreases by less than 1% with the inclusion of\ndifferential privacy. The proposed system's performance is indicative of a\npromising research direction that will lead to the development of privacy-aware\ndiagnostic systems.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2306.05652v1",
    "pdf_url": "http://arxiv.org/pdf/2306.05652v1",
    "full_text": "Privacy Aware Question-Answering System for Online Mental Health Risk\nAssessment\n\nPrateek Chhikara∗ †, Ujjwal Pasupulety†, John Marshall,\nDhiraj Chaurasia and Shweta Kumari\nUniversity of Southern California, Los Angeles, USA\n{pchhikar,upasupul,jjmarsha,dchauras,shwetaku}@usc.edu\n\nAbstract\n\nSocial media platforms have enabled individu-\nals suffering from mental illnesses to share their\nlived experiences and find the online support\nnecessary to cope. However, many users fail\nto receive genuine clinical support, thus exacer-\nbating their symptoms. Screening users based\non what they post online can aid providers in\nadministering targeted healthcare and minimize\nfalse positives. Pre-trained Language Models\n(LMs) can assess users’ social media data and\nclassify them in terms of their mental health\nrisk. We propose a Question-Answering (QA)\napproach to assess mental health risk using\nthe Unified-QA model on two large mental\nhealth datasets. To protect user data, we ex-\ntend Unified-QA by anonymizing the model\ntraining process using differential privacy. Our\nresults demonstrate the effectiveness of model-\ning risk assessment as a QA task, specifically\nfor mental health use cases. Furthermore, the\nmodel’s performance decreases by less than 1%\nwith the inclusion of differential privacy. The\nproposed system’s performance is indicative of\na promising research direction that will lead to\nthe development of privacy-aware diagnostic\nsystems.\n\n1\n\nIntroduction\n\nIn recent years, Natural Language Processing\n(NLP) has emerged as a powerful field of study\nthat focuses on the interaction between human lan-\nguage and computational systems (Singh et al.,\n2020). Mental health is a crucial aspect of overall\nwell-being, and gaining insights into individuals’\nmental states has become an increasingly important\narea of study. NLP techniques have been useful\nin identifying text markers that indicate an individ-\nual’s mental well-being (Zhang et al., 2022). Social\nmedia websites, such as Twitter and Reddit, pro-\nvide a wealth of textual data that offers a unique\n\n∗ Corresponding author\n† These authors contributed equally to this work\n\nopportunity to analyze the mental health status of\ntheir users at scale, enabling the exploration of\npatterns, trends, and potential interventions (Skaik\nand Inkpen, 2020). Assessing users’ mental health\nrisk can be reduced to a basic text classification\ntask, where the Transformer architecture (Vaswani\net al., 2017) has demonstrated state-of-the-art per-\nformance. BERT (Devlin et al., 2019) encodings\nhave been utilized for training a variety of mental\nhealth risk detection systems (Jiang et al., 2020;\nNisa and Muhammad, 2021; Zeberga et al., 2022).\nBERT models fine-tuned on social media data (Ji\net al., 2022; Murarka et al., 2020) are able to clas-\nsify at-risk individuals with high accuracy.\n\nHowever, advances in text classification models\nhave stagnated with the advent of BERT encodings.\nPosing the risk assessment problem as a QA task\nis more analogous to consulting a trained clinician\n(Mutabazi et al., 2021). QA systems built using\nBERT have been used for public education on top-\nics in mental health (Guo et al., 2021). Nearly\n30% of QA healthcare systems focus on mental\nhealth applications such as workplace empower-\nment, screening, effecting behavior change, and re-\nducing smoking/alcohol dependence (Cilar Budler\net al., 2023). Multiple-choice QA models demon-\nstrate a promising alternative approach to depres-\nsion severity estimation even with low amounts\nof training data (Gabín et al., 2021). Further de-\nvelopment of QA models could lead to better au-\ntonomous diagnostic systems. This work proposes\nthe use of AllenAI’s Unified-QA model (Khashabi\net al., 2020) to assess the mental health risk of users\nfrom their social media posts. The research objec-\ntive is to explore whether QA transformer models\nare better than text classification transformers at\nassessing the risk to mental health and modeling\nlanguage markers that are indicative of specific\nmental illnesses. We compare Unified-QA to state-\nof-the-art pre-trained language models that perform\ntext classification on the same data.\n\n3\n2\n0\n2\n\nn\nu\nJ\n\n9\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n2\n5\n6\n5\n0\n.\n6\n0\n3\n2\n:\nv\ni\nX\nr\na\n\n \n \n \n \n \n \n\f(a) Binary Classification\n\n(b) Multi Classification\n\nFigure 1: Proposed Pipeline.\n\nTraining models on sensitive user data in their\nraw form makes them non-compliant with data\nprivacy rules which can have serious legal rami-\nfications in the case of unexpected data breaches\n(Brown et al., 2022). By using Differential Privacy,\nlanguage models can be trained such that they do\nnot memorize the training data, leading to data se-\ncurity and better model generalization (Basu et al.,\n2021; Behnia et al., 2022). This work also studies\nthe impact of differential private training on QA\nmodel performance. The contributions of the paper\nare as follows.\n\n1. We approached the text classification task for\nmental health posts using a QA framework.\nSpecifi"
  },
  {
    "title": "A Hybrid Approach for Depression Classification: Random Forest-ANN\n  Ensemble on Motor Activity Signals",
    "authors": [
      "Anket Patil",
      "Dhairya Shah",
      "Abhishek Shah",
      "Mokshit Gala"
    ],
    "abstract": "Regarding the rising number of people suffering from mental health illnesses\nin today's society, the importance of mental health cannot be overstated.\nWearable sensors, which are increasingly widely available, provide a potential\nway to track and comprehend mental health issues. These gadgets not only\nmonitor everyday activities but also continuously record vital signs like heart\nrate, perhaps providing information on a person's mental state. Recent research\nhas used these sensors in conjunction with machine learning methods to identify\npatterns relating to different mental health conditions, highlighting the\nimmense potential of this data beyond simple activity monitoring. In this\nresearch, we present a novel algorithm called the Hybrid Random forest - Neural\nnetwork that has been tailored to evaluate sensor data from depressed patients.\nOur method has a noteworthy accuracy of 80\\% when evaluated on a special\ndataset that included both unipolar and bipolar depressive patients as well as\nhealthy controls. The findings highlight the algorithm's potential for reliably\ndetermining a person's depression condition using sensor data, making a\nsubstantial contribution to the area of mental health diagnostics.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2310.09277v1",
    "pdf_url": "http://arxiv.org/pdf/2310.09277v1",
    "full_text": "A HYBRID APPROACH FOR DEPRESSION CLASSIFICATION:\nRANDOM FOREST-ANN ENSEMBLE ON MOTOR ACTIVITY\nSIGNALS\n\n3\n2\n0\n2\n\nt\nc\nO\n3\n1\n\n]\n\nG\nL\n.\ns\nc\n[\n\n1\nv\n7\n7\n2\n9\n0\n.\n0\n1\n3\n2\n:\nv\ni\nX\nr\na\n\nAnket Patil∗\nDepartment of Information Technology\nK. J. Somaiya Institute of Technology\nMaharashtra, India\npatilanket11@gmail.com\n\nAbhishek Shah\nDepartment of Information Technology\nK. J. Somaiya Institute of Technology\nMaharashtra, India\nahs1@somaiya.edu\n\nDhairya Shah\nDepartment of Information Technology\nK. J. Somaiya Institute of Technology\nMaharashtra, India\ndhairya.as@somaiya.edu\n\nMokshit Gala\nDepartment of Information Technology\nK. J. Somaiya Institute of Technology\nMaharashtra, India\nmokshit.gala@somaiya.edu\n\nOctober 16, 2023\n\nABSTRACT\n\nRegarding the rising number of people suffering from mental health illnesses in today’s society,\nthe importance of mental health cannot be overstated. Wearable sensors, which are increasingly\nwidely available, provide a potential way to track and comprehend mental health issues. These\ngadgets not only monitor everyday activities but also continuously record vital signs like heart rate,\nperhaps providing information on a person’s mental state. Recent research has used these sensors in\nconjunction with machine learning methods to identify patterns relating to different mental health\nconditions, highlighting the immense potential of this data beyond simple activity monitoring. In this\nresearch, we present a novel algorithm called the Hybrid Random forest - Neural network that has\nbeen tailored to evaluate sensor data from depressed patients. Our method has a noteworthy accuracy\nof 80% when evaluated on a special dataset that included both unipolar and bipolar depressive patients\nas well as healthy controls. The findings highlight the algorithm’s potential for reliably determining\na person’s depression condition using sensor data, making a substantial contribution to the area of\nmental health diagnostics.\n\nKeywords Depression · Motor Activity · Machine Learning · Random Forest · Neural Network · Hybrid Model ·\nArtificial Intelligence\n\n1\n\nIntroduction\n\nGlobal health is greatly impacted by the widespread mental health problems of depression and bipolar disorder. The\nWorld Health Organization (WHO) estimates that over 264 million people worldwide suffer from depression, making it\nthe main cause of disability [1]. Although bipolar disorder only affects 1% to 2% of the world’s population, it has a\nsignificant negative impact on the affected population’s quality of life and functional impairment [2]. These diseases\nhave significant financial repercussions; depression and anxiety are estimated to cost US$ 1 trillion annually in lost\nproductivity [3]. With the introduction of on-body sensors, personal health monitoring has undergone a revolutionary\nchange. Today’s people use enormous amounts of data every day for a variety of goals, such as improving life quality,\n\n∗\n\n \n \n \n \n \n \n\fA PREPRINT - OCTOBER 16, 2023\n\ntracking their fitness levels, and changing unhealthy habits. This information includes continuous records of heart rate\nand activity levels, which have considerable promise in the field of psychiatry and go beyond the simple metrics of\ndaily steps taken or calories burned. Growing emphasis has been paid to the complex association between activity\ndata and a variety of mental health problems such mood swings, stress management, and social disengagement [4–5].\nSince 2010, mental health issues—with depression leading the list of most common illnesses [6]–[8] have been the\nprimary reason for years lived with disability worldwide. Depression presents a variety of difficulties in the physical,\nfinancial, and emotional spheres, which frequently result in problems at work and sick days [9]. The underlying etiology\nof these illnesses involves a complex combination of genetic, environmental, and social variables, with biological\nrhythm disruptions—often sparked by environmental disturbances—showing up in afflicted people as altered motor\nactivity patterns [10]. By examining actigraph data to find patterns of motor activity suggestive of depressive and\nbipolar illnesses, this study aims to advance our understanding of these disorders. The study intends to clarify the\ndistinctive motor activity patterns connected to various mood disorders using cutting-edge statistical and machine\nlearning technologies, potentially permitting better diagnostic and curative approaches.\n\nThe main contributions of this paper are:\n\n1. Our study introduces a groundbreaking Hybrid Random Forest – Neural Network model for depression\n\nclassification, promising enhanced accuracy in mental health diagnosis.\n\n2. Our findings directly benefit clinical practice by enabling early depression detection, potentially improving\n\npatient outcomes in mental healthcare.\n\nThe paper is organized as follows: Section 2 provides a comprehensive literature review, summarizing prior work\nand baseline algorithms. Section 3 presents the proposed approach, whi"
  },
  {
    "title": "Challenges of Large Language Models for Mental Health Counseling",
    "authors": [
      "Neo Christopher Chung",
      "George Dyer",
      "Lennart Brocki"
    ],
    "abstract": "The global mental health crisis is looming with a rapid increase in mental\ndisorders, limited resources, and the social stigma of seeking treatment. As\nthe field of artificial intelligence (AI) has witnessed significant\nadvancements in recent years, large language models (LLMs) capable of\nunderstanding and generating human-like text may be used in supporting or\nproviding psychological counseling. However, the application of LLMs in the\nmental health domain raises concerns regarding the accuracy, effectiveness, and\nreliability of the information provided. This paper investigates the major\nchallenges associated with the development of LLMs for psychological\ncounseling, including model hallucination, interpretability, bias, privacy, and\nclinical effectiveness. We explore potential solutions to these challenges that\nare practical and applicable to the current paradigm of AI. From our experience\nin developing and deploying LLMs for mental health, AI holds a great promise\nfor improving mental health care, if we can carefully navigate and overcome\npitfalls of LLMs.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2311.13857v1",
    "pdf_url": "http://arxiv.org/pdf/2311.13857v1",
    "full_text": "3\n2\n0\n2\n\nv\no\nN\n3\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n7\n5\n8\n3\n1\n.\n1\n1\n3\n2\n:\nv\ni\nX\nr\na\n\nChallenges of Large Language Models for Mental Health\nCounseling\n\nNeo Christopher Chunga,b,∗, George Dyerb, Lennart Brockia,b\n\naInstitute of Informatics, University of Warsaw, Poland\nbInformatism, New Mexico, United States\n\nAbstract\n\nThe global mental health crisis is looming with a rapid increase in mental\ndisorders, limited resources, and the social stigma of seeking treatment. As\nthe ﬁeld of artiﬁcial intelligence (AI) has witnessed signiﬁcant advancements\nin recent years, large language models (LLMs) capable of understanding and\ngenerating human-like text may be used in supporting or providing psycho-\nlogical counseling. However, the application of LLMs in the mental health\ndomain raises concerns regarding the accuracy, eﬀectiveness, and reliability of\nthe information provided. This paper investigates the major challenges asso-\nciated with the development of LLMs for psychological counseling, including\nmodel hallucination, interpretability, bias, privacy, and clinical eﬀectiveness.\nWe explore potential solutions to these challenges that are practical and ap-\nplicable to the current paradigm of AI. From our experience in developing\nand deploying LLMs for mental health, AI holds a great promise for improv-\ning mental health care, if we can carefully navigate and overcome pitfalls of\nLLMs.\nKeywords:\ncounseling, psychology, chat bot, bias, interpretability\n2000 MSC: 68T07, 68T35, 68T50\n\nlarge language model, artiﬁcial intelligence, mental health,\n\nThe global prevalence of mental disorders is increasing owing to a lack of\ntreatment, services, and clinical professionals [1, 2]. Over 658 million people\nsuﬀer from psychological distress worldwide [3].\nIn the United Kingdom,\nonly 35% of people with mental health issues receive any form of therapy\n\n∗n.chung@uw.edu.pl\n\nPreprint submitted to Elsevier\n\nNovember 27, 2023\n\n \n \n \n \n \n \n\for treatment [4]. In this setting, the use of large language models (LLMs),\nrecently popularized by the transformer architecture [5, 6, 7], presents both\npromising opportunities and unique challenges in the ﬁeld of psychological\ncounseling.\n\nThese AI models have the potential to assist therapists in the daily provi-\nsion of mental health services, through content suggestion and patient man-\nagement [8, 9]. These eﬀorts tend to focus on mental health issues that\nare not life-threatening and rather requires counseling. In this role, AI can\nhelp providers scale the delivery of mental health services and reduce patient\ncosts, thus helping to address the global shortage of counselors and thera-\npists. Additionally, several applications have been developed that place an\nLLM model in the role of digital counselor [10, 11, 12]. The primary chal-\nlenge to all of these proposed uses is model accuracy and reliability, which\nare both critical for delivering ethical and eﬀective services. In this paper,\nwe will lay out major challenges and actionable solutions for using LLMs in\nthe mental health ﬁeld.\n\nLLMs are a subset of artiﬁcial neural networks (ANN) that demonstrate\nhuman-like general-purpose language understanding and generation. A broad\nreview of ML methods used in mental health counseling is available in [13].\nLLMs for language generation are built on the principle of autoregression,\nmeaning that the model is trained to predict the next token (roughly equiv-\nalent to the next word) in a given sequence of tokens. Their training is per-\nformed using large data sets of language [14, 15, 16] and the model learns to\npredict, given a sequence of tokens, a probability distribution over all tokens\nin its vocabulary for the next token in the sequence. In the current paradigm\nof LLMs (e.g., recurrent neural network [17]; transformer architecture [18]),\nthe apparent language understanding is therefore of purely stochastic nature\nand amounts to predicting what’s the most probable thing to “say” in a given\ncontext. Despite the ostensibly simple training objective of predicting the\nnext word,” LLMs acquire impressive capabilities when trained on extremely\nlarge sets of data [19, 20]. But the models do reﬂect the biases and patterns\nexisting in the training data [21, 22].\n\nSeveral mental health applications for use by individuals and institutions\nincorporate LLMs into their architecture. They can be divided into two\nbroad categories: 1) user facing counseling and therapy; and 2) therapist\nassistants. Among user facing applications, we ﬁnd some that provide an\nimmersive conversation experience directly with the underlying model (e.g.,\n[10, 11]), others that oﬀer a combination of open-ended conversation with\n\n2\n\n\fthe model and rule-based elements (e.g. [23]), and ﬁnally, those that rely on\nthe LLM primarily to understand and categorize the user’s message input,\nso as to better connect them with a “real” human therapist working for\nthe service [24, 9]. This last category of user facing apps may overlap with\ntherapist assistant apps, whose"
  },
  {
    "title": "An Integrative Survey on Mental Health Conversational Agents to Bridge\n  Computer Science and Medical Perspectives",
    "authors": [
      "Young Min Cho",
      "Sunny Rai",
      "Lyle Ungar",
      "João Sedoc",
      "Sharath Chandra Guntuku"
    ],
    "abstract": "Mental health conversational agents (a.k.a. chatbots) are widely studied for\ntheir potential to offer accessible support to those experiencing mental health\nchallenges. Previous surveys on the topic primarily consider papers published\nin either computer science or medicine, leading to a divide in understanding\nand hindering the sharing of beneficial knowledge between both domains. To\nbridge this gap, we conduct a comprehensive literature review using the PRISMA\nframework, reviewing 534 papers published in both computer science and\nmedicine. Our systematic review reveals 136 key papers on building mental\nhealth-related conversational agents with diverse characteristics of modeling\nand experimental design techniques. We find that computer science papers focus\non LLM techniques and evaluating response quality using automated metrics with\nlittle attention to the application while medical papers use rule-based\nconversational agents and outcome metrics to measure the health outcomes of\nparticipants. Based on our findings on transparency, ethics, and cultural\nheterogeneity in this review, we provide a few recommendations to help bridge\nthe disciplinary divide and enable the cross-disciplinary development of mental\nhealth conversational agents.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2310.17017v1",
    "pdf_url": "http://arxiv.org/pdf/2310.17017v1",
    "full_text": "An Integrative Survey on Mental Health Conversational Agents to Bridge\nComputer Science and Medical Perspectives\n\nYoung-Min Cho1\nJoão Sedoc2\n\nSunny Rai1 Lyle Ungar1\n\nSharath Chandra Guntuku1\n\n3\n2\n0\n2\n\nt\nc\nO\n5\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n7\n1\n0\n7\n1\n.\n0\n1\n3\n2\n:\nv\ni\nX\nr\na\n\n1University of Pennsylvania\n\n2New York University\n\n{jch0,sunnyrai,ungar,sharathg}@seas.upenn.edu, jsedoc@stern.nyu.edu\n\nAbstract\n\nMental health conversational agents (a.k.a.\nchatbots) are widely studied for their poten-\ntial to offer accessible support to those experi-\nencing mental health challenges. Previous sur-\nveys on the topic primarily consider papers pub-\nlished in either computer science or medicine,\nleading to a divide in understanding and hin-\ndering the sharing of beneficial knowledge be-\ntween both domains. To bridge this gap, we\nconduct a comprehensive literature review us-\ning the PRISMA framework, reviewing 534\npapers published in both computer science and\nmedicine. Our systematic review reveals 136\nkey papers on building mental health-related\nconversational agents with diverse characteris-\ntics of modeling and experimental design tech-\nniques. We find that computer science papers\nfocus on LLM techniques and evaluating re-\nsponse quality using automated metrics with\nlittle attention to the application while medi-\ncal papers use rule-based conversational agents\nand outcome metrics to measure the health out-\ncomes of participants. Based on our findings on\ntransparency, ethics, and cultural heterogeneity\nin this review, we provide a few recommenda-\ntions to help bridge the disciplinary divide and\nenable the cross-disciplinary development of\nmental health conversational agents.\n\n1\n\nIntroduction\n\nThe proliferation of conversational agents (CAs),\nalso known as chatbots or dialog systems, has\nbeen spurred by advancements in Natural Language\nProcessing (NLP) technologies. Their application\nspans diverse sectors, from education (Okonkwo\nand Ade-Ibijola, 2021; Durall and Kapros, 2020) to\ne-commerce (Shenoy et al., 2021), demonstrating\ntheir increasing ubiquity and potency.\n\nThe utility of CAs within the mental health do-\nmain has been gaining recognition. Over 30% of\nthe world’s population suffers from one or more\nmental health conditions; about 75% individuals in\nlow and middle-income countries and about 50%\n\nindividuals in high-income countries do not receive\ncare and treatment (Kohn et al., 2004; Arias et al.,\n2022). The sensitive (and often stigmatized) nature\nof mental health discussions further exacerbates\nthis problem, as many individuals find it difficult\nto disclose their struggles openly (Corrigan and\nMatthews, 2003).\n\nConversational agents like Woebot (Fitzpatrick\net al., 2017) and Wysa (Inkster et al., 2018) were\nsome of the first mobile applications to address this\nissue. They provide an accessible and consider-\nably less intimidating platform for mental health\nsupport, thereby assisting a substantial number of\nindividuals. Their effectiveness highlights the po-\ntential of mental health-focused CAs as one of the\nviable solutions to ease the mental health disclosure\nand treatment gap.\n\nDespite the successful implementation of certain\nCAs in mental health, a significant disconnect per-\nsists between research in computer science (CS)\nand medicine. This disconnect is particularly ev-\nident when we consider the limited adoption of\nadvanced NLP (e.g. large language models) mod-\nels in the research published in medicine. While CS\nresearchers have made substantial strides in NLP,\nthere is a lack of focus on the human evaluation\nand direct impacts these developments have on pa-\ntients. Furthermore, we observe that mental health\nCAs are drawing significant attention in medicine,\nyet remain underrepresented in health-applications-\nfocused research in NLP. This imbalance calls for\na more integrated approach in future studies to op-\ntimize the potential of these evolving technologies\nfor mental health applications.\n\nIn this paper, we present a comprehensive anal-\nysis of academic research related to mental health\nconversational agents, conducted within the do-\nmains of CS and medicine1. Employing the Pre-\nferred Reporting Items for Systematic Reviews\n\n1Our data and papers are available on our GitHub:\n\nhttps://github.com/JeffreyCh0/mental_chatbot_survey\n\n \n \n \n \n \n \n\fand Meta-Analyses (PRISMA) framework (Mo-\nher et al., 2010), we systematically reviewed 136\npertinent papers to discern the trends and research\ndirections in the domain of mental health conversa-\ntional agents over the past five years. We find that\nthere is a disparity in research focus and technol-\nogy across communities, which is also shown in the\ndifferences in evaluation. Furthermore, we point\nout the issues that apply across domains, including\ntransparency and language/cultural heterogeneity.\nThe primary objective of our study is to con-\nduct a systematic and transparent review of mental\nhealth CA research papers across the domains of\nCS and medicine. This process aims not on"
  },
  {
    "title": "Usable Security for ML Systems in Mental Health: A Framework",
    "authors": [
      "Helen Jiang",
      "Erwen Senge"
    ],
    "abstract": "While the applications and demands of Machine learning (ML) systems in mental\nhealth are growing, there is little discussion nor consensus regarding a\nuniquely challenging aspect: building security methods and requirements into\nthese ML systems, and keep the ML system usable for end-users. This question of\nusable security is very important, because the lack of consideration in either\nsecurity or usability would hinder large-scale user adoption and active usage\nof ML systems in mental health applications.\n  In this short paper, we introduce a framework of four pillars, and a set of\ndesired properties which can be used to systematically guide and evaluate\nsecurity-related designs, implementations, and deployments of ML systems for\nmental health. We aim to weave together threads from different domains,\nincorporate existing views, and propose new principles and requirements, in an\neffort to lay out a clear framework where criteria and expectations are\nestablished, and are used to make security mechanisms usable for end-users of\nthose ML systems in mental health. Together with this framework, we present\nseveral concrete scenarios where different usable security cases and profiles\nin ML-systems in mental health applications are examined and evaluated.",
    "year": 2020,
    "url": "http://arxiv.org/abs/2008.07738v1",
    "pdf_url": "http://arxiv.org/pdf/2008.07738v1",
    "full_text": "0\n2\n0\n2\n\ng\nu\nA\n8\n1\n\n]\n\nY\nC\n.\ns\nc\n[\n\n1\nv\n8\n3\n7\n7\n0\n.\n8\n0\n0\n2\n:\nv\ni\nX\nr\na\n\nUsable Security for ML Systems in Mental Health: A Framework\n\nHelen Jiang\nIndependent (aﬃliated with Georgia Institute of\nTechnology)\nhelen.h.jiang@gmail.com\n\nABSTRACT\nWhile the applications and demands of Machine learning (ML) sys-\ntems in mental health are growing, there is little discussion nor\nconsensus regarding a uniquely challenging aspect: building secu-\nrity methods and requirements into these ML systems, and keep\nthe ML system usable for end-users. This question of usable secu-\nrity is very important, because the lack of consideration in either\nsecurity or usability would hinder large-scale user adoption and\nactive usage of ML systems in mental health applications.\n\nIn this short paper, we introduce a framework of four pillars,\nand a set of desired properties which can be used to systematically\nguide and evaluate security-related designs, implementations, and\ndeployments of ML systems for mental health. We aim to weave to-\ngether threads from diﬀerent domains, incorporate existing views,\nand propose new principles and requirements, in an eﬀort to lay\nout a clear framework where criteria and expectations are estab-\nlished, and are used to make security mechanisms usable for end-\nusers of those ML systems in mental health. Together with this\nframework, we present several concrete scenarios where diﬀerent\nusable security cases and proﬁles in ML-systems in mental health\napplications are examined and evaluated.\n\nKEYWORDS\nMental Health, Machine Learning (ML), Security, Usability, Evalu-\nation, Computer System Life Cycle, Failure Modes\n\n1 INTRODUCTION\nWith a mental health crisis looming large and many ML systems\nbeing built for mental health use cases, it is challenging to trace,\nanalyze, and compare all the designs and implementations of such\nsystems. So far, there is a lack of well-deﬁned framework that de-\nscribes properties relating to the security of such ML systems in\nmental health, and even less considerations are given to how such\nsecurity mechanisms can be usable for those systems’ end users.\nHowever, without usable security, undiscovered, undisclosed, and\nill-considered limitations and properties of security decisions would\nhold back large-scale adoption and usage[2] of ML systems in men-\ntal health use cases. For more detailed and nuanced discussions, see\nour treatment at section 4.3.\n\nThe goal of this framework is to establish discussions in commu-\nnities of mental health, ML, and security, so we can build a com-\nmon ground for directions and expectations for usable security in\n\nKDD 2020 Workshop: Designing AI in Support of Good Mental Health (GOOD), August\n24th, 2020,\n© 2020 Association for Computing Machinery.\nThis is the author’s version of the work. It is posted here for your personal use. Not\nfor redistribution. The deﬁnitive Version of Record was published in KDD’20: KDD\nGOOD Workshop, August 24th 2020, https://doi.org/10.1145/1122445.1122456.\n\nErwen Senge\nIndependent\nerwen@protonmail.com\n\nML systems used in mental health scenarios. Moreover, this frame-\nwork serves to raise awareness, so that both ML and mental health\ncommunities will heed this critical aspect of usable security in ML\nsystems for mental health. We hope that this new, interdisciplinary\nframework would allow researchers and practitioners to system-\natically compare usable security attributes across ML systems for\nmental health, meanwhile to identify potential limitations of par-\nticular approaches and trade-oﬀs in diﬀerent scenarios.\n\nIn this short paper, we propose that ML systems in mental health\nuse cases, beyond the privacy and security requirements already\nmandated by legislation’s and regulations — for example, Health\nInsurance Portability and Accountability Act (HIPPA)[38, 43, 64]\nin United States, and General Data Protection Regulation (GDPR)\nin European Union and its member states’ national laws[11, 12]\n— should consider properties of usable security proposed by this\nframework’s four pillars, and be evaluated on their (1)context mod-\nels, (2)functionality criteria, (3)trustworthiness requirements,\nand (4)recovery principles across their life cycles.\n\nThis work presents our eﬀort to generate discussions and con-\nsensus for a common framework in a naturally interdisciplinary\narea. We built our research on the foundation of computer security\nresearch, which has a rich history and long tradition of devising\ncriteria and evaluation rubrics for system designs and implemen-\ntations. We also incorporated important and recent literature from\nhuman-computer interaction (HCI), usable security, and fairness,\naccountability, and transparency (FAT) research of ML. Weaving\nthese interdisciplinary threads together, we hope that our frame-\nwork will beneﬁt both researchers and practitioners working on\nML systems in mental health.\n\n2 RELATED WORK\nThere is a long and distinguished tradition in computer security re-\nsearch: presciently deﬁne evaluation criteri"
  },
  {
    "title": "Mobile Mental Health Apps: Alternative Intervention or Intrusion?",
    "authors": [
      "Shalini Saini",
      "Dhiral Panjwani",
      "Nitesh Saxena"
    ],
    "abstract": "Mental health is an extremely important subject, especially in these\nunprecedented times of the COVID-19 pandemic. Ubiquitous mobile phones can\nequip users to supplement psychiatric treatment and manage their mental health.\nMobile Mental Health (MMH) apps emerge as an effective alternative to assist\nwith a broad range of psychological disorders filling the much-needed\npatient-provider accessibility gap. However, it also raises significant\nconcerns with sensitive information leakage.The absence of a transparent\nprivacy policy and lack of user awareness may pose a significant threat to\nundermining the applicability of such tools. We conducted a multifold study of\n- 1) Privacy Policies (Manually and with Polisis, an automated framework to\nevaluate privacy policies); 2) App permissions; 3) Static Analysis for inherent\nsecurity issues; 4) Dynamic Analysis for threat surface and vulnerabilities\ndetection, and 5) Traffic Analysis.\n  Our results indicate that apps' exploitable flaws, dangerous permissions, and\ninsecure data handling pose a potential threat to the users' privacy and\nsecurity. The Dynamic analysis identified 145 vulnerabilities in 20 top-rated\nMMH apps where attackers and malicious apps can access sensitive information.\n45% of MMH apps use a unique identifier, Hardware Id, which can link a unique\nid to a particular user and probe users' mental health. Traffic analysis shows\nthat sensitive mental health data can be leaked through insecure data\ntransmission. MMH apps need better scrutiny and regulation for more widespread\nusage to meet the increasing need for mental health care without being\nintrusive to the already vulnerable population.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2206.10728v2",
    "pdf_url": "http://arxiv.org/pdf/2206.10728v2",
    "full_text": "Mobile Mental Health Apps:\nAlternative Intervention or Intrusion?\n\nShalini Saini\nDepartment of Computer Science\nTexas A&M University\nCollege Station, TX, USA\ns.saini@tamu.edu\n\nDhiral Panjwani\nIT- Department of Medicine\nUniveristy of Alabama at Birmingham\nBirmingham, AL, USA\ndpanjwani@uabmc.edu\n\nNitesh Saxena\nDepartment of Computer Science\nTexas A&M University\nCollege Station, TX, USA\nnsaxena@tamu.edu\n\n2\n2\n0\n2\n\nl\nu\nJ\n\n9\n\n]\n\nY\nC\n.\ns\nc\n[\n\n2\nv\n8\n2\n7\n0\n1\n.\n6\n0\n2\n2\n:\nv\ni\nX\nr\na\n\nAbstract—Mental health is an extremely important subject,\nespecially in these unprecedented times of the COVID-19 pan-\ndemic. Ubiquitous mobile phones can equip users to supplement\npsychiatric treatment and manage their mental health. Mobile\nMental Health (MMH) apps emerge as an effective alternative\nto assist with a broad range of psychological disorders ﬁlling\nthe much-needed patient-provider accessibility gap. However, it\nalso raises signiﬁcant concerns with sensitive information leakage.\nThe absence of a transparent privacy policy and lack of user\nawareness may pose a signiﬁcant threat to undermining the\napplicability of such tools. We conducted a multifold study of\n- 1) Privacy policies (Manually and with Polisis, an automated\nframework to evaluate privacy policies); 2) App permissions; 3)\nStatic Analysis for inherent security issues; 4) Dynamic Analysis\nfor threat surface and vulnerabilities detection, and 5) Trafﬁc\nAnalysis.\n\nOur results indicate that apps’ exploitable ﬂaws, dangerous\npermissions, and insecure data handling pose a potential threat to\nthe users’ privacy and security. The Dynamic analysis identiﬁed\n145 vulnerabilities in 20 top-rated MMH apps where attackers\nand malicious apps can access sensitive information. 45% of\nMMH apps use a unique identiﬁer, Hardware Id, which can\nlink a unique id to a particular user and probe users’ mental\nhealth. Trafﬁc analysis shows that sensitive mental health data\ncan be leaked through insecure data transmission. MMH apps\nneed better scrutiny and regulation for more widespread usage\nto meet the increasing need for mental health care without being\nintrusive to the already vulnerable population.\n\nIndex Terms—Mobile Apps, Mental Health, Privacy and Se-\n\ncurity\n\nI. INTRODUCTION\n\nAs per the Centers for Disease Control and Prevention\n(CDC), from mid-2020 to early 2021 (after starting COVID-\n19 ), there is an increase in anxiety or depressive disorder\nfrom 36.4% to 41.5%. The percentage of unmet mental health\ncare needs is increased from 9.2% to 11.7% [1]. Depression,\nanxiety, and other mental disorders can cripple everyday\nfunctioning and even can claim lives as suicide is the tenth\nleading cause of death in the U.S. [2]. Winkler et al. found\nthat COVID-19 increased the prevalence of major depressive\ndisorder and suicide risk three times and almost doubled\nthe current anxiety disorders [3]. However, a shortage of\nproviders may encourage people to seek alternatives more\noften for immediate help [4]. Ubiquitous mobile devices can\nhelp to bridge the patient-provider gap and health divide for\n\nunderserved and hard-to-reach populations to manage their\nmental health needs [5]. As per Wang et al., MMH apps\nhave the potential to improve mental health, but most of the\ncurrently available apps lack clinical evidence to support their\nefﬁcacy [6]. Mainstream clinical practice incorporating MMH\napps is also challenging as research is open to ensure that\ntechnological vulnerabilities do not compromise the privacy\nand safety of patients [7]–[9].\n\nMobile app developers may need standard guidelines to\ndevelop a secure MMH app with the help of the medical\ncommunity on the usability [10]. Selecting a secure and\nreliable MMH app from a vast pool of available MMH apps\nmay be daunting for the end-user. A well-deﬁned privacy\npolicy may be the starting point for app users in making de-\ncisions balancing information-sharing and preserving privacy.\nNo explicit declaration on apps’ permissions, information is\ncollected, and intended usage of collected information makes it\ndifﬁcult to grade the apps on security and privacy parameters.\nUnfortunately, unintended biases towards mental disorders\nincrease a victim’s vulnerability to unwanted or unknown\ndisclosure of his/her mental disorder.\n\nThere is a lack of reproducible rigorous scientiﬁc testing\nto support rapidly developed MMH apps and quick launches\nin awaiting market. Currently, there is no national standard\nfor evaluating the effectiveness of the available hundreds of\nmental health apps [11]. It is essential to maintain transparency\nin privacy policies to build the needed trust for the broader\nusage of MMH apps. Our contribution is manifold through\nthis study as follows:\n\n• Analyzing the availability, accessibility, and deﬁciencies\n\nof MMH apps’ privacy policies.\n\n• Dynamic analysis to explore the threat surface, dangerous\n\npermissions, and injection vulnerabilities.\n\n• Static analysis to study the apps’ code ﬁles exposing\n\nmajor exploitable security and privacy ﬂaws"
  },
  {
    "title": "Bias Reducing Multitask Learning on Mental Health Prediction",
    "authors": [
      "Khadija Zanna",
      "Kusha Sridhar",
      "Han Yu",
      "Akane Sano"
    ],
    "abstract": "There has been an increase in research in developing machine learning models\nfor mental health detection or prediction in recent years due to increased\nmental health issues in society. Effective use of mental health prediction or\ndetection models can help mental health practitioners re-define mental\nillnesses more objectively than currently done, and identify illnesses at an\nearlier stage when interventions may be more effective. However, there is still\na lack of standard in evaluating bias in such machine learning models in the\nfield, which leads to challenges in providing reliable predictions and in\naddressing disparities. This lack of standards persists due to factors such as\ntechnical difficulties, complexities of high dimensional clinical health data,\netc., which are especially true for physiological signals. This along with\nprior evidence of relations between some physiological signals with certain\ndemographic identities restates the importance of exploring bias in mental\nhealth prediction models that utilize physiological signals. In this work, we\naim to perform a fairness analysis and implement a multi-task learning based\nbias mitigation method on anxiety prediction models using ECG data. Our method\nis based on the idea of epistemic uncertainty and its relationship with model\nweights and feature space representation. Our analysis showed that our anxiety\nprediction base model introduced some bias with regards to age, income,\nethnicity, and whether a participant is born in the U.S. or not, and our bias\nmitigation method performed better at reducing the bias in the model, when\ncompared to the reweighting mitigation technique. Our analysis on feature\nimportance also helped identify relationships between heart rate variability\nand multiple demographic groupings.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2208.03621v1",
    "pdf_url": "http://arxiv.org/pdf/2208.03621v1",
    "full_text": "Bias Reducing Multitask Learning on Mental\nHealth Prediction\n\nKhadija Zanna, Kusha Sridhar, Han Yu, Akane Sano\nDepartment of Electrical and Computer Engineering\nRice University\nHouston, USA\n(khzanna, kh82, hy29, Akane.Sano)@rice.edu\n\n2\n2\n0\n2\n\ng\nu\nA\n7\n\n]\n\nG\nL\n.\ns\nc\n[\n\n1\nv\n1\n2\n6\n3\n0\n.\n8\n0\n2\n2\n:\nv\ni\nX\nr\na\n\nAbstract—There has been an increase in research in developing\nmachine learning models for mental health detection or predic-\ntion in recent years due to increased mental health issues in\nsociety. Effective use of mental health prediction or detection\nmodels can help mental health practitioners re-deﬁne mental\nillnesses more objectively than currently done, and identify\nillnesses at an earlier stage when interventions may be more\neffective. However, there is still a lack of standard in evaluating\nbias in such machine learning models in the ﬁeld, which leads\nto challenges in providing reliable predictions and in addressing\ndisparities. This lack of standards persists due to factors such as\ntechnical difﬁculties, complexities of high dimensional clinical\nhealth data, etc., which are especially true for physiological\nsignals. This along with prior evidence of relations between some\nphysiological signals with certain demographic identities restates\nthe importance of exploring bias in mental health prediction\nmodels that utilize physiological signals. In this work, we aim\nto perform a fairness analysis and implement a multi-task\nlearning based bias mitigation method on anxiety prediction\nmodels using ECG data. Our method is based on the idea of\nepistemic uncertainty and its relationship with model weights\nand feature space representation. Our analysis showed that our\nanxiety prediction base model introduced some bias with regards\nto age, income, ethnicity, and whether a participant is born in the\nU.S. or not, and our bias mitigation method performed better at\nreducing the bias in the model, when compared to the reweighting\nmitigation technique. Our analysis on feature importance also\nhelped identify relationships between heart rate variability and\nmultiple demographic groupings.\n\nIndex Terms—bias, epistemic uncertainty,\n\nfairness metric,\n\nMonte-Carlo dropout, protected label, multi-task learning\n\nI. INTRODUCTION AND BACKGROUND\n\nIrrespective of the advancements that machine learning has\nmade possible in several ﬁelds such as language technologies,\ncomputer vision and medical applications, negative bias is\noften embedded in the essence of machine learning algorithms.\nNegative bias is an erroneous assumption made by an algo-\nrithm, that is systemically prejudiced against certain groups\nof people. Negative biases can be encoded in algorithms\ndue to a number of factors, the ﬁrst being imbalance in the\nrepresentation of different population categories in the training\n\nThis work was supported by NSF #1840167 and #2047296.\n\ndata. If certain demographics are lacking from the sample\ndata, models trained on this data often do not generalize when\napplied to new data that contains those missing demographics\n[12]. The second factor that could introduce negative bias in\nmachine learning algorithms is biased human labeling. This is\ndue to the fact that data that are fed into models, especially\nsupervised or semi-supervised models which are widely used\nin various jurisdictions, are manually labeled by humans who\nare inherently biased. These models ultimately reﬂect people’s\nimpressions and sustain or further magnify bias from the\nlabeled data [34]. Training and labeled data aside, there is\nstill risk of introducing bias in the functional form of a model\nthrough features and modeling techniques [12].\n\nDue to the expanding popularity of machine learning and the\ninherent biases that come with it, there has been an increased\nfocus on bias and fairness in the ﬁeld. There are several works\non how to accurately deﬁne and measure fairness in systems\n[18], [21], [29], how to analyze and mitigate bias using various\ntechniques [12], [22], [38], and a few works that assess the\ntrade-offs between fairness and accuracy in these models [26],\n[33].\n\nMental health poses a signiﬁcant challenge for an individ-\nual’s well-being, and it is estimated that 792 million people\nlived with a mental health disorder in 2017 [27]. This is\nslightly more than one in ten people globally (10.7%). Rising\nstatistics like this has led to an increase in research on mental\nhealth, including mental health and well-being prediction using\nphysiological signals over the past couple of years. Several\nauthors research on predicting stress levels, and various mental\nhealth conditions using data collected both in clinical settings\nand in the wild [1], [7], [30], [31], [36], [39].\n\nWith the rise in popularity of this ﬁeld of research and\nits widespread applications in psychiatry and psychology, the\nneed for effective bias mitigation techniques has become\napparent, especially with the sensitive nature of physiological\ndata. Previous research that explored emotional responses\ncap"
  },
  {
    "title": "Identifying Risk Factors for Post-COVID-19 Mental Health Disorders: A\n  Machine Learning Perspective",
    "authors": [
      "Maitham G. Yousif",
      "Fadhil G. Al-Amran",
      "Hector J. Castro"
    ],
    "abstract": "In this study, we leveraged machine learning techniques to identify risk\nfactors associated with post-COVID-19 mental health disorders. Our analysis,\nbased on data collected from 669 patients across various provinces in Iraq,\nyielded valuable insights. We found that age, gender, and geographical region\nof residence were significant demographic factors influencing the likelihood of\ndeveloping mental health disorders in post-COVID-19 patients. Additionally,\ncomorbidities and the severity of COVID-19 illness were important clinical\npredictors. Psychosocial factors, such as social support, coping strategies,\nand perceived stress levels, also played a substantial role. Our findings\nemphasize the complex interplay of multiple factors in the development of\nmental health disorders following COVID-19 recovery. Healthcare providers and\npolicymakers should consider these risk factors when designing targeted\ninterventions and support systems for individuals at risk. Machine\nlearning-based approaches can provide a valuable tool for predicting and\npreventing adverse mental health outcomes in post-COVID-19 patients. Further\nresearch and prospective studies are needed to validate these findings and\nenhance our understanding of the long-term psychological impact of the COVID-19\npandemic. This study contributes to the growing body of knowledge regarding the\nmental health consequences of the COVID-19 pandemic and underscores the\nimportance of a multidisciplinary approach to address the diverse needs of\nindividuals on the path to recovery. Keywords: COVID-19, mental health, risk\nfactors, machine learning, Iraq",
    "year": 2023,
    "url": "http://arxiv.org/abs/2309.16055v1",
    "pdf_url": "http://arxiv.org/pdf/2309.16055v1",
    "full_text": "  https://www.isohe.org/medical-advances-and-innovations-journal     August  2023 | Volume 1 | Issue 3 \n\nIdentifying Risk Factors for Post-COVID-19 Mental Health Disorders: A Machine \nLearning Perspective \n\nMaitham G. Yousif*1\n\n , Fadhil G. Al-Amran2, Hector J. Castro3  \n\n1Biology Department, College of Science, University of Al-Qadisiyah, Iraq, Visiting Professor in Liverpool John Moors \nUniversity, Liverpool, United Kingdom \n\n2Cardiovascular Department, College of Medicine, Kufa University, Iraq  \n\n3Specialist in Internal Medicine - Pulmonary Disease in New York, USA  \n\nReceived 3/10/2022, Accepted 2/2/2023, Published 1/8/2023 \n\n This work is licensed under a Creative Commons Attribution 4.0 International License. \n\nAbstract \n\n   In this study, we leveraged machine learning techniques to identify risk factors associated with post-\nCOVID-19  mental  health  disorders.  Our  analysis,  based  on  data  collected  from  669  patients  across \nvarious  provinces  in  Iraq,  yielded  valuable  insights.  We  found  that  age,  gender,  and  geographical \nregion  of  residence  were  significant  demographic  factors  influencing  the  likelihood  of  developing \nmental  health  disorders  in  post-COVID-19  patients.  Additionally,  comorbidities  and  the  severity  of \nCOVID-19  illness  were  important  clinical  predictors.  Psychosocial  factors,  such  as  social  support, \ncoping strategies, and perceived stress levels, also played a substantial role. Our findings emphasize \nthe  complex  interplay  of  multiple  factors  in  the  development  of  mental  health  disorders  following \nCOVID-19  recovery.  Healthcare  providers and  policymakers  should  consider  these  risk  factors when \ndesigning targeted interventions and support systems for individuals at risk. Machine learning-based \napproaches  can  provide  a  valuable  tool  for  predicting  and  preventing  adverse  mental  health \noutcomes in post-COVID-19 patients. Further research and prospective studies are needed to validate \nthese findings and enhance our understanding of the long-term psychological impact of the COVID-19 \npandemic.  This  study  contributes  to  the  growing  body  of  knowledge  regarding  the  mental  health \nconsequences  of  the  COVID-19  pandemic  and  underscores  the  importance  of  a  multidisciplinary \napproach to address the diverse needs of individuals on the path to recovery. \n\nKeywords: COVID-19, mental health, risk factors, machine learning, Iraq \n\n*Corresponding author: Maithm Ghaly Yousif  matham.yousif@qu.edu.iq    m.g.alamran@ljmu.ac.uk \n\n                     https://www.isohe.org/medical-advances-and-innovations-journal                               \n\n1 \n\n                                               August  2023 | Volume 1 | Issue 3 \n\n \n \n \n                                 \n \n \n \n \n\f  https://www.isohe.org/medical-advances-and-innovations-journal     August  2023 | Volume 1 | Issue 3 \n\nIntroduction \n\nto \n\nvarious \n\nThe  COVID-19  pandemic,  caused  by  the  novel \ncoronavirus  SARS-CoV-2,  has  not  only  posed  a \nsignificant threat to global public health but has \nindirect \nlight \nalso  brought \nconsequences affecting individuals' mental well-\nbeing[1-5].  As  healthcare  systems  around  the \nworld grapple with the immediate challenges of \ntreating  COVID-19  patients, \nit  has  become \nincreasingly  evident  that  there  is  a  pressing \nneed  to  understand  and  address  the  potential \nlong-term  mental  health  repercussions  of  this \nglobal crisis. Numerous studies have reported a \nspectrum  of  mental  health  issues  emerging  in \nincluding \nthe  wake  of  COVID-19  recovery, \nanxiety,  depression,  post-traumatic \nstress \ndisorder  (PTSD),  and  other  neuropsychiatric \noften \ndisorders[4-6]. \ncollectively referred to as post-COVID-19 mental \nhealth disorders, can be debilitating and require \ncomprehensive evaluation, risk assessment, and \ntimely intervention. To effectively mitigate these \nmental  health  challenges,  it  is  imperative  to \nidentify  the  risk  factors  contributing  to  their \nits \ndevelopment.  Machine \ncapacity  to  analyze  vast  datasets  and  extract \n\nlearning,  with \n\nconditions, \n\nThese \n\nfacilities \n\nintricate  patterns,  presents  an  invaluable  tool \nfor this purpose[7-9]. By leveraging data-driven \ninsights, we can gain a deeper understanding of \nthe variables and circumstances that predispose \nindividuals  to  post-COVID-19  mental  health \ndisorders.  In  this  study,  we  utilize  a  machine \nlearning  perspective  to  identify  key  risk  factors \nassociated  with  the  onset  of  mental  health \ndisorders in individuals recovering from COVID-\n19.  Our  dataset  comprises  medical  information \nfrom  669  patients  collected  across  various \nIraq.  By  applying \nin \nhealthcare \nadvanced  analytical  techniques,  we  aim  to \npinpoint \nsignificantly \ninfluence  the  likelihood  of  developing  mental \nhealth \nfollowing  COVID-19 \ninfection.  This  "
  },
  {
    "title": "What Makes Digital Support Effective? How Therapeutic Skills Affect\n  Clinical Well-Being",
    "authors": [
      "Anna Fang",
      "Wenjie Yang",
      "Raj Sanjay Shah",
      "Yash Mathur",
      "Diyi Yang",
      "Haiyi Zhu",
      "Robert Kraut"
    ],
    "abstract": "Online mental health support communities have grown in recent years for\nproviding accessible mental and emotional health support through volunteer\ncounselors. Despite millions of people participating in chat support on these\nplatforms, the clinical effectiveness of these communities on mental health\nsymptoms remains unknown. Furthermore, although volunteers receive some\ntraining based on established therapeutic skills studied in face-to-face\nenvironments such as active listening and motivational interviewing, it remains\nunderstudied how the usage of these skills in this online context affects\npeople's mental health status. In our work, we collaborate with one of the\nlargest online peer support platforms and use both natural language processing\nand machine learning techniques to measure how one-on-one support chats affect\ndepression and anxiety symptoms. We measure how the techniques and\ncharacteristics of support providers, such as using affirmation, empathy, and\npast experience on the platform, affect support-seekers' mental health changes.\nWe find that online peer support chats improve both depression and anxiety\nsymptoms with a statistically significant but relatively small effect size.\nAdditionally, support providers' techniques such as emphasizing the autonomy of\nthe client lead to better mental health outcomes. However, we also found that\nsome behaviors (e.g. persuading) are actually harmful to depression and anxiety\noutcomes. Our work provides key understanding for mental health care in the\nonline setting and designing training systems for online support providers.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2312.10775v1",
    "pdf_url": "http://arxiv.org/pdf/2312.10775v1",
    "full_text": "3\n2\n0\n2\nc\ne\nD\n7\n1\n\n]\n\nC\nH\n.\ns\nc\n[\n\n1\nv\n5\n7\n7\n0\n1\n.\n2\n1\n3\n2\n:\nv\ni\nX\nr\na\n\nWhat Makes Digital Support Effective? How Therapeutic Skills Affect Clinical\nWell-Being\n\nWENJIE YANG* and ANNA FANG*, Carnegie Mellon University, USA\nRAJ SANJAY SHAH, Georgia Institute of Technology, USA\nYASH MATHUR, Carnegie Mellon University, USA\nDIYI YANG, Stanford University, USA\nHAIYI ZHU, Carnegie Mellon University, USA\nROBERT KRAUT, Carnegie Mellon University, USA\n\nOnline mental health support communities have grown in recent years for providing accessible mental and emotional health support\n\nthrough volunteer counselors. Despite millions of people participating in chat support on these platforms, the clinical effectiveness of\n\nthese communities on mental health symptoms remains unknown. Furthermore, although volunteers receive some training based on\n\nestablished therapeutic skills studied in face-to-face environments such as active listening and motivational interviewing, it remains\n\nunderstudied how the usage of these skills in this online context affects people’s mental health status. In our work, we collaborate\n\nwith one of the largest online peer support platforms and use both natural language processing and machine learning techniques to\n\nmeasure how one-on-one support chats affect depression and anxiety symptoms. We measure how the techniques and characteristics\n\nof support providers, such as using affirmation, empathy, and past experience on the platform, affect support-seekers’ mental health\n\nchanges. We find that online peer support chats improve both depression and anxiety symptoms with a statistically significant but\n\nrelatively small effect size. Additionally, support providers’ techniques such as emphasizing the autonomy of the client lead to better\n\nmental health outcomes. However, we also found that some behaviors (e.g. persuading) are actually harmful to depression and anxiety\n\noutcomes. Our work provides key understanding for mental health care in the online setting and designing training systems for online\n\nsupport providers.\n\nCCS Concepts: • Human-centered computing → Empirical studies in collaborative and social computing.\n\nAdditional Key Words and Phrases: online communities, mental health, peer support, social computing\n\nACM Reference Format:\n\nWenjie Yang*, Anna Fang*, Raj Sanjay Shah, Yash Mathur, Diyi Yang, Haiyi Zhu, and Robert Kraut. 2023. What Makes Digital Support\n\nEffective? How Therapeutic Skills Affect Clinical Well-Being. 1, 1 (December 2023), 27 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn\n\n1 INTRODUCTION\n\nMental health issues continue to rise globally and under-treatment of serious mental health problems remains a major\n\nproblem, with more than one in ten people living with a mental health disorder [20]. Although there is significant\n\nAuthors’ addresses: Wenjie Yang*; Anna Fang*, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Raj Sanjay Shah, Georgia Institute of\nTechnology, USA; Yash Mathur, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Diyi Yang, Stanford University, USA; Haiyi Zhu, Carnegie\nMellon University, Pittsburgh, Pennsylvania, USA; Robert Kraut, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA.\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not\nmade or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components\nof this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to\nredistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\n\n© 2023 Association for Computing Machinery.\nManuscript submitted to ACM\n\nManuscript submitted to ACM\n\n1\n\n \n \n \n \n \n \n\f2\n\nFang and Yang et al.\n\nevidence supporting the effectiveness of professional treatments, such as therapy, a substantial proportion of people\n\nwith mental health problems fail to receive any treatment due to reasons such as lacking access to services or having\n\nneeds unmet by health services [48, 65]. As a result, peer-to-peer support through online mental health communities\n\n(OMHCs) has emerged as an accessible tool for achieving mental and emotional support. OMHCs include sites like 7\n\nCups and TalkLife, which usually provide free 24/7 peer-to-peer support from volunteers; online support communities\n\nare thus able to provide mental and emotional support at scale and on a wide variety of challenges [25, 31].\n\nDespite the many benefits available through OMHCs, support providers on online platforms receive relatively\n\nlittle training [105] in contrast to the extensive training for mental health professionals and even volunteers for crisis\n\nintervention programs [10, 35, 67, 71]. OMHCs often require volunteer support providers to complete short training\n\nsessions along with opt"
  },
  {
    "title": "Share with Me: A Study on a Social Robot Collecting Mental Health Data",
    "authors": [
      "Raida Karim",
      "Edgar Lopez",
      "Katelynn Oleson",
      "Tony Li",
      "Elin A. Björling",
      "Maya Cakmak"
    ],
    "abstract": "Social robots have been used to assist with mental well-being in various ways\nsuch as to help children with autism improve on their social skills and\nexecutive functioning such as joint attention and bodily awareness. They are\nalso used to help older adults by reducing feelings of isolation and\nloneliness, as well as supporting mental well-being of teens and children.\nHowever, existing work in this sphere has only shown support for mental health\nthrough social robots by responding interactively to human activity to help\nthem learn relevant skills. We hypothesize that humans can also get help from\nsocial robots in mental well-being by releasing or sharing their mental health\ndata with the social robots. In this paper, we present a human-robot\ninteraction (HRI) study to evaluate this hypothesis. During the five-day study,\na total of fifty-five (n=55) participants shared their in-the-moment mood and\nstress levels with a social robot. We saw a majority of positive results\nindicating it is worth conducting future work in this direction, and the\npotential of social robots to largely support mental well-being.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2208.04389v1",
    "pdf_url": "http://arxiv.org/pdf/2208.04389v1",
    "full_text": "2\n2\n0\n2\n\ng\nu\nA\n8\n\n]\n\nO\nR\n.\ns\nc\n[\n\n1\nv\n9\n8\n3\n4\n0\n.\n8\n0\n2\n2\n:\nv\ni\nX\nr\na\n\nShare with Me: A Study on a Social Robot\nCollecting Mental Health Data(cid:63)\n\nRaida Karim1[0000−0002−2854−3985], Edgar Lopez1[0000−0001−6835−855X],\nKatelynn Oleson1, Tony Li1[0000−0001−7552−6689], Elin A.\nBj¨orling1[0000−0002−0385−2562], and Maya Cakmak1[0000−0001−8457−6610]\n\nUniversity of Washington WA 98195, USA\n{rk1997, mcakmak}@cs.washington.edu,\n{lopeze7, kjoleson, tonywli, bjorling}@uw.edu\n\nAbstract. Social robots have been used to assist with mental well-being\nin various ways such as to help children with autism improve on their\nsocial skills and executive functioning such as joint attention and bodily\nawareness. They are also used to help older adults by reducing feelings of\nisolation and loneliness, as well as supporting mental well-being of teens\nand children. However, existing work in this sphere has only shown sup-\nport for mental health through social robots by responding interactively\nto human activity to help them learn relevant skills. We hypothesize that\nhumans can also get help from social robots in mental well-being by re-\nleasing or sharing their mental health data with the social robots. In this\npaper, we present a human-robot interaction (HRI) study to evaluate this\nhypothesis. During the ﬁve-day study, a total of ﬁfty-ﬁve (n=55) partic-\nipants shared their in-the-moment mood and stress levels with a social\nrobot. We saw a majority of positive results indicating it is worth con-\nducting future work in this direction, and the potential of social robots\nto largely support mental well-being.\n\nKeywords: Social Robot · Mental Health · Data Sharing.\n\n1\n\nIntroduction\n\nApart from genetic or birth related causes, any kind of mental health issues\nin our daily lives are usually caused by some kind of trouble such as stressful\nevents, grief from accidents or deaths, and trauma from tragic or fearful inci-\ndents [19]. Research shows that sharing these troubling experiences helps gain\ninsights from others which helps develop coping skills, and makes one feel less\nalone in pain which helps to tackle trouble more eﬀectively [3][12]. Therefore,\nsharing about trouble can potentially help treat or lessen mental health issues.\nHowever, people are not always willing to share their mental health with oth-\ners or publicly, even with their family members, let alone outside community\n\n(cid:63) This study was funded in part by National Science Foundation: National Robotics\nInitiative, SES: Award Abstract 1734100 - Design and Development of a Social Robot\nfor Gathering Ecological Momentary Stress Data from Teens.\n\n \n \n \n \n \n \n\f2\n\nR. Karim et al.\n\nmembers due to social stigma, personal beliefs or limitations [18]. Therefore, to\ntackle mental health issues, the main source of support is usually individualized\ntherapy, which is expensive and thus inaccessible to many [7][17]. Digital therapy\nis a relatively more accessible option compared to in-person therapy because of\nlower cost and availability in any location [1][20]. However, digital therapy has\ndrawbacks, such as lack of face-to-face interaction, user disengagement, and soft-\nware incompatibility [8]. So, we hypothesize that sharing mental health with an\nendearing social robot that overcomes these challenges of therapy options can\nhelp support mental health.\n\n2 Related Work\n\nWhen people share their personally relevant emotions in social media like Face-\nbook, they experience satisfaction causing positive mental state [3]. People tend\nto be discreet about sharing their emotional data, as we see Facebook users\nshare more intense and negative emotions in private messages [3]. Prior work\nthat looked into sharing one’s emotions through technologies like a virtual mood\nwall reported a positive relation between online emotional sharing and comfort\nin negative emotions [12]. Social robots are often perceived as friendly or pet-like\ncompanions by humans for their endearing appearances (e.g., outﬁt, facial ex-\npressions) and capabilities that can include haptics, sounds, and movements [16].\nSuch perceptions or relationships boost user engagement with social robots [4].\nThus, social robots can better foster emotional support with mental health data\ncompared to other technologies (e.g., smartphone apps, websites rendered by\ntouch screen devices) [6]. In a study conducted by Bj¨orling et al. [5], teens re-\nported social robots as a plausible source of emotional support. Additionally,\nsocial robots have been studied in the context of assisting mental healthcare by\nsharing its emotions with people [11], having behavioral models fulﬁlling user\nneeds [15], and providing companionship [9].\nTo the best of our knowledge, the existing literature in this domain does indicate\nthat social robots have not yet been used as a means for collecting mental health\ndata from humans, which makes this research direction a novel one in HRI.\n\n3 Sharing Mental Health Data with a Social Robot\n\n3.1 Study Setup\n\nWe conduct a ﬁ"
  },
  {
    "title": "WellXplain: Wellness Concept Extraction and Classification in Reddit\n  Posts for Mental Health Analysis",
    "authors": [
      "Muskan Garg"
    ],
    "abstract": "During the current mental health crisis, the importance of identifying\npotential indicators of mental issues from social media content has surged.\nOverlooking the multifaceted nature of mental and social well-being can have\ndetrimental effects on one's mental state. In traditional therapy sessions,\nprofessionals manually pinpoint the origins and outcomes of underlying mental\nchallenges, a process both detailed and time-intensive. We introduce an\napproach to this intricate mental health analysis by framing the identification\nof wellness dimensions in Reddit content as a wellness concept extraction and\ncategorization challenge. We've curated a unique dataset named WELLXPLAIN,\ncomprising 3,092 entries and totaling 72,813 words. Drawing from Halbert L.\nDunn's well-regarded wellness theory, our team formulated an annotation\nframework along with guidelines. This dataset also includes human-marked\ntextual segments, offering clear reasoning for decisions made in the wellness\nconcept categorization process. Our aim in publishing this dataset and\nanalyzing initial benchmarks is to spearhead the creation of advanced language\nmodels tailored for healthcare-focused concept extraction and categorization.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2308.13710v1",
    "pdf_url": "http://arxiv.org/pdf/2308.13710v1",
    "full_text": "Highlights\n\nWELLXPLAIN: Wellness Concept Extraction and Classification in Reddit Posts for Mental Health\nAnalysis\nMuskan Garg\n\n• Introducing the need of datasets for reliable simulations in mental healthcare.\n\n• Corpus construction for wellness concept extraction and classification.\n\n• Analyzing domain-specific transformers and large language models for this task.\n\n• Examining reliability of traditional multi-class classifiers.\n\n3\n2\n0\n2\n\ng\nu\nA\n5\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n0\n1\n7\n3\n1\n.\n8\n0\n3\n2\n:\nv\ni\nX\nr\na\n\n \n \n \n \n \n \n\fWELLXPLAIN: Wellness Concept Extraction and Classification in\nReddit Posts for Mental Health Analysis\n\nMuskan Garga,∗,1\n\naMayo Clinic, Rochester, 55901 MN, USA\n\nA R T I C L E I N F O\n\nA B S T R A C T\n\nKeywords:\nCorpus construction\nmental health\nWellXplain\nwellness dimensions\n\nAmid the ongoing mental health crisis, there is an increasing need to discern possible signs of mental\ndisturbance manifested in social media text. Neglecting multi-dimensional aspects of social and mental\nwell-being (i.e., wellness dimensions) over time can adversely affect an individual’s mental health.\nDuring in-person therapy sessions, manual efforts are used to identify the causes and consequences\nof triggering latent factors of mental disturbance, which is a meticulous and time-consuming task for\nmental health professionals. To enable such fine-grained mental health screening, we define the task\nof determining wellness dimensions in Reddit posts as wellness concept extraction and classification\nproblem. We construct a novel dataset called WELLXPLAIN, which consists of 3,092 instances and\na total of 72,813 words. Our experts developed an annotation scheme and perplexity guidelines for\nannotation based on a well-adapted Halbert L. Dunn’s theory of wellness dimensions. Further, the\ndata encompasses human-annotated text spans as pertinent explanations for decision-making during\nwellness concept classification. We anticipate that releasing the dataset and evaluating the baselines\nwill facilitate the development of new language models for concept extraction and classification in\nhealthcare domain.\n\n1. Introduction\n\nA clinically significant impairment in a person’s in-\ntellect, emotional control, or behavior is what is known\nas a mental disorder, suggesting cognitive decline. The\nUN Resolution of “Transforming our World: the Agenda\n2030 for Sustainable Development” adopted in September\n2015 [1], outlined an ambitious vision to tackle Goal 3:\nEnsure healthy lives and promote well-being for all at all\nages of Sustainable Development Goals (SDG). By 2030,\nUN plans to reduce by one-third premature mortality from\nnon-communicable diseases through prevention/treatment\nand promote the mental health and well-being.1 Untreated\ndepression is conjectured to be the leading cause of sui-\ncide [2]. Reports released in August 20212 indicate that\n1.6 million people in England were on waiting lists to seek\nprofessional help with mental health care.\n\nDespite significant technological advances, mental health\nassessment remains a dark mark on public health efforts.\nCauses for mental health disturbances are broad, including\nan unspecific gamut of factors such as physical health prob-\nlems, social conflicts (e.g., bullying, prejudice, stigma, race\nissues), abuse, grief, financial and professional difficulties,\netc.. These causes are aggravated when patients do not\ndisclose their concerns to mental health professionals, rather\nfind solace on social media [3]. Motivated with non-intrusive\nhigh value information, social media data lessens the effect\nof limited availability of mental health practitioners. In these\ndire circumstances, online platforms are frequently relied\n\ngarg.muskan@mayo.edu (M. Garg)\n\nORCID(s):\n1https://www.un.org/development/desa/disabilities/envision2030-\n\ngoal3.html\n\n2https://www.theguardian.com/society/2021/aug/29/strain-on-mental-\n\nhealth-care-leaves-8m-people-without-help-say-nhs-leaders\n\nupon not only as open and unobtrusive sources of informa-\ntion, but also as a place for honest disclosure, where people\nmay freely express themselves along with their thoughts,\nbeliefs, and emotions [4].\n\nHowever, social media is extremely noisy because of\npopular culture references and slang terms that are pervasive\nin online expressions. This noise makes it hard to develop\nautomated methods for mental health screening methods that\nlevels with mental health professionals [5, 6]. Furthermore,\nprior work on mental health analyses from social media\nfocuses on assessing posts that already exhibit particular\nmental health traits (e.g., analyzing mental health subreddits\nrelated to suicidality and depression) [7, 8, 9].\n\nAmid the huge social impact of COVID-19 pandemic,\nthe research community witness the presence of mental\ndisorders in an individual through consequential affect on\nwellness dimensions due to prevailing reasons behind men-\ntal disturbance. We do not intend to invalidate the prior\nworks with causal analysis such as CAMS, but expect to\n"
  },
  {
    "title": "Associational and plausible causal effects of COVID-19 public health\n  policies on economic and mental distress",
    "authors": [
      "Reka Sundaram-Stukel",
      "Richard J Davidson"
    ],
    "abstract": "Background The COVID-19 pandemic has increased mental distress globally. The\nproportion of people reporting anxiety is 26%, and depression is 34% points.\nDisentangling associational and causal contributions of behavior, COVID-19\ncases, and economic distress on mental distress will dictate different\nmitigation strategies to reduce long-term pandemic-related mental distress.\nMethods We use the Household Pulse Survey (HPS) April 2020 to February 2021\ndata to examine mental distress among U.S. citizens attributable to COVID-19.\nWe combined HPS survey data with publicly available state-level weekly:\nCOVID-19 case and death data from the Centers for Disease Control, public\npolicies, and Apple and Google mobility data. Finally, we constructed economic\nand mental distress measures to estimate structural models with lag dependent\nvariables to tease out public health policies' associational and causal path\ncoefficients on economic and mental distress. Findings From April 2020 to\nFebruary 2021, we found that anxiety and depression had steadily climbed in the\nU.S. By design, mobility restrictions primarily affected public health policies\nwhere businesses and restaurants absorbed the biggest hit. Period t-1 COVID-19\ncases increased job loss by 4.1% and economic distress by 6.3% points in the\nsame period. Job-loss and housing insecurity in t-1 increased period t mental\ndistress by 29.1% and 32.7%, respectively. However, t-1 food insecurity\ndecreased mental distress by 4.9% in time t. The pandemic-related potential\ncausal path coefficient of period t-1 economic distress on period t depression\nis 57.8%, and anxiety is 55.9%. Thus, we show that period t-1 COVID-19 case\ninformation, behavior, and economic distress may be causally associated with\npandemic related period t mental distress.",
    "year": 2021,
    "url": "http://arxiv.org/abs/2112.11564v1",
    "pdf_url": "http://arxiv.org/pdf/2112.11564v1",
    "full_text": "Title: Associational and plausible causal effects of COVID-19 public health policies on economic and \nmental distress. \n\nReka Sundaram-Stukel1 and Richard J Davidson2 \n\nSummary \nBackground  \nThe COVID-19 pandemic has increased mental distress globally. The proportion of people reporting \nanxiety is 26%, and depression is 34% points. Disentangling associational and causal contributions of \nbehavior, COVID-19 cases, and economic distress on mental distress will dictate different mitigation \nstrategies to reduce long-term pandemic-related mental distress. \nMethods We use the Household Pulse Survey (HPS) April 2020 – February 2021 data to examine \nmental distress among U.S. citizens attributable to COVID-19. We combined HPS survey data with \npublicly available state-level weekly: COVID-19 case and death data from the Centers for Disease \nControl, public policies, and Apple and Google mobility data. Finally, we constructed economic and \nmental distress measures to estimate structural models with lag dependent variables to tease out public \nhealth policies' associational and causal path coefficients on economic and mental distress.  \nFindings  \nFrom April 2020 to February 2021, we found that anxiety and depression had steadily climbed in the \nU.S. By design, mobility restrictions primarily affected public health policies where businesses and \nrestaurants absorbed the biggest hit. Period t-1 COVID-19 cases increased job-loss by 4.1% and \neconomic distress by 6.3% points in the same period. Job-loss and housing insecurity in t-1 increased \nperiod t mental distress by 29.1% and 32.7%, respectively. However, t-1 food insecurity decreased \nmental distress by 4.9% in time t. The pandemic-related potential causal path coefficient of period t-1 \neconomic distress on period t depression is 57.8%, and anxiety is 55.9%. Thus, we show that period t-1 \nCOVID-19 case information, behavior, and economic distress may be causally associated with \npandemic-related period t mental distress. \nInterpretation  \nExploring the association and potential causal relationships between economic distress at t-1 and \nmental distress at t may have several interpretations. First, long-term pandemic-related involuntary job \nloss could have persistent wage scarring effects for many workers post-pandemic. Second, labor \nproductivity may decline because of the lingering effects of mental distress. Third, as the economy \nrecovers, investments in job-retraining programs with skill appreciation complemented with resilience \ntraining for displaced workers would enhance welfare. Finally, expanded mental health teleservices for \nworkers adjusting to post-pandemic work-life may increase emotional well-being.  \nFunding No funding was used to support this research. \nAcknowledgements \nWe thank Dr. Adams for many discussions, valuable feedback, and detailed comments. Ms. Stukel for \nediting. All errors are our own. \n\nAuthor Information \n1Dr. Reka Sundaram-Stukel (corresponding author) \nResearch Fellow, Department of Economics \n7415 Social Sciences, University of Wisconsin–Madison, Madison, Wisconsin 53706 \nrsundara@wisc.edu \n\n2Dr. Richard J Davidson \nWilliam James Professor of Psychology and Psychiatry \n318 Psychology, University of Wisconsin–Madison, Madison, Wisconsin 53706 \nrjdavids@wisc.edu \n\n1 \n\n \n \n \n \n \n\fResearch in context  \n\nEvidence before this study  \nOur search terms in APA, PubMed, medRxiv, arXiv, NBER, and Econlit included “anxiety,” “fear,” \n“depression,” “mental health,” “COVID-19”, “COVID-19”, “economic fallout,” “stimulus,” “unemployment \ninsurance,” “employment,” “eviction,” and “economic distress.” We focused on all studies from April \n2020 to May 2021 that met the search criteria and were COVID-19 relevant. We found five major \nempirical studies that directly addressed either significant mental health or economic consequences of \nCOVID-19. We excluded the studies that relied on simulated data or studies that used theoretical \nmodels unsupported by data. Nevertheless, there is a consensus that mental distress restricts \nconsumption behavior, that mental distress is rising among the US population, those in high contact \nsectors disproportionately feel economic fallout, and that recovery from the COVID-19 pandemic is \nlikely to follow a “K” shaped path where some economic sectors recover fast, and others fall behind. \nThe mental health side of the story acknowledges that there are widespread increases in anxiety, fear, \nworry, and depression. Still, no large-scale studies explicitly link these factors to economic distress. \n\nAdded value of this study  \nThe unique large-scale shock of COVID-19 that precipitated stringent public health containment \nmeasures caused an economic and mental health crisis. We unpack the causal implications of case \ninformation, behavior, and public policy on economic and mental distress. \n\nImplications of all the available evidence  \nCompared to pre-pandemic reported prevalence rates for anxiety and depression, the "
  },
  {
    "title": "MentalBERT: Publicly Available Pretrained Language Models for Mental\n  Healthcare",
    "authors": [
      "Shaoxiong Ji",
      "Tianlin Zhang",
      "Luna Ansari",
      "Jie Fu",
      "Prayag Tiwari",
      "Erik Cambria"
    ],
    "abstract": "Mental health is a critical issue in modern society, and mental disorders\ncould sometimes turn to suicidal ideation without adequate treatment. Early\ndetection of mental disorders and suicidal ideation from social content\nprovides a potential way for effective social intervention. Recent advances in\npretrained contextualized language representations have promoted the\ndevelopment of several domain-specific pretrained models and facilitated\nseveral downstream applications. However, there are no existing pretrained\nlanguage models for mental healthcare. This paper trains and release two\npretrained masked language models, i.e., MentalBERT and MentalRoBERTa, to\nbenefit machine learning for the mental healthcare research community. Besides,\nwe evaluate our trained domain-specific models and several variants of\npretrained language models on several mental disorder detection benchmarks and\ndemonstrate that language representations pretrained in the target domain\nimprove the performance of mental health detection tasks.",
    "year": 2021,
    "url": "http://arxiv.org/abs/2110.15621v1",
    "pdf_url": "http://arxiv.org/pdf/2110.15621v1",
    "full_text": "MentalBERT:\nPublicly Available Pretrained Language Models for Mental Healthcare\n\nShaoxiong Ji†, Tianlin Zhang‡, Luna Ansari†, Jie Fu§, Prayag Tiwari†, and Erik Cambria¶\n† Aalto University, Finland ‡ The University of Manchester, UK\n§ Mila, Québec AI Institute, Canada ¶ Nanyang Technological University, Singapore\n{shaoxiong.ji; luna.ansari; prayag.tiwari}@aalto.fi\ntianlin.zhang@postgrad.manchester.ac.uk\n\nfujie@mila.quebec\n\ncambria@ntu.edu.sg\n\nAbstract\n\nMental health is a critical issue in modern so-\nciety, and mental disorders could sometimes\nturn to suicidal ideation without adequate treat-\nment. Early detection of mental disorders and\nsuicidal ideation from social content provides\na potential way for effective social interven-\ntion. Recent advances in pretrained contextual-\nized language representations have promoted\nthe development of several domain-speciﬁc\npretrained models and facilitated several down-\nstream applications. However, there are no\nexisting pretrained language models for men-\ntal healthcare. This paper trains and release\ntwo pretrained masked language models, i.e.,\nMentalBERT and MentalRoBERTa, to bene-\nﬁt machine learning for the mental healthcare\nresearch community. Besides, we evaluate\nour trained domain-speciﬁc models and sev-\neral variants of pretrained language models on\nseveral mental disorder detection benchmarks\nand demonstrate that language representations\npretrained in the target domain improve the\nperformance of mental health detection tasks.\n\n1\n\nIntroduction\n\nMental health is a global issue, especially severe\nin most developed countries and many emerging\nmarkets. According to the mental health action\nplan (2013 - 2020) from the World Health Organi-\nzation, 1 in 4 people worldwide suffer from mental\ndisorders to some extent. Moreover, 3 out of 4\npeople with severe mental disorders do not receive\ntreatment, worsening the problem. During some\nperiods like the pandemic, people struggle with\nmental health issues, and many may not get mental\nhealth practitioners’ help. Previous studies reveal\nthat suicide risk usually has a connection to mental\ndisorders (Windfuhr and Kapur, 2011). Partly due\nto severe mental disorders, 900,000 people com-\nmit suicide each year worldwide, making suicide\nthe second most common cause of death among\nthe young. Suicide attempters have been reported\n\nas suffering from mental disorders, with an inves-\ntigation on a shift from mental health to suicidal\nideation conducted by language and interactional\nmeasures (De Choudhury et al., 2016).\n\nEarly identiﬁcation is a practical approach to\nmental illness and suicidal ideation prevention. Ex-\ncept for traditional proactive screening, social me-\ndia is a good channel for mental health care. Social\nmedia platforms such as Reddit and Twitter provide\nanonymous space for users to discuss stigmatic top-\nics and self-report personal issues. Social content\nfrom users who wrote about mental health issues\nand posted suicidal ideation has been widely used\nto study mental health issues (e.g., Ji et al., 2018;\nTadesse et al., 2019). Machine learning-based de-\ntection techniques can empower healthcare workers\nin early detection and assessment to take an action\nof proactive prevention.\n\nRecent advances in deep learning facilitate the\ndevelopment of effective early detection meth-\nods (Ji et al., 2021a). A new trend in natural lan-\nguage processing (NLP), contextualized pretrained\nlanguage models, has attracted much attention for\nvarious text processing tasks. The seminal work\non a pretrained language model called BERT (De-\nvlin et al., 2019) utilizes bidirectional transformer-\nbased text encoders and trains the model on a large-\nscale corpus. With the success of BERT, several\ndomain-speciﬁc pretrained language models for\nlearning text representations have also been devel-\noped and released, such as biomedical BERT (Lee\net al., 2020) and clinical BERT (Alsentzer et al.,\n2019; Huang et al., 2019) for the biomedical and\nclinical domain, respectively.\n\nHowever, there are no pretrained language mod-\nels customized for the domain of mental healthcare.\nOur paper trains and releases two representative\nbidirectional masked language models, i.e., BERT\nand RoBERTa (Liu et al., 2019), with corpus col-\nlected from social forums for mental health discus-\nsion. The pretrained models in the mental health\n\n1\n2\n0\n2\n\nt\nc\nO\n9\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n1\n2\n6\n5\n1\n.\n0\n1\n1\n2\n:\nv\ni\nX\nr\na\n\n \n \n \n \n \n \n\fdomain are dubbed MentalBERT and Mental-\nRoBERTa. To our best knowledge, this work is the\nﬁrst to pre-train language models for mental health-\ncare. Besides, we conduct a comprehensive eval-\nuation on several mental health detection datasets\nwith pretrained language models in different do-\nmains. We release the pretrained MentalBERTs\nwith Huggingface’s model repository, available at\nhttps://huggingface.co/mental.\n\n2 Methods and Setup\n\nThis section introduces the language model pre-\ntraining technique and the pretraining corpus we\ncollected. We then present th"
  },
  {
    "title": "Opportunities in Mental Health Support for Informal Dementia Caregivers\n  Suffering from Verbal Agitation",
    "authors": [
      "Taewook Kim",
      "Hyeok Kim",
      "Angela Roberts",
      "Maia Jacobs",
      "Matthew Kay"
    ],
    "abstract": "People with dementia (PwD) often present verbal agitation such as cursing,\nscreaming, and persistently complaining. Verbal agitation can impose mental\ndistress on informal caregivers (e.g., family, friends), which may cause severe\nmental illnesses, such as depression and anxiety disorders. To improve informal\ncaregivers' mental health, we explore design opportunities by interviewing 11\ninformal caregivers suffering from verbal agitation of PwD. In particular, we\nfirst characterize how the predictability of verbal agitation impacts informal\ncaregivers' mental health and how caregivers' coping strategies vary before,\nduring, and after verbal agitation. Based on our findings, we propose design\nopportunities to improve the mental health of informal caregivers suffering\nfrom verbal agitation: distracting PwD (in-situ support; before), prompting\njust-in-time maneuvers (information support; during), and comfort and education\n(social & information support; after). We discuss our reflections on cultural\ndisparities between participants. Our work envisions a broader design space for\nsupporting informal caregivers' well-being and describes when and how that\nsupport could be provided.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2311.10912v1",
    "pdf_url": "http://arxiv.org/pdf/2311.10912v1",
    "full_text": "3\n2\n0\n2\n\nv\no\nN\n7\n1\n\n]\n\nC\nH\n.\ns\nc\n[\n\n1\nv\n2\n1\n9\n0\n1\n.\n1\n1\n3\n2\n:\nv\ni\nX\nr\na\n\nOpportunities in Mental Health Support for Informal\nDementia Caregivers Suﬀering from Verbal Agitation\n\nTAEWOOK KIM, Northwestern University, USA\nHYEOK KIM, Northwestern University, USA\nANGELA ROBERTS, University of Western Ontario, Canada\nMAIA JACOBS, Northwestern University, USA\nMATTHEW KAY, Northwestern University, USA\n\nPeople with dementia (PwD) often present verbal agitation such as cursing, screaming, and persistently com-\nplaining. Verbal agitation can impose mental distress on informal caregivers (e.g., family, friends), which\nmay cause severe mental illnesses, such as depression and anxiety disorders. To improve informal caregivers’\nmental health, we explore design opportunities by interviewing 11 informal caregivers suﬀering from verbal\nagitation of PwD. In particular, we ﬁrst characterize how the predictability of verbal agitation impacts in-\nformal caregivers’ mental health and how caregivers’ coping strategies vary before, during, and after verbal\nagitation. Based on our ﬁndings, we propose design opportunities to improve the mental health of informal\ncaregivers suﬀering from verbal agitation: distracting PwD (in-situ support; before), prompting just-in-time\nmaneuvers (information support; during), and comfort and education (social & information support; after).\nWe discuss our reﬂections on cultural disparities between participants. Our work envisions a broader design\nspace for supporting informal caregivers’ well-being and describes when and how that support could be\nprovided.\nCCS Concepts: • Human-centered computing → Empirical studies in HCI.\n\nAdditional Key Words and Phrases: Informal caregivers, Mental health, People with dementia, Verbal agitation\n\n1 INTRODUCTION\n\nPeople with dementia (PwD) often exhibit verbal agitation, a major behavioral symptom of de-\nmentia that includes screaming, swearing, and repeating phrases [9, 20, 88]. Verbal agitation is\nmore common for people in advanced stages of Alzheimer’s and vascular dementia [49, 83, 87, 97],\nin conjunction with other psychological symptoms such as aggression and disinhibition [87, 89].\nSuch verbal agitation often causes signiﬁcant mental distress in caregivers [7, 44], which may im-\npede them from performing their essential care activities (e.g., changing a diaper, assisting with\neating).\n\nInformal caregivers, such as family members, spouses, or friends, are a primary care source for\nmany PwD [28, 38, 79]. They often suﬀer from mental distress due to verbal agitation, impeding\ntheir care responsibilities for PwD [34, 45, 82]. For instance, informal caregivers often experience\ncursing or threats from PwD while providing daily personal care, such as changing diapers and\n\nAuthors’ addresses: Taewook Kim, taewook@u.northwestern.edu, Northwestern University, Evanston, IL, USA; Hyeok\nKim, hyeokkim2024@u.northwestern.edu, Northwestern University, Evanston, IL, USA; Angela Roberts, angela.roberts@\nuwo.ca, University of Western Ontario, London, Ontario, Canada; Maia Jacobs, maia.jacobs@northwestern.edu, North-\nwestern University, Evanston, IL, USA; Matthew Kay, mjskay@northwestern.edu, Northwestern University, Evanston, IL,\nUSA.\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee\nprovided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and\nthe full citation on the ﬁrst page. Copyrights for components of this work owned by others than ACM must be honored.\nAbstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires\nprior speciﬁc permission and/or a fee. Request permissions from permissions@acm.org.\n© 2023 Association for Computing Machinery.\nXXXX-XXXX/2023/11-ART $15.00\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnn\n\n, Vol. 1, No. 1, Article . Publication date: November 2023.\n\n \n \n \n \n \n \n\f2\n\nTaewook Kim, Hyeok Kim, Angela Roberts, Maia Jacobs, and Matthew Kay\n\nbrushing teeth [29, 86]. A substantial number of informal caregivers experience serious mental\nhealth issues such as depression [19] and anxiety disorder [35, 50]. The poor mental health con-\nditions of informal caregivers impacted by verbal agitation can be a barrier to sustainable and\ncomprehensive care for their loved ones with dementia. In addition, many informal caregivers\nlack access to helpful resources and professional education on dementia care practices, as they\nare caregivers by necessity, not by training [77, 78]. Hence, exploring design opportunities for\ninformal caregivers to handle verbal agitation from PwD and manage their mental health is an\nimportant step toward developing technological support to better sustain their care activities.\n\nWith this in mind, we interviewed 11 informal caregivers who suﬀer from verbal agitation of\nPwD in South Korea and the USA. We asked them in what contexts they face verbal agitat"
  },
  {
    "title": "Financial technologies (FinTech) for mental health: The potential of\n  objective financial data to better understand the relationships between\n  financial behavior and mental health",
    "authors": [
      "Johnna Blair",
      "Jeff Brozena",
      "Mark Matthews",
      "Thomas Richardson",
      "Saeed Abdullah"
    ],
    "abstract": "In this paper, we present novel research methods for collecting and analyzing\npersonal financial data alongside mental health factors, illustrated through a\nN=1 case study using data from one individual with bipolar disorder. While we\nhave not found statistically significant trends nor our findings are\ngeneralizable beyond this case, our approach provides an insight into the\nchallenges of accessing objective financial data. We outline what data is\ncurrently available, what can be done with it, and what factors to consider\nwhen working with financial data. More specifically, using these methods\nresearchers might be able to identify symptomatic traces of mental ill health\nin personal financial data such as identifying early warning signs and thereby\nenable preemptive care for individuals with serious mental illnesses. Based on\nthis work, we have also explored future directions for developing interventions\nto support financial wellbeing. Furthermore, we have described the technical,\nethical, and equity challenges for financial data-driven assessments and\nintervention methods, as well as provided a broad research agenda to address\nthese challenges. By leveraging objective, personalized financial data in a\nprivacy-preserving and ethical manner help lead to a shift in mental health\ncare.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2204.05448v4",
    "pdf_url": "http://arxiv.org/pdf/2204.05448v4",
    "full_text": "3\n2\n0\n2\n\nn\na\nJ\n\n9\n\n]\n\nC\nH\n.\ns\nc\n[\n\n4\nv\n8\n4\n4\n5\n0\n.\n4\n0\n2\n2\n:\nv\ni\nX\nr\na\n\nFinancial technologies (FinTech) for mental\nhealth: The potential of objective ﬁnancial\ndata to better understand the relationships\nbetween ﬁnancial behavior and mental health\nJohnna Blair 1,∗, Jeff Brozena 1, Mark Matthews 2, Thomas Richardson 3 and\nSaeed Abdullah 1\n1Penn State University, PA, USA\n2University College Dublin, Ireland\n3University of Southampton, UK\nCorrespondence*:\nJohnna Blair\njlb883@psu.edu\n\nABSTRACT\n\nFinancial stability is a key challenge for individuals with mental illnesses. Symptomatic periods\noften manifest\nin poor ﬁnancial decision-making including compulsive spending and risky\nbehaviors. This article explores research opportunities and challenges in developing ﬁnancial\ntechnologies (FinTech) to support individuals with mental health. Speciﬁcally, we focus on\nhow objective ﬁnancial data might lead to novel mental health assessment and intervention\nmethods. We have used data from one individual with bipolar disorder (i.e., an N=1 case study)\nto illustrate feasibility of collecting and analyzing objective ﬁnancial data alongside mental health\nfactors. While we have not found statistically signiﬁcant trends nor our ﬁndings are generalizable\nbeyond this case, our approach provides an insight into the potential of using objective ﬁnancial\ndata to identify early warning signs and thereby, enable preemptive care for individuals with\nserious mental illnesses. We have also identiﬁed challenges of accessing objective ﬁnancial\ndata. The paper outlines what data is currently available, what can be done with it, and what\nfactors to consider when working with ﬁnancial data. We have also explored future directions\nfor developing interventions to support ﬁnancial wellbeing and stability. Furthermore, we have\ndescribed the technical, ethical, and equity challenges for ﬁnancial data-driven assessments and\nintervention methods, as well as provided a broad research agenda to address these challenges.\n\nKeywords: Mental Health, Financial technologies, FinTech, Open banking, Intervention, Impulsive spending, Privacy preserving\n\n1 INTRODUCTION\n\nMental illness is a serious public health crisis on a global scale. It affects more than one billion individuals\n(1). This results in signiﬁcant economic consequences, with an estimated total annual cost of $2.5\ntrillion globally (1). This growing issue impacts many facets of daily life, including a strong association\nbetween mental health and ﬁnancial instability. Individuals with mental health issues are more likely to\nlive in relative poverty (2, 3). Symptoms of some illnesses can also manifest in poor ﬁnancial decision\n\n1\n\n \n \n \n \n \n \n\fBlair et al.\n\nFinTech for mental health\n\nmaking. More speciﬁcally, bipolar disorder (BD) appears to be linked with greater risk of impulsive\nﬁnancial behaviors—The diagnostic criteria for hypomanic and manic episodes speciﬁcally lists impulsive\nspending as possible symptoms (4). Those with BD are at greater risk of problem gambling (5), and 71%\nreport impulsive spending whilst hypomanic (6). This impulsive spending has also been shown to be\nlinked to negative feelings and subsequent comfort spending (7, 8). As this illustrates, there is often a\ncyclical and bidirectional relationship between ﬁnancial stability and mental health—ﬁnancial instability\ncan worsen mental health, which in turn, can cause further ﬁnancial challenges, leading to a vicious cycle\n(9, 10, 7, 8).\n\nThe lack of access to objective ﬁnancial data has been a key challenge in understanding the nuanced\nrelationship between mental health and ﬁnancial behaviors. Prior studies have mostly used surveys (2)\nand focus group interviews (10) to assess ﬁnancial behaviors associated with serious mental illnesses.\nThis means that much of what we know about this relationship is mediated through subjective methods\nthat may be prone to bias and retrospective recall error. For example, Richardson et al. (8) measured\nself-reported compulsive spending in Bipolar Disorder, rather than objective data on spending patterns.\nWhile this provides a useful broad overview, there remains a knowledge gap regarding how idiosyncratic,\ncontext-driven, and illness-speciﬁc factors impact ﬁnancial decision making and stability of an individual\nliving with mental illness. Furthermore, the lack of granular, in-situ assessment methods is a key barrier\nagainst developing just-in-time, adaptive, and personalized interventions focusing on ﬁnancial stability\nfor this population. Given the importance of ﬁnancial wellbeing for mental health, this remains a serious\nknowledge gap with broad practical implications.\n\nIn recent years, there has been considerable progress toward more open and accessible ﬁnancial data.\nFinancial institutes are increasingly adopting open banking application programming interface (API)\nmandating access to accounts, payments, and transactions. There have also been third-party tools and\nplatforms (e.g., Plaid (11)) "
  },
  {
    "title": "Multi-Task Learning for Mental Health using Social Media Text",
    "authors": [
      "Adrian Benton",
      "Margaret Mitchell",
      "Dirk Hovy"
    ],
    "abstract": "We introduce initial groundwork for estimating suicide risk and mental health\nin a deep learning framework. By modeling multiple conditions, the system\nlearns to make predictions about suicide risk and mental health at a low false\npositive rate. Conditions are modeled as tasks in a multi-task learning (MTL)\nframework, with gender prediction as an additional auxiliary task. We\ndemonstrate the effectiveness of multi-task learning by comparison to a\nwell-tuned single-task baseline with the same number of parameters. Our best\nMTL model predicts potential suicide attempt, as well as the presence of\natypical mental health, with AUC > 0.8. We also find additional large\nimprovements using multi-task learning on mental health tasks with limited\ntraining data.",
    "year": 2017,
    "url": "http://arxiv.org/abs/1712.03538v1",
    "pdf_url": "http://arxiv.org/pdf/1712.03538v1",
    "full_text": "Multi-Task Learning for Mental Health\nusing Social Media Text\n\nAdrian Benton\nJohns Hopkins University\nadrian@cs.jhu.edu\n\nMargaret Mitchell\nMicrosoft Research∗\nmmitchellai@google.com\n\nDirk Hovy\nUniversity of Copenhagen\nmail@dirkhovy.com\n\n7\n1\n0\n2\nc\ne\nD\n0\n1\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n8\n3\n5\n3\n0\n.\n2\n1\n7\n1\n:\nv\ni\nX\nr\na\n\nAbstract\n\nWe introduce initial groundwork for esti-\nmating suicide risk and mental health in\na deep learning framework. By model-\ning multiple conditions, the system learns\nto make predictions about suicide risk and\nmental health at a low false positive rate.\nConditions are modeled as tasks in a multi-\ntask learning (MTL) framework, with gen-\nder prediction as an additional auxiliary\ntask. We demonstrate the effectiveness\nof multi-task learning by comparison to\na well-tuned single-task baseline with the\nsame number of parameters. Our best\nMTL model predicts potential suicide at-\ntempt, as well as the presence of atypical\nmental health, with AUC > 0.8. We also\nﬁnd additional large improvements using\nmulti-task learning on mental health tasks\nwith limited training data.\n\n1\n\nIntroduction\n\nSuicide is one of the leading causes of death\nworldwide, and over 90% of individuals who die\nby suicide experience mental health conditions.1\nHowever, detecting the risk of suicide, as well\nas monitoring the effects of related mental health\nconditions, is challenging. Traditional methods\nrely on both self-reports and impressions formed\nduring short sessions with a clinical expert, but it is\noften unclear when suicide is a risk in particular.2\nConsequently, conditions leading to preventable\nsuicides are often not adequately addressed.\n\n∗Now at Google Research.\n1https://www.nami.org/Learn-\n\nMore/Mental-Health-Conditions/Related-\nConditions/Suicide#sthash.dMAhrKTU.dpuf\n\n2Communication with clinicians at the 2016 JSALT work-\n\nshop (Hollingshead, 2016).\n\nAutomated monitoring and risk assessment of\npatients’ language has the potential to complement\ntraditional assessment methods, providing objec-\ntive measurements to motivate further care and ad-\nditional support for people with difﬁculties related\nto mental health. This paves the way towards ver-\nifying the need for additional care with insurance\ncoverage, for example, as well as offering direct\nbeneﬁts to clinicians and patients.\n\nWe explore some of the possibilities in the deep\nlearning and mental health space using written so-\ncial media text that people with different mental\nhealth conditions are already producing. Uncov-\nering methods that work with such text provides\nthe opportunity to help people with different men-\ntal health conditions by leveraging a task they are\nalready participating in.\n\nSocial media text carries implicit information\nabout the author, which has been modeled in nat-\nural language processing (NLP) to predict au-\nthor characteristics such as age (Goswami et al.,\n2009; Rosenthal and McKeown, 2011; Nguyen\net al., 2014), gender (Sarawgi et al., 2011; Ciot\net al., 2013; Liu and Ruths, 2013; Volkova et\nal., 2015; Hovy, 2015), personality (Schwartz\net al., 2013; Volkova et al., 2014; Plank and\nHovy, 2015; Park et al., 2015; Preot¸iuc-Pietro et\nal., 2015), and occupation (Preotiuc-Pietro et al.,\n2015). Similar text signals have been effectively\nused to predict mental health conditions such as\ndepression (De Choudhury et al., 2013; Copper-\nsmith et al., 2015b; Schwartz et al., 2014), suici-\ndal ideation (Coppersmith et al., 2016; Huang et\nal., 2015), schizophrenia (Mitchell et al., 2015) or\npost-traumatic stress disorder (PTSD) (Pedersen,\n2015).\n\nHowever, these studies typically model each\ncondition in isolation, which misses the op-\nportunity to model coinciding inﬂuence factors.\nTasks with underlying commonalities (e.g., part-\n\n \n \n \n \n \n \n\fof-speech tagging, parsing, and NER) have been\nshown to beneﬁt from multi-task learning (MTL),\nas the learning implicitly leverages interactions\nbetween them (Caruana, 1993; Sutton et al., 2007;\nRush et al., 2010; Collobert et al., 2011; Søgaard\nand Goldberg, 2016). Suicide risk and related\nmental health conditions are therefore good can-\ndidates for modeling in a multi-task framework.\n\nIn this paper, we propose multi-task learning\nfor detecting suicide risk and mental health condi-\ntions. The tasks of our model include neuroatypi-\ncality (i.e., atypical mental health) and suicide at-\ntempt, as well as the related mental health condi-\ntions of anxiety, depression, eating disorder, panic\nattacks, schizophrenia, bipolar disorder, and post-\ntraumatic stress disorder (PTSD), and we explore\nthe effect of task selection on model performance.\nWe additionally include the effect of modeling\ngender, which has been shown to improve accu-\nracy in tasks using social media text (Volkova et\nal., 2013; Hovy, 2015).\n\nPredicting suicide risk and several mental health\nconditions jointly opens the possibility for the\nto leverage a shared representation for\nmodel\nconditions that frequently occur together, a phe-\nnomenon known as comorbidity. "
  },
  {
    "title": "Can We Assess Mental Health through Social Media and Smart Devices?\n  Addressing Bias in Methodology and Evaluation",
    "authors": [
      "Adam Tsakalidis",
      "Maria Liakata",
      "Theo Damoulas",
      "Alexandra I. Cristea"
    ],
    "abstract": "Predicting mental health from smartphone and social media data on a\nlongitudinal basis has recently attracted great interest, with very promising\nresults being reported across many studies. Such approaches have the potential\nto revolutionise mental health assessment, if their development and evaluation\nfollows a real world deployment setting. In this work we take a closer look at\nstate-of-the-art approaches, using different mental health datasets and\nindicators, different feature sources and multiple simulations, in order to\nassess their ability to generalise. We demonstrate that under a pragmatic\nevaluation framework, none of the approaches deliver or even approach the\nreported performances. In fact, we show that current state-of-the-art\napproaches can barely outperform the most na\\\"ive baselines in the real-world\nsetting, posing serious questions not only about their deployment ability, but\nalso about the contribution of the derived features for the mental health\nassessment task and how to make better use of such data in the future.",
    "year": 2018,
    "url": "http://arxiv.org/abs/1807.07351v1",
    "pdf_url": "http://arxiv.org/pdf/1807.07351v1",
    "full_text": "8\n1\n0\n2\n\nl\nu\nJ\n\n9\n1\n\n]\n\nY\nC\n.\ns\nc\n[\n\n1\nv\n1\n5\n3\n7\n0\n.\n7\n0\n8\n1\n:\nv\ni\nX\nr\na\n\nCan We Assess Mental Health through Social\nMedia and Smart Devices? Addressing Bias in\nMethodology and Evaluation\n\nAdam Tsakalidis1,2, Maria Liakata1,2, Theo Damoulas1,2, and Alexandra I.\nCristea1,3\n\n1 University of Warwick, UK\n{a.tsakalidis, m.liakata, t.damoulas, a.i.cristea}@warwick.ac.uk\n2 The Alan Turing Institute, UK\n3 Durham University, UK\n\nAbstract. Predicting mental health from smartphone and social media\ndata on a longitudinal basis has recently attracted great interest, with\nvery promising results being reported across many studies [3,9,13,26].\nSuch approaches have the potential to revolutionise mental health as-\nsessment, if their development and evaluation follows a real world de-\nployment setting. In this work we take a closer look at state-of-the-art\napproaches, using diﬀerent mental health datasets and indicators, dif-\nferent feature sources and multiple simulations, in order to assess their\nability to generalise. We demonstrate that under a pragmatic evaluation\nframework, none of the approaches deliver or even approach the reported\nperformances. In fact, we show that current state-of-the-art approaches\ncan barely outperform the most na¨ıve baselines in the real-world setting,\nposing serious questions not only about their deployment ability, but\nalso about the contribution of the derived features for the mental health\nassessment task and how to make better use of such data in the future.\n\nKeywords: mental health · bias · evaluation · wellbeing · natural lan-\nguage processing · smartphones · sensors · social media\n\n1\n\nIntroduction\n\nEstablishing the right indicators of mental well-being is a grand challenge posed\nby the World Health Organisation [7]. Poor mental health is highly correlated\nwith low motivation, lack of satisfaction, low productivity and a negative eco-\nnomic impact [20]. The current approach is to combine census data at the pop-\nulation level [19], thus failing to capture well-being on an individual basis. The\nlatter is only possible via self-reporting on the basis of established psychological\nscales, which are hard to acquire consistently on a longitudinal basis, and they\ncapture long-term aggregates instead of the current state of the individual.\n\nThe widespread use of smart-phones and social media oﬀers new ways of\nassessing mental well-being, and recent research [1,2,3,5,9,10,13,14,22,23,26] has\nstarted exploring the eﬀectiveness of these modalities for automatically assessing\n\n \n \n \n \n \n \n\f2\n\nA. Tsakalidis et al.\n\nthe mental health of a subject, reporting very high accuracy. What is typically\ndone in these studies is to use features based on the subjects’ smart phone\nlogs and social media, to predict some self-reported mental health index (e.g.,\n“wellbeing”, “depression” and others), which is provided either on a Likert scale\nor on the basis of a psychological questionnaire (e.g., PHQ-8 [12], PANAS [29],\nWEMWBS [25] and others).\n\nMost of these studies are longitudinal, where data about individuals is col-\nlected over a period of time and predictions of mental health are made over a\nsliding time window. Having such longitudinal studies is highly desirable, as it\ncan allow ﬁne-grained monitoring of mental health. However, a crucial question\nis what constitutes an appropriate evaluation framework, in order for such ap-\nproaches to be employable in a real world setting. Generalisation to previously\nunobserved users can only be assessed via leave-N-users-out cross-validation se-\ntups, where typically, N is equal to one (LOUOCV, see Table 1). However,\ndue to the small number of subjects that are available, such generalisation is\nhard to achieve by any approach [13]. Alternatively, personalised models [3,13]\nfor every individual can be evaluated via a within-subject, leave-N-instances-out\ncross-validation (for N=1, LOIOCV), where an instance for a user u at time i\nis deﬁned as a {Xui, yui} tuple of {features(u, i), mental-health-score(u, i)}. In a\nreal world setting, a LOIOCV model is trained on some user-speciﬁc instances,\naiming to predict her mental health state at some future time points. Again how-\never, the limited number of instances for every user make such models unable to\ngeneralize well. In order to overcome these issues, previous work [2,5,9,10,22,26]\nhas combined the instances {Xuj i, yuj i} from diﬀerent individuals uj and per-\nformed evaluation using randomised cross validation (MIXED). While such\napproaches can attain optimistic performance, the corresponding models fail to\ngeneralise to the general population and also fail to ensure eﬀective personalised\nassessment of the mental health state of a single individual.\n\nLOUOCV\nBuild a model m that\ngeneralises to a previ-\nously unseen user u\n\nReal\nworld\naim\nTrain {{X(cid:54)ui, y(cid:54)ui}}\nTest\n\n{Xui, yui}\nFew users for training\nand evaluation\n\nLimits\n\nLOIOCV\nBuild a personalised model mu per\nuser u that generalises on u, given\nsome manual inp"
  },
  {
    "title": "Smartphone app to investigate the relationship between social\n  connectivity and mental health",
    "authors": [
      "Tjeerd W. Boonstra",
      "Aliza Werner-Seidler",
      "Bridianne O'Dea",
      "Mark E. Larsen",
      "Helen Christensen"
    ],
    "abstract": "Interpersonal relationships are necessary for successful daily functioning\nand wellbeing. Numerous studies have demonstrated the importance of social\nconnectivity for mental health, both through direct peer-to-peer influence and\nby the location of individuals within their social network. Passive monitoring\nusing smartphones provides an advanced tool to map social networks based on the\nproximity between individuals. This study investigates the feasibility of using\na smartphone app to measure and assess the relationship between social network\nmetrics and mental health. The app collected Bluetooth and mental health data\nin 63 participants. Social networks of proximity were estimated from Bluetooth\ndata and 95% of the edges were scanned at least every 30 minutes. The majority\nof participants found this method of data collection acceptable and reported\nthat they would be likely to participate in future studies using this app.\nThese findings demonstrate the feasibility of using a smartphone app that\nparticipants can install on their own phone to investigate the relationship\nbetween social connectivity and mental health.",
    "year": 2017,
    "url": "http://arxiv.org/abs/1702.02644v2",
    "pdf_url": "http://arxiv.org/pdf/1702.02644v2",
    "full_text": "Smartphone App to Investigate the Relationship between Social \nConnectivity and Mental Health* \n\nTjeerd W. Boonstra, Aliza Werner-Seidler, Bridianne O'Dea, Mark E. Larsen, and Helen Christensen \n\nAbstract—  Interpersonal  relationships  are  necessary  for \nsuccessful  daily  functioning  and  wellbeing.  Numerous  studies \nhave  demonstrated  the  importance  of  social  connectivity  for \nmental  health,  both  through  direct  peer-to-peer  influence  and \nby  the  location  of  individuals  within  their  social  network. \nPassive  monitoring  using  smartphones  provides  an  advanced \ntool  to  map  social  networks  based  on  the  proximity  between \nindividuals.  This  study  investigates  the  feasibility  of  using  a \nsmartphone  app  to  measure  and  assess  the  relationship \nbetween  social  network  metrics  and  mental  health.  The  app \ncollected  Bluetooth  and  mental  health  data  in  63  participants. \nSocial  networks  of  proximity  were  estimated  from  Bluetooth \ndata  and  95%  of  the  edges  were  scanned  at  least  every  30 \nminutes.  The  majority  of  participants  found  this  method  of \ndata  collection  acceptable  and  reported  that  they  would  be \nlikely  to  participate  in  future  studies  using  this  app.  These \nfindings demonstrate the feasibility of using a smartphone app \nthat  participants  can  install  on  their  own  phone  to  investigate \nthe relationship between social connectivity and mental health. \n\nI.  INTRODUCTION \n\nSocial  connections  are  critically  important  to  health  and \nwellbeing,  with  numerous  studies  finding  that  aspects  of \nsocial  connection  affect  morbidity  and  mortality  at  levels \ncomparable  to  smoking  and  obesity  [1].  Social  connectivity \nalso shares an important and specific relationship with mental \nhealth,  with  studies  showing  that  individuals  who  have \nsmaller  networks,  fewer  interpersonal  relationships  or  lower \nlevels  of  social  support  consistently  report  elevated  rates  of \ndepression  [2,  3].  Furthermore,  a  significant  proportion  of \nthose who die by suicide have a history of social isolation [4].  \n\nAlthough  both  prospective  and  cross-sectional  studies \nhave  been  conducted  to  investigate  the  association  between \nsocial  network  factors  and  mental  illness,  these  studies  rely \nprimarily  on  questionnaire  data.  Studies  have  typically \ndepended  on  an  array  of  self-report  indices,  such  as  name \ngenerators  (identifying  who  is  in  one’s  social  network), \nnumber  of  friends,  frequency  of  participation  in  social \nactivity, and whether someone is living alone or not, in order \nto  identify  the  size  and  nature  of  social  networks  [5,  6]. \nHowever,  these  measures  are  limited  by  the  nature  of  self-\nreport  –  which  is  inherently  vulnerable  to  confounding  and \nsystematic  bias  [7].  These  methods  are  also  practically \n\n*  Research  supported  by  the  NHMRC  Centre  of  Research  Excellence  in \nSuicide  Prevention  APP1042580  and  NHMRC  John  Cade  Fellowship \nAPP1056964.  B.  O’Dea  and  M.  E.  Larsen  are  supported  by  Society  of \nMental Health 2015 Early Career Research Awards. \n\n T.  W.  Boonstra,  A.  Werner-Seidler,  B.  O'Dea,  M.  E.  Larsen,  H. \nChristensen  are  with  the  Black  Dog  Institute,  University  of  New  South \nWales,  Sydney,  NSW  2031,  Australia.  T.  W.  Boonstra  is  also  with  QIMR \nInstitute,  Brisbane,  Australia.  Email: \nBerghofer  Medial  Research \nt.boonstra@unsw.edu, \nmark.larsen, \nb.odea, \nh.christensen}@blackdog.org.au.  \n\n{a.werner-seidler, \n\nlimited  by  the  time  and  effort  required  to  administer  and \nprocess  such  data.  This  can  severely  impede  the  extent  to \nwhich  certain  populations,  communities,  and  individual \nnetworks  can  be  studied.  New  technologies  are  needed  to \nadvance the field of social network analysis. \n\nSensor-enabled  mobile  phones  have  recently  been  tested \nas  a  method  to  measure  the  proximity  between  participants \nand  map  face-to-face  interactions,  with  evidence  showing \nthat  proximity  is  a  valid  metric  of  social  connections  [8]. \nSocial connections can be accurately deduced from proximity \nby  distinguishing  typical  proximal  behavioral  patterns  (for \nexample,  proximity  to  colleagues  at  work  during  the  day) \nfrom  other  behaviors  (proximity \nto  others  outside  of \nworkplace).  However,  this  technology  has  been  limited  by \nseveral  factors.  First,  Bluetooth  data  has  only  been  captured \non Nokia smartphones [8] or those with an Android operating \nsystem  [9].  As  such,  this  technology  is  not  available  to  the \nestimated  700  million  iPhone  users  who  rely  on  the  iOS \noperating system. Second, past studies involved pre-installing \nthe  application  on  a  device  that  was  then  distributed  to \nparticipants for the duration of the study [10, 11]. "
  },
  {
    "title": "Hashtag Healthcare: From Tweets to Mental Health Journals Using Deep\n  Transfer Learning",
    "authors": [
      "Benjamin Shickel",
      "Martin Heesacker",
      "Sherry Benton",
      "Parisa Rashidi"
    ],
    "abstract": "As the popularity of social media platforms continues to rise, an\never-increasing amount of human communication and self- expression takes place\nonline. Most recent research has focused on mining social media for public user\nopinion about external entities such as product reviews or sentiment towards\npolitical news. However, less attention has been paid to analyzing users'\ninternalized thoughts and emotions from a mental health perspective. In this\npaper, we quantify the semantic difference between public Tweets and private\nmental health journals used in online cognitive behavioral therapy. We will use\ndeep transfer learning techniques for analyzing the semantic gap between the\ntwo domains. We show that for the task of emotional valence prediction, social\nmedia can be successfully harnessed to create more accurate, robust, and\npersonalized mental health models. Our results suggest that the semantic gap\nbetween public and private self-expression is small, and that utilizing the\nabundance of available social media is one way to overcome the small sample\nsizes of mental health data, which are commonly limited by availability and\nprivacy concerns.",
    "year": 2017,
    "url": "http://arxiv.org/abs/1708.01372v1",
    "pdf_url": "http://arxiv.org/pdf/1708.01372v1",
    "full_text": "7\n1\n0\n2\n\ng\nu\nA\n4\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n2\n7\n3\n1\n0\n.\n8\n0\n7\n1\n:\nv\ni\nX\nr\na\n\nHashtagHealthcare:FromTweetstoMentalHealthJournalsUsingDeepTransferLearningBenjaminShickel1,a,MartinHeesacker2,b,SherryBenton3,c,andParisaRashidi4,d1DepartmentofComputerandInformationScienceandEngineering,UniversityofFlorida,Gainesville,FL,32611,USA2DepartmentofPsychology,UniversityofFlorida,Gainesville,FL,32611,USA3TAOConnect,Inc.,St.Petersburg,FL,33701,USA4DepartmentofBiomedicalEngineering,UniversityofFlorida,Gainesville,FL,32611,USAashickelb@uﬂ.edubheesack@uﬂ.educsherry.benton@taoconnect.orgdparisa.rashidi@uﬂ.eduABSTRACTAsthepopularityofsocialmediaplatformscontinuestorise,anever-increasingamountofhumancommunicationandself-expressiontakesplaceonline.Mostrecentresearchhasfocusedonminingsocialmediaforpublicuseropinionaboutexternalentitiessuchasproductreviewsorsentimenttowardspoliticalnews.However,lessattentionhasbeenpaidtoanalyzingusers’internalizedthoughtsandemotionsfromamentalhealthperspective.Inthispaper,wequantifythesemanticdifferencebetweenpublicTweetsandprivatementalhealthjournalsusedinonlinecognitivebehavioraltherapy.Wewillusedeeptransferlearningtechniquesforanalyzingthesemanticgapbetweenthetwodomains.Weshowthatforthetaskofemotionalvalenceprediction,socialmediacanbesuccessfullyharnessedtocreatemoreaccurate,robust,andpersonalizedmentalhealthmodels.Ourresultssuggestthatthesemanticgapbetweenpublicandprivateself-expressionissmall,andthatutilizingtheabundanceofavailablesocialmediaisonewaytoovercomethesmallsamplesizesofmentalhealthdata,whicharecommonlylimitedbyavailabilityandprivacyconcerns.IntroductionSentimentanalysis,thetaskreferringtotheautomaticdeterminationofuseropinionfromtext,hasreceivedincreasedattentioninthepastdecade1–5.Muchofthesuccessofsentimentanalysistechniquescanbeattributedtotheriseofsocialmediaplatforms,wheremillionsofuserssharetheiropinionsonawidevarietyofsubjects.Themajorityofsentimentanalysismethodsareaimedataggregatingopinionstowardsentitieslikemovies,people,products,orcompanies.Werefertothiswell-knownresearchareaasexternalsentimentanalysis,inwhichsentimentandtextualpolarityiscalculatedwithrespecttoaspeciﬁcexternalentity.Incontrast,wedeﬁneinternalsentimentanalysisasthestudyofthepolarityofusertextwithrespecttothemselves,primarilyconcernedwithstatementsofemotionandmentalhealth6.Inthispaper,wedealstrictlywithinternalsentimentanalysis,speciﬁcallywiththevalencepredictionofprivatejournalsinamentalhealththerapysetting.Ourworkpartlyalignswithpreviousresearchregardingemotiondetectionintext7–12,asubtaskoftheﬁeldofaffectivecomputingandanalysis,butunlikepreviouswork,wefocusontheexpansionofvalencecategoriesinamentalhealthsetting.Oneusefulapplicationdomainofautomatedinternalsentimentanalysisframeworksistheburgeoningﬁeldofonlinementalhealththerapyservices13–23.Theseprogramsprovidethepatienteducationcomponentsinherentincognitivebehavioraltherapy(CBT).PracticeidentifyingandchangingunhelpfulthoughtpatternsorcognitivedistortionsisacentralpartofCBT.Ongoingpracticewithfeedbackcanincreasepatients’abilitytoaccuratelyidentifymorehelpfulandlesshelpfulthoughts,butupuntilnow,ongoingfeedbackhasbeendifﬁculttoprovide.Aspartofonlinetreatment,userstypicallysubmitseveraldirectedjournalsfordocumentingtheirdailythoughtsandfeelingsastheyimprovetheirmentalwell-beingusingself-directedstrategiestaughtaspartoftherapy.Anaccurateandvalidatedsystemforautomaticallycategorizingusertexthasobviousbeneﬁtstosuchatherapyservice,suchasﬂaggingtextwhichmaybeanearlywarningforsuiciderisk,providingapositiveandalways-availablefeedbackforpatientswithdistortedthinking,orsimplyprovidingenhancedandmoreﬁne-grainedanalysisofoverallpatientwell-being.Traditionalsentimentanalysisinvolvesdetectingwhetheragiventextfragmentissubjectiveorobjective,andinthecaseofsubjectivity,classiﬁesthetextaseitherpositiveornegative.Whilecertainlythemoststraightforwarddesignforexternalopinionmining,wetakethisanalysisastepfurtherformentalhealthpolarity.Ratherthanframingthesubjectivityidentiﬁcation \n \n \n \n \n \n\ftaskasabinaryclassiﬁcationbetweenpositivityandnegativity,weintroducetwoadditionalclassesofpolarity:bothpositiveandnegative,andneitherpositivenornegative.Wemadethisdecisionbasedonpsychologicalresearch,whichsuggestsemotionscannotberepresentedonasingleaxisofvalence24–28.Thus,textclassiﬁedasneutralusingtraditionalframeworkswould,usingournewannotationscheme,fallintoeitherofthetwoaugmentedclasses.Unfortunately,publicly-availablementalhealthdatasetssuitableformachinelearning-basedinternalsentimentanalysisarefewandfarbetween.However,largeamountsofsocialmediatexthavebecomeavailableinrecentyears,andseveralstudieshaveexaminedtraditionalsentimentanalysisinthecontextofsocialmediaplatformssuchasTwitter?,29–34.Givensocialmediausers’tendencytowardsself-expression,wehypothesizethatthesocialmediadomainisquitesimilartothementalhealthdomainwithregardstotextuallanguagemodelingandclassiﬁcation,andcanbeusedtohelptrainmentalhealthmodelsandsystems.Wequantifythesimilaritybetweenthetwodomainsusingamachinelearningtechniquekn"
  },
  {
    "title": "Quantifying the Effects of COVID-19 on Mental Health Support Forums",
    "authors": [
      "Laura Biester",
      "Katie Matton",
      "Janarthanan Rajendran",
      "Emily Mower Provost",
      "Rada Mihalcea"
    ],
    "abstract": "The COVID-19 pandemic, like many of the disease outbreaks that have preceded\nit, is likely to have a profound effect on mental health. Understanding its\nimpact can inform strategies for mitigating negative consequences. In this\nwork, we seek to better understand the effects of COVID-19 on mental health by\nexamining discussions within mental health support communities on Reddit.\nFirst, we quantify the rate at which COVID-19 is discussed in each community,\nor subreddit, in order to understand levels of preoccupation with the pandemic.\nNext, we examine the volume of activity in order to determine whether the\nquantity of people seeking online mental health support has risen. Finally, we\nanalyze how COVID-19 has influenced language use and topics of discussion\nwithin each subreddit.",
    "year": 2020,
    "url": "http://arxiv.org/abs/2009.04008v1",
    "pdf_url": "http://arxiv.org/pdf/2009.04008v1",
    "full_text": "Quantifying the Effects of COVID-19 on Mental Health Support Forums\n\nLaura Biester∗, Katie Matton∗, Janarthanan Rajendran,\nEmily Mower Provost, Rada Mihalcea\nComputer Science & Engineering, University of Michigan, USA\n{lbiester,katiemat,rjana,emilykmp,mihalcea}@umich.edu\n\n0\n2\n0\n2\n\np\ne\nS\n8\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n8\n0\n0\n4\n0\n.\n9\n0\n0\n2\n:\nv\ni\nX\nr\na\n\nAbstract\n\nThe COVID-19 pandemic, like many of the\ndisease outbreaks that have preceded it,\nis\nlikely to have a profound effect on men-\ntal health. Understanding its impact can in-\nform strategies for mitigating negative conse-\nquences.\nIn this work, we seek to better un-\nderstand the effects of COVID-19 on mental\nhealth by examining discussions within mental\nhealth support communities on Reddit. First,\nwe quantify the rate at which COVID-19 is\ndiscussed in each community, or subreddit, in\norder to understand levels of preoccupation\nwith the pandemic. Next, we examine the vol-\nume of activity in order to determine whether\nthe quantity of people seeking online mental\nhealth support has risen. Finally, we analyze\nhow COVID-19 has inﬂuenced language use\nand topics of discussion within each subreddit.\n\n1\n\nIntroduction\n\nThe implications of COVID-19 extend far beyond\nits immediate physical health effects. Uncertainty\nand fear surrounding the disease and its effects, in\naddition to a lack of consistent and reliable infor-\nmation, contribute to rising levels of anxiety and\nstress (Torales et al., 2020). Policies designed to\nhelp contain the disease also have signiﬁcant conse-\nquences. Social distancing policies and lockdowns\nlead to increased feelings of isolation and uncer-\ntainty (Huremovi´c, 2019). They have also triggered\nan economic downturn (ahin et al., 2020), resulting\nin soaring unemployment rates and causing many\nto experience ﬁnancial stress. Therefore, in ad-\ndition to the profound effects on physical health\naround the world, psychiatrists have warned that\nwe should also brace for a mental health crisis as a\nresult of the pandemic (Qiu et al., 2020; Greenberg\net al., 2020; Yao et al., 2020; Torales et al., 2020).\n\n∗Denotes equal contribution.\n\nIndeed, the literature on the impact of past epi-\ndemics indicates that they are associated with a\nmyriad of adverse mental health effects. In a re-\nview of studies on the 2002-2003 SARS outbreak,\nthe 2009 H1N1 inﬂuenza outbreak, and the 2018\nEbola outbreak, Chew et al. (2020) found that\nanxiety, fear, depression, anger, guilt, grief, and\npost-traumatic stress were all commonly observed\npsychological responses. Furthermore, many of\nthe factors commonly cited for inducing these re-\nsponses are applicable to the situation with COVID-\n19; these include: fear of contracting the disease,\na disruption in daily routines, isolation related to\nbeing quarantined, and uncertainty regarding the\ndisease treatment process and outcomes, the well\nbeing of loved ones, and one’s economic situation.\nWhile disease outbreaks pose a risk to the men-\ntal health of the general population, research sug-\ngests that this risk is heightened for those with pre-\nexisting mental health concerns. People with men-\ntal health disorders are particularly susceptible to\nexperiencing negative mental health consequences\nduring times of social isolation (Usher et al., 2020).\nFurther, as Yao et al. (2020) warns, they are likely\nto have a stronger emotional response to the feel-\nings of fear, anxiety, and depression that come\nalong with COVID-19 than the general population.\nGiven the potential for the COVID-19 outbreak\nto have devastating consequences for mental health,\nit is critical that we work to understand and miti-\ngate its negative psychological effects. In this work,\nwe use Reddit, a popular social media platform, to\nstudy how COVID-19 has impacted the behavior\nof people who express mental health concerns. We\nfocus on three Reddit sub-forums, referred to as\nsubreddits, that are designed to offer peer support\nfor users who are struggling with speciﬁc types of\nmental illness. We ﬁrst measure changes in the\namount of activity on these subreddits to determine\nwhether, for a subset of the population, the need for\n\n \n \n \n \n \n \n\fonline mental health support has increased or de-\ncreased. We then analyze the content of subreddit\ndiscussions, gaining insight into how the pandemic\naffects what people choose to discuss when seek-\ning support and what types of issues push people\nto seek support. Our ﬁndings provide insights into\nhow and when COVID-19 related stressors affect\npeople dealing with mental health concerns. Criti-\ncally, we believe that this information can help to\nbetter understand the nature of a potential COVID-\n19 related mental health crisis.\n\n2 Related Work\n\n2.1 Studying Mental Health via Social Media\n\nIn the past decade, social media has emerged as\na powerful tool for understanding human behav-\nior, and correspondingly mental health. A grow-\ning number of studies have applied computational\nmethods to data collected from social media plat-\nforms in order to "
  },
  {
    "title": "A Computational Approach to Understanding Empathy Expressed in\n  Text-Based Mental Health Support",
    "authors": [
      "Ashish Sharma",
      "Adam S. Miner",
      "David C. Atkins",
      "Tim Althoff"
    ],
    "abstract": "Empathy is critical to successful mental health support. Empathy measurement\nhas predominantly occurred in synchronous, face-to-face settings, and may not\ntranslate to asynchronous, text-based contexts. Because millions of people use\ntext-based platforms for mental health support, understanding empathy in these\ncontexts is crucial. In this work, we present a computational approach to\nunderstanding how empathy is expressed in online mental health platforms. We\ndevelop a novel unifying theoretically-grounded framework for characterizing\nthe communication of empathy in text-based conversations. We collect and share\na corpus of 10k (post, response) pairs annotated using this empathy framework\nwith supporting evidence for annotations (rationales). We develop a multi-task\nRoBERTa-based bi-encoder model for identifying empathy in conversations and\nextracting rationales underlying its predictions. Experiments demonstrate that\nour approach can effectively identify empathic conversations. We further apply\nthis model to analyze 235k mental health interactions and show that users do\nnot self-learn empathy over time, revealing opportunities for empathy training\nand feedback.",
    "year": 2020,
    "url": "http://arxiv.org/abs/2009.08441v1",
    "pdf_url": "http://arxiv.org/pdf/2009.08441v1"
  },
  {
    "title": "On the State of Social Media Data for Mental Health Research",
    "authors": [
      "Keith Harrigian",
      "Carlos Aguirre",
      "Mark Dredze"
    ],
    "abstract": "Data-driven methods for mental health treatment and surveillance have become\na major focus in computational science research in the last decade. However,\nprogress in the domain, in terms of both medical understanding and system\nperformance, remains bounded by the availability of adequate data. Prior\nsystematic reviews have not necessarily made it possible to measure the degree\nto which data-related challenges have affected research progress. In this\npaper, we offer an analysis specifically on the state of social media data that\nexists for conducting mental health research. We do so by introducing an\nopen-source directory of mental health datasets, annotated using a standardized\nschema to facilitate meta-analysis.",
    "year": 2020,
    "url": "http://arxiv.org/abs/2011.05233v2",
    "pdf_url": "http://arxiv.org/pdf/2011.05233v2",
    "full_text": "On the State of Social Media Data for Mental Health Research\n\nKeith Harrigian, Carlos Aguirre, Mark Dredze\nJohns Hopkins University\nkharrigian@jhu.edu, caguirr4@jhu.edu, mdredze@cs.jhu.edu\n\n1\n2\n0\n2\n\nr\np\nA\n5\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n2\nv\n3\n3\n2\n5\n0\n.\n1\n1\n0\n2\n:\nv\ni\nX\nr\na\n\nAbstract\n\nData-driven methods for mental health treat-\nment and surveillance have become a major\nfocus in computational science research in the\nlast decade. However, progress in the do-\nmain remains bounded by the availability of\nadequate data. Prior systematic reviews have\nnot necessarily made it possible to measure\nthe degree to which data-related challenges\nhave affected research progress. In this paper,\nwe offer an analysis speciﬁcally on the state\nof social media data that exists for conduct-\ning mental health research. We do so by in-\ntroducing an open-source directory of mental\nhealth datasets, annotated using a standardized\nschema to facilitate meta-analysis.1\n\n1\n\nIntroduction\n\nThe last decade has seen exponential growth\nin computational research devoted to modeling\nmental health phenomena using non-clinical data\n(Bucci et al., 2019). Studies analyzing data from\nthe web, such as social media platforms and peer-\nto-peer messaging services, have been particularly\nappealing to the research community due to their\nscale and deep entrenchment within contemporary\nculture (Perrin, 2015; Fuchs, 2015; Graham et al.,\n2015). Such studies have yielded novel insights\ninto population-level mental health (De Choudhury\net al., 2013; Amir et al., 2019a) and shown promis-\ning avenues for the incorporation of data-driven\nanalyses in the treatment of psychiatric disorders\n(Eichstaedt et al., 2018).\n\nThese research achievements have come despite\ncomplexities speciﬁc to the mental health space\noften making it difﬁcult to obtain a sufﬁcient sam-\nple size of high-quality data. For instance, be-\nhavioral disorders are known to display variable\nclinical presentations amongst different popula-\ntions, rendering annotations of ground truth inher-\n\n1https://github.com/kharrigian/\n\nmental-health-datasets\n\nently noisy (De Choudhury et al., 2017; Arseniev-\nKoehler et al., 2018). Scalable methods for cap-\nturing an individual’s mental health status, such as\nusing regular expressions to identify self-reported\ndiagnoses or grouping individuals based on activity\npatterns, have provided opportunities to construct\ndatasets aware of this heterogeneity (Coppersmith\net al., 2015b; Kumar et al., 2015). However, they\ntypically rely on oversimpliﬁcations that lack the\nsame clinical validation and robustness as some-\nthing like a mental health battery (Zhang et al.,\n2014; Ernala et al., 2019).\n\nEthical considerations further complicate data\nacquisition, with the sensitive nature of mental\nhealth data requiring tremendous care when con-\nstructing, analyzing, and sharing datasets (Benton\net al., 2017). Privacy-preserving measures, such\nas de-identifying individuals and requiring IRB\napproval to access data, have made it possible to\nshare some data across research groups. However,\nthese mechanisms can be technically cumbersome\nto implement and are subject to strict governance\npolicies when clinical information is involved due\nto HIPAA (Price and Cohen, 2019). Moreover,\nmany privacy-preserving practices require that sig-\nnal relevant to modeling mental health, such as an\nindividual’s demographics or their social network,\nare discarded (Bakken et al., 2004). This miss-\ningness has the potential to limit algorithmic fair-\nness, statistical generalizability, and experimental\nreproducibility (Gorelick, 2006). Although mental\nhealth researchers may anecdotally recall difﬁcul-\nties acquiring quality data or reproducing prior art\ndue to data sharing constraints, no study to our\nknowledge has explicitly quantiﬁed this challenge.\nIndeed, prior reviews of computational research\nfor mental health have noted several of the afore-\nmentioned challenges, but have predominantly dis-\ncussed technical methods (e.g. model architectures,\nfeature engineering) developed to surmount exist-\ning constraints (Guntuku et al., 2017; Wongkoblap\n\n \n \n \n \n \n \n\fet al., 2017). Recent work from Chancellor and\nDe Choudhury (2020), completed concurrently\nwith our own, was the ﬁrst review to focus speciﬁ-\ncally on the shortcomings of data for mental health\nresearch. Our study afﬁrms the ﬁndings of Chancel-\nlor and De Choudhury (2020), using an expanded\npool of literature that more acutely focuses on lan-\nguage found in social media data. To this end,\nwe construct a new open-source directory of men-\ntal health datasets, annotated using a standardized\nschema that not only enables researchers to iden-\ntify relevant datasets, but also to identify accessible\ndatasets. We draw upon this resource to offer nu-\nanced recommendations regarding future dataset\ncuration efforts.\n\n2 Data\n\nTo generate evidence-based recommendations re-\ngarding mental health dataset curation, we require\nknowledge of the extant data landscape. Unlike\nsome comput"
  },
  {
    "title": "Teacher Mental Health During the COVID-19 Pandemic: Informing Policies\n  to Support Teacher Well-being and Effective Teaching Practices",
    "authors": [
      "Joseph M. Kush",
      "Elena Badillo-Goicoechea",
      "Rashelle J. Musci",
      "Elizabeth A. Stuart"
    ],
    "abstract": "While there is an emergence of research investigating the educational impacts\nof the COVID-19 pandemic, empirical studies assessing teacher mental health\nthroughout the pandemic have been scarce. Using a large national dataset, the\ncurrent study first compared mental health outcomes during the pandemic between\npK-12 teachers and professionals in other occupations. Further, we compared the\nprevalence of mental health outcomes between in-person and remote teachers (n =\n131,154). Findings indicated teachers reported greater mental health concerns\nthan those in other professions, and that remote teachers reported\nsignificantly higher levels of distress than those teaching in-person. Policy\nimplications are discussed, with a focus on providing support to meet the\nevolving needs of teachers.",
    "year": 2021,
    "url": "http://arxiv.org/abs/2109.01547v1",
    "pdf_url": "http://arxiv.org/pdf/2109.01547v1",
    "full_text": "1\n2\n0\n2\n\np\ne\nS\n3\n\n]\nP\nA\n\n.\nt\na\nt\ns\n[\n\n1\nv\n7\n4\n5\n1\n0\n.\n9\n0\n1\n2\n:\nv\ni\nX\nr\na\n\nTeacher Mental Health During the COVID-19 Pandemic:\n\nInforming Policies to Support Teacher Well-being and Eﬀective\n\nTeaching Practices\n\nJoseph M. Kush1∗, Elena Badillo-Goicoechea1, Rashelle J. Musci1, and Elizabeth A.\nStuart1\n\n1Department of Mental Health, Johns Hopkins Bloomberg School of Public Health\n\nSeptember 3, 2021\n\nAbstract\n\nWhile there is an emergence of research investigating the educational impacts of the COVID-19\n\npandemic, empirical studies assessing teacher mental health throughout the pandemic have been\n\nscarce. Using a large national dataset, the current study ﬁrst compared mental health outcomes\n\nduring the pandemic between pK-12 teachers and professionals in other occupations. Further, we\n\ncompared the prevalence of mental health outcomes between in-person and remote teachers (n =\n\n131,154). Findings indicated teachers reported greater mental health concerns than those in other\n\nprofessions, and that remote teachers reported signiﬁcantly higher levels of distress than those\n\nteaching in-person. Policy implications are discussed, with a focus on providing support to meet\n\nthe evolving needs of teachers.\n\n1 Introduction\n\nSchool districts across the United States faced an unprecedented disruption during the spring\n\nof 2020 and the 2020/2021 academic year due to the COVID-19 pandemic. Although the initial\n\nresponse of most districts was to switch to fully virtual learning (National Academies of Sciences,\n\nEngineering, and Medicine, 2020), schools varied in their instructional policies throughout the course\n\nof the pandemic: pivoting between fully remote, full onsite, and a combination of remote and onsite,\n\nsometimes allowing both students and teachers in school buildings, and other times not. While there\n\nis an ongoing emergence of research investigating the eﬀects of the COVID-19 pandemic on student\n\nachievement (e.g., Bailey et al., 2021; Kuhfeld et al., 2020), student mental health (e.g., Prowse et\n\n∗Correspondence concerning this article should be addressed to Joseph Kush, Johns Hopkins Bloomberg School of\n\nPublic Health, 624 N Broadway Room 841, Baltimore, MD 21205. Email: jkush1@jhu.edu\n\n1\n\n \n \n \n \n \n \n\fal., 2021; Tortella et al., 2021; Wasil et al., 2021), and public health and safety measures in academic\n\nsettings (e.g., Lessler et al., 2021; Doyle et al., 2021; Ismail et al., 2021), there has been less focus\non teacher mental health during the pandemic and how the instructional modalities, and changes in\n\nthem, might relate to teacher mental health.\n\nEven before the challenges brought about by the pandemic, teacher stress has long been a major\n\nconcern, with teachers consistently experiencing some of the highest levels of occupational stress among\n\nmost occupations (Johnson et al., 2005; Markow et al., 2013).With the quick initial pivot to remote\n\nteaching, followed by uncertainty due to modiﬁcations of instructional policies, we might expect that\n\nthere would be particularly high levels of stress and negative mental health outcomes among teachers\n\nduring the pandemic. As districts continue to grapple with decisions regarding in-person and remote\n\nmodalities as the ongoing public health emergency evolves, teachers face even higher uncertainty. More\n\nresearch is needed to understand teacher mental health during the pandemic, in an eﬀort to identify\n\ngroups in need of additional supports and potential interventions in the context of necessary public\n\nhealth containment measures, such as school closures.\n\nThe current study aims to address this gap in the literature by examining associations between\n\nthe COVID-19 pandemic and teachers’ mental health among primary and secondary school teachers\n\nacross the United States. Utilizing a large national dataset, we ﬁrst examined diﬀerences in mental\n\nhealth during the pandemic between pre-Kindergarten through 12th grade (pK-12) teachers and other\n\nprofessionals, including healthcare workers, oﬃce workers, and “other” professionals. Second, we\n\ncompared diﬀerences in mental health outcomes between individuals teaching in-person and remote\n\nmodalities. Findings from our study contribute to the growing body of literature on the educational\n\nimpacts of the pandemic by focusing explicitly on teachers and teacher mental health, and is the ﬁrst\n\nstudy to do so using a large national dataset.\n\n2 Teacher Stress\n\nTeachers experience some of the highest levels of occupational stress and lowest levels of well-being\n\namong all professions (Johnson et al., 2005; Bauer et al., 2006). Nearly one in four public school\n\nteachers in elementary and secondary schools in the U.S. indicates stress as a reason to discontinue\n\nteaching, a number that continues to increase over time (Snyder et al., 2019). Markow et al. (2013)\n\nfound that 51% of teachers U.S. K-12 public school teachers report “feeling under great stress several\n\ndays a week”, culminating in the lowest levels of teacher satisfactio"
  },
  {
    "title": "Incorporating Financial Hardship in Measuring the Mental Health Impact\n  of Housing Stress",
    "authors": [
      "Timothy Ludlow",
      "Jonas Fooken",
      "Christiern Rose",
      "Kam Tang"
    ],
    "abstract": "Housing expenditure tends to be sticky and costly to adjust, and makes up a\nlarge proportion of household expenditure. Additionally, the loss of housing\ncan have catastrophic consequences. These specific features of housing\nexpenditure imply that housing stress could cause negative mental health\nimpacts. This research investigates the effects of housing stress on mental\nhealth, contributing to the literature by nesting housing stress within a\nmeasure of financial hardship, thus improving robustness to omitted variables\nand creating a natural comparison group for matching. Fixed effects (FE)\nregressions and a difference-in-differences (DID) methodology are estimated\nutilising data from the Household Income and Labour Dynamics in Australia\n(HILDA) Survey. The results show that renters who are in housing stress have a\nsignificant decline in self-reported mental health, with those in prior\nfinancial hardship being more severely affected. In contrast, there is little\nto no evidence of housing stress impacting on owners with a mortgage. The\nresults also suggest that the mental health impact of housing stress is more\nimportant than some, but not all, aspects of financial hardship.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2205.01255v1",
    "pdf_url": "http://arxiv.org/pdf/2205.01255v1",
    "full_text": "Incorporating Financial Hardship in Measuring the Mental\n\nHealth Impact of Housing Stress\n\nTimothy Ludlow1,2\n\nJonas Fooken3\n\nChristiern Rose1\n\nKam Ki Tang1\n\nMay 4, 2022\n\nAbstract\n\nHousing expenditure tends to be sticky and costly to adjust, and makes up a large\n\nproportion of household expenditure. Additionally, the loss of housing can have catas-\n\ntrophic consequences. These speciﬁc features of housing expenditure imply that housing\n\nstress could cause negative mental health impacts. This research investigates the eﬀects\n\nof housing stress on mental health, contributing to the literature by nesting housing stress\n\nwithin a measure of ﬁnancial hardship, thus improving robustness to omitted variables\n\nand creating a natural comparison group for matching. Fixed eﬀects (FE) regressions\n\nand a diﬀerence-in-diﬀerences (DID) methodology are estimated utilising data from the\n\nHousehold Income and Labour Dynamics in Australia (HILDA) Survey. The results show\n\nthat renters who are in housing stress have a signiﬁcant decline in self-reported mental\n\nhealth, with those in prior ﬁnancial hardship being more severely aﬀected. In contrast,\n\nthere is little to no evidence of housing stress impacting on owners with a mortgage. The\n\nresults also suggest that the mental health impact of housing stress is more important\n\nthan some, but not all, aspects of ﬁnancial hardship.\n\n2\n2\n0\n2\n\ny\na\nM\n3\n\n]\n\nN\nG\n.\nn\no\nc\ne\n[\n\n1\nv\n5\n5\n2\n1\n0\n.\n5\n0\n2\n2\n:\nv\ni\nX\nr\na\n\n1School of Economics, The University of Queensland\n2Corresponding author: timothy.ludlow1@uqconnect.edu.au\n3Centre for the Business and Economics of Health, The University of Queensland\n\n1\n\n \n \n \n \n \n \n\f1\n\nIntroduction\n\nA frequent research ﬁnding is that lower socioeconomic status is associated with higher rates of\n\ncommon mental health disorders, suggesting prima facie that living and working in lower so-\n\ncioeconomic environments can lead to poor mental health outcomes (Dohrenwend et al., 1992;\n\nLorant et al., 2003). A prominent explanation is that disadvantaged environmental circum-\n\nstances can cause chronic arousal of stress pathways, with physiological disregulation increasing\n\nthe risk of developing mental illness (Tafet & Bernardini, 2003; Fisher & Baum, 2010). Al-\n\nthough a number of socioeconomic factors, such as poverty, low eduction, unemployment, and\n\nhousing circumstances, are associated with poor mental health, the highly correlated nature of\n\nsocioeconomic variables makes causal pathways hard to identify (Fuchs, 2004). This research\n\ninvestigates the eﬀects of housing stress on mental health. It contributes to the literature by\n\nnesting housing stress within a measure of ﬁnancial hardship, allowing for a natural comparison\n\ngroup, and therefore increasing robustness to omitted variables and reverse causality.\n\nHousing is a commonly investigated social determinant of health, with some researchers\n\nhypothesising that the experience of housing stress, where housing costs become overly bur-\n\ndensome on individual ﬁnances, can lead to declines in mental health, contributing towards the\n\nobserved socioeconomic gradient in mental health (Bentley et al., 2011; Reeves et al., 2016).\n\nThe economic features of housing expenditure means it has a particularly strong inﬂuence on\n\npersonal ﬁnances, especially for those with limited resources. Housing costs make up a large\n\nproportion of total expenditure for most lower income individuals, and actions taken to reduce\n\nthis expenditure can involve large adjustment costs. Additionally, housing is a necessity and,\n\nthus, the loss of housing can have catastrophic consequences.\n\nPrevious research investigating the eﬀect of housing stress on mental health has tended to\n\nﬁnd that unaﬀordable housing leads to small but signiﬁcant declines in mental health (Mason\n\net al., 2013; Bentley et al., 2011). However the challenges of reverse causality and omitted\n\nvariables suggest there are limitations to these results. Reverse causation is a concern as it\n\nis highly plausible that individuals with declining mental health are more prone to ﬁnancial\n\ndiﬃculties, including housing stress. This could occur, for example, if mental health declines\n\nare associated with more erratic or impulsive behaviour, which in turn increases the probability\n\nof experiencing housing stress. Omitted variables are a challenge for any observational setting\n\nand especially when investigating housing stress, as many socioeconomic variables are highly\n\ncorrelated (Fuchs, 2004). One concern is that the literature on housing stress tends to omit\n\n2\n\n\fﬁnancial hardship from the analyses, despite ﬁnancial hardship and mental health having\n\nstrong associations (Fryers et al., 2003; Butterworth et al., 2009). If results are based on a\n\nﬁxed eﬀects (FE) regressions alone, the predominant methodology used in this research area,\n\nthen they could be prone to bias in the presence of omitted variables and reverse causality.\n\nA further complication encountered in this line of research "
  },
  {
    "title": "Facilitating Self-Guided Mental Health Interventions Through\n  Human-Language Model Interaction: A Case Study of Cognitive Restructuring",
    "authors": [
      "Ashish Sharma",
      "Kevin Rushton",
      "Inna Wanyin Lin",
      "Theresa Nguyen",
      "Tim Althoff"
    ],
    "abstract": "Self-guided mental health interventions, such as \"do-it-yourself\" tools to\nlearn and practice coping strategies, show great promise to improve access to\nmental health care. However, these interventions are often cognitively\ndemanding and emotionally triggering, creating accessibility barriers that\nlimit their wide-scale implementation and adoption. In this paper, we study how\nhuman-language model interaction can support self-guided mental health\ninterventions. We take cognitive restructuring, an evidence-based therapeutic\ntechnique to overcome negative thinking, as a case study. In an IRB-approved\nrandomized field study on a large mental health website with 15,531\nparticipants, we design and evaluate a system that uses language models to\nsupport people through various steps of cognitive restructuring. Our findings\nreveal that our system positively impacts emotional intensity for 67% of\nparticipants and helps 65% overcome negative thoughts. Although adolescents\nreport relatively worse outcomes, we find that tailored interventions that\nsimplify language model generations improve overall effectiveness and equity.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2310.15461v2",
    "pdf_url": "http://arxiv.org/pdf/2310.15461v2",
    "full_text": "4\n2\n0\n2\n\nr\np\nA\n0\n1\n\n]\n\nC\nH\n.\ns\nc\n[\n\n2\nv\n1\n6\n4\n5\n1\n.\n0\n1\n3\n2\n:\nv\ni\nX\nr\na\n\nFacilitating Self-Guided Mental Health Interventions Through\nHuman-Language Model Interaction: A Case Study of Cognitive\nRestructuring\n\nAshish Sharma\nashshar@cs.washington.edu\nUniversity of Washington\nSeattle, WA, USA\n\nKevin Rushton\nkrushton@mhanational.org\nMental Health America\nAlexandria, VA, USA\n\nInna Wanyin Lin\nilin@cs.washington.edu\nUniversity of Washington\nSeattle, WA, USA\n\nTheresa Nguyen\ntnguyen@mhanational.org\nMental Health America\nAlexandria, VA, USA\n\nTim Althoff\nalthoff@cs.washington.edu\nUniversity of Washington\nSeattle, WA, USA\n\nABSTRACT\nSelf-guided mental health interventions, such as “do-it-yourself”\ntools to learn and practice coping strategies, show great promise\nto improve access to mental health care. However, these interven-\ntions are often cognitively demanding and emotionally triggering,\ncreating accessibility barriers that limit their wide-scale implemen-\ntation and adoption. In this paper, we study how human-language\nmodel interaction can support self-guided mental health interven-\ntions. We take cognitive restructuring, an evidence-based therapeutic\ntechnique to overcome negative thinking, as a case study. In an\nIRB-approved randomized field study on a large mental health web-\nsite with 15,531 participants, we design and evaluate a system that\nuses language models to support people through various steps of\ncognitive restructuring. Our findings reveal that our system posi-\ntively impacts emotional intensity for 67% of participants and helps\n65% overcome negative thoughts. Although adolescents report rel-\natively worse outcomes, we find that tailored interventions that\nsimplify language model generations improve overall effectiveness\nand equity.\n\nCCS CONCEPTS\n• Human-centered computing → Interactive systems and\ntools; • Computing methodologies → Natural language pro-\ncessing.\n\nKEYWORDS\nmental health, language models, human-AI collaboration, cognitive\nrestructuring, field study, randomized trial\n\nACM Reference Format:\nAshish Sharma, Kevin Rushton, Inna Wanyin Lin, Theresa Nguyen, and Tim\nAlthoff. 2024. Facilitating Self-Guided Mental Health Interventions Through\n\nPermission to make digital or hard copies of part or all of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for third-party components of this work must be honored.\nFor all other uses, contact the owner/author(s).\nCHI’24, May 11–16, 2024, Honolulu, HI, USA\n© 2024 Copyright held by the owner/author(s).\nACM ISBN 979-8-4007-0330-0/24/05.\nhttps://doi.org/10.1145/3613904.3642761\n\nHuman-Language Model Interaction: A Case Study of Cognitive Restruc-\nturing. In CHI’24: ACM CHI conference on Human Factors in Computing\nSystems, May 11–16, 2024, Hawaii, USA. ACM, New York, NY, USA, 29 pages.\nhttps://doi.org/10.1145/3613904.3642761\n\n1 INTRODUCTION\nAs mental health conditions surge worldwide, healthcare systems\nare struggling to provide accessible mental health care for all [62,\n63, 83]. Self-guided mental health interventions, such as tools to\njournal and reflect on negative thoughts, offer great promise to\nexpand modes of care and help people learn coping strategies [64,\n71, 72, 82]. While not a replacement for formal psychotherapy, these\ninterventions provide immediate on-demand access to resources\nthat can help develop techniques for mental well-being, especially\nfor those who lack access to a trained professional, are on waiting\nlists, or seek to supplement therapy with other forms of care [1].\n\nHowever, developing interventions that individuals can effec-\ntively use without the assistance of a professional therapist is\nchallenging [34]. Currently, most self-guided interventions sim-\nply transform traditional manual therapeutic worksheets into digi-\ntal online formats with limited instructions and support [82]. Us-\ning these worksheets without professional support often leads to\ncognitively demanding and emotionally triggering experiences,\nlimiting engagement and usage [7, 32, 34, 94]. For example, a pop-\nular self-guided intervention involves independently practicing\nCognitive Restructuring of Negative Thoughts, an evidence-based,\nwell-established process that helps people notice and change their\nnegative thinking patterns [9, 21]. However, the practice includes\ncomplex steps like identifying thinking traps (faulty or distorted\npatterns of thinking like “all-or-nothing thinking”), which pose a\nsignificant challenge for many [9, 21]. Most individuals lack the\nnecessary knowledge or experience to successfully use such in-\nterventions independently without explicit training and support.\nMoreover, analyzing one’s own thoughts, emotions, and behav-\nioral patterns can be emotionally triggering, especially for those\nactively experiencing distress. Such accessibility barriers inhibit the\nwid"
  },
  {
    "title": "Intelligent interactive technologies for mental health and well-being",
    "authors": [
      "Mladjan Jovanovic",
      "Aleksandar Jevremovic",
      "Milica Pejovic-Milovancevic"
    ],
    "abstract": "Mental healthcare has seen numerous benefits from interactive technologies\nand artificial intelligence. Various interventions have successfully used\nintelligent technologies to automate the assessment and evaluation of\npsychological treatments and mental well-being and functioning. These\ntechnologies include different types of robots, video games, and conversational\nagents. The paper critically analyzes existing solutions with the outlooks for\ntheir future. In particular, we: i)give an overview of the technology for\nmental health, ii) critically analyze the technology against the proposed\ncriteria, and iii) provide the design outlooks for these technologies.",
    "year": 2021,
    "url": "http://arxiv.org/abs/2105.05306v1",
    "pdf_url": "http://arxiv.org/pdf/2105.05306v1",
    "full_text": "1\n2\n0\n2\n\ny\na\nM\n1\n1\n\n]\n\nC\nH\n.\ns\nc\n[\n\n1\nv\n6\n0\n3\n5\n0\n.\n5\n0\n1\n2\n:\nv\ni\nX\nr\na\n\nIntelligent interactive technologies for mental\nhealth and well-being\n\nMladjan Jovanovic, Aleksandar Jevremovic, Milica Pejovic-Milovancevic\n\nAbstract 1 Mental healthcare has seen numerous beneﬁts from interactive tech-\nnologies and artiﬁcial intelligence. Various interventions have successfully used\nintelligent technologies to automate the assessment and evaluation of psychological\ntreatments and mental well-being and functioning. These technologies include dif-\nferent types of robots, video games, and conversational agents. The paper critically\nanalyzes existing solutions with the outlooks for their future. In particular, we: i)\ngive an overview of the technology for mental health, ii) critically analyze the tech-\nnology against the proposed criteria, and iii) provide the design outlooks for these\ntechnologies.\n\nKey words: Human-AI interaction, intelligent systems, digital healthcare, mental\nhealth, mental well-being, review, survey, robotic technologies, video games, con-\nversational agents, chatbots, aﬀective computing.\n\n1 Introduction\n\nArtiﬁcial Intelligence (AI) is among the oldest disciplines of computer science that\nbuilds systems that resemble humans in learning, thinking, problem-solving, and\n\nMladjan Jovanovic\nSingidunum University, Belgrade, Serbia, e-mail: mjovanovic@singidunum.ac.rs\n\nAleksandar Jevremovic\nSingidunum University, Belgrade, Serbia, e-mail: ajevremovic@singidunum.ac.rs\n\nMilica Pejovic-Milovancevic\nInstitute of Mental Health and Faculty of Medicine, University of Belgrade, Serbia, e-mail:\nmilica.pejovic@imh.org.rs\n\n1 This a pre-print version of the paper published in: E. Pap (ed.), Artiﬁcial Intelligence: Theory and\nApplications, Studies in Computational Intelligence 973, Springer Nature Switzerland AG 2021,\nDOI: https://doi.org/10.1007/978-3-030-72711-6_18\n\n1\n\n \n \n \n \n \n \n\f2\n\nMladjan Jovanovic, Aleksandar Jevremovic, Milica Pejovic-Milovancevic\n\ndecision making. The ﬁeld received signiﬁcant interest in the previous decade, mainly\ndue to advances in automated machine learning (ML) and deep learning (DL). They\nlearn useful patterns from a large amount of data and keep the acquired knowledge\nas model structures and parameters that can be further applied to make predictions\nby interpreting unseen data [1]. These models are either a set of elements or features\nthat contribute when making decisions (in ML) or are organized into several layers\nof abstraction (such as neural networks) for general and speciﬁc interpretation tasks\n(in DL).\n\nHealthcare provision and medicine are one of the most signiﬁcant challenges\nof AI due to being the pillars for a global society and the necessity of providing\nhigher-quality assistance to the healthcare workforce [2].\n\nAn emerging and expanding domain for for application of AI is mental health.\nReadily available and ubiquitous devices and applications enable the provision of\nﬂexible mental care - on-demand, at any time, both at healthcare facilities and at\nhome. Societal challenges, such as the ongoing Covid-19 pandemic, can necessitate\nphysical distancing. Consequently, prolonged social isolation brings common risks\nfor mental health and well-being, potentially triggering conditions such as loneliness,\nanxiety, and depression [3, 4]. The growing demand for telemedicine as contactless,\nremote, and accessible healthcare services can help users stay connected, visit their\ndoctors remotely, and self-manage their mental functioning during the global Covid-\n19 lockdown [3].\n\nAs they move into the digital era, mental healthcare is seeing substantial beneﬁts\nfrom interactive technologies and ML/DL, including treatment both at home and\nin hospitals. Medical decision-making is by its very nature uncertain, unknown,\ninconsistent, and lacking data from multi-dimensional spaces. At the same time, it\nmust capture patients’ heterogeneity to adjust healthcare decisions, prescriptions,\nand therapies to the individual. Moreover, healthcare professionals must understand\nthe automated decision-making process to verify it. Prevention is crucial here. It\nmaintains normal mental functioning, avoids the onset of critical conditions, pre-\nvents existing illnesses from progressing, reduces healthcare burden, and makes\npeople satisﬁed and happier [5]. Reducing the gap between health and well-being is\nsomething that traditional healthcare may struggle to achieve. These technologies can\nhelp by ingraining positive health habits through sustained user engagement [6, 7].\n\nThis paper does not focus on the implementation and performance details of the AI\nmodels and algorithms, but the consequences they have for the user experience of a\nspeciﬁc healthcare technology employing these models. In particular, we concentrate\non user-related aspects of these technologies that may inﬂuence their acceptance and\nthe eﬀectiveness of mental healthcare provision.\n\nThe paper is structured as follows. Section 2 describes a landsc"
  },
  {
    "title": "Counseling Summarization using Mental Health Knowledge Guided Utterance\n  Filtering",
    "authors": [
      "Aseem Srivastava",
      "Tharun Suresh",
      "Sarah Peregrine",
      "Lord",
      "Md. Shad Akhtar",
      "Tanmoy Chakraborty"
    ],
    "abstract": "The psychotherapy intervention technique is a multifaceted conversation\nbetween a therapist and a patient. Unlike general clinical discussions,\npsychotherapy's core components (viz. symptoms) are hard to distinguish, thus\nbecoming a complex problem to summarize later. A structured counseling\nconversation may contain discussions about symptoms, history of mental health\nissues, or the discovery of the patient's behavior. It may also contain\ndiscussion filler words irrelevant to a clinical summary. We refer to these\nelements of structured psychotherapy as counseling components. In this paper,\nthe aim is mental health counseling summarization to build upon domain\nknowledge and to help clinicians quickly glean meaning. We create a new dataset\nafter annotating 12.9K utterances of counseling components and reference\nsummaries for each dialogue. Further, we propose ConSum, a novel\ncounseling-component guided summarization model. ConSum undergoes three\nindependent modules. First, to assess the presence of depressive symptoms, it\nfilters utterances utilizing the Patient Health Questionnaire (PHQ-9), while\nthe second and third modules aim to classify counseling components. At last, we\npropose a problem-specific Mental Health Information Capture (MHIC) evaluation\nmetric for counseling summaries. Our comparative study shows that we improve on\nperformance and generate cohesive, semantic, and coherent summaries. We\ncomprehensively analyze the generated summaries to investigate the capturing of\npsychotherapy elements. Human and clinical evaluations on the summary show that\nConSum generates quality summary. Further, mental health experts validate the\nclinical acceptability of the ConSum. Lastly, we discuss the uniqueness in\nmental health counseling summarization in the real world and show evidences of\nits deployment on an online application with the support of mpathic.ai",
    "year": 2022,
    "url": "http://arxiv.org/abs/2206.03886v1",
    "pdf_url": "http://arxiv.org/pdf/2206.03886v1",
    "full_text": "Counseling Summarization using Mental Health Knowledge\nGuided Utterance Filtering\nAseem Srivastava1, Tharun Suresh1, Sarah Peregrine (Grin) Lord2, 3,\nMd. Shad Akhtar1, Tanmoy Chakraborty1\n1IIIT-Delhi, India; 2University of Washington; 3Mpathic.ai\n{aseems,tharun20119,shad.akhtar,tanmoy}@iiitd.ac.in;grin@mpathic.ai\n\n2\n2\n0\n2\n\nn\nu\nJ\n\n8\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n6\n8\n8\n3\n0\n.\n6\n0\n2\n2\n:\nv\ni\nX\nr\na\n\nABSTRACT\nThe psychotherapy intervention technique is a multifaceted con-\nversation between a therapist and a patient. Unlike general clinical\ndiscussions, psychotherapy’s core components (viz. symptoms) are\nhard to distinguish, thus becoming a complex problem to sum-\nmarize later. A structured counseling conversation may contain\ndiscussions about symptoms, history of mental health issues, or\nthe discovery of the patient’s behavior. It may also contain discus-\nsion filler words irrelevant to a clinical summary. We refer to these\nelements of structured psychotherapy as counseling components.\nIn this paper, the aim is mental health counseling summarization\nto build upon domain knowledge and to help clinicians quickly\nglean meaning. We create a new dataset after annotating 12.9𝐾\nutterances of counseling components and reference summaries for\neach dialogue. Further, we propose ConSum, a novel counseling-\ncomponent guided summarization model. ConSum undergoes three\nindependent modules. First, to assess the presence of depressive\nsymptoms, it filters utterances utilizing the Patient Health Question-\nnaire (PHQ-9), while the second and third modules aim to classify\ncounseling components. At last, we propose a problem-specific Men-\ntal Health Information Capture (MHIC) evaluation metric for coun-\nseling summaries. Our comparative study shows that we improve\non performance and generate cohesive, semantic, and coherent\nsummaries. We comprehensively analyze the generated summaries\nto investigate the capturing of psychotherapy elements. Human and\nclinical evaluations on the summary show that ConSum generates\nquality summary. Further, mental health experts validate the clini-\ncal acceptability of the ConSum. Lastly, we discuss the uniqueness\nin mental health counseling summarization in the real world and\nshow evidences of its deployment on an online application with\nthe support of mpathic.ai.\n\nCCS CONCEPTS\n• Computing methodologies → Discourse, dialogue and prag-\nmatics; Natural language generation.\n\nKEYWORDS\nDialogue Summarization, Natural Language Processing\n\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nKDD ’22, August 14–18, 2022, Washington, DC, USA\n© 2022 Association for Computing Machinery.\nACM ISBN 978-1-4503-9385-0/22/08. . . $15.00\nhttps://doi.org/10.1145/3534678.3539187\n\nFigure 1: A sample counseling session instance from the\nMEMO dataset. Symptom and History, Patient Discovery, Re-\nflecting, and Discussion Filler are psychotherapy elements.\nThe summaries pertaining to this truncated snippet of con-\nversation is shown at the bottom. Note: The summary and\nconversation are truncated for brevity.\n\n1 INTRODUCTION\nMental health counseling is one of the front-line defenses against\nmental health illness. In medical and primary care settings, the\ndoctor follows a highly-structured assessment approach that elic-\nits specific information about the patient’s medical problems to\nrule out different diagnoses. In psychotherapy counseling sessions,\npatients take center stage in elucidating their situation with sub-\ntle details. The therapist introduces diverse auxiliary context in\nconversations to put the patient at ease, discuss events happening\nin the patient’s recent past including the feelings, reflections and\nemotions that the patient experiences, and other relevant topics.\nFollow-up conversations with the patient are also vital for a suc-\ncessful treatment. The points of the counseling session that are\ncrucial for continuity of care in follow-up and treatment planning\ninclude: (a) the patient’s presenting problem, (b) symptoms and\ndiagnosis, (c) treatments (current and prior), (d) mental status and\n\nTherapist: I'm doing well. Thanks for asking. I understand you had some symptoms recently they've been bothering you.Patient: Yeah Therapist: Could you tell me about those? Patient: Yeah, for the last eight months, you know, I have this position at work where I have to make these weekly presentations and it's killing me. I can't do it anymore.Therapist: Tell me about how these presentations are set up?Patient: So it's a it's"
  },
  {
    "title": "Benefits and Harms of Large Language Models in Digital Mental Health",
    "authors": [
      "Munmun De Choudhury",
      "Sachin R. Pendse",
      "Neha Kumar"
    ],
    "abstract": "The past decade has been transformative for mental health research and\npractice. The ability to harness large repositories of data, whether from\nelectronic health records (EHR), mobile devices, or social media, has revealed\na potential for valuable insights into patient experiences, promising early,\nproactive interventions, as well as personalized treatment plans. Recent\ndevelopments in generative artificial intelligence, particularly large language\nmodels (LLMs), show promise in leading digital mental health to uncharted\nterritory. Patients are arriving at doctors' appointments with information\nsourced from chatbots, state-of-the-art LLMs are being incorporated in medical\nsoftware and EHR systems, and chatbots from an ever-increasing number of\nstartups promise to serve as AI companions, friends, and partners. This article\npresents contemporary perspectives on the opportunities and risks posed by LLMs\nin the design, development, and implementation of digital mental health tools.\nWe adopt an ecological framework and draw on the affordances offered by LLMs to\ndiscuss four application areas -- care-seeking behaviors from individuals in\nneed of care, community care provision, institutional and medical care\nprovision, and larger care ecologies at the societal level. We engage in a\nthoughtful consideration of whether and how LLM-based technologies could or\nshould be employed for enhancing mental health. The benefits and harms our\narticle surfaces could serve to help shape future research, advocacy, and\nregulatory efforts focused on creating more responsible, user-friendly,\nequitable, and secure LLM-based tools for mental health treatment and\nintervention.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2311.14693v1",
    "pdf_url": "http://arxiv.org/pdf/2311.14693v1",
    "full_text": "Benefits and Harms of Large Language Models\nin Digital Mental Health\n\nMunmun De Choudhury†, Sachin R. Pendse, Neha Kumar\nSchool of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA\n{munmund, sachin.r.pendse, neha.kumar}@gatech.edu\n\n† Corresponding author\n\nAbstract\n\nThe past decade has been transformative for mental health research and practice. The abil-\nity to harness large repositories of data, whether from electronic health records (EHR), mobile\ndevices, or social media, has revealed a potential for valuable insights into patient experiences,\npromising early, proactive interventions, as well as personalized treatment plans. Recent devel-\nopments in generative artificial intelligence, particularly large language models (LLMs), show\npromise in leading digital mental health to uncharted territory. Patients are arriving at doctors’\nappointments with information sourced from chatbots, state-of-the-art LLMs are being incor-\nporated in medical software and EHR systems, and chatbots from an ever-increasing number\nof startups promise to serve as AI companions, friends, and partners. This article presents\ncontemporary perspectives on the opportunities and risks posed by LLMs in the design, devel-\nopment, and implementation of digital mental health tools. We adopt an ecological framework\nand draw on the affordances offered by LLMs to discuss four application areas—care-seeking\nbehaviors from individuals in need of care, community care provision, institutional and med-\nical care provision, and larger care ecologies at the societal level. We engage in a thoughtful\nconsideration of whether and how LLM-based technologies could or should be employed for\nenhancing mental health. The benefits and harms our article surfaces could serve to help shape\nfuture research, advocacy, and regulatory efforts focused on creating more responsible, user-\nfriendly, equitable, and secure LLM-based tools for mental health treatment and intervention.\n\n3\n2\n0\n2\n\nv\no\nN\n7\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n3\n9\n6\n4\n1\n.\n1\n1\n3\n2\n:\nv\ni\nX\nr\na\n\n1\n\nIntroduction\n\n“When I use ChatGPT to talk things through and vent about how I feel, it goes on to tell me\nto get help and that I’m not alone. But why does it feel as if it’s mocking me? It feels as if it’s\nhaving a laugh at my expense.” – A paraphrased social media post\n\nIn November 2022 [1], OpenAI released ChatGPT. ChatGPT followed the mold of past chatbots by\nproviding a simple interface for people to easily interact with a conversational agent. However, unlike past\npublicly accessible chatbots, ChatGPT was powered by OpenAI’s proprietary language generation model,\noften called Large Language Models (LLMs). OpenAI’s LLM (named GPT, for Generative Pre-trained\n\n1\n\n \n \n \n \n \n \n\fTransformers [2]) was created through a large-scale collection of text from the Internet combined with man-\nual review through a process often called Reinforcement Learning From Human Feedback (RLHF) [3].\nChatGPT’s underlying language and simple interface astonished users with answers that were surprisingly\ncoherent and wide-ranging. Since then, conversations across academic, medical, industry, and policy do-\nmains have begun to discuss how LLMs could offer new possibilities for diagnosis, treatment, and patient\ncare in mental health.\n\nOver the past decade, there has been increased conversation around the growing potential for digital\ntechnologies, artificial intelligence (AI), and machine learning to contribute value to mental health research\nand practice. Research has demonstrated some of this potential. For example, methods from natural lan-\nguage processing (such as sentiment analysis) have been used to assess people’s emotional states from their\ntext, speech, or social media language [4, 5]. These studies have consistently shown that computational or\npredictive analyses of digital data can accurately detect mood [6], mental health states [7], and even the risk\nof potential harm [8] and suicide [9]. Collectively, the implications of this research include the potential for\nvaluable insights into daily patient experiences, a paving of the way for early and proactive interventions,\nand the design of personalized treatment plans. However, as people further rely on online tools to seek\ncare for their mental health, researchers and activists have sounded the alarm about the potential for harm\nif digital mental health interventions are staged without the awareness or consent of people experiencing\ndistress [10, 11]. Scholars have also expressed concern that the use of predictive analytics in mental health\ncould compromise patient and clinician agency [12], exacerbate systemic disparities encoded in the training\ndata of AI models [10, 13], and propagate insights poor in clinical grounding or construct validity [14].\nThe challenges in implementing an AI-informed mental health care model have further invited criticism and\nskepticism around the role of AI in this field [15], even as researchers have increasingly sought to draw upon"
  },
  {
    "title": "Big Data Analytics and AI in Mental Healthcare",
    "authors": [
      "Ariel Rosenfeld",
      "David Benrimoh",
      "Caitrin Armstrong",
      "Nykan Mirchi",
      "Timothe Langlois-Therrien",
      "Colleen Rollins",
      "Myriam Tanguay-Sela",
      "Joseph Mehltretter",
      "Robert Fratila",
      "Sonia Israel",
      "Emily Snook",
      "Kelly Perlman",
      "Akiva Kleinerman",
      "Bechara Saab",
      "Mark Thoburn",
      "Cheryl Gabbay",
      "Amit Yaniv-Rosenfeld"
    ],
    "abstract": "Mental health conditions cause a great deal of distress or impairment;\ndepression alone will affect 11% of the world's population. The application of\nArtificial Intelligence (AI) and big-data technologies to mental health has\ngreat potential for personalizing treatment selection, prognosticating,\nmonitoring for relapse, detecting and helping to prevent mental health\nconditions before they reach clinical-level symptomatology, and even delivering\nsome treatments. However, unlike similar applications in other fields of\nmedicine, there are several unique challenges in mental health applications\nwhich currently pose barriers towards the implementation of these technologies.\nSpecifically, there are very few widely used or validated biomarkers in mental\nhealth, leading to a heavy reliance on patient and clinician derived\nquestionnaire data as well as interpretation of new signals such as digital\nphenotyping. In addition, diagnosis also lacks the same objective 'gold\nstandard' as in other conditions such as oncology, where clinicians and\nresearchers can often rely on pathological analysis for confirmation of\ndiagnosis. In this chapter we discuss the major opportunities, limitations and\ntechniques used for improving mental healthcare through AI and big-data. We\nexplore both the computational, clinical and ethical considerations and best\npractices as well as lay out the major researcher directions for the near\nfuture.",
    "year": 2019,
    "url": "http://arxiv.org/abs/1903.12071v1",
    "pdf_url": "http://arxiv.org/pdf/1903.12071v1",
    "full_text": "9\n1\n0\n2\n\nr\na\n\nM\n2\n1\n\n]\n\nY\nC\n.\ns\nc\n[\n\n1\nv\n1\n7\n0\n2\n1\n.\n3\n0\n9\n1\n:\nv\ni\nX\nr\na\n\nBig Data Analytics and AI in Mental Healthcare\n\nAriel Rosenfeld∗\n\nBar-Ilan University, Israel\n\nDavid Benrimoh∗\n\nMcGill University, Canada. Aifred Health\n\nCaitrin Armstrong, Nykan Mirchi, Timothe Langlois-Therrien, Colleen Rollins, Myriam Tanguay-Sela,\nJoseph Mehltretter, Robert Fratila, Sonia Israel, Emily Snook, Kelly Perlman\n\nAifred Health\n\nAkiva Kleinerman\n\nBar-Ilan University, Israel\n\nBechara Saab, Mark Thoburn\n\nMobio Interactive\n\nCheryl Gabbay\n\nMcGill University, Canada\n\nAmit Yaniv-Rosenfeld\n\nTel-Aviv University, Israel\n\nAbstract\n\nMental health conditions cause a great deal of distress or impairment; depression alone will aﬀect 11% of the\n\nworld’s population. The application of Artiﬁcial Intelligence (AI) and big-data technologies to mental health\n\nhas great potential for personalizing treatment selection, prognosticating, monitoring for relapse, detecting\n\nand helping to prevent mental health conditions before they reach clinical-level symptomatology, and even\n\ndelivering some treatments. However, unlike similar applications in other ﬁelds of medicine, there are several\n\nunique challenges in mental health applications which currently pose barriers towards the implementation\n\nof these technologies. Speciﬁcally, there are very few widely used or validated biomarkers in mental health,\n\nleading to a heavy reliance on patient and clinician derived questionnaire data as well as interpretation of\n\nnew signals such as digital phenotyping. In addition, diagnosis also lacks the same objective gold standard as\n\nin other conditions such as oncology, where clinicians and researchers can often rely on pathological analysis\n\nfor conﬁrmation of diagnosis. In this chapter we discuss the major opportunities, limitations and techniques\n\nused for improving mental healthcare through AI and big-data. We explore both the computational, clinical\n\nand ethical considerations and best practices as well as lay out the major researcher directions for the near\n\nfuture.\n\nPreprint submitted to Journal of LATEX Templates\n\nMarch 29, 2019\n\n \n \n \n \n \n \n\f1. Introduction\n\nThe conceptualization, diagnosis, treatment and prevention of mental disorders is limited by existing\n\noptions for collecting, organizing and analyzing information. Big data and machine learning/artiﬁcial intel-\n\nligence (ML/AI) can be applied to the development of tools that could help patients, providers and systems\n\novercome these limitations. As many as 1 in 5 people experience mental illness. Mental disorders aﬀect\n\nindividuals’ abilities to function, engage meaningfully in daily activities and maintain relationships. They\n\ncause signiﬁcant suﬀering to individuals and their families and are a signiﬁcant source of socio-economic\n\nburden [1]. Many mental disorders are also risk factors for suicide which occurs at an alarming rate globally\n\n[2]. These are disorders that often strike young and otherwise healthy people, a socially and economically\n\ncritical segment of the population. As such, improving the detection, treatment, and monitoring of mental\n\nillness is crucial.\n\nDesigning tools for practical use-cases in mental healthcare requires a deep understanding of psychiatric\n\nillness, the current mental healthcare system, and medical ethics. We begin with an introduction of mental\n\nillness and healthcare, and proceed to discussing their complexities from a clinical and data-driven per-\n\nspective, before discussing speciﬁc use cases and applications of big data and machine learning approaches.\n\nTo the reader from engineering and computer science: perhaps the most important conclusion from this\n\nchapter is that close collaboration with domain experts and clinicians will be required invariably in order to\n\nsuccessfully build safe, eﬀective, and useful mental healthcare applications.\n\nMental illnesses are a group of diverse conditions with varying severity, complexity, and duration. In\n\nconsidering deviations from normal thought, feeling and behavior, characteristic of mental illness, it is\n\ncritical to recognize the extent to which they lead to functional impairment. To be classiﬁed as a disorder,\n\na set of symptoms must cause signiﬁcant suﬀering or interference with daily functions or life goals [3]. This\n\nmeans that the treatment of mental illnesses has largely the same objective as other branches of medicine:\n\nthe alleviation of suﬀering, the improvement of function and quality of life, and the reduction of morbidity\n\n(the incidence of new diseases or impairments) and mortality (or the rate of death, primarily from suicide\n\nor reduced life expectancy because of impaired self-care). These then are the objectives of the clinical\n\nprofessionals who treat patients with mental illness. Family doctors are the primary providers of mental\n\nhealthcare [4] and are accompanied by many other healthcare workers and specialists such as psychiatrists,\n\npsychologists, nurses, social workers, case managers, occu"
  },
  {
    "title": "Mental Health Diagnosis in the Digital Age: Harnessing Sentiment\n  Analysis on Social Media Platforms upon Ultra-Sparse Feature Content",
    "authors": [
      "Haijian Shao",
      "Ming Zhu",
      "Shengjie Zhai"
    ],
    "abstract": "Amid growing global mental health concerns, particularly among vulnerable\ngroups, natural language processing offers a tremendous potential for early\ndetection and intervention of people's mental disorders via analyzing their\npostings and discussions on social media platforms. However, ultra-sparse\ntraining data, often due to vast vocabularies and low-frequency words, hinders\nthe analysis accuracy. Multi-labeling and Co-occurrences of symptoms may also\nblur the boundaries in distinguishing similar/co-related disorders. To address\nthese issues, we propose a novel semantic feature preprocessing technique with\na three-folded structure: 1) mitigating the feature sparsity with a weak\nclassifier, 2) adaptive feature dimension with modulus loops, and 3)\ndeep-mining and extending features among the contexts. With enhanced semantic\nfeatures, we train a machine learning model to predict and classify mental\ndisorders. We utilize the Reddit Mental Health Dataset 2022 to examine\nconditions such as Anxiety, Borderline Personality Disorder (BPD), and\nBipolar-Disorder (BD) and present solutions to the data sparsity challenge,\nhighlighted by 99.81% non-zero elements. After applying our preprocessing\ntechnique, the feature sparsity decreases to 85.4%. Overall, our methods, when\ncompared to seven benchmark models, demonstrate significant performance\nimprovements: 8.0% in accuracy, 0.069 in precision, 0.093 in recall, 0.102 in\nF1 score, and 0.059 in AUC. This research provides foundational insights for\nmental health prediction and monitoring, providing innovative solutions to\nnavigate challenges associated with ultra-sparse data feature and intricate\nmulti-label classification in the domain of mental health analysis.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2311.05075v1",
    "pdf_url": "http://arxiv.org/pdf/2311.05075v1",
    "full_text": "Mental  Health  Diagnosis  in  the  Digital  Age:  Harnessing  Sentiment \nAnalysis on Social Media Platforms upon Ultra-Sparse Feature Content \n\nHaijian Shao, Ming Zhu, Shengjie Zhai* \nDept. of Electrical and Computer Engineering, University of Nevada, Las Vegas, NV 89154, USA \n\nCorresponding author: Dr. Shengjie Zhai (shengjie.zhai@unlv.edu) \n\nAbstract:  \nAmid  growing  global  mental  health  concerns,  particularly  among  vulnerable  groups, \nnatural  language  processing  offers  a  tremendous  potential  for  early  detection  and \nintervention of people’s mental disorders via analyzing their postings and discussions on \nsocial media platforms. However, ultra-sparse training data, often due to vast vocabularies \nand low-frequency words, hinders the analysis accuracy. Multi-labeling/Cooccurrences of \nsymptoms may also blur the boundaries in distinguishing similar/co-related disorders. To \naddress these issues, we propose a novel semantic feature preprocessing technique with a \nthree-folded structure: 1) mitigating the feature sparsity with a weak classifier, 2) adaptive \nfeature dimension with modulus loops, and 3) deep-mining and extending features among \nthe  contexts.  With  enhanced  semantic  features,  we  train  a  machine  learning  model  to \npredict and classify mental disorders. We utilize the Reddit Mental Health Dataset 2022 to \nexamine conditions such as Anxiety, Borderline Personality Disorder (BPD), and Bipolar-\nDisorder (BD) and present solutions to the data sparsity challenge, highlighted by 99.81% \nnon-zero  elements.  After  applying  our  preprocessing  technique,  the  feature  sparsity \ndecreases to 85.4%. Overall, our methods, when compared to seven benchmark models, \ndemonstrate significant performance improvements: 8.0% in accuracy, 0.069 in precision, \n0.093 in recall, 0.102 in F1 score, and 0.059 in AUC. This research provides foundational \ninsights  for  mental  health  prediction  and  monitoring,  providing  innovative  solutions  to \nnavigate  challenges  associated  with  ultra-sparse  data/feature  and  intricate  multi-label \nclassification in the domain of mental health analysis. \n\n1. Introduction \n\n       Over the last decade, the prevalence and increasing impact of mental health disorders \nhave raised a pivotal concern in global public health discourses (World Health Organization, \n2021)1.  These  disorders  transcend  age,  gender,  and  socio-economic  statuses.  However, \nparticular  populations  find  themselves  more  susceptible  due  to  a  confluence  of  social \ndeterminants, including but not limited to, economic deprivation, systemic discrimination, \nand  restricted  educational  opportunities2.  Such  socio-economic  determinants  have  been \nempirically  shown  to  widen  health  disparities,  particularly  for  marginalized  groups.  To \nelucidate, data suggests that ethnic minorities within the United States frequently encounter \nbarriers to accessing premium mental health services, especially when compared to their \nnon-Hispanic white counterparts3. Such systematic inadequacies in prevention, treatment, \nand  access  for  these  vulnerable  demographics  underscore  and  amplify  the  overarching \n\nPage 1 of 21 \n\n \n \n\fchallenges of mental health care.        \n      Concurrently, as we navigate through the digital era, there has been a transformative \nascendancy  of  social  media  platforms.  These  platforms  have  evolved  beyond  their \nfoundational role as communication tools, encompassing multifarious roles ranging from \nnews dissemination and entertainment to e-commerce and public service facilitation4. This \nparadigm shift is most evident in the massive user engagements observed on platforms like \nFacebook and Reddit. What is particularly salient about contemporary social media is its \ndemocratization of information, empowering users not only as passive consumers, but also \nas active participants and creators, fostering direct, meaningful engagements with others. \nIn this vast ocean of user-generated content lies an untapped reservoir of potential insights \nfor the mental health sector. Pioneering researchers have begun harnessing the capabilities \nof Natural  Language Processing (NLP)  and machine learning  (ML) techniques, such as \nsentiment  analysis,  to  distill  actionable  insights  from  this  vast  and  dynamic  data  pool. \nThese  methodologies  are  poised  to  revolutionize  early  detection  mechanisms  for \nindividuals grappling with mental health issues5. Yet, a quintessential challenge specific to \nsocial  media  data  lies  in  its  linguistic  informality—abbreviated  lexicons,  syntactic \nanomalies,  and  sometimes  logical  inconsistencies.  Such  linguistic  traits  are  especially \npronounced in posts from users with mental disorders, leading to an overall reduction in \nthe “informatic feature density”. Consequently, enhancing the robustness and accuracy of \nsentiment analysis in such contexts demands rigorous exploratio"
  },
  {
    "title": "Identifying physical health comorbidities in a cohort of individuals\n  with severe mental illness: An application of SemEHR",
    "authors": [
      "Rebecca Bendayan",
      "Honghan Wu",
      "Zeljko Kraljevic",
      "Robert Stewart",
      "Tom Searle",
      "Jaya Chaturvedi",
      "Jayati Das-Munshi",
      "Zina Ibrahim",
      "Aurelie Mascio",
      "Angus Roberts",
      "Daniel Bean",
      "Richard Dobson"
    ],
    "abstract": "Multimorbidity research in mental health services requires data from physical\nhealth conditions which is traditionally limited in mental health care\nelectronic health records. In this study, we aimed to extract data from\nphysical health conditions from clinical notes using SemEHR. Data was extracted\nfrom Clinical Record Interactive Search (CRIS) system at South London and\nMaudsley Biomedical Research Centre (SLaM BRC) and the cohort consisted of all\nindividuals who had received a primary or secondary diagnosis of severe mental\nillness between 2007 and 2018. Three pairs of annotators annotated 2403\ndocuments with an average Cohen's Kappa of 0.757. Results show that the NLP\nperformance varies across different diseases areas (F1 0.601 - 0.954)\nsuggesting that the language patterns or terminologies of different condition\ngroups entail different technical challenges to the same NLP task.",
    "year": 2020,
    "url": "http://arxiv.org/abs/2002.08901v1",
    "pdf_url": "http://arxiv.org/pdf/2002.08901v1",
    "full_text": "Identifying physical health comorbidities in a cohort of individuals with \nsevere mental illness: An application of SemEHR \n\nRebecca Bendayan1, 2, Honghan Wu,3,4, Zeljko Kraljevic1, Robert Stewart2,5, Tom Searle1, \nJaya Chaturvedi1, Jayati Das-Munshi2,5, Zina Ibrahim1, Aurelie Mascio1, Angus Roberts1,2, \nDaniel Bean1,6, Richard Dobson1,2,6,7  \n\n1Department of Biostatistics and Health Informatics, Institute of Psychiatry, Psychology and Neuroscience, \nKing’s College London, London, United Kingdom \n2NIHR Biomedical Research Centre at South London and Maudsley NHS Foundation Trust and King’s \nCollege London, London, United Kingdom \n3Centre for Medical Informatics, Usher Institute, University of Edinburgh, United Kingdom \n4Health Data Research UK Edinburgh, University of Edinburgh, United Kingdom \n5Department of Psychological Medicine, Institute of Psychiatry, Psychology and Neuroscience, King’s College \nLondon, London, United Kingdom \n6Health Data Research UK London, University College London, London, United Kingdom \n7Institute of Health Informatics, University College London, London, United Kingdom \n\nAbstract \n\nMultimorbidity research in mental health services requires data from physical health conditions which is traditionally \nlimited in mental health care electronic health records. In this study, we aimed to extract data from physical health \nconditions from clinical notes using SemEHR. Data was extracted from Clinical Record Interactive Search (CRIS) \nsystem  at  South  London  and Maudsley  Biomedical  Research  Centre  (SLaM  BRC)  and  the  cohort  consisted  of  all \nindividuals who had received a primary or  secondary diagnosis of severe mental illness between 2007 and 2018. \nThree pairs of annotators annotated 2403 documents with an average Cohen's κ of 0.757. Results show that the NLP \nperformance  varies  across  different  diseases  areas  (F1  0.601  –  0.954)  suggesting  that  the  language  patterns  or \nterminologies of different condition groups entail different technical challenges to the same NLP task.  \n\nIntroduction \n\nThe Academy of Medical Sciences (2018) has highlighted that the increase of multimorbidity (2 or more co-existent \nhealth  conditions)  in  our  population  constitutes  a  challenge  for  our  health  care.  Research  on  multimorbidity \ntraditionally  focuses  on  the  ageing  population,  however  there  is  a  need  to  understand  multimorbidity  in  other \npopulations such as individuals with mental health disorders. Similarly, the Framework for Mental Health Research \ndeveloped by the Department of Health (2017) acknowledged the need to account for the interactions between mental \nand  physical  health  to  reduce  the  mortality  gap  between  individuals  with  severe  mental  illnesses  (SMI),  such  as \nschizophrenia or bipolar disorder, and the general population.  \n\nLarge national population studies have very limited data for individuals with mental health disorders and therefore \nstudies have to use other data sources such as electronic health records (EHRs). The rise of the use of EHRs and the \nUK  government’s  commitment  for  the  NHS  to  be  paperless  by  2020  provides  us  a  unique  opportunity  to  access \nrelevant data for this population. One of the largest providers of secondary mental health care in UK and Europe is \nthe  South London and Maudsley (SLaM) NHS Foundation Trust.  In 2007, the SLaM NIHR Biomedical Research \nCentre (BRC) developed the Clinical Record Interactive Search (CRIS) system to enable routinely collected mental \nhealth EHRs to be used in research, and since 2013 this has been deployed successfully at other mental health NHS \nFoundation Trusts across the UK. However, structured data on physical health conditions is limited in mental health \ncare EHRs and this data is mainly hidden in unstructured clinical notes which has so far limited their use for the study \nof multimorbidity in SMI. Within this context, there is a need to make this data on physical health conditions available \nfor researchers. \n\nSemEHR,  an  open  source  toolkit  that  integrates  text  mining  and  semantic  computing  for  identifying  mentions  of \nUnified  Medical  Language  System  (UMLS)  concepts  from  clinical  documents,  has  been  particularly  helpful  in \nextracting data from systems such as the CRIS system [1]. A preliminary study [2] focusing in schizophrenia patients \n\n \n \n \n\fhas  used  SemEHR  to  extract  and  validate  9  ICD-10  chapter  level  codes  representing  viral  infection,  endocrine, \nneurologic, cardiovascular, respiratory, digestive, skin, musculoskeletal and urogenital systems. The present study \nbuilds on this work as we aim to identify a larger number of chapter level codes and validate them in the larger SMI \ncohort, including additionally bipolar affective disorders and non-organic psychoses.  \n\nMethods \n\nCorpus selection and preprocessing: The South London and Maudsley Mental Health Case Register \n\nData was extracte"
  },
  {
    "title": "Personal Mental Health Navigator: Harnessing the Power of Data, Personal\n  Models, and Health Cybernetics to Promote Psychological Well-being",
    "authors": [
      "Amir M. Rahmani",
      "Jocelyn Lai",
      "Salar Jafarlou",
      "Asal Yunusova",
      "Alex. P. Rivera",
      "Sina Labbaf",
      "Sirui Hu",
      "Arman Anzanpour",
      "Nikil Dutt",
      "Ramesh Jain",
      "Jessica L. Borelli"
    ],
    "abstract": "Traditionally, the regime of mental healthcare has followed an episodic\npsychotherapy model wherein patients seek care from a provider through a\nprescribed treatment plan developed over multiple provider visits. Recent\nadvances in wearable and mobile technology have generated increased interest in\ndigital mental healthcare that enables individuals to address episodic mental\nhealth symptoms. However, these efforts are typically reactive and\nsymptom-focused and do not provide comprehensive, wrap-around, customized\ntreatments that capture an individual's holistic mental health model as it\nunfolds over time. Recognizing that each individual is unique, we present the\nnotion of Personalized Mental Health Navigation (MHN): a therapist-in-the-loop,\ncybernetic goal-based system that deploys a continuous cyclic loop of\nmeasurement, estimation, guidance, to steer the individual's mental health\nstate towards a healthy zone. We outline the major components of MHN that is\npremised on the development of an individual's personal mental health state,\nholistically represented by a high-dimensional cover of multiple knowledge\nlayers such as emotion, biological patterns, sociology, behavior, and\ncognition. We demonstrate the feasibility of the personalized MHN approach via\na 12-month pilot case study for holistic stress management in college students\nand highlight an instance of a therapist-in-the-loop intervention using MHN for\nmonitoring, estimating, and proactively addressing moderately severe depression\nover a sustained period of time. We believe MHN paves the way to transform\nmental healthcare from the current passive, episodic, reactive process (where\nindividuals seek help to address symptoms that have already manifested) to a\ncontinuous and navigational paradigm that leverages a personalized model of the\nindividual, promising to deliver timely interventions to individuals in a\nholistic manner.",
    "year": 2020,
    "url": "http://arxiv.org/abs/2012.09131v1",
    "pdf_url": "http://arxiv.org/pdf/2012.09131v1",
    "full_text": "0\n2\n0\n2\nc\ne\nD\n5\n1\n\n]\n\nC\nH\n.\ns\nc\n[\n\n1\nv\n1\n3\n1\n9\n0\n.\n2\n1\n0\n2\n:\nv\ni\nX\nr\na\n\nPersonal Mental Health Navigator: Harnessing the Power of Data, Personal\nModels, and Health Cybernetics to Promote Psychological Well-being\n\nAmir M. Rahmania,b,∗, Jocelyn Laic, Salar Jafarloua, Asal Yunusovac, Alex. P. Riverac, Sina Labbafa, Sirui Hud,e,\nArman Anzanpourf, Nikil Dutta, Ramesh Jaina, Jessica L. Borellic\n\naDepartment of Computer Science, University of California, Irvine, USA\nbSchool of Nursing, University of California, Irvine, USA\ncDepartment of Psychological Science, University of California, Irvine, USA\ndDepartment of Statistics, University of California, Irvine, USA\neDepartment of Economics, University of California, Irvine, USA\nfDepartment of Future Technologies, University of Turku, Turku, Finland\n\nAbstract\n\nTraditionally, the regime of mental healthcare has followed an episodic psychotherapy model wherein patients seek\ncare from a provider through a prescribed treatment plan developed over multiple provider visits. Recent advances in\nwearable and mobile technology have generated increased interest in digital mental healthcare that enables individuals\nto address episodic mental health symptoms such as depression and anxiety. However, despite providers’ best inten-\ntions, these efforts are typically reactive and symptom-focused, and do not provide comprehensive, wrap-around,\ncustomized treatments that capture an individual’s holistic mental health model as it unfolds over time. Recogniz-\ning that each individual is unique and requires personally tailored mental health treatment, we present the notion of\nPersonalized Mental Health Navigation (MHN): a therapist-in-the-loop, cybernetic goal-based system that deploys\na continuous cyclic loop of measurement, estimation, guidance, to steer the individual’s mental health state towards\na healthy zone. We outline the major components of MHN that is premised on the development of an individual’s\npersonal mental health state, holistically represented by a high-dimensional cover of multiple knowledge layers such\nas emotion, biological patterns, sociology, behavior, and cognition. We demonstrate the feasibility of the personalized\nMHN approach via a 12-month pilot case study for holistic stress reduction and management in college students, and\nhighlight an instance of a therapist-in-the-loop intervention using MHN for monitoring, estimating, and proactively\naddressing moderately severe depression over a sustained period of time. We believe MHN paves the way to transform\nmental healthcare from the current passive, episodic, reactive process (where individuals seek help to address symp-\ntoms that have already manifested) to a continuous and navigational paradigm that leverages a personalized model of\nthe individual, promising to deliver timely interventions to individuals in a holistic manner.\n\nKeywords: Mental Health, Stress, Anxiety, Personicle, Life-logging, Internet-of-Things, Wearable Technology,\nHealth Cybernetics, Personal Health Models\n\n1. Introduction\n\nMental health is an important factor in determining an individual’s quality of life. While it can directly affect the\nquality of life, mental health can also have indirect effects, for instance by changing the ways in which individuals\nengage in decision making processes, resulting in potential long-term effects across the lifespan [1, 2]. Recognizing\nthat each person is unique, the recent P4 medicine approach [3] aims to transform the practice of medicine from a\ntraditionally reactive, symptomatic approach to a proactive systems approach that addresses the causes via predictive,\npreventive, personalized and participatory strategies. The current mental healthcare system similarly deploys an acute\nand symptom-focused reactive approach to patient well-being. Healthcare providers often intervene after symptoms\n\n∗Corresponding author\nEmail address: a.rahmani@uci.edu (Amir M. Rahmani)\n\n1\n\n \n \n \n \n \n \n\fhave already manifested within an individual, as opposed to adopting an approach that seeks to prevent illness from\ndeveloping or sustain well-being. One major drawback of this system is its passive approach to mental health. Indeed,\nin many cases individuals only become conscious of their issues once their conditions become severe or reach a point\nwhere they perceive a need for the issue to be addressed [4, 5]. In this passive, reactive model, there would be little\neffort to monitor one’s own behavior or experiences as well as actively seek guidance in the absence of conscious\ndiscomfort.\n\nFurthermore, the traditional episodic medical and psychotherapy model of treatment for mental health is premised\non the notion that providers interact with the individual during scheduled appointments potentially few and far be-\ntween, or otherwise for prearranged circumscribed amounts of time per week. The provider relies upon the individual\nto be an accurate reporter of their symptoms and health, both in the present moment and over a period of t"
  },
  {
    "title": "Extended Reality for Mental Health Evaluation -A Scoping Review",
    "authors": [
      "Omisore Olatunji",
      "Ifeanyi Odenigbo",
      "Joseph Orji",
      "Amelia Beltran",
      "Nilufar Baghaei",
      "Meier Sandra",
      "Rita Orji"
    ],
    "abstract": "Mental health disorders are the leading cause of health-related problems\nglobally. It is projected that mental health disorders will be the leading\ncause of morbidity among adults as the incidence rates of anxiety and\ndepression grows globally. Recently, extended reality (XR), a general term\ncovering virtual reality (VR), augmented reality (AR) and mixed reality (MR),\nis paving a new way to deliver mental health care. In this paper, we conduct a\nscoping review on the development and application of XR in the area of mental\ndisorders. We performed a scoping database search to identify the relevant\nstudies indexed in Google Scholar, PubMed, and the ACM Digital Library. A\nsearch period between August 2016 and December 2023 was defined to select\narticles related to the usage of VR, AR, and MR in a mental health context. We\nidentified a total of 85 studies from 27 countries across the globe. By\nperforming data analysis, we found that most of the studies focused on\ndeveloped countries such as the US (16.47%) and Germany (12.94%). None of the\nstudies were for African countries. The majority of the articles reported that\nXR techniques led to a significant reduction in symptoms of anxiety or\ndepression. More studies were published in the year 2021, i.e., 31.76% (n =\n31). This could indicate that mental disorder intervention received a higher\nattention when COVID-19 emerged. Most studies (n = 65) focused on a population\nbetween 18 and 65 years old, only a few studies focused on teenagers (n = 2).\nAlso, more studies were done experimentally (n = 67, 78.82%) rather than by\nanalytical and modeling approaches (n = 8, 9.41%). This shows that there is a\nrapid development of XR technology for mental health care. Furthermore, these\nstudies showed that XR technology can effectively be used for evaluating mental\ndisorders in similar or better way as the conventional approaches.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2204.01348v2",
    "pdf_url": "http://arxiv.org/pdf/2204.01348v2",
    "full_text": "Accepted for Publication in JMIR Serious Games \n\nReview \n\nExtended Reality for Mental Health Evaluation —A Scoping \nReview \n\nOlatunji Omisore, PhD1; Ifeanyi Odenigbo, MSc2; Joseph Orji, MSc2; Amelia Beltran, MSc2; \nMeier Sandra, PhD, MD3; Nilufar Baghaei, PhD4; Rita Orji, PhD2 \n\n1\n\nShenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen 518055, China. \n\n2\n\n3\n\n4\n\nFaculty of Computer Science, Dalhousie University, Halifax, Canada \n\nSchool of Information Technology and Electrical Engineering, University of Queensland, Brisbane, Australia \n\nDepartment of Psychiatry, Dalhousie University, Halifax, Nova Scotia, Canada  \n\nCorresponding Author: \nOlatunji Omisore, \nShenzhen Institutes of Advanced Technology,  \nChinese Academy of Sciences, Shenzhen 518055, China.  \nPhone: 8613172482240  \nEmail: ootsorewilly@gmail.com  \n\nAbstract \nBackground:  Mental  health disorders  are the  leading cause  of health-related  problems globally. It  is  projected \nthat mental health disorders will be the leading cause of morbidity among adults as the incidence rates of anxiety \nand  depression  grows  globally.  Recently,  extended  reality  (XR),  a  general  term  covering  virtual  reality  (VR), \naugmented reality (AR) and mixed reality (MR), is paving a new way to deliver mental health care. In this paper, \nwe conduct a scoping review of the development and application of XR in the area of mental disorders.  \nObjective: We investigated the adoption and implementation XR technologies used for the intervention of mental \ndisorders. This study aims to provide statistical analyses of the design, usage, and effectiveness of XR technology \nfor mental health intervention with a global demographic focus.  \nMethods:  We performed a scoping database search to identify the relevant studies indexed in Google Scholar, \nPubMed, and the ACM Digital Library. A search period between August 2016 and December 2023 was defined \nto select articles related to the usage of VR, AR, and MR in a mental health context. The database search was \nperformed with pre-defined queries, and a total of 831 articles were identified. Ten (10) additional articles were \nidentified  through  professional  recommendation.  Inclusion  and  exclusion  criteria  were  designed  and  applied  to \nensure that only the relevant studies were included in the literature review. \nResults:  W e identified a total of 85 studies from 27 countries across the globe. By performing data analysis, we \nfound that most of the studies focused on developed countries such as the United States (16.47%) and Germany \n(12.94%).  None  of  the  studies  were  for  African  countries.  The  majority  of  the  articles  reported  that  XR \ntechniques  led  to  a  significant  reduction  in  symptoms  of  anxiety  or  depression.  The  majority  of  studies  were \npublished in the year 2021, i.e., 31.76% (n = 31) of the included studies. This could indicate that mental disorder \nintervention received a higher attention when COVID-19 emerged. Most studies (n = 65, 76.47%) focused on a \npopulation between the age range of 18 to 65 years old, while only fewer studies focused on teenagers (n = 2, \n3.35%), i.e. subjects between the ages of 10 to 19 years old. Also, more studies were done experimentally (n = \n67, 78.82%) rather than by analytical and modeling approaches (n = 8, 9.41%). This shows that there is a rapid \ndevelopment  of  XR  technology  for  mental  health  care.  Furthermore,  these  studies  showed  that  XR  technology \ncan effectively be used for evaluating mental disorders in similar or better way as the conventional approaches. \nConclusions: In this scoping review, we studied the adoption and implementation of XR technology for mental \ndisorder care. This covers 85 studies that used different types of VR, AR, and MR techniques for managing 14 \ntypes of mental disorders. Our study identifies that XR treatment yields high patient satisfaction and follow-up \nassessments show significant improvement with large effect sizes. Moreover, the studies adopted unique designs \nthat  are  set  up  to  record  and  analyze  the  symptoms  reported  by  their  participants.  This  review  study  may  aid \nfuture research and development of various XR mechanisms for differentiated mental disorder procedures. \n\nKEYWORDS:  \nExtended reality; mental health; depression; anxiety; exposure therapy;  \n\n \n \n \n \n\fOmisore et al. 2024 \n\nIntroduction \nBackground \nMental disorders are defined as behavioral or mental patterns that cause significant distress or impairment \nfor an individual. These are highly prevalent and, currently, are the leading cause of disability globally. In \nthe last decades, a global increase in the incidence of these disorders has been observed [1, 2]. According \nto  the  World  Health  Organization  (WHO),  mental  disorders  are  the  leading  cause  of  disability  in  the \nUnited States and the United Kingdom. The WHO predicted that mental disorders would accou"
  },
  {
    "title": "Mental-LLM: Leveraging Large Language Models for Mental Health\n  Prediction via Online Text Data",
    "authors": [
      "Xuhai Xu",
      "Bingsheng Yao",
      "Yuanzhe Dong",
      "Saadia Gabriel",
      "Hong Yu",
      "James Hendler",
      "Marzyeh Ghassemi",
      "Anind K. Dey",
      "Dakuo Wang"
    ],
    "abstract": "Advances in large language models (LLMs) have empowered a variety of\napplications. However, there is still a significant gap in research when it\ncomes to understanding and enhancing the capabilities of LLMs in the field of\nmental health. In this work, we present a comprehensive evaluation of multiple\nLLMs on various mental health prediction tasks via online text data, including\nAlpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4. We conduct a broad range of\nexperiments, covering zero-shot prompting, few-shot prompting, and instruction\nfine-tuning. The results indicate a promising yet limited performance of LLMs\nwith zero-shot and few-shot prompt designs for mental health tasks. More\nimportantly, our experiments show that instruction finetuning can significantly\nboost the performance of LLMs for all tasks simultaneously. Our best-finetuned\nmodels, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of\nGPT-3.5 (25 and 15 times bigger) by 10.9% on balanced accuracy and the best of\nGPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with the\nstate-of-the-art task-specific language model. We also conduct an exploratory\ncase study on LLMs' capability on mental health reasoning tasks, illustrating\nthe promising capability of certain models such as GPT-4. We summarize our\nfindings into a set of action guidelines for potential methods to enhance LLMs'\ncapability for mental health tasks. Meanwhile, we also emphasize the important\nlimitations before achieving deployability in real-world mental health\nsettings, such as known racial and gender bias. We highlight the important\nethical risks accompanying this line of research.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2307.14385v4",
    "pdf_url": "http://arxiv.org/pdf/2307.14385v4",
    "full_text": "32\n\n4\n2\n0\n2\n\nn\na\nJ\n\n8\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n4\nv\n5\n8\n3\n4\n1\n.\n7\n0\n3\n2\n:\nv\ni\nX\nr\na\n\nMental-LLM: Leveraging Large Language Models for Mental Health\nPrediction via Online Text Data\nXUHAI XU, Massachusetts Institute of Technology & University of Washington, USA\nBINGSHENG YAO, Rensselaer Polytechnic Institute, USA\nYUANZHE DONG, Stanford University, USA\nSAADIA GABRIEL, Massachusetts Institute of Technology, USA\nHONG YU, University of Massachusetts Lowell, USA\nJAMES HENDLER, Rensselaer Polytechnic Institute, USA\nMARZYEH GHASSEMI, Massachusetts Institute of Technology, USA\nANIND K. DEY, University of Washington, USA\nDAKUO WANG, Northeastern University, USA\n\nAdvances in large language models (LLMs) have empowered a variety of applications. However, there is still a significant\ngap in research when it comes to understanding and enhancing the capabilities of LLMs in the field of mental health. In this\nwork, we present a comprehensive evaluation of multiple LLMs on various mental health prediction tasks via online text data,\nincluding Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4. We conduct a broad range of experiments, covering zero-shot\nprompting, few-shot prompting, and instruction fine-tuning. The results indicate a promising yet limited performance of\nLLMs with zero-shot and few-shot prompt designs for mental health tasks. More importantly, our experiments show that\ninstruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned\nmodels, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of GPT-3.5 (25 and 15 times bigger) by\n10.9% on balanced accuracy and the best of GPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with\nthe state-of-the-art task-specific language model. We also conduct an exploratory case study on LLMs’ capability on mental\nhealth reasoning tasks, illustrating the promising capability of certain models such as GPT-4. We summarize our findings into\na set of action guidelines for potential methods to enhance LLMs’ capability for mental health tasks. Meanwhile, we also\nemphasize the important limitations before achieving deployability in real-world mental health settings, such as known racial\nand gender bias. We highlight the important ethical risks accompanying this line of research.\n\nCCS Concepts: • Human-centered computing → Ubiquitous and mobile computing; • Applied computing → Life\nand medical sciences.\n\nAdditional Key Words and Phrases: Mental Health, Large Language Model, Instruction Finetuning\n\nACM Reference Format:\nXuhai Xu, Bingsheng Yao, Yuanzhe Dong, Saadia Gabriel, Hong Yu, James Hendler, Marzyeh Ghassemi, Anind K. Dey,\nand Dakuo Wang. 2024. Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data.\nProc. ACM Interact. Mob. Wearable Ubiquitous Technol. 8, 1, Article 32 (March 2024), 32 pages. https://doi.org/10.1145/3643540\n\nAuthors’ addresses: Xuhai Xu, xuhaixu@uw.edu, Massachusetts Institute of Technology & University of Washington, USA; Bingsheng Yao,\nRensselaer Polytechnic Institute, USA; Yuanzhe Dong, Stanford University, USA; Saadia Gabriel, Massachusetts Institute of Technology, USA;\nHong Yu, University of Massachusetts Lowell, USA; James Hendler, Rensselaer Polytechnic Institute, USA; Marzyeh Ghassemi, Massachusetts\nInstitute of Technology, USA; Anind K. Dey, University of Washington, USA; Dakuo Wang, Northeastern University, USA.\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that\ncopies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.\nCopyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy\notherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from\npermissions@acm.org.\n© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\n2474-9567/2024/3-ART32 $15.00\nhttps://doi.org/10.1145/3643540\n\nProc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 8, No. 1, Article 32. Publication date: March 2024.\n\n \n \n \n \n \n \n\f32:2\n\n• Xu et al.\n\n1\n\nINTRODUCTION\n\nThe recent surge of Large Language Models (LLMs), such as GPT-4 [18], PaLM [23], FLAN-T5 [24], and Al-\npaca [115], demonstrates the promising capability of large pre-trained models to solve various tasks in zero-shot\nsettings (i.e., tasks not encountered during training). Example tasks include question answering [87, 100], logic\nreasoning [124, 135], machine translation [15, 45], etc. A number of experiments have revealed that, built on\nhundreds of billions of parameters, these LLMs have started to show the capability to understand the human\ncommon sense beneath the natural language and do proper reasoning and inference accordingly [18, 85].\n\nAmong d"
  },
  {
    "title": "FedTherapist: Mental Health Monitoring with User-Generated Linguistic\n  Expressions on Smartphones via Federated Learning",
    "authors": [
      "Jaemin Shin",
      "Hyungjun Yoon",
      "Seungjoo Lee",
      "Sungjoon Park",
      "Yunxin Liu",
      "Jinho D. Choi",
      "Sung-Ju Lee"
    ],
    "abstract": "Psychiatrists diagnose mental disorders via the linguistic use of patients.\nStill, due to data privacy, existing passive mental health monitoring systems\nuse alternative features such as activity, app usage, and location via mobile\ndevices. We propose FedTherapist, a mobile mental health monitoring system that\nutilizes continuous speech and keyboard input in a privacy-preserving way via\nfederated learning. We explore multiple model designs by comparing their\nperformance and overhead for FedTherapist to overcome the complex nature of\non-device language model training on smartphones. We further propose a\nContext-Aware Language Learning (CALL) methodology to effectively utilize\nsmartphones' large and noisy text for mental health signal sensing. Our\nIRB-approved evaluation of the prediction of self-reported depression, stress,\nanxiety, and mood from 46 participants shows higher accuracy of FedTherapist\ncompared with the performance with non-language features, achieving 0.15 AUROC\nimprovement and 8.21% MAE reduction.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2310.16538v1",
    "pdf_url": "http://arxiv.org/pdf/2310.16538v1",
    "full_text": "FedTherapist: Mental Health Monitoring with User-Generated\nLinguistic Expressions on Smartphones via Federated Learning\n\nJaemin Shin1, Hyungjun Yoon1, Seungjoo Lee1, Sungjoon Park2,\nYunxin Liu3, Jinho D. Choi4, Sung-Ju Lee1\n1KAIST 2SoftlyAI 3Tsinghua University 4Emory University\n{jaemin.shin, hyungjun.yoon, seungjoo.lee, profsj}@kaist.ac.kr,\n\nsungjoon.park@softly.ai, liuyunxin@air.tsinghua.edu.cn, jinho.choi@emory.edu\n\nAbstract\n\nPsychiatrists diagnose mental disorders via the\nlinguistic use of patients. Still, due to data\nprivacy, existing passive mental health mon-\nitoring systems use alternative features such\nas activity, app usage, and location via mo-\nbile devices. We propose FedTherapist, a mo-\nbile mental health monitoring system that uti-\nlizes continuous speech and keyboard input in\na privacy-preserving way via federated learn-\ning. We explore multiple model designs by\ncomparing their performance and overhead for\nFedTherapist to overcome the complex nature\nof on-device language model training on smart-\nphones. We further propose a Context-Aware\nLanguage Learning (CALL) methodology to ef-\nfectively utilize smartphones’ large and noisy\ntext for mental health signal sensing. Our IRB-\napproved evaluation of the prediction of self-\nreported depression, stress, anxiety, and mood\nfrom 46 participants shows higher accuracy of\nFedTherapist compared with the performance\nwith non-language features, achieving 0.15 AU-\nROC improvement and 8.21% MAE reduction.\n\n1\n\nIntroduction\n\nNearly a billion people worldwide are living with\nmental disorders, which seriously affect one’s cog-\nnition, emotion regulation, and behavior. Early\ndiagnosis and proper treatment are the keys to alle-\nviating the negative impact of the mental disor-\nder (Sharp and Lipsky, 2002). However, most\npatients have been unaware of their disorder for\nyears (Epstein et al., 2010), which delays treatment\nwhile the symptoms worsen.\n\nGiven their ubiquity in users’ lives, researchers\nhave leveraged smartphones to resolve this un-\nawareness problem, using features such as phone\nusage patterns, location, and activity for seam-\nless mental health monitoring (LiKamWa et al.,\n2013; Wang et al., 2014, 2018; Li and Sano, 2020;\nTlachac et al., 2022a). However, these features fail\nto reflect how licensed psychiatrists diagnose men-\n\ntal disorders by conversing with patients (Murphy\net al., 2000). While analyzing linguistic use is ideal\nfor monitoring smartphone users’ mental health,\nsubstantial privacy concerns it raises present chal-\nlenges in amassing sufficient data to train advanced\nNLP neural networks (Devlin et al., 2019).\n\nWe propose FedTherapist, a privacy-preserving\nmental health monitoring system that leverages\nuser-generated text (speech and keyboard) on\nsmartphones via Federated Learning (FL). FL de-\ncentralizes model training on client devices (e.g.,\nsmartphones) using locally stored data (McMahan\net al., 2016), ensuring privacy on FedTherapist by\nonly collecting securely aggregated model updates.\nFor a detailed introduction to FL, see Appendix A.\nDespite recent advances in FL + NLP (Lin et al.,\n2022; Xu et al., 2023; Zhang et al., 2023a), on-\ndevice training (i.e., training on smartphones) of\nlanguage models for mental status monitoring re-\nmains unexplored. We explore the best model de-\nsign for FedTherapist across multiple candidates,\nincluding Large Language Models (LLMs), by\ncomparing their mental health monitoring perfor-\nmance and smartphone overhead.\n\nIn realizing FedTherapist, the challenge remains\nto effectively capture mental health-related signals\nfrom a large corpus of spoken and typed user lan-\nguage on smartphones, which differs from prior\nNLP mental health studies based on social me-\ndia (Yates et al., 2017; Park et al., 2020) – see\nAppendix G. To address such a challenge, we pro-\npose Context-Aware Language Learning (CALL)\nmethodology, which integrates various temporal\ncontexts of users (e.g., time, location) captured on\nsmartphones to enhance the model’s ability to sense\nmental health signals from the text data. Our eval-\nuation of 46 participants shows that FedTherapist\nwith CALL achieves more accurate mental health\nprediction than the model trained with non-text\ndata (Wang et al., 2018), achieving 0.15 AUROC\nimprovement and 8.21% reduction in MAE.\n\n3\n2\n0\n2\n\nt\nc\nO\n5\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n8\n3\n5\n6\n1\n.\n0\n1\n3\n2\n:\nv\ni\nX\nr\na\n\n \n \n \n \n \n \n\f2 Data Collection\n\nWe conducted an IRB (Institutional Review Board)-\napproved data collection study to evaluate FedTher-\napist on real-world user data. Although FL works\nwithout user data collection, we collected the data\nto fully explore the potential of smartphone text\ndata on mental health monitoring. We recruited\n52 participants over the Amazon Mechanical Turk\n(MTurk) who identified English as the first and\nonly language they use daily. Participants collected\ndata for 10 days on our Android application, where\nwe provided no instructions or restrictions to the\nparticipants’ behavior during the stud"
  },
  {
    "title": "Gender differences of the effect of vaccination on perceptions of\n  COVID-19 and mental health in Japan",
    "authors": [
      "Eiji Yamamura",
      "Youki Kosaka",
      "Yoshiro Tsutsui",
      "Fumio Ohtake"
    ],
    "abstract": "Vaccination has been promoted to mitigate the spread of the coronavirus\ndisease 2019 (COVID-19). Vaccination is expected to reduce the probability of\nand alleviate the seriousness of COVID-19 infection. Accordingly, this might\nsignificantly change an individuals subjective well-being and mental health.\nHowever, it is unknown how vaccinated people perceive the effectiveness of\nCOVID-19 and how their subjective well-being and mental health change after\nvaccination. We thus observed the same individuals on a monthly basis from\nMarch 2020 to September 2021 in all parts of Japan. Then, large sample panel\ndata (N=54,007) were independently constructed. Using the data, we compared the\nindividuals perceptions of COVID-19, subjective well-being, and mental health\nbefore and after vaccination. Furthermore, we compared the effect of\nvaccination on the perceptions of COVID-19 and mental health for females and\nmales. We used the fixed-effects model to control for individual time-invariant\ncharacteristics. The major findings were as follows: First, the vaccinated\npeople perceived the probability of getting infected and the seriousness of\nCOVID-19 to be lower than before vaccination. This was observed not only when\nwe used the whole sample, but also when we used sub-samples. Second, using the\nwhole sample, subjective well-being and mental health improved. The same\nresults were also observed using the sub-sample of females, whereas the\nimprovements were not observed using a sub-sample of males.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2203.07663v1",
    "pdf_url": "http://arxiv.org/pdf/2203.07663v1",
    "full_text": "Gender  differences  of  the  effect  of  vaccination  on  perceptions  of \n\nCOVID-19 and mental health in Japan \n\nEiji Yamamura1*, Youki Kosaka2, Yoshiro Tsutsui3, Fumio Ohtake4, \n\n1  Department  of  Economics,  Seinan  Gakuin  University,  Fukuoka,  Japan  2  Kyoto \n\nEconomic College, Japan 3 Kyoto-Bunkyo University, Japan 4 Osaka University, Japan \n\nAbstract \n\nVaccination  has  been  promoted  to  mitigate  the  spread  of  the  coronavirus  disease \n\n2019 (COVID-19). Vaccination is expected to reduce the probability of and alleviate the \n\nseriousness  of  COVID-19  infection.  Accordingly,  this  might  significantly  change  an \n\nindividual’s  subjective  well-being  and  mental  health.  However,  it  is  unknown  how \n\nvaccinated people perceive the effectiveness of COVID-19 and how their subjective well-\n\nbeing and mental health change after vaccination. We thus observed the same individuals \n\non a monthly basis from March 2020 to September 2021 in all parts of Japan. Then, large \n\nsample  panel  data  (N=54,007)  were  independently  constructed.  Using  the  data,  we \n\ncompared the individuals’ perceptions of COVID-19, subjective well-being, and mental \n\nhealth before and after vaccination. Furthermore, we compared the effect of vaccination \non the perceptions of COVID-19 and mental health for females and males. We used the \nfixed-effects  model  to  control  for  individual  time-invariant  characteristics.  The  major \n\nfindings were as follows: First, the vaccinated people perceived the probability of getting \n\ninfected and the seriousness of COVID-19 to be lower than before vaccination. This was \n\nobserved not only when we used the whole sample, but also when we used sub-samples. \nSecond, using the whole sample, subjective well-being and mental health improved. The \n\nsame  results  were  also  observed  using  the  sub-sample  of  females,  whereas  the \n\nimprovements were not observed using a sub-sample of males.   \n\nKeywords: Vaccination, COVID-19, Subjective well-being, Mental health, Japan, Panel \n\ndata. \n\n1 \n\n \n \n \n \n \n\f1. Introduction \n\nVaccination against the coronavirus disease 2019 (COVID-19) is anticipated to play \n\na  critical  role  in  mitigating  the  spread  of  COVID-19.  Many  newly  reported  cases  of \n\nCOVID-19  have  been  reduced  in  countries  where  vaccines  have  become  rapidly \n\npervasive(WHO  Coronavirus  (COVID-19)  Dashboard  2021).  Through  scientific \n\nexperiments,  the  COVID-19  vaccine  reduced  the  probability  of  infection  and  the \n\nseriousness of COVID-19. The sufficient rate of the vaccinated population in society must \n\nreach herd immunity to terminate the COVID-19 pandemic(Randolph and Barreiro 2020). \n\nHowever, some individuals hesitate to receive the COVID-19 vaccine(Almaghaslah et al. \n\n2021a; Lucia, Kelekar, and Afonso 2021a; Machingaidze and Wiysonge 2021a; Murphy \n\net  al.  2021a;  Solís  Arce  et  al.  2021).  Their  attitude  may  change  if  they  know  that \n\nvaccinated people have  a  more positive view about  the vaccination  after  receiving the \n\nvaccine.  Therefore,  how  and  the  extent  to  which  the  subjective  views  about  the \n\neffectiveness  of  the  COVID-9  vaccine  changes  after  one  gets  vaccinated  should  be \n\nexamined.   \n\nVarious  measures  against  COVID-19,  such  as  lockdown  restrictions,  cause \n\nsignificant  economic  loss(Inoue,  Murase,  and  Todo  2021;  Mottaleb,  Mainuddin,  and \n\nSonobe 2020) and exert a detrimental impact on individuals’ mental health(Chinna et al. \n\n2 \n\n \n\f2021; Fiorenzato et al. 2021; Greyling, Rossouw, and Adhikari 2021; Ogden 2021). In \n\nJapan, even without enforcement, individuals voluntarily exhibit preventive behaviors, \n\nsuch  as  staying  indoors  and  avoiding  face-to-face  conversations(Muto  et  al.  2020; \n\nWatanabe  and  Yabu  2021;  Yamamura  and  Tsutsui  2020).  Accordingly,  this  changed \n\nlifestyle, for instance, lack of exercise and short sleep duration, results  in  a decline  in \n\nmental health(Nagasu and Yamamoto 2020; Yamamura and Tsustsui 2021a; Yamamura \n\nand  Tsutsui  2020).  Vaccination  is  anticipated  to  reduce  the  probability  of  contracting \n\nCOVID-19; thus, vaccinated individuals can return to normal daily life. This return to \n\nnormal daily life improves subjective well-being and mental health, so vaccination for \n\npeople with mental illness is necessary(Mazereel et al. 2021a, 2021b; Siva 2021; Warren, \n\nKisely, and Siskind 2021). \n\nThe mental conditions of vaccinated individuals improved in the U.S(Perez-Arce et \n\nal.  2021).  However,  hesitancy \n\nto  be  vaccinated  was  observed \n\nin  various \n\ncountries(Almaghaslah et al. 2021b; Machingaidze and Wiysonge 2021b; Murphy et al. \n\n2021b; Solís Arce et al. 2021). This has hampered the establishment of herd immunity \n\nand increased social costs caused by COVID-19. Furthermore, people are less likely to \n\nreceive the vaccination  and to trust health experts(Lucia, Kelekar, and Afonso 2021b)."
  },
  {
    "title": "The Relationship between Deteriorating Mental Health Conditions and\n  Longitudinal Behavioral Changes in Google and YouTube Usages among College\n  Students in the United States during COVID-19: Observational Study",
    "authors": [
      "Anis Zaman",
      "Boyu Zhang",
      "Ehsan Hoque",
      "Vincent Silenzio",
      "Henry Kautz"
    ],
    "abstract": "Mental health problems among the global population are worsened during the\ncoronavirus disease (COVID-19). How individuals engage with online platforms\nsuch as Google Search and YouTube undergoes drastic shifts due to pandemic and\nsubsequent lockdowns. Such ubiquitous daily behaviors on online platforms have\nthe potential to capture and correlate with clinically alarming deteriorations\nin mental health profiles in a non-invasive manner. The goal of this study is\nto examine, among college students, the relationship between deteriorating\nmental health conditions and changes in user behaviors when engaging with\nGoogle Search and YouTube during COVID-19. This study recruited a cohort of 49\nstudents from a U.S. college campus during January 2020 (prior to the pandemic)\nand measured the anxiety and depression levels of each participant. This study\nfollowed up with the same cohort during May 2020 (during the pandemic), and the\nanxiety and depression levels were assessed again. The longitudinal Google\nSearch and YouTube history data were anonymized and collected. From\nindividual-level Google Search and YouTube histories, we developed 5 signals\nthat can quantify shifts in online behaviors during the pandemic. We then\nassessed the differences between groups with and without deteriorating mental\nhealth profiles in terms of these features. Significant features included\nlate-night online activities, continuous usages, and time away from the\ninternet, porn consumptions, and keywords associated with negative emotions,\nsocial activities, and personal affairs. Though further studies are required,\nour results demonstrated the feasibility of utilizing pervasive online data to\nestablish non-invasive surveillance systems for mental health conditions that\nbypasses many disadvantages of existing screening methods.",
    "year": 2020,
    "url": "http://arxiv.org/abs/2009.09076v1",
    "pdf_url": "http://arxiv.org/pdf/2009.09076v1",
    "full_text": "Original Paper \n\nThe Relationship between Deteriorating Mental Health \nConditions and Longitudinal Behavioral Changes in Google and \nYouTube Usages among College Students in the United States \nduring COVID-19: Observational Study \n\n1Anis\tZaman*,\t1Boyu\tZhang*,\t1Ehsan\tHoque,\t2Vincent\tSilenzio,\t1Henry\tKautz\t\n\n1Department\tof\tComputer\tScience,\tUniversity\tof\tRochester,\tRochester,\tNY,\tUSA\t\n\n2Department\tof\tUrban-Global\tPublic\tHealth,\tRutgers\tUniversity,\tJersey\tCity,\tNJ,\tUSA\t\n\n*Equal\tContribution\t\n\nCorrespondence\tto\t\n\nMr.\tBoyu\tZhang\t\n\nDepartment\tof\tComputer\tScience,\tUniversity\tof\tRochester,\tRochester,\tNY\t14627,\t\n\nUSA\t\n\nE-mail:\tbzhang25@u.rochester.edu\t\n\n&\t\n\nMr.\tAnis\tZaman\t\n\nDepartment\tof\tComputer\tScience,\tUniversity\tof\tRochester,\tRochester,\tNY\t14627,\t\n\nUSA\t\n\nE-mail:\tazaman2@cs.rochester.edu\t\n\nAbstract \nBackground:\tMental\thealth\tproblems\tamong\tthe\tglobal\tpopulation\tare\tworsened\t\nduring\tthe\tcoronavirus\tdisease\t(COVID-19).\tYet,\tcurrent\tmethods\tfor\tscreening\t\nmental\thealth\tissues\trely\ton\tin-person\tinterviews,\twhich\tcan\tbe\texpensive,\ttime-\nconsuming,\tblocked\tby\tsocial\tstigmas\tand\tquarantines.\tMeanwhile,\thow\tindividuals\t\nengage\twith\tonline\tplatforms\tsuch\tas\tGoogle\tSearch\tand\tYouTube\tundergoes\tdrastic\t\nshifts\tdue\tto\tCOVID-19\tand\tsubsequent\tlockdowns.\tSuch\tubiquitous\tdaily\tbehaviors\t\non\tonline\tplatforms\thave\tthe\tpotential\tto\tcapture\tand\tcorrelate\twith\tclinically\t\nalarming\tdeteriorations\tin\tmental\thealth\tprofiles\tof\tusers\tin\ta\tnon-invasive\tmanner.\t\n\n\t\n\t\n\t\n\t\n\fObjective:\tThe\tgoal\tof\tthis\tstudy\tis\tto\texamine,\tamong\tcollege\tstudents\tin\tthe\tUnited\t\nStates,\tthe\trelationship\tbetween\tdeteriorating\tmental\thealth\tconditions\tand\tchanges\t\nin\tuser\tbehaviors\twhen\tengaging\twith\tGoogle\tSearch\tand\tYouTube\tduring\tCOVID-19.\t\n\nMethods:\tThis\tstudy\trecruited\ta\tcohort\tof\tundergraduate\tstudents\t(N=49)\tfrom\ta\t\nU.S.\tcollege\tcampus\tduring\tJanuary\t2020\t(prior\tto\tthe\tpandemic)\tand\tmeasured\tthe\t\nanxiety\tand\tdepression\tlevels\tof\teach\tparticipant.\tThe\tanxiety\tlevel\twas\tassessed\tvia\t\nthe\tGeneral\tAnxiety\tDisorder-7\t(GAD-7).\tThe\tdepression\tlevel\twas\tassessed\tvia\tthe\t\nPatient\tHealth\tQuestionnaire-9\t(PHQ-9).\tThis\tstudy\tfollowed\tup\twith\tthe\tsame\t\ncohort\tduring\tMay\t2020\t(during\tthe\tpandemic),\tand\tthe\tanxiety\tand\tdepression\t\nlevels\twere\tassessed\tagain.\tThe\tlongitudinal\tGoogle\tSearch\tand\tYouTube\thistory\t\ndata\tof\tall\tparticipants\twere\tanonymized\tand\tcollected.\tFrom\tindividual-level\t\nGoogle\tSearch\tand\tYouTube\thistories,\twe\tdeveloped\t5\tsignals\tthat\tcan\tquantify\t\nshifts\tin\tonline\tbehaviors\tduring\tthe\tpandemic.\tWe\tthen\tassessed\tthe\tdifferences\t\nbetween\tgroups\twith\tand\twithout\tdeteriorating\tmental\thealth\tprofiles\tin\tterms\tof\t\nthese\tfeatures.\t\t\n\nResults:\tOf\tthe\t49\tparticipants,\t41%\t(n=20)\tof\tthem\treported\ta\tsignificant\tincrease\t\n(increase\tin\tthe\tPHQ-9\tscore\t³\t5)\tin\tdepression,\tdenoted\tas\tDEP;\t45%\t(n=22)\tof\t\nthem\treported\ta\tsignificant\tincrease\t(increase\tin\tthe\tGAD-7\tscore\t³\t5)\tin\tanxiety,\t\ndenoted\tas\tANX.\tOf\tthe\t5\tfeatures\tproposed\tto\tquantify\tonline\tbehavior\tchanges,\t\nstatistical\tsignificances\twere\tfound\tbetween\tthe\tDEP\tand\tnon-DEP\tgroups\tfor\tall\tof\t\nthem\t(P£.01,\teffect\tsizes\t𝜂!\"#$%\"&\nsignificances\twere\tfound\tbetween\tthe\tANX\tand\tnon-ANX\tgroups\tfor\t4\tof\tthem\t\n(P£.02,\teffect\tsizes\t𝜂!\"#$%\"&\n\tranging\tbetween\t0.115\tto\t0.231).\tSignificant\tfeatures\t\nincluded\tlate-night\tonline\tactivities,\tcontinuous\tusages\tand\ttime\taway\tfrom\tthe\t\ninternet,\tporn\tconsumptions,\tand\tkeywords\tassociated\twith\tnegative\temotions,\t\nsocial\tactivities,\tand\tpersonal\taffairs.\t\n\n\tranging\tbetween\t0.130\tto\t0.320);\tstatistical\t\n\n’\n\n’\n\nConclusions:\tThe\tresults\tsuggested\tstrong\tdiscrepancies\tbetween\tcollege\tstudent\t\ngroups\twith\tand\twithout\tdeteriorating\tmental\thealth\tconditions\tin\tterms\tof\t\nbehavioral\tchanges\tin\tGoogle\tSearch\tand\tYouTube\tusages\tduring\tthe\tCOVID-19.\t\nThough\tfurther\tstudies\tare\trequired,\tour\tresults\tdemonstrated\tthe\tfeasibility\tof\t\nutilizing\tpervasive\tonline\tdata\tto\testablish\tnon-invasive\tsurveillance\tsystems\tfor\t\nmental\thealth\tconditions\tthat\tbypasses\tmany\tdisadvantages\tof\texisting\tscreening\t\nmethods.\t\t\n\nKeywords:\tmental\thealth;\tanxiety;\tdepression;\tGoogle\tSearch;\tYouTube;\tpandemic;\t\nCOVID-19\t\n\nIntroduction \n\nBackground \nGlobally,\tmental\thealth\tproblems\tsuch\tas\tdepression,\tanxiety,\tand\tsuicide\tideations\t\nare\tseverely\tworsened\tduring\tthe\tcoronavirus\tdisease\t(COVID-19)\t[1–3],\tspecifically\t\n\n\t\n\t\n\t\n\t\n\t\n\ffor\tcollege\tstudents\t[4,5–7].\tYet,\tcurrent\tmethods\tfor\tscreening\tmental\thealth\tissues\t\nand\tidentifying\tvulnerable\tindividuals\trely\ton\tin-person\tinterviews.\tSuch\t\nassessments\tcan\tbe\texpensive,\ttime-consuming,\tand\tblocked\tby\tsocial\tstigmas,\tnot\t\nto\tmention\tthe\treluctancy\tinduced\tby\ttravel\trestrictions\tand\texposure\trisks.\tIt\thas\t\nbeen\treported\tthat\tvery\tfew\tpatients\tin\tneed\twere\tcorrectly\tidentified\tand\treceived\t\nproper\tmental\thealth\ttreatments\ton\ttime\tunder\tthe\tcurrent\thealthcare\tsystem\t[8,9].\t\nEven\twith\temerging\tTelehealth\ttechnologies\tand\tonline\tsurveys,\tthe\tscreening\t\nrequires\tpatients\tto\tactively\treach\tout\tto\tcare\tproviders.\t\t\n\nAt\tthe\tsame\ttime,\tbecause\tof\tthe\tlockdown\tenforced\tby\tthe\tglobal\tpandemic\t"
  },
  {
    "title": "Towards Interpretable Mental Health Analysis with Large Language Models",
    "authors": [
      "Kailai Yang",
      "Shaoxiong Ji",
      "Tianlin Zhang",
      "Qianqian Xie",
      "Ziyan Kuang",
      "Sophia Ananiadou"
    ],
    "abstract": "The latest large language models (LLMs) such as ChatGPT, exhibit strong\ncapabilities in automated mental health analysis. However, existing relevant\nstudies bear several limitations, including inadequate evaluations, lack of\nprompting strategies, and ignorance of exploring LLMs for explainability. To\nbridge these gaps, we comprehensively evaluate the mental health analysis and\nemotional reasoning ability of LLMs on 11 datasets across 5 tasks. We explore\nthe effects of different prompting strategies with unsupervised and distantly\nsupervised emotional information. Based on these prompts, we explore LLMs for\ninterpretable mental health analysis by instructing them to generate\nexplanations for each of their decisions. We convey strict human evaluations to\nassess the quality of the generated explanations, leading to a novel dataset\nwith 163 human-assessed explanations. We benchmark existing automatic\nevaluation metrics on this dataset to guide future related works. According to\nthe results, ChatGPT shows strong in-context learning ability but still has a\nsignificant gap with advanced task-specific methods. Careful prompt engineering\nwith emotional cues and expert-written few-shot examples can also effectively\nimprove performance on mental health analysis. In addition, ChatGPT generates\nexplanations that approach human performance, showing its great potential in\nexplainable mental health analysis.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2304.03347v4",
    "pdf_url": "http://arxiv.org/pdf/2304.03347v4",
    "full_text": "Towards Interpretable Mental Health Analysis with Large Language\nModels\n\nKailai Yang 1\n\nShaoxiong Ji ∗ 2 Tianlin Zhang ∗ 1 Qianqian Xie †1\nSophia Ananiadou 1,3\n\nZiyan Kuang 4\n1 The University of Manchester\n\n2 University of Helsinki\n\n3 Artificial Intelligence Research Center, AIST\n\n4 Jiangxi Normal University\n\n{kailai.yang,tianlin.zhang}@postgrad.manchester.ac.uk; shaoxiong.ji@helsinki.fi\nsophia.ananiadou@manchester.ac.uk; {xqq.sincere,plumjane1225}@gmail.com\n\n3\n2\n0\n2\n\nt\nc\nO\n1\n1\n\n]\nL\nC\n.\ns\nc\n[\n\n4\nv\n7\n4\n3\n3\n0\n.\n4\n0\n3\n2\n:\nv\ni\nX\nr\na\n\nAbstract\n\nThe latest large language models (LLMs) such\nas ChatGPT, exhibit strong capabilities in au-\ntomated mental health analysis. However,\nexisting relevant studies bear several limita-\ntions, including inadequate evaluations, lack of\nprompting strategies, and ignorance of explor-\ning LLMs for explainability. To bridge these\ngaps, we comprehensively evaluate the mental\nhealth analysis and emotional reasoning abil-\nity of LLMs on 11 datasets across 5 tasks. We\nexplore the effects of different prompting strate-\ngies with unsupervised and distantly super-\nvised emotional information. Based on these\nprompts, we explore LLMs for interpretable\nmental health analysis by instructing them to\ngenerate explanations for each of their deci-\nsions. We convey strict human evaluations to\nassess the quality of the generated explanations,\nleading to a novel dataset with 163 human-\nassessed explanations1. We benchmark existing\nautomatic evaluation metrics on this dataset to\nguide future related works. According to the\nresults, ChatGPT shows strong in-context learn-\ning ability but still has a significant gap with ad-\nvanced task-specific methods. Careful prompt\nengineering with emotional cues and expert-\nwritten few-shot examples can also effectively\nimprove performance on mental health analysis.\nIn addition, ChatGPT generates explanations\nthat approach human performance, showing\nits great potential in explainable mental health\nanalysis.\n\n1\n\nIntroduction\n\nWARNING: This paper contains examples and de-\nscriptions that are depressive in nature.\n\nMental health conditions such as depression\nand suicidal ideation seriously challenge global\n\n∗ Equal contribution, listed alphabetically.\n† Corresponding author. Qianqian is now affiliated with\nYale University. The work was done when she was at The\nUniversity of Manchester.\ndata\n\nhttps://github.com/\n\nreleased\n\n1The\n\nat\n\nis\n\nSteveKGYang/MentalLLaMA\n\nhealth care (Zhang et al., 2022a). NLP researchers\nhave devoted much effort to automatic mental\nhealth analysis, with current mainstream meth-\nods leveraging the Pre-trained Language Models\n(PLMs) (Yang et al., 2022; Abed-Esfahani et al.,\n2019). Most recently Large Language Models\n(LLMs) (Brown et al., 2020; Ouyang et al., 2022),\nespecially ChatGPT 2 and GPT-4 (OpenAI, 2023),\nhave exhibited strong general language processing\nability (Wei et al., 2022; Luo et al., 2023; Yuan\net al., 2023). In mental health analysis, Lamich-\nhane (2023) evaluated ChatGPT on stress, depres-\nsion, and suicide detection and glimpsed its strong\nlanguage understanding ability to mental health-\nrelated texts. Amin et al. (2023) compared the zero-\nshot performance of ChatGPT on suicide and de-\npression detection with previous fine-tuning-based\nmethods.\n\nThough previous works depict a promising fu-\nture for a new LLM-based paradigm in mental\nhealth analysis, several issues remain unresolved.\nFirstly, mental health condition detection is a safe-\ncritical task requiring careful evaluation and high\ntransparency for any predictions (Zhang et al.,\n2022a), while these works simply tested on a few\nbinary mental health condition detection tasks and\nlack the explainability on detection results. More-\nover, other important mental health analysis tasks,\nsuch as the cause/factor detection of mental health\nconditions (Mauriello et al., 2021; Garg et al.,\n2022), were ignored. Secondly, previous works\nmostly use simple prompts to detect mental health\nconditions directly. These vanilla methods ig-\nnore useful information, especially emotional cues,\nwhich are widely utilized for mental health analysis\nin previous works (Zhang et al., 2023). We believe\nit requires a comprehensive exploration and evalu-\nation of the ability and explainability of LLMs on\nmental health analysis, including mental health de-\ntection, emotional reasoning, and cause detection\n\n2https://openai.com/blog/chatgpt\n\n \n \n \n \n \n \n\fFigure 1: The pipeline of obtaining and evaluating the LLM-generated explanations for mental health analysis.\nIn LLM responses, red, green, and blue words are marked as relevant clues for rating fluency, reliability, and\ncompleteness in human evaluations.\n\nof mental health conditions. Therefore, we raise\nthe following three research questions (RQ):\n\n• RQ 1: How well can LLMs perform in gen-\neralized mental health analysis and emotional\nreasoning with zero-shot/few-shot settings?\n\n• RQ 2: How do different prompting strategies\nand emotional cues impact the mental "
  },
  {
    "title": "Discovering Mental Health Research Topics with Topic Modeling",
    "authors": [
      "Xin Gao",
      "Cem Sazara"
    ],
    "abstract": "Mental health significantly influences various aspects of our daily lives,\nand its importance has been increasingly recognized by the research community\nand the general public, particularly in the wake of the COVID-19 pandemic. This\nheightened interest is evident in the growing number of publications dedicated\nto mental health in the past decade. In this study, our goal is to identify\ngeneral trends in the field and pinpoint high-impact research topics by\nanalyzing a large dataset of mental health research papers. To accomplish this,\nwe collected abstracts from various databases and trained a customized\nSentence-BERT based embedding model leveraging the BERTopic framework. Our\ndataset comprises 96,676 research papers pertaining to mental health, enabling\nus to examine the relationships between different topics using their abstracts.\nTo evaluate the effectiveness of the model, we compared it against two other\nstate-of-the-art methods: Top2Vec model and LDA-BERT model. The model\ndemonstrated superior performance in metrics that measure topic diversity and\ncoherence. To enhance our analysis, we also generated word clouds to provide a\ncomprehensive overview of the machine learning models applied in mental health\nresearch, shedding light on commonly utilized techniques and emerging trends.\nFurthermore, we provide a GitHub link* to the dataset used in this paper,\nensuring its accessibility for further research endeavors.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2308.13569v1",
    "pdf_url": "http://arxiv.org/pdf/2308.13569v1",
    "full_text": "Discovering Mental Health Research Topics with Topic Modeling\n\nXin Gao 1 Cem Sazara 1\n\nAbstract\n\nMental health significantly influences various as-\npects of our daily lives, and its importance has\nbeen increasingly recognized by the research com-\nmunity and the general public, particularly in the\nwake of the COVID-19 pandemic. This height-\nened interest is evident in the growing number of\npublications dedicated to mental health in the past\ndecade. In this study, our goal is to identify gen-\neral trends in the field and pinpoint high-impact\nresearch topics by analyzing a large dataset of\nmental health research papers. To accomplish this,\nwe collected abstracts from various databases and\ntrained a customized Sentence-BERT based em-\nbedding model leveraging the BERTopic frame-\nwork. Our dataset comprises 96,676 research pa-\npers pertaining to mental health, enabling us to\nexamine the relationships between different top-\nics using their abstracts. To evaluate the effective-\nness of the model, we compared it against two\nother state-of-the-art methods: Top2Vec model\nand LDA-BERT model. The model demonstrated\nsuperior performance in metrics that measure\ntopic diversity and coherence. To enhance our\nanalysis, we also generated word clouds to pro-\nvide a comprehensive overview of the machine\nlearning models applied in mental health research,\nshedding light on commonly utilized techniques\nand emerging trends. Furthermore, we provide\na GitHub link* to the dataset used in this paper,\nensuring its accessibility for further research en-\ndeavors.\n\n3\n2\n0\n2\n\ng\nu\nA\n5\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n9\n6\n5\n3\n1\n.\n8\n0\n3\n2\n:\nv\ni\nX\nr\na\n\n1. Introduction\n\nThe COVID-19 pandemic, which has significantly impacted\nour lifestyle for nearly two years, has led to a rise in psy-\n\n1Amazon Web Services, Seattle, WA, USA. Correspondence\n\nto: Xin Gao <goxi@amazon.com>.\n\nWorkshop on Interpretable ML in Healthcare at International Con-\nference on Machine Learning (ICML), Honolulu, Hawaii, USA.\n2023. Copyright 2023 by the author(s).\n\n*https://github.com/stella-gao/Mental-Health-Research-Paper-\n\nDataset\n\n1\n\nchosocial stressors and mental health problems. Conse-\nquently, there has been a notable surge in mental health\nresearch as a response to these challenges. To understand\nthe specific topics studied by the research community, we\nemployed topic modeling methods on the titles and abstracts\nof conference and journal research papers focused on men-\ntal health field. Our primary objective is to identify studies\naimed at improving mental health and analyze the prominent\nresearch topics of the past decade.\n\nTo accomplish this, we collected abstracts from various\ndatabases, including arXiv, ACM, bioRxiv, medRxiv, and\nPubMed, spanning the period from Jan 2010 to March 2023.\nThis extensive dataset reveals a growing interest in mental\nhealth-related research during the last decade, with a signifi-\ncant peak occurring during the COVID-19 pandemic. Our\nstudy aims to identify key trends and significant research\ntopics by analyzing a dataset of 96,676 research papers. To\nextract meaningful insights from the dataset, we employed a\nSentence-BERT based embedding model called BERTopic\n(Grootendorst, 2022). BERTopic generates document em-\nbeddings and clusters them into semantically coherent top-\nics, enabling further analysis. By applying this model, we\ncan identify specific concepts associated with each topic,\nproviding a basis for further analysis and investigation. For\ninstance, the topic related to suicide prominently includes\nterms such as “suicidal,” “ideation,” and “attempt.” These\nidentified topics may help uncover interdisciplinary connec-\ntions and foster collaboration among different fields.\n\nIn evaluating our approach, we conducted performance eval-\nuation using various metrics (Ferdinand Kapl, 2022). These\nmetrics included TD (Topic Distinctiveness/Diversity), mea-\nsuring topic uniqueness and diversity. Inv. RBO (Inverted\nRank-Biased Overlap) evaluates topic coherence and word\norder similarity. NPMI (Normalized Pointwise Mutual In-\nformation) measures semantic coherence within topics by\ncalculating the average pairwise similarity between words\nwithin a topic. Cv (Coefficient of Topic Coherence) as-\nsesses coherence among top-ranked words. Higher metric\nvalues indicate better topic coherence and interpretability.\nBy evaluating these metrics, we optimized topic model-\ning by experimenting with hyperparameters. Our goal was\nto find the configuration that yielded topics with high co-\nherence, diversity, and interpretability, as indicated by the\nmetrics mentioned above. These performance evaluation\n\n \n \n \n \n \n \n\fDiscovering Mental Health Research Topics with Topic Modeling\n\nmetrics provided valuable insights into the quality of the\ngenerated topics and guided our decision-making process\nin selecting the values that optimized the topic modeling\nresults. We evaluated the BERTopic based model’s effec-\ntiveness by comparing it against two other state-of-the-art\nmethods, "
  },
  {
    "title": "Canada Protocol: an ethical checklist for the use of Artificial\n  Intelligence in Suicide Prevention and Mental Health",
    "authors": [
      "Carl-Maria Mörch",
      "Abhishek Gupta",
      "Brian L. Mishara"
    ],
    "abstract": "Introduction: To improve current public health strategies in suicide\nprevention and mental health, governments, researchers and private companies\nincreasingly use information and communication technologies, and more\nspecifically Artificial Intelligence and Big Data. These technologies are\npromising but raise ethical challenges rarely covered by current legal systems.\nIt is essential to better identify, and prevent potential ethical risks.\nObjectives: The Canada Protocol - MHSP is a tool to guide and support\nprofessionals, users, and researchers using AI in mental health and suicide\nprevention. Methods: A checklist was constructed based upon ten international\nreports on AI and ethics and two guides on mental health and new technologies.\n329 recommendations were identified, of which 43 were considered as applicable\nto Mental Health and AI. The checklist was validated, using a two round Delphi\nConsultation. Results: 16 experts participated in the first round of the Delphi\nConsultation and 8 participated in the second round. Of the original 43 items,\n38 were retained. They concern five categories: \"Description of the Autonomous\nIntelligent System\" (n=8), \"Privacy and Transparency\" (n=8), \"Security\" (n=6),\n\"Health-Related Risks\" (n=8), \"Biases\" (n=8). The checklist was considered\nrelevant by most users, and could need versions tailored to each category of\ntarget users.",
    "year": 2019,
    "url": "http://arxiv.org/abs/1907.07493v1",
    "pdf_url": "http://arxiv.org/pdf/1907.07493v1",
    "full_text": "Canada Protocol: an ethical checklist for the use of Artificial Intelligence in \nSuicide Prevention and Mental Health \n\nCarl-Maria Mörch, M.Psy., Ph.D. Student1 \n\nContribution : Lead researcher, study design, writing, coordinated the validation \nAbhishek Gupta, B.A.2 \n\nContribution : Co-author, co-designed the checklist, participated to the selection of the checklist’s items.  \n\nBrian L. Mishara, Ph.D.3 \n\nContribution : Scientific supervision, complete revisions \n\nAbstract \n\nIntroduction: To improve current public health strategies in suicide prevention and mental health, governments, \nresearchers and private companies increasingly use information and communication technologies, and more \nspecifically Artificial Intelligence and Big Data. These technologies are promising but raise ethical challenges rarely \ncovered by current legal systems. It is essential to better identify, and prevent potential ethical risks. Objectives: The \nCanada Protocol - MHSP is a tool to guide and support professionals, users, and researchers using AI in mental \nhealth and suicide prevention. Methods: A checklist was constructed based upon ten international reports on AI and \nethics and two guides on mental health and new technologies. 329 recommendations were identified, of which 43 \nwere considered as applicable to Mental Health and AI. The checklist was validated, using a two round Delphi \nConsultation. Results: 16 experts participated in the first round of the Delphi Consultation and 8 participated in the \nsecond round. Of the original 43 items, 38 were retained. They concern five categories: \"Description of the \nAutonomous Intelligent System\" (n=8), \"Privacy and Transparency\" (n=8), \"Security\" (n=6), \"Health-Related \nRisks\" (n=8), \"Biases\" (n=8). The checklist was considered relevant by most users, and could need versions tailored \nto each category of target users. \n\nFunding: This article has not been funded.  \n\nConflict of Interests: The authors declare no conflict of interests.  \n\nEthics: In agreement with the Université du Québec à Montréal’s ethics board rules, this research did not include \nany sensitive or identifiable information on individuals.  \n\n1 Centre for Research and Intervention on Suicide, Ethical Issues and End of Life Practices (CRISE) \n\nPsychology Department, Université du Québec à Montréal \nc.p. 8888, Succ. Centre-Ville, Montréal, Québec, H3C 3P8, Canada \ncmmorch@gmail.com  \n2 Montreal AI Ethics Institute, Canada \n\nMicrosoft, Montreal, Canada \n\n3  Centre for Research and Intervention on Suicide, Ethical Issues and End of Life Practices (CRISE) \n\nPsychology Department, Université du Québec à Montréal \n\n \n \n \n \n \n \n                                                \n \n\fTable 1 : The Canada Protocol – the ethical checklist \n\nDESCRIPTION \n\nObjectives \n\nTechnology \n\nFunding & \nconflict of interest \n\nCredentials \n\nTarget population \n\nEvidence \n\nTesting \n\nComplaints \n\nDescribe your project's objectives and/or rationale and describe the role and functioning of your \nAutonomous Intelligent System \nName and describe the technologies and techniques used (e.g. supervised or unsupervised learning, \nmachine learning, random forest, decision tree...). You can refer to the report of the AI Initiative incubated \nat Harvard http://ai-initiative.org/wp-content/uploads/2017/08/Making-the-AI-Revolution-work-for-\neveryone.-Report-to-OECD.-MARCH-2017.pdf. Mention the names of any technological intermediary or \nsupplier allowing you to use the technology (e.g. technical provider, cloud provider)  \nIndicate all sources of funding for your project (public and private) and who might have an interest (e.g. \nfinancial, political) in your Autonomous Intelligent System \nIf you have noted that you or someone in your team has an expertise in relation to the Autonomous \nIntelligent System (e.g. in a document, a webpage, an interview), clearly indicate the name of the \nprofessional, their technical, academic or medical credentials, and their training (e.g. \"Professor Smith, \nPhD in computer systems engineering from Harvard University. Specialist in the Online Detection of \nDepression\") \nDescribe your target population and its size, or identify its subgroups and their sizes. Describe if and how \nthe target population (and, or its subgroups) assisted in the design of your Autonomous Intelligent System. \nIf you made claims about your Autonomous Intelligent System's efficacy, performance, or benefits, please \njustify them and provide the evidence underlying them. If you have mentioned or used scientific papers, \nplease cite your sources \nIf you have run your Autonomous Intelligent System under adversarial examples or worst-case scenarios, \ndescribe the type of tests used and their outcomes \nDescribe the process whereby users can formally complain or express their concerns about your \nAutonomous Intelligent System \n\nPRIVACY & TRANSPARENCY \nResponsibility \n\nData collection \n\nAccessibility \n\nInformed consent \n\nConsent withdrawal \n\nAccess to the data "
  },
  {
    "title": "Mental Illness Classification on Social Media Texts using Deep Learning\n  and Transfer Learning",
    "authors": [
      "Iqra Ameer",
      "Muhammad Arif",
      "Grigori Sidorov",
      "Helena Gòmez-Adorno",
      "Alexander Gelbukh"
    ],
    "abstract": "Given the current social distance restrictions across the world, most\nindividuals now use social media as their major medium of communication.\nMillions of people suffering from mental diseases have been isolated due to\nthis, and they are unable to get help in person. They have become more reliant\non online venues to express themselves and seek advice on dealing with their\nmental disorders. According to the World health organization (WHO),\napproximately 450 million people are affected. Mental illnesses, such as\ndepression, anxiety, etc., are immensely common and have affected an\nindividuals' physical health. Recently Artificial Intelligence (AI) methods\nhave been presented to help mental health providers, including psychiatrists\nand psychologists, in decision making based on patients' authentic information\n(e.g., medical records, behavioral data, social media utilization, etc.). AI\ninnovations have demonstrated predominant execution in numerous real-world\napplications broadening from computer vision to healthcare. This study analyzes\nunstructured user data on the Reddit platform and classifies five common mental\nillnesses: depression, anxiety, bipolar disorder, ADHD, and PTSD. We trained\ntraditional machine learning, deep learning, and transfer learning multi-class\nmodels to detect mental disorders of individuals. This effort will benefit the\npublic health system by automating the detection process and informing\nappropriate authorities about people who require emergency assistance.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2207.01012v1",
    "pdf_url": "http://arxiv.org/pdf/2207.01012v1",
    "full_text": "2\n2\n0\n2\n\nl\nu\nJ\n\n3\n\n]\n\nG\nL\n.\ns\nc\n[\n\n1\nv\n2\n1\n0\n1\n0\n.\n7\n0\n2\n2\n:\nv\ni\nX\nr\na\n\nMental Illness Classiﬁcation on Social Media\nTexts using Deep Learning and Transfer\nLearning\n\nIqra Ameer1[0000−0002−1134−9713], Muhammad Arif1[0000−0001−06141−02047],\nGrigori Sidorov1[0000−0003−3901−3522], Helena\nG´omez-Adorno2[0000−0002−6966−9912], Alexander Gelbukh1[0000−0001−7845−9039],\nand\n\n1 Instituto Polit´ecnico Nacional, Centro de Investigaci´on en Computaci´on, Mexico\nCity, Mexico\n{iameer2019,mariff2021,sidorov,gelbukh}@cic.ipn.mx\n2 Instituto de Investigaciones en Matem´aticas Aplicadas y en Sistemas, Universidad\nNacional Aut´onoma de M´exico, Mexico City, Mexico\nhelena.gomez@iimas.unam.mx\n\nAbstract. Given the current social distance restrictions across the world,\nmost individuals now use social media as their major medium of com-\nmunication. Millions of people suﬀering from mental diseases have been\nisolated due to this, and they are unable to get help in person. They\nhave become more reliant on online venues to express themselves and\nseek advice on dealing with their mental disorders. According to the\nWorld health organization (WHO), approximately 450 million people\nare aﬀected. Mental illnesses, such as depression, anxiety, etc., are im-\nmensely common and have aﬀected an individual’s physical health. Re-\ncently Artiﬁcial Intelligence (AI) methods have been presented to help\nmental health providers, including psychiatrists and psychologists, in\ndecision-making based on patients’ authentic information (e.g., medi-\ncal records, behavioral data, social media utilization, etc.). AI innova-\ntions have demonstrated predominant execution in numerous real-world\napplications broadening from computer vision to healthcare. This study\nanalyzes unstructured user data on the Reddit platform and classiﬁes ﬁve\ncommon mental illnesses: depression, anxiety, bipolar disorder, ADHD,\nand PTSD. We trained traditional machine learning, deep learning, and\ntransfer learning multi-class models to detect mental disorders of indi-\nviduals. This eﬀort will beneﬁt the public health system by automating\nthe detection process and informing appropriate authorities about people\nwho require emergency assistance.\n\nKeywords: Mental Illnesses Classiﬁcation · Machine Learning · Deep\nLearning · Transfer Learning · Reddit\n\n1\n\nIntroduction\n\nMental illness could be a sort of health condition that changes a person’s intellect,\nfeelings, or behavior (or all three) and has been appeared to aﬀect an individual’s\n\n \n \n \n \n \n \n\f2\n\nI. Ameer et al.\n\nphysical health [28,23]. Mental health issues including depression, schizophre-\nnia, attention-deﬁcit hyperactivity disorder (ADHD), autism spectrum disorder\n(ASD), etc., are highly prevalent today, and it is estimated that around 450\nmillion people worldwide suﬀer from such problems[28].\n\nTo way better get the mental health conditions and provide care, early de-\ntection of mental health problems is a basic step. Diﬀerent from the diagnosis of\nother chronic conditions that depend on research facility tests and measurements,\nmental illnesses are regularly diagnosed based on an individual’s self-report to\nparticular surveys planned for the detection of speciﬁc patterns of feelings or\nsocial interactions [18].\n\nAmid these uncertain times when COVID-19 torments the world, many peo-\nple have indicated clinical anxiety or depression. This could be due to lockdown,\nlimited social activities, a higher unemployment rate, economic depression, and\nfatigue related to work. American Foundation for Suicide Anticipation reported\nthat individuals encounter anxiety (53%) and sadness (51%) more regularly now\nas compared to the time before covid-19 widespread.\n\nWithin the past decade, social media has changed social interaction. Along\nwith sharing data and news, individuals eﬀectively communicate their day-to-day\nactivities, experiences, hopes, emotions, etc., and generate tons of data online.\nThis textual data gives information that can be utilized to design systems to\npredict people’s mental health. Moreover, the current limited social interaction\nstate has forced people to express their thoughts on social media. It gives people\nan open stage to share their opinions with others numerous times attempt to\nﬁnd assistance [25].\n\nA previous study explored the application of Machine Learning (ML) tech-\nniques in mental health [31]. They reviewed literature by grouping them into four\nmain application domains, such as detection and diagnosis (ii) prognosis, treat-\nment and support, (iii) public health applications, and (iv) research and clinical\nadministration. Another study explored the emerging area of application of DL\ntechniques in psychiatry. They focused on DL by embedding semantically inter-\npretable computational models of brain dynamics or behavior into a statistical\nmachine learning context [15].\n\nThis study uses reddit.com3 user data proposed by Murarka and Radhakrish-\nnan [25] to determine mental illnesses, see sample of dataset instances in "
  },
  {
    "title": "Engaging with mental health: a global challenge",
    "authors": [
      "David Coyle",
      "Mark Matthews",
      "Gavin Doherty",
      "John Sharry"
    ],
    "abstract": "Using the metrics of the World Health Organisation, the Global Burden of\nDisease Study has found that mental health difficulties are currently the\nleading cause of disability in developed countries [1]. Projections also\nindicate that the global burden of mental health difficulties will continue to\nrise in the coming decades. The human and economic costs of this trend will be\nsubstantial. In this paper we discuss how effectively designed interactive\nsystems, developed through collaborative, interdisciplinary efforts, can play a\nsignificant role in helping to address this challenge. Our discussion is\ngrounded in a description of four exploratory systems, each of which has\nundergone initial clinical evaluations. Directions for future research on\nmental health technologies are also identified.",
    "year": 2013,
    "url": "http://arxiv.org/abs/1307.3174v1",
    "pdf_url": "http://arxiv.org/pdf/1307.3174v1",
    "full_text": "Presented at the Workshop on Interactive Systems in Healthcare at CHI 2010, Atlanta, Georgia. April 11th 2010.  \n\nEngaging with mental health: a global challenge\n\nDavid Coyle \n\nGavin Doherty \n\nThe Computer Laboratory \n\nSchool of Computer Science      \n\nUniversity of Cambridge \n\nand Statistics \n\nWilliam Gates Building \n\nTrinity College Dublin \n\n15 JJ Thomson Avenue  \n\nCollege Green \n\nCambridge CB3 0FD, UK \n\nDublin 2, Ireland \n\ncoyledt@tcd.ie \n\ngavin.doherty@cs.tcd.ie \n\nMark Matthews \n\nJohn Sharry \n\nStudent Counselling Service \n\nChild and Adolescent Psychiatry \n\nTrinity College Dublin \n\nMater Misericordiae Hospital \n\nCollege Green \n\nDublin 2, Ireland \n\nMetropolitan Building \n\nJames Joyce Street \n\nmark.matthews@cs.tcd.ie \n\nDublin 1, Ireland \n\njsharry@mater.ie  \n\nCopyright is held by the author/owner(s).  \nWISH 2010 April 11, 2010, Atlanta, Georgia, USA. \n\nAbstract \nUsing the metrics of the World Health Organisation, the \nGlobal Burden of Disease Study has found that mental \nhealth difficulties are currently the leading cause of \ndisability in developed countries [1]. Projections also \nindicate that the global burden of mental health \ndifficulties will continue to rise in the coming decades. \nThe human and economic costs of this trend will be \nsubstantial. In this paper we discuss how effectively \ndesigned interactive systems, developed through \ncollaborative, interdisciplinary efforts, can play a \nsignificant role in helping to address this challenge. Our \ndiscussion is grounded in a description of four \nexploratory systems, each of which has undergone \ninitial clinical evaluations. Directions for future research \non mental health technologies are also identified. \n\nKeywords \nMental health, collaborative design, interactive systems \n\nACM Classification Keywords \nH.5.m [Information Interfaces and Presentation]: \nMiscellaneous – interdisciplinary design, mental health \n\nIntroduction \nMental disorders are health conditions defined by the \nexperiencing of severe and distressing psychological \nsymptoms, to the extent that normal functioning is \nseriously impaired, and some form of help is usually \nneeded for recovery. The US Surgeon General’s first \nreport on mental health concluded that (1) the efficacy \n\n \n \n \n \n \n \n \n \n \n\fof mental health treatments is well documented and (2) \na range of effective treatments exist for most mental \ndisorders [2]. Unfortunately international studies also \nconclude that the majority of people experiencing \ndifficulties do not receive appropriate specialist \ntreatment [2, 3]. Research concludes that in the UK \nmental health has now overtaken unemployment as the \nnation’s most expensive social problem [4]. \n\nAn interdisciplinary challenge \nAddressing the challenges of providing more effective \nmental healthcare (MHC) services will require the \nconcerted efforts of professionals across a range of \ndisciplines. It is likely – indeed necessary – that \ntechnology will play a significant role in future service \ndelivery. Coyle et al [5] identifies two broad challenges \nwhich interactive systems can help in addressing [5]: \n\n1.  Access/capacity constraints: traditional mental \nhealth intervention strategies, particularly talk-based \nstrategies, are time and resource intensive. As a result \nexisting services often do not have sufficient capacity to \nmeet the needs of people requiring professional help. \n\n2.  Engagement: research suggests that, even when \nprofessional help is available, many clients find it \ndifficult to successfully engage with traditional \ntreatment. The level to which clients engage with their \ntreatment, and draw on their own personal resources, \nis a major factor in the success of interventions.  \n\nWith several notable exceptions, early research on the \nuse of technology was generally justified on the basis of \nincreased access - e.g. electronic contact as a natural \nextension of face-to-face dialogue and the \ncomputerisation of self-help materials. Increased \nengagement and actual improvements in the \n\neffectiveness of treatment have received less attention \n[5]. Collaboration between HCI and MHC professionals \ncan help in maximising the effectiveness of new \ntechnologies. While MHC professionals have the \nnecessary domain expertise, HCI researchers are \nexperienced in design methodologies and are likely to \nhave a broader knowledge of the potential uses of new \ntechnologies. For example the experience of HCI \nresearchers is important given the high cost of systems \nfailures in sensitive interventions. Other ongoing areas \nof HCI research, such as designing for personal \nreflection and behaviour change, can play a valuable \nrole in future research on mental health technologies. \n\nExamples of exploratory systems \nWe have primarily focused on the design of technology \nto support talk-based, psychological approaches to \nmental health treatment, e.g. psychotherapy. Reviews \nof previous research on technology in this area are \navailable in [5, 6]. Over the past 7 years we h"
  },
  {
    "title": "Semiparametric count data regression for self-reported mental health",
    "authors": [
      "Daniel R. Kowal",
      "Bohan Wu"
    ],
    "abstract": "\"For how many days during the past 30 days was your mental health not good?\"\nThe responses to this question measure self-reported mental health and can be\nlinked to important covariates in the National Health and Nutrition Examination\nSurvey (NHANES). However, these count variables present major distributional\nchallenges: the data are overdispersed, zero-inflated, bounded by 30, and\nheaped in five- and seven-day increments. To meet these challenges, we design a\nsemiparametric estimation and inference framework for count data regression.\nThe data-generating process is defined by simultaneously transforming and\nrounding (STAR) a latent Gaussian regression model. The transformation is\nestimated nonparametrically and the rounding operator ensures the correct\nsupport for the discrete and bounded data. Maximum likelihood estimators are\ncomputed using an EM algorithm that is compatible with any continuous data\nmodel estimable by least squares. STAR regression includes asymptotic\nhypothesis testing and confidence intervals, variable selection via information\ncriteria, and customized diagnostics. Simulation studies validate the utility\nof this framework. STAR is deployed to study the factors associated with\nself-reported mental health and demonstrates substantial improvements in\ngoodness-of-fit compared to existing count data regression models.",
    "year": 2021,
    "url": "http://arxiv.org/abs/2106.09114v2",
    "pdf_url": "http://arxiv.org/pdf/2106.09114v2",
    "full_text": "Semiparametric count data regression for\n\nself-reported mental health\n\nDaniel R. Kowal and Bohan Wu∗\n\nAbstract\n\n“For how many days during the past 30 days was your mental health not good?”\n\nThe responses to this question measure self-reported mental health and can be linked\n\nto important covariates in the National Health and Nutrition Examination Survey\n\n(NHANES). However, these count variables present major distributional challenges:\n\nthe data are overdispersed, zero-inﬂated, bounded by 30, and heaped in ﬁve- and seven-\n\nday increments. To address these challenges—which are especially common for health\n\nquestionnaire data—we design a semiparametric estimation and inference framework\n\nfor count data regression. The data-generating process is deﬁned by simultaneously\n\ntransforming and rounding (star) a latent Gaussian regression model. The transfor-\n\nmation is estimated nonparametrically and the rounding operator ensures the correct\n\nsupport for the discrete and bounded data. Maximum likelihood estimators are com-\n\nputed using an EM algorithm that is compatible with any continuous data model\n\nestimable by least squares. star regression includes asymptotic hypothesis testing\n\nand conﬁdence intervals, variable selection via information criteria, and customized\n\ndiagnostics. Simulation studies validate the utility of this framework. Using star\n\nregression, we identify key factors associated with self-reported mental health and\n\ndemonstrate substantial improvements in goodness-of-ﬁt compared to existing count\n\ndata regression models.\n\nKeywords: generalized linear model; health data; questionnaire data; transformation.\n∗Department of Statistics, Rice University, Houston, TX (Correspondence: daniel.kowal@rice.edu).\n\n1\n2\n0\n2\n\nt\nc\nO\n3\n1\n\n]\nE\nM\n\n.\nt\na\nt\ns\n[\n\n2\nv\n4\n1\n1\n9\n0\n.\n6\n0\n1\n2\n:\nv\ni\nX\nr\na\n\n \n \n \n \n \n \n\f1\n\nIntroduction\n\nThe National Health and Nutrition Examination Survey (NHANES) asks a critical question:\n\n“For how many days during the past 30 days was your mental health not good?” The\n\nresponses (DaysMentHlthNotGood) provide insights on self-reporting of mental health issues\n\nand can be linked to demographic, socioeconomic, behavioral, and health-related covariates.\n\nMental health and mental disorders are key factors in quality of life, depression, and risk of\n\nself-harm, and are focal points of many research studies (Scheid and Wright, 2017). Previous\n\nresearch has sought to associate mental health, mental disorders, or depression with gender\n\n(Seedat et al., 2009), race (Williams et al., 2010a), socioeconomic status (Ortega and Corzine,\n\n1990), marital status (Williams et al., 2010b), age (Mirowsky and Ross, 1999), smoking\n\n(Klungsøyr et al., 2006), and blood pressure (Tzourio et al., 1999), among many other\n\nfactors. Notably, NHANES data include relevant covariates for all of these factors—and\n\nseveral others (see Table 4)—on a large sample of individuals, and thus oﬀers a unique\n\nopportunity for a joint analysis of multiple factors.\n\nOur goal is to construct an adequate count regression model for these health question-\n\nnaire data and characterize the eﬀects of covariates on self-reported mental health. Health\n\nquestionnaire data often require customized statistical methodology, including life event\n\nstressors (Herring et al., 2004), sleep quality (Dunson, 2005), nutritional and food intake\n\n(Kipnis et al., 2009), and drug use (Song et al., 2017), among many others. From a sta-\n\ntistical modeling perspective, DaysMentHlthNotGood is an overdispersed, zero-inﬂated, and\n\nbounded count variable. Figure 1 shows the empirical probability mass function (PMF) for\n\nDaysMentHlthNotGood. The PMF has spikes at both the lower bound (zero days) and the\n\nupper bound (30 days) and, most uniquely, heaping in ﬁve- and seven-day increments. This\n\nis an expected consequence of self-reported behavior: individuals are more likely to report\n\n1\n\n\f14 or 15 days than they are 16 or 17 days regardless of the exact truth. Hence, a regression\n\nmodel for DaysMentHlthNotGood must be capable of modeling discreteness, overdispersion,\n\nzero-inﬂation, boundedness, and heaping.\n\nFigure 1: Empirical probability mass function (PMF) for DaysMentHlthNotGood with estimated\nPMFs for zero-inﬂated Poisson (ZIP, left) and star (right). While star neatly captures zero-\ninﬂation, heaping (light gray), and boundedness, ZIP is inadequate for the nonzero counts.\n\nMost count regression models build upon the Poisson distribution. Poisson regression\n\ncan be suitable for point estimation or point prediction (see Section 5), but is often in-\n\nadequate for modeling and inference due to the rigid equidispersion requirements. Exten-\n\nsions for over/underdispersion typically introduce additional parameters or latent variables,\n\nsuch as quasi-Poisson, Negative Binomial, or Conway-Maxwell-Poisson (Sellers and Shmueli,\n\n2010). Other features such as zero-inﬂation can be appended to the Poisson model or its\n\ngeneralizations. However, the added complexity of generalized"
  },
  {
    "title": "Measuring Depression Symptom Severity from Spoken Language and 3D Facial\n  Expressions",
    "authors": [
      "Albert Haque",
      "Michelle Guo",
      "Adam S Miner",
      "Li Fei-Fei"
    ],
    "abstract": "With more than 300 million people depressed worldwide, depression is a global\nproblem. Due to access barriers such as social stigma, cost, and treatment\navailability, 60% of mentally-ill adults do not receive any mental health\nservices. Effective and efficient diagnosis relies on detecting clinical\nsymptoms of depression. Automatic detection of depressive symptoms would\npotentially improve diagnostic accuracy and availability, leading to faster\nintervention. In this work, we present a machine learning method for measuring\nthe severity of depressive symptoms. Our multi-modal method uses 3D facial\nexpressions and spoken language, commonly available from modern cell phones. It\ndemonstrates an average error of 3.67 points (15.3% relative) on the\nclinically-validated Patient Health Questionnaire (PHQ) scale. For detecting\nmajor depressive disorder, our model demonstrates 83.3% sensitivity and 82.6%\nspecificity. Overall, this paper shows how speech recognition, computer vision,\nand natural language processing can be combined to assist mental health\npatients and practitioners. This technology could be deployed to cell phones\nworldwide and facilitate low-cost universal access to mental health care.",
    "year": 2018,
    "url": "http://arxiv.org/abs/1811.08592v2",
    "pdf_url": "http://arxiv.org/pdf/1811.08592v2",
    "full_text": "8\n1\n0\n2\n\nv\no\nN\n7\n2\n\n]\n\nV\nC\n.\ns\nc\n[\n\n2\nv\n2\n9\n5\n8\n0\n.\n1\n1\n8\n1\n:\nv\ni\nX\nr\na\n\nMeasuring Depression Symptom Severity from\nSpoken Language and 3D Facial Expressions\n\nAlbert Haque1\n\nMichelle Guo1\n\nAdam S Miner2,3\n\nLi Fei-Fei1\n\n1Department of Computer Science, Stanford University\n2Department of Psychiatry and Behavioral Sciences, Stanford University\n3Department of Health Research and Policy, Stanford University\n\nAbstract\n\nWith more than 300 million people depressed worldwide, depression is a global\nproblem. Due to access barriers such as social stigma, cost, and treatment availabil-\nity, 60% of mentally-ill adults do not receive any mental health services. Effective\nand efﬁcient diagnosis relies on detecting clinical symptoms of depression. Au-\ntomatic detection of depressive symptoms would potentially improve diagnostic\naccuracy and availability, leading to faster intervention. In this work, we present a\nmachine learning method for measuring the severity of depressive symptoms. Our\nmulti-modal method uses 3D facial expressions and spoken language, commonly\navailable from modern cell phones. It demonstrates an average error of 3.67 points\n(15.3% relative) on the clinically-validated Patient Health Questionnaire (PHQ)\nscale. For detecting major depressive disorder, our model demonstrates 83.3%\nsensitivity and 82.6% speciﬁcity. Overall, this paper shows how speech recognition,\ncomputer vision, and natural language processing can be combined to assist mental\nhealth patients and practitioners. This technology could be deployed to cell phones\nworldwide and facilitate low-cost universal access to mental health care.\n\n1\n\nIntroduction\n\nWorldwide, more than 300 million people are depressed [48]. In the worst case, depression can lead to\nsuicide, with close to 800,000 people committing suicide every year. In general, patients with mental\ndisorders are seen by a wide spectrum of health care providers, including primary care physicians\n[22]. However, compared to physical illnesses, mental disorders are more difﬁcult to detect. The\nburden of mental health is exacerbated by barriers to care such as social stigma, ﬁnancial cost, and\na lack of accessible treatment options. To address entrenched barriers to care, scalable approaches\nfor detecting mental health symptoms have been called for [19]. If successful, early detection may\nimpact access for the 60% of mentally-ill adults who do not receive treatment [33].\n\nIn practice, clinicians identify depression in patients by ﬁrst measuring the severity of depressive\nsymptoms1 during in-person clinical interviews. During these interviews, clinicians assess both verbal\nand non-verbal indicators of depressive symptoms including monotone pitch, reduced articulation\nrate, lower speaking volumes [16, 41], fewer gestures, and more downward gazes [46, 40, 37]. If\nsuch symptoms persist for two weeks [4], the patient is considered to have a major depressive episode.\nStructured questionnaires have been developed and validated in clinical populations to assess the\nseverity of depressive symptoms. One of the most common questionnaires is the Patient Health\nQuestionnaire (PHQ) [23]. This clinically-validated tool measures depression symptom severity\nacross several personal dimensions [21]. Assessing symptom severity is time-intensive, and critical\nfor both initial diagnosis and improvement across time. Thus, AI-based solutions to assessing\nsymptom severity may address entrenched barriers to access and treatment.\n\n1Depressive symptoms include feelings of worthlessness, loss of interest in hobbies, or thoughts of suicide.\n\nMachine Learning for Health (ML4H) Workshop at NeurIPS 2018, Montréal, Canada.\n\n \n \n \n \n \n \n\fFigure 1: Multi-modal data. For each clinical interview, we use: (a) video of 3D facial scans, (b)\naudio recording, visualized as a log-mel spectrogram, and (c) text transcription of the patient’s speech.\nOur model predicts the severity of depressive symptoms using all three modalities.\n\nWe envision an AI-based solution where depressed individuals can receive evidence-based mental\nhealth services while avoiding existing barriers to access. Such a solution could leverage multi-modal\nsensors or text messages, as is common on modern smartphones, to increase timely and cost-effective\nsymptom screening [3]. Conversational AIs are another potential solution [31, 32]. Our hope is that\nautomated feedback will (i) provide actionable feedback to individuals who may be depressed, and\n(ii) improve automated depression screening tools for clinicians, by including visual, audio, and\nlinguistic signals.\n\nContributions. We propose a machine learning method for measuring depressive symptom severity\nfrom de-identiﬁed multi-modal data. The input to our model is audio, 3D video of facial keypoints,\nand a text transcription of a patient speaking during a clinical interview. The output of our model is\neither a PHQ score or classiﬁcation label indicating major depressive disorder. Our method leverages\na causal conv"
  },
  {
    "title": "EmoMent: An Emotion Annotated Mental Health Corpus from two South Asian\n  Countries",
    "authors": [
      "Thushari Atapattu",
      "Mahen Herath",
      "Charitha Elvitigala",
      "Piyanjali de Zoysa",
      "Kasun Gunawardana",
      "Menasha Thilakaratne",
      "Kasun de Zoysa",
      "Katrina Falkner"
    ],
    "abstract": "People often utilise online media (e.g., Facebook, Reddit) as a platform to\nexpress their psychological distress and seek support. State-of-the-art NLP\ntechniques demonstrate strong potential to automatically detect mental health\nissues from text. Research suggests that mental health issues are reflected in\nemotions (e.g., sadness) indicated in a person's choice of language. Therefore,\nwe developed a novel emotion-annotated mental health corpus (EmoMent),\nconsisting of 2802 Facebook posts (14845 sentences) extracted from two South\nAsian countries - Sri Lanka and India. Three clinical psychology postgraduates\nwere involved in annotating these posts into eight categories, including\n'mental illness' (e.g., depression) and emotions (e.g., 'sadness', 'anger').\nEmoMent corpus achieved 'very good' inter-annotator agreement of 98.3% (i.e. %\nwith two or more agreement) and Fleiss' Kappa of 0.82. Our RoBERTa based models\nachieved an F1 score of 0.76 and a macro-averaged F1 score of 0.77 for the\nfirst task (i.e. predicting a mental health condition from a post) and the\nsecond task (i.e. extent of association of relevant posts with the categories\ndefined in our taxonomy), respectively.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2208.08486v1",
    "pdf_url": "http://arxiv.org/pdf/2208.08486v1",
    "full_text": "EmoMent: An Emotion Annotated Mental Health Corpus from two South\nAsian Countries\n\nThushari Atapattu1, Mahen Herath2, Charith Elvitigala3, Piyanjali de Zoysa4,\nKasun Gunawardane3, Menasha Thilakaratne1,\nKasun de Zoysa3 and Katrina Falkner1\n1School of Computer Science, The University of Adelaide, Adelaide, Australia\n2Department of Computer Science & Engineering, University of Moratuwa, Katubedda, Sri Lanka\n3University of Colombo School of Computing, Colombo, Sri Lanka\n4Department of Psychology, University of Colombo, Sri Lanka\nemail: thushari.atapattu@adelaide.edu.au\n\nAbstract\n\nPeople often utilise online media (e.g., Face-\nbook, Reddit) as a platform to express their\npsychological distress and seek support. State-\nof-the-art NLP techniques demonstrate strong\npotential to automatically detect mental health\nissues from text. Research suggests that men-\ntal health issues are reﬂected in emotions (e.g.,\nsadness) indicated in a person’s choice of\nlanguage. Therefore, we developed a novel\nemotion-annotated mental health corpus (Emo-\nMent), consisting of 2802 Facebook posts\n(14845 sentences) extracted from two South\nAsian countries - Sri Lanka and India. Three\nclinical psychology postgraduates were in-\nvolved in annotating these posts into eight cate-\ngories, including ‘mental illness’ (e.g., depres-\nsion) and emotions (e.g., ‘sadness’, ‘anger’).\nEmoMent corpus achieved ‘very good’ inter-\nannotator agreement of 98.3% (i.e. % with two\nor more agreement) and Fleiss’ Kappa of 0.82.\nOur RoBERTa based models achieved an F1\nscore of 0.76 and a macro-averaged F1 score\nof 0.77 for the ﬁrst task (i.e. predicting a men-\ntal health condition from a post) and the sec-\nond task (i.e. extent of association of relevant\nposts with the categories deﬁned in our taxon-\nomy), respectively.\n\n1\n\nIntroduction\n\nMental health issues remain a leading cause for\npoor well-being and suicide. The World Health\nOrganisation (WHO) indicates that 400 million\npeople are affected by mental disorders such as\ndepression, resulting in a cost of US$ 1 trillion\nper year from the global economy allocated for de-\npression and anxiety disorders alone (WHO, 2019;\nJames et al., 2018). Recent research using AI and\nNLP demonstrates strong potential to automatically\ndetect mental health issues from digital footprints\nsuch that professionals could provide timely inter-\nventions and mental health resources to vulnerable\n\npersons. These data contain useful information to\nunderstand patients’ distressed state of mind out-\nside a traditional clinical environment.\n\nResearch suggests that mental health issues are\nreﬂected in the ‘emotions’ (e.g., sadness, anger)\nindicated in one’s expression of language. De-\nspite the popularity of research studies in detecting\nmental disorders using online data such as Twit-\nter (Coppersmith et al., 2014, 2015; Cohan et al.,\n2018) and emotion modeling (Strapparava and Mi-\nhalcea, 2007; Mohammad et al., 2018; Demszky\net al., 2020; Oberländer and Klinger, 2018), the au-\ntomated identiﬁcation of the association between\nemotions and mental disorders have largely being\nignored, apart from a recent study (CEASE corpus\n(Ghosh et al., 2020)) that focused on the role of\nemotions on suicidal ideation.\n\nMotivated by this, we introduce a novel,\nemotion-annotated mental health (EmoMent) cor-\npus1 using Facebook posts extracted from two\nSouth Asian countries - Sri Lanka and India. In\nSouth Asia, due to the lack of awareness of symp-\ntoms of mental illnesses and its associated stigma,\npeople often do not seek professional help, result-\ning in many instances of mental disorders being\nleft undiagnosed (Arora et al., 2016). However,\nsince recently, these countries have demonstrated\na tendency to use social media, particularly Face-\nbook, to seek mental health help using private and\npublic groups (e.g., Psychology group in Sri Lanka,\nIndian Psychology Association).\n\nDepression and anxiety disorders are amongst\nthe most common mental disorders worldwide\n(James et al., 2018; Black Dog Institute, 2020).\nTherefore, our dataset includes de-identiﬁable Face-\nbook posts from individuals who have indicated a\ndiagnosis of depression or anxiety, the disorder-\n\n1dataset and the code is available on request for research\n\npurposes.\n\n2\n2\n0\n2\n\ng\nu\nA\n7\n1\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n6\n8\n4\n8\n0\n.\n8\n0\n2\n2\n:\nv\ni\nX\nr\na\n\n \n \n \n \n \n \n\frelated issues they express including associated\nemotions, and their help-seeking behaviours from\nprofessionals and/or community. EmoMent con-\nsists of 2802 posts (14845 sentences) extracted\nfrom public Facebook groups dedicated to discuss\nmental health concerns in Sri Lanka and India.\nThree clinical psychology postgraduates were in-\nvolved in the data annotation process. Their task\nwas to read the entire post and assign one or more\nlabels from a given set of eight categories (e.g.,\nmental illness, sadness, psychosomatic, irrelevant)\n(Table 2). We have achieved ‘very good’ inter-\nannotator agreement of 98.3% (i.e. % with two or\nmore rater-agreement) and "
  },
  {
    "title": "Language and Mental Health: Measures of Emotion Dynamics from Text as\n  Linguistic Biosocial Markers",
    "authors": [
      "Daniela Teodorescu",
      "Tiffany Cheng",
      "Alona Fyshe",
      "Saif M. Mohammad"
    ],
    "abstract": "Research in psychopathology has shown that, at an aggregate level, the\npatterns of emotional change over time -- emotion dynamics -- are indicators of\none's mental health. One's patterns of emotion change have traditionally been\ndetermined through self-reports of emotions; however, there are known issues\nwith accuracy, bias, and ease of data collection. Recent approaches to\ndetermining emotion dynamics from one's everyday utterances addresses many of\nthese concerns, but it is not yet known whether these measures of utterance\nemotion dynamics (UED) correlate with mental health diagnoses. Here, for the\nfirst time, we study the relationship between tweet emotion dynamics and mental\nhealth disorders. We find that each of the UED metrics studied varied by the\nuser's self-disclosed diagnosis. For example: average valence was significantly\nhigher (i.e., more positive text) in the control group compared to users with\nADHD, MDD, and PTSD. Valence variability was significantly lower in the control\ngroup compared to ADHD, depression, bipolar disorder, MDD, PTSD, and OCD but\nnot PPD. Rise and recovery rates of valence also exhibited significant\ndifferences from the control. This work provides important early evidence for\nhow linguistic cues pertaining to emotion dynamics can play a crucial role as\nbiosocial markers for mental illnesses and aid in the understanding, diagnosis,\nand management of mental health disorders.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2310.17369v2",
    "pdf_url": "http://arxiv.org/pdf/2310.17369v2",
    "full_text": "Language and Mental Health:\nMeasures of Emotion Dynamics from Text as Linguistic Biosocial Markers\nDaniela Teodorescu1,2∗, Tiffany Cheng3, Alona Fyshe1,4, Saif M. Mohammad5\n1Dept. Computing Science, Alberta Machine Intelligence Institute (Amii), University of Alberta\n2MaiNLP, Center for Information and Language Processing, LMU Munich, Germany\n3Carleton University\n4Dept. Psychology, University of Alberta\n5National Research Council Canada\n{dteodore,alona}@ualberta.ca, tiffany.cheng@carleton.ca, saif.mohammad@nrc-cnrc.gc.ca\n\nAbstract\n\nResearch in psychopathology has shown that,\nat an aggregate level, the patterns of emotional\nchange over time—emotion dynamics—are in-\ndicators of one’s mental health. One’s pat-\nterns of emotion change have traditionally been\ndetermined through self-reports of emotions;\nhowever, there are known issues with accu-\nracy, bias, and ease of data collection. Recent\napproaches to determining emotion dynamics\nfrom one’s everyday utterances addresses many\nof these concerns, but it is not yet known\nwhether these measures of utterance emotion\ndynamics (UED) correlate with mental health\ndiagnoses. Here, for the first time, we study\nthe relationship between tweet emotion dynam-\nics and mental health disorders. We find that\neach of the UED metrics studied varied by the\nuser’s self-disclosed diagnosis. For example:\naverage valence was significantly higher (i.e.,\nmore positive text) in the control group com-\npared to users with ADHD, MDD, and PTSD.\nValence variability was significantly lower in\nthe control group compared to ADHD, depres-\nsion, bipolar disorder, MDD, PTSD, and OCD\nbut not PPD. Rise and recovery rates of valence\nalso exhibited significant differences from the\ncontrol. This work provides important early\nevidence for how linguistic cues pertaining to\nemotion dynamics can play a crucial role as\nbiosocial markers for mental illnesses and aid\nin the understanding, diagnosis, and manage-\nment of mental health disorders.\n\n1\n\nIntroduction\n\nLanguage is inherently social—from the way in\nwhich we say things, the expressions we use and\nthe things we choose to share, being impacted by\nour social environment and lived experiences. As\nour social environments have evolved over time,\nlanguage has evolved to better support our commu-\nnication needs and collaborative societies. There-\nfore, language is also variable, as the way in which\n\n∗ Work done while at the University of Alberta.\n\nwe use it has adapted to cultures and communi-\nties around the world, and it is influenced by an\nindividual’s experiences.\n\nGiven the prominent role of language in human\nevolution from hunters–gathers to collaborative so-\ncieties, and the large extent to which we rely on\nlanguage today, it is not surprising that our mental\nhealth impacts our language usage. Quantitative\nfeatures in language (e.g., aspects which can be\nmeasured) have already been shown to indicate\nand help clinicians monitor the progression of men-\ntal health conditions (MHCs), acting as biomark-\ners. A linguistic biomarker is a language-based\nmeasure that is associated with a disease outcome\nor biology in general (Ballman, 2015; Gagliardi\nand Tamburini, 2022; Lena, 2021). Some well-\nknown linguistic biomarkers include: the propor-\ntion of pronouns (indicator of depression, Koops\net al. (2023)), syntax reduction (Anorexia Nervosa,\nCuteri et al. (2022)), certain lexical and syntactic\nfeatures (mild cognitive impairment and demen-\ntia, Calzà et al. (2021); Gagliardi and Tamburini\n(2021)), and semantic connectedness (schizophre-\nnia, Corcoran et al. (2020). Also, the emotions\nexpressed in text have been shown to correlate with\nmental health diagnosis. For example, more neg-\native sentiment in text by individuals with depres-\nsion (De Choudhury et al., 2013; Seabrook et al.,\n2018; De Choudhury et al., 2021). Other work has\nshown that suicide watch, anxiety, and self-harm\nsubreddits had noticeably lower negative sentiment\ncompared to other mental health subreddits such as\nAutism and Asperger’s (Gkotsis et al., 2016).\n\nWhile language can be a biomarker for mental\nhealth, the substantial social nature of language\nhas implications. Notably, the tremendous vari-\nability in language use—especially across social\ngroups—means that we should be skeptical about\nuniversal biomarkers; and instead realize that lin-\nguistic biomarkers alone are not capable of pre-\ndicting MHCs. A vast amount of contextual and\n\n3\n2\n0\n2\n\nv\no\nN\n4\n\n]\nL\nC\n.\ns\nc\n[\n\n2\nv\n9\n6\n3\n7\n1\n.\n0\n1\n3\n2\n:\nv\ni\nX\nr\na\n\n \n \n \n \n \n \n\fclinical information (often only available to an indi-\nvidual’s physician) helps determine well-being, and\nsometimes linguistic markers can aid the process.\nFurther, linguistic biomarkers are more likely to be\na stronger indicator among groups with commonal-\nities; for example, when applied to people from the\nsame region, culture, or medium of expression (e.g.,\nsocial media platform). For example, social factors\nsuch as parental socioeconomic status, neighbour-\nhood, and institutio"
  },
  {
    "title": "Modeling trajectories of mental health: challenges and opportunities",
    "authors": [
      "Lauren Erdman",
      "Ekansh Sharma",
      "Eva Unternahrer",
      "Shantala Hari Dass",
      "Kieran ODonnell",
      "Sara Mostafavi",
      "Rachel Edgar",
      "Michael Kobor",
      "Helene Gaudreau",
      "Michael Meaney",
      "Anna Goldenberg"
    ],
    "abstract": "More than two thirds of mental health problems have their onset during\nchildhood or adolescence. Identifying children at risk for mental illness later\nin life and predicting the type of illness is not easy. We set out to develop a\nplatform to define subtypes of childhood social-emotional development using\nlongitudinal, multifactorial trait-based measures. Subtypes discovered through\nthis study could ultimately advance psychiatric knowledge of the early\nbehavioural signs of mental illness. To this extent we have examined two types\nof models: latent class mixture models and GP-based models. Our findings\nindicate that while GP models come close in accuracy of predicting future\ntrajectories, LCMMs predict the trajectories as well in a fraction of the time.\nUnfortunately, neither of the models are currently accurate enough to lead to\nimmediate clinical impact. The available data related to the development of\nchildhood mental health is often sparse with only a few time points measured\nand require novel methods with improved efficiency and accuracy.",
    "year": 2016,
    "url": "http://arxiv.org/abs/1612.01055v1",
    "pdf_url": "http://arxiv.org/pdf/1612.01055v1",
    "full_text": "Modeling trajectories of mental health: \nchallenges and opportunities  \n\nLauren Erdman1, Ekansh Sharma1, Eva Unternährer2, Shantala Hari Dass2, \nKieran O’Donnell2, Sara Mostafavi3, Rachel Edgar3, Michael Kobor3,  \nHélène Gaudreau4, Michael Meaney2, Anna Goldenberg1 \n1University of Toronto Department of Science,  \n2McGill University Ludmer Centre for Neuroinformatics and Mental Health,   \n3University of British Columbia Centre for Molecular Medicine and Therapeutics  \n4Douglas Mental Health University Institute \n\nAbstract \n\nMore than two thirds of mental health problems have their onset during childhood \nor  adolescence.  Identifying  children  at  risk  for  mental  illness  later  in  life  and \npredicting the type of illness is not easy. We set out to develop a platform to define \nsubtypes  of  childhood  social-emotional  development  using \nlongitudinal, \nmultifactorial trait-based measures. Subtypes discovered through this study could \nultimately advance psychiatric knowledge of the early behavioral signs of mental \nillness. To this extent we have examined two types of models: latent class mixture \nmodels and GP-based models. Our findings indicate that while GP models come \nclose in accuracy of predicting future trajectories, LCMMs predict the trajectories \nas well in a fraction of the time. Unfortunately, neither of the models are currently \naccurate enough to lead to immediate clinical impact. The available data related \nto the development of childhood mental health is  often  sparse  with only a  few \ntime points  measured and require novel  methods  with improved efficiency and \naccuracy. \n\nIn trod u cti on  \n\n1 \nMental disorders constitute the largest contributor to the global burden of disease as measured using \nthe disability-adjusted life years index [1]. The most common mental disorders, including attention \ndeficit  hyperactive  disorder  and  major  depression  show  a  peak  age  of  onset  in  childhood  and \nadolescence thus derailing the quality of life and productivity of individuals over entire lifetimes. \nBy identifying at risk children at an early age we have an opportunity to intervene and reduce the \nnegative consequences of or prevent many such mental disorders. The challenge is in effectively \nidentifying truly vulnerable children to be able to intervene in a timely manner. Current programs \nfor  identifying  at  risk  children  are  constructed  on  evidence  linking  early  life  adversity,  such  as \npoverty or birth outcomes, and the risk for mental illness. These factors predict mental illness at the \nlevel  of  the  population,  but  are  ineffective  at  the  level  of  the  individual  due  to  the  considerable \nvariability in outcomes: many children born early, small, or into poverty are healthy and productive. \n\nThe goal of this work is to identify a model, using patients’ phenotypic time series data alone, that \nwould both (i) discover underlying subtypes of individuals based on their disease trajectories as well \nas (ii) predict future phenotypic values on an individual basis. The ultimate goal is to use this model \nto inform targeted, and personalized interventions aimed at both reducing the severity of onset of \nthese  disorders  and  the  negative  outcomes  that  accompany  them,  such  as  suicide  and  substance \nabuse. The difficulty in solving this task is that the longitudinal data usually available in existing \ncohorts is very short and irregularly measured. \n\nIn the field of group-based disease trajectory modeling, there are two primary modeling directions \nstemming from the different fields of model development: those from the field of machine learning \n\n \n \n \n \n\fprimarily  employing  Gaussian  (or  some  other)  stochastic  processes  and  those  from  the  field  of \nstatistics/epidemiology  mainly  in  the  form  of  linear/non-linear  mixed  modeling  with  structured \ncovariance between time-points [2]. We use each of these two paradigms in application to identify \nsubtypes  and  predict  future  internalizing  behavior  (e.g.  fearfulness  and  social  withdrawal),  a \nphenotype  which is predictive of anxiety and depressive  disorders in adolescence and adulthood \n[3].  We used longitudinal data from the Maternal Adversity, Vulnerability and Neurodevelopment \n(MAVAN) project [4] to assess model performance. \n\n1 . 1  \n\nR e l a t e d   L i t e r a t u re  \n\nGaussian processes (GPs) have become popular for modeling time-dependent phenomena owing to \ntheir  applicability  to  modeling  a  wide  variety  of  functions  and  their  ability  to  handle  overfitting \nmore directly [5].The intuitive Gaussian output of a GP (providing both an average line of fit and a \nconfidence  bound  around  this  line)  makes  results  interpretable  and  intuitive  across  fields  and \ncomputational  expertise  [6].  GPs  have  been  successfully  developed  for  group-based  trajectory \nmodeling such as the Dirichlet Process-Gaussian Process (DP-GP) developed by Hensm"
  },
  {
    "title": "Security for People with Mental Illness in Telehealth Systems: A\n  Proposal",
    "authors": [
      "Helen Jiang"
    ],
    "abstract": "A mental health crisis is looming large, and needs to be addressed. But\nacross age groups, even just in the United States, more than 50% of people with\nany mental illness (AMI) did not seek or receive any service or treatment. The\nproliferation of telehealth and telepsychiatry tools and systems can help\naddress this crisis, but outside of traditional regulatory aspects on privacy,\ne.g. Health Insurance Portability and Accountability Act (HIPPA), there does\nnot seem to be enough attention on the security needs, concerns, or user\nexperience of people with AMI using those telehealth systems. In this text, I\ntry to explore some priority security properties for telehealth systems used by\npeople with AMI for mental heath services (MHS). I will also suggest some key\nsteps in a proposed process for designing and building security mechanisms into\nsuch systems, so that security is accessible and usable to patients with AMI,\nand these systems can achieve their goals of ameliorate this mental health\ncrisis.",
    "year": 2020,
    "url": "http://arxiv.org/abs/2008.03406v1",
    "pdf_url": "http://arxiv.org/pdf/2008.03406v1",
    "full_text": "0\n2\n0\n2\n\ng\nu\nA\n8\n\n]\n\nY\nC\n.\ns\nc\n[\n\n1\nv\n6\n0\n4\n3\n0\n.\n8\n0\n0\n2\n:\nv\ni\nX\nr\na\n\nSecurity for People with Mental Illness in Telehealth Systems: A Proposal\n\nHelen Jiang\nIndependent (afﬁliated with Georgia Institute of Technology)\n\nAbstract\n\nA mental health crisis is looming large, and needs to be ad-\ndressed. But across age groups, even just in the United States,\nmore than 50% of people with any mental illness (AMI) did\nnot seek or receive any service or treatment [49]. The prolifer-\nation of telehealth and telepsychiatry tools and systems [8,12]\ncan help address this crisis, but outside of traditional regu-\nlatory aspects on privacy, e.g. Health Insurance Portability\nand Accountability Act (HIPPA), there does not seem to be\nenough attention on the security needs, concerns, or user ex-\nperience of people with AMI using those telehealth systems.\nIn this text, I try to explore some priority security properties\nfor telehealth systems used by people with AMI for mental\nheath services (MHS). I will also suggest some key steps in a\nproposed process for designing and building security mech-\nanisms into such systems, so that security is accessible and\nusable to patients with AMI, and these systems can achieve\ntheir goals of ameliorate this mental health crisis.f\n\n1 Introduction\n\nMental health issues are prevalent around all of us, and the\nscale is staggering. Within the United States alone, in 2017,\n46.6 million adults had a mental illness, 49.5% of adolescents\nhad any mental disorder, and 10.6 million adults seriously\nconsidered suicide [1, 49]. Estimates are that 50% of mental\nillness begins by age 14, and 75% by 24, while suicide is the\nthird biggest cause of death for age group 10 – 24, among\nwhom 90% had underlying mental illness [9, 50]. Telehealth\nand telepsychiatry tools and systems have been developed\nwith the hope to help address this crisis, and while they all\nmust comply to HIPPA, there is a missing dimension: psycho-\nlogically acceptable security to people with AMI.\n\nThe “psychological acceptability” principle is identiﬁed as\n“usable” in 1975 [59], but it wasn’t until the 1990s, that “usable\nsecurity” started to get its due attention [52, 74]. Moreover,\nthe audience of “psychological acceptability” is open and\nwide: to whom, or to what audience are the security measures\n\nand mechanisms psychologically acceptable? What if the\npsychological or mental state of the audience is impaired, or\nthe audience has mental disorders?\n\nThis question is open, wide, and more importantly, tricky.\nWhile it is relatively easy to diagnose and notice cognitive im-\npairment and neurocognitive disorders as they manifest in do-\nmains such as attention, recognition, and language [28,46,57],\nthe vast majority of people with mental illness keep function-\ning in daily lives [10]. What is even trickier, is that mental\ndisorder may eventually turn to affect cognition and behav-\niors, as Diagnostic and Statistical Manual of Mental Disorders\n(DSM, latest edition DSM-5) deﬁnes a mental disorder as “...a\nsyndrome characterized by clinically signiﬁcant disturbance\nin an individual’s cognition, emotion regulation, or behav-\niors...” [11]. How might we build security into telehealth\nsystems, which would be relied upon by many with mental\nillness, who a diverse and complex, but under-served and\nusually invisible user base? This is a question worth asking\nand solving. In this work, I will propose some priority prop-\nerties of security in telehealth systems used for MHS, and\nsuggest some key steps in a process when building usable\nand secure telehealth systems for people with AMI. Here\nI will adapt [56]’s deﬁnition of telehealth, to better suit the\nMHS context. While it is still fundamentally ”the use of elec-\ntronic information and telecommunication technologies to\nsupport long-distance clinical health care etc.,” providers\nof MHS via telehealth need not to be only human — they\ncan be automated, interactive agents such as social bots, e.g.\nconversational agents (colloquially “chatbots”).\n\n2 Related Work\n\nFor security and usable security, much has been written and\nresearched. However, even though “psychological accept-\nability” to users was proposed as a key principle for secu-\nrity, it only started getting attention much later. Meanwhile,\nsecurity measures keep confusing users [2, 19, 60, 70, 74].\nMoreover, the “psychological acceptability” principle is of-\nten doubted as incompatible with the goal of “security”\n\n1\n\n \n \n \n \n \n \n\f[13, 22, 51, 54, 61, 64, 73, 74], and usable security is still a\nsmall community compared to other areas of security research.\nAlso, as [69] points out, usable security is designed with the\ngeneral population in mind, and may leave out speciﬁc vul-\nnerable groups that are under-served. This leaves us not a\ndeep foundation to work with, when we consider building\npsychologically acceptable security, for those whose mental\nstate may suffer from disorders or illness, and into systems\nthat many of them may rely on to get treatment a"
  },
  {
    "title": "Data Augmentation for Mental Health Classification on Social Media",
    "authors": [
      "Gunjan Ansari",
      "Muskan Garg",
      "Chandni Saxena"
    ],
    "abstract": "The mental disorder of online users is determined using social media posts.\nThe major challenge in this domain is to avail the ethical clearance for using\nthe user generated text on social media platforms. Academic re searchers\nidentified the problem of insufficient and unlabeled data for mental health\nclassification. To handle this issue, we have studied the effect of data\naugmentation techniques on domain specific user generated text for mental\nhealth classification. Among the existing well established data augmentation\ntechniques, we have identified Easy Data Augmentation (EDA), conditional BERT,\nand Back Translation (BT) as the potential techniques for generating additional\ntext to improve the performance of classifiers. Further, three different\nclassifiers Random Forest (RF), Support Vector Machine (SVM) and Logistic\nRegression (LR) are employed for analyzing the impact of data augmentation on\ntwo publicly available social media datasets. The experiments mental results\nshow significant improvements in classifiers performance when trained on the\naugmented data.",
    "year": 2021,
    "url": "http://arxiv.org/abs/2112.10064v1",
    "pdf_url": "http://arxiv.org/pdf/2112.10064v1",
    "full_text": "Data Augmentation for Mental Health Classiﬁcation on Social Media\n\nGunjan Ansari\nJSS Academy of Technical\nEducation, Noida, India\ngunjanansari@jssaten.ac.in\n\nMuskan Garg\nThapar Institute of\nEngineering & Technology\nPatiala, Punjab,\nIndia\nmuskanphd@gmail.com\n\nChandni Saxena\nThe Chinese University\nof Hong Kong, Shatin,\nNT, Hong Kong\ncsaxena@cse.cuhk.edu.hk\n\n1\n2\n0\n2\nc\ne\nD\n9\n1\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n4\n6\n0\n0\n1\n.\n2\n1\n1\n2\n:\nv\ni\nX\nr\na\n\nAbstract\n\nThe mental disorder of online users is deter-\nmined using social media posts. The ma-\njor challenge in this domain is to avail the\nethical clearance for using the user-generated\ntext on social media platforms. Academic re-\nsearchers identiﬁed the problem of insufﬁcient\nand unlabeled data for mental health classiﬁ-\ncation. To handle this issue, we have studied\nthe effect of data augmentation techniques on\ndomain-speciﬁc user-generated text for men-\ntal health classiﬁcation. Among the exist-\ning well-established data augmentation tech-\nniques, we have identiﬁed Easy Data Augmen-\ntation (EDA), conditional BERT, and Back-\nTranslation (BT) as the potential techniques\nfor generating additional text to improve the\nperformance of classiﬁers. Further, three dif-\nferent classiﬁers- Random Forest (RF), Sup-\nport Vector Machine (SVM) and Logistic Re-\ngression (LR) are employed for analyzing the\nimpact of data augmentation on two publicly\navailable social media datasets. The experi-\nmental results show signiﬁcant improvements\nin classiﬁers’ performance when trained on the\naugmented data.\n\n1\n\nIntroduction\n\nRecent studies over mental health classiﬁcation\n(Salari et al., 2020; Garg, 2021; Biester et al., 2021)\nconvey that amid COVID-19 pandemic, the num-\nber of stress, anxiety and depression related mental\ndisorders have increased. As per the recent survey,\nthe rate of increase of mental disorders is more\nthan those of physical health impacts on the Chi-\nnese population (Huang and Zhao, 2020). In this\ncontext, the early detection of psychological dis-\norders is very important for good governance. It\nis observed that more than 80% of the people who\ncommit suicide, disclose their intention to do so\non social media (Sawhney et al., 2021). Clinical\ndepression is the result of frequent tensions and\n\nstress. Further, prevailing clinical depression for a\nlonger time period results in suicidal tendencies.\n\nThe information mining from social media helps\nin identifying stressful and casual conversations\n(Thelwall, 2017; Turcan and McKeown, 2019; Tur-\ncan et al., 2021). Many Machine Learning (ML)\nalgorithms are developed in literature using both\nautomatic and handcrafted features for classifying\nMicroblog. The problem of data sparsity is under-\nexplored for mental health studies on social media\ndue to the sensitivity of data (Wongkoblap et al.,\n2017). Multiple ethical clearances are required for\nnew developments in mental health classiﬁcation.\nTo deal with this issue of data sparsity, we have\nused data augmentation techniques to multiply the\ntraining data (Turcan and McKeown, 2019; Haque\net al., 2021). The increase in training data may\nhelp to improve the hyper-parameter learning of\ntextual features and thereby, reducing overﬁtting.\nData Augmentation is the method of increasing the\ndata diversity without collecting more data (Feng\net al., 2021). The idea behind the use of Data\nAugmentation (DA) techniques is to understand\nthe improvements in training classiﬁers for mental\nhealth detection on social media.\n\nIn this manuscript, the mental health classiﬁ-\ncation is performed for two datasets to test the\nscalability of data augmentation approaches for\nmental healthcare domain. The classiﬁcation of ca-\nsual and stressful conversations (Turcan and McK-\neown, 2019), and classifying depression and suici-\ndal posts (Haque et al., 2021) on social media. We\nselect a rule based approach which preserves the\noriginal label and diversiﬁes the text. To the best of\nour knowledge, this is the ﬁrst attempt of stufﬁng\nadditional data for mental health classiﬁcation and\nthere is no such study in the existing literature. The\nkey contributions of this work are as follows:\n\n• To determine the feasibility and the impor-\n\n \n \n \n \n \n \n\ftance of data augmentation in the domain-\nspeciﬁc study of mental health classiﬁcation\nto solve the problem of data sparsity.\n\n• The empirical study for different classiﬁca-\ntion algorithms show signiﬁcantly improved\nF-measure.\n\nEthical Clearance: We use limited, sparse and\npublicly available dataset for this study and so, no\nethical approval is required from the Institutional\nReview Board (IRB) or elsewhere.\n\nWe organize rest of the manuscript in different\nsections. Section 2 describes the historical per-\nspective of data augmentation and mental health\nclassiﬁcation on social media. We discuss the data\naugmentation methods and the architecture for ex-\nperimental setups in Section 3. Section 4 elucidates\nthe experimental results and evaluation over the\nproposed architecture of experimental setup wh"
  },
  {
    "title": "What Are You Anxious About? Examining Subjects of Anxiety during the\n  COVID-19 Pandemic",
    "authors": [
      "Lucia L. Chen",
      "Steven R. Wilson",
      "Sophie Lohmann",
      "Daniela V. Negraia"
    ],
    "abstract": "COVID-19 poses disproportionate mental health consequences to the public\nduring different phases of the pandemic. We use a computational approach to\ncapture the specific aspects that trigger an online community's anxiety about\nthe pandemic and investigate how these aspects change over time. First, we\nidentified nine subjects of anxiety (SOAs) in a sample of Reddit posts ($N$=86)\nfrom r/COVID19\\_support using thematic analysis. Then, we quantified Reddit\nusers' anxiety by training algorithms on a manually annotated sample ($N$=793)\nto automatically label the SOAs in a larger chronological sample ($N$=6,535).\nThe nine SOAs align with items in various recently developed pandemic anxiety\nmeasurement scales. We observed that Reddit users' concerns about health risks\nremained high in the first eight months of the pandemic. These concerns\ndiminished dramatically despite the surge of cases occurring later. In general,\nusers' language disclosing the SOAs became less intense as the pandemic\nprogressed. However, worries about mental health and the future increased\nsteadily throughout the period covered in this study. People also tended to use\nmore intense language to describe mental health concerns than health risks or\ndeath concerns. Our results suggest that this online group's mental health\ncondition does not necessarily improve despite COVID-19 gradually weakening as\na health threat due to appropriate countermeasures. Our system lays the\ngroundwork for population health and epidemiology scholars to examine aspects\nthat provoke pandemic anxiety in a timely fashion.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2209.13595v1",
    "pdf_url": "http://arxiv.org/pdf/2209.13595v1",
    "full_text": "What Are You Anxious About? Examining Subjects of Anxiety during the\nCOVID-19 Pandemic\n\nLucia L. Chen,1 Steven R. Wilson, 2 Sophie Lohmann 3 Daniela V. Negraia 3,4\n1 Department of Health Policy, Stanford University, United States\n2 School of Engineering and Computer Science, Oakland University, United States\n3 Max Planck Institute for Demographic Research\n4 Department of Sociology, Oxford University, United Kingdom\nlucia.chen@stanford.edu, stevenwilson@oakland.edu, lohmann@demogr.mpg.de, negraia@demogr.mpg.de\n\nAbstract\n\nCOVID-19 poses disproportionate mental health conse-\nquences to the public during different phases of the pandemic.\nWe use a computational approach to capture the speciﬁc as-\npects that trigger an online community’s anxiety about the\npandemic and investigate how these aspects change over time.\nFirst, we identiﬁed nine subjects of anxiety (SOAs) in a sam-\nple of Reddit posts (N =86) from r/COVID19 support using\nthematic analysis. Then, we quantiﬁed Reddit users’ anxi-\nety by training algorithms on a manually annotated sample\n(N =793) to automatically label the SOAs in a larger chrono-\nlogical sample (N =6,535). The nine SOAs align with items\nin various recently developed pandemic anxiety measurement\nscales. We observed that Reddit users’ concerns about health\nrisks remained high in the ﬁrst eight months of the pan-\ndemic. These concerns diminished dramatically despite the\nsurge of cases occurring later. In general, users’ language dis-\nclosing the SOAs became less intense as the pandemic pro-\ngressed. However, worries about mental health and the future\nincreased steadily throughout the period covered in this study.\nPeople also tended to use more intense language to describe\nmental health concerns than health risks or death concerns.\nOur results suggest that this online group’s mental health con-\ndition does not necessarily improve despite COVID-19 grad-\nually weakening as a health threat due to appropriate coun-\ntermeasures. Our system lays the groundwork for popula-\ntion health and epidemiology scholars to examine aspects that\nprovoke pandemic anxiety in a timely fashion.\n\nIntroduction\nThe novel Coronavirus Disease (COVID-19) pandemic has\ncreated a global crisis. Unlike other recent pandemics (e.g.,\nH1N1 or type-A inﬂuenza), the COVID-19 pandemic has re-\nsulted in strict and extensive lockdown measures for large\nswathes of the global population, such as complete lock-\ndowns, 14-day quarantine periods, closing of national bor-\nders, and disruption of international travel. A series of life\ninterruptions resulting from the COVID-19 pandemic are re-\nlated to heightened anxiety and depression in many people\n(Smith et al. 2020). In a 2020 study, over 80% of respon-\ndents reported that their day-to-day thoughts were occupied\nby topics related to the COVID-19 pandemic (Roy et al.\n\nCopyright © 2021, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\n\n2020). Sleep difﬁculties, extreme anxiety about becoming\ninfected with COVID-19, and distress caused by informa-\ntion from social media were reported by 12.5%, 37.8%, and\n36.4% of participants, respectively (Roy et al. 2020).\n\nAnxiety is conceptualized as a multi-system response to\nperceived risks, experienced as a feeling of unease, worry,\nor fear (Wilkinson 2001). Experiencing occasional anxiety\nabout a situation is a normal part of life. However, prolonged\nor frequent anxiety may lead to general anxiety disorders,\nheightened depressive symptoms, reduction of sleep quality\n(Huang and Zhao 2020), and other mental health risks. Psy-\nchological studies often use scales to assess levels of anx-\niety. Studies that examine COVID-19 anxiety mainly fall\ninto two categories: those that treat anxiety as a clinical en-\ntity with a focus on the symptoms (Ahorsu et al. 2020) and\nthose that examine the speciﬁc aspects of the pandemic that\ntrigger anxiety (McElroy et al. 2020; Taylor et al. 2020). Al-\nthough methodologies that use a survey approach with scale\nmeasurements can provide detailed descriptions of individ-\nual respondents, their implementation is expensive and time-\nconsuming.\n\nIn an effort to collect data in a timely and cost-effective\nmanner, researchers have been exploring avenues to approx-\nimate the anxiety of the public using proxy signals in social\nmedia records (Guntuku et al. 2019). Our study does not aim\nto replace the measurement using scales because some of the\nbehavioral, affective, and cognitive characteristics measured\nwith their items may rarely be reﬂected in the social me-\ndia text. Rather, our automatic system may provide a proxy\nvalue for the scientiﬁc and public health community to un-\nderstand better how the public responds to large-scale health\nthreats promptly.\n\nOur objective is to use data from Reddit to understand the\naspects that provoke people’s anxiety during early phases\nof the pandemic and how these aspects have changed as\nthe pandemic has developed. Reddit is an online platform\nin "
  },
  {
    "title": "Managing mental & psychological wellbeing amidst COVID-19 pandemic:\n  Positive psychology interventions",
    "authors": [
      "Maria Tresita Paul V.",
      "N. Uma Devi"
    ],
    "abstract": "COVID-19 pandemic has shaken the roots of healthcare facilities worldwide,\nwith the US being one of the most affected countries irrespective of being a\nsuperpower. Along with the current pandemic, COVID-19 can cause a secondary\ncrisis of mental health pandemic if left unignored. Various studies from past\nepidemics, financial turmoil and pandemic, especially SARS and MERS, have shown\na steep increase in mental and psychological issues like depression, low\nquality of life, self-harm and suicidal tendencies among general populations.\nThe most venerable being the individuals infected and cured due to social\ndiscrimination. The government is taking steps to contain and prevent further\ninfections of COVID-19. However, the mental and psychological wellbeing of\npeople is still left ignored in developing countries like India. There is a\nsignificant gap in India concerning mental and psychological health still being\nstigmatized and considered 'non-existent'. This study's effort is to highlight\nthe importance of mental and psychological health and to suggest interventions\nbased on positive psychology literature. These interventions can support the\nwellbeing of people acting as a psychological first aid. Keywords: COVID-19,\nCoronavirus, Pandemic, Mental wellbeing, Psychological Wellbeing, Positive\nPsychology Interventions.\n  KEYWORDS - COVID-19, Coronavirus, Pandemic, Wellbeing, Positive Psychology,\nInterventions, PPI.",
    "year": 2021,
    "url": "http://arxiv.org/abs/2104.11726v3",
    "pdf_url": "http://arxiv.org/pdf/2104.11726v3",
    "full_text": "THE American Journal of Humanities and Social Sciences Research (THE \nAJHSSR) \n\n2021 \n\nE-ISSN: 2581-8868 \nVolume-04, Issue-03, pp-121-131 \nwww.theajhssr.com \nResearch Paper                                                                                                                      Open Access \n\nManaging mental & psychological wellbeing amidst COVID-19 \npandemic: Positive psychology interventions \n\nMaria Tresita Paul V.1\n\n & Uma Devi N.2 \n\n1 & 2 Bharathiar School of Management and Entrepreneur Development  \n(BSMED), Bharathiar University, Tamil Nadu, India. \nmaria.tresi@gmail.com \n\nABSTRACT \n\nCOVID‐19 pandemic has shaken the roots of healthcare facilities worldwide, with the US being one of the most \naffected countries irrespective of being a superpower. Along with the current pandemic, COVID-19 can cause a \nsecondary  crisis  of  mental  health  pandemic  if  left  unignored.  Various  studies  from  past  epidemics,  financial \nturmoil and pandemic, especially SARS and MERS, have shown a steep increase in mental and psychological \nissues like depression, low quality of life, self-harm and suicidal tendencies among general populations. The most \nvenerable being the individuals infected and cured due to social discrimination. The government is taking steps \nto  contain  and  prevent  further  infections  of  COVID  19.  However,  the  mental  and  psychological  wellbeing  of \npeople is still left ignored in developing countries like India. There is a significant gap in India concerning mental \nand psychological health still being stigmatized and considered 'non-existent'. This study's effort is to highlight \nthe importance of mental and psychological health and to suggest interventions based on positive psychology \nliterature. These interventions can support the wellbeing of people acting as a psychological first aid. \n\nKEYWORDS  - COVID-19, Coronavirus, Pandemic, Wellbeing, Positive Psychology, Interventions, PPI. \n\nI. \n\nINTRODUCTION \n\nChina reported the first documented case of newly identified chronic respiratory illness COVID-19, on December \n16th, 2019, in Wuhan province. Unaware of the upcoming global catastrophe, by this time, the rest of the world \nwas in a celebration mode preparing for the new year 2020. Diseased doctor 'Li Wenliang' was the whistleblower, \nwho  alerted  about  this  suspicious  new  disease  novel  coronavirus  -  COVID-19  via  social  media.  The  Chinese \ngovernment's numerous attempts to suppress this caught the attention of international media. By late December \nand  early  January  of  2020,    reports  of  confirmed  cases  of  COVID  19  diseases  spreading  outside  of  China  to \ncountries like Americal, Italy, England & India, came to light affirming the human to human transition. With the \nglobal  news  covering  COVID-19,  came  enormous  pieces  of  information  causing  anxiety,  distress  and  fear \nworldwide among people, of this unknown new disease infecting and killing thousands worldwide (Wang et al. \n2020), especially the vulnerable and elderly (Centers for Disease Control and Prevention 2020). By January 2020, \nthe World Health Organisation (WHO) announced COVID-19 epidemic outbreak, a public health emergency of \ninternational significance, and reported a high risk of COVID-19 spreading to other countries around the world. \nThe COVID-19 virus is a zoonotic infection thought to have originated from pangolins, snakes and bats in wet \nmarkets of Wuhan (Ji et al. 2020). By January 2020 WHO confirmed the human-to-human transition of COVID \n19. In March 2020, the WHO assessed and declared coronavirus as a pandemic. Between March to June 2020, \nthere is an exponential growth of coronavirus disease infected victims. Pandemic related containment measures \nworldwide as recommended by WHO are 'quarantine, social distancing, and self-isolation'.  \n\nRecent  research  has  shown  that  a  long  period  of  'quarantine,  social  distancing,  and  self-isolation'  in  already \nuncertain situations like pandemic can harm mental and psychological wellbeing globally (Brooks et al., 2020; \nDubey et al., 2020; Qui et al., 2020). The need  of mental wellbeing and stress coping of medical practitioners has \nbecome crucial area of study (Paul et al., 2021). Positive psychology has proven to heal and enhance the mental \nand psychological wellbeing of individuals (Seligman 2004; Seligman and Csikszentmihalyi  2014; Slade 2010; \nVázquez et al., 2009).  \nPositive psychology is explained as the scientific study of \"what makes life most worth living\" (Peterson, 2008), \nfocusing on a) positive experiences, (e.g. joy, happiness, life satisfaction, inspiration and love); b) positive traits \n\nT H E A J H S S R   J o u r n a l                                 P a g e  | 121 \n\n \n \n \n \n \n \n \n \n \n \n \n \n\fManaging mental & psychological wellbeing … \n\nand states (e.g. resilience, optimism, gratitude, hope, efficacy and compassion); c) positive institutions (applying \npositive principles with"
  },
  {
    "title": "Chatbots for Mental Health Support: Exploring the Impact of Emohaa on\n  Reducing Mental Distress in China",
    "authors": [
      "Sahand Sabour",
      "Wen Zhang",
      "Xiyao Xiao",
      "Yuwei Zhang",
      "Yinhe Zheng",
      "Jiaxin Wen",
      "Jialu Zhao",
      "Minlie Huang"
    ],
    "abstract": "The growing demand for mental health support has highlighted the importance\nof conversational agents as human supporters worldwide and in China. These\nagents could increase availability and reduce the relative costs of mental\nhealth support. The provided support can be divided into two main types:\ncognitive and emotional support. Existing work on this topic mainly focuses on\nconstructing agents that adopt Cognitive Behavioral Therapy (CBT) principles.\nSuch agents operate based on pre-defined templates and exercises to provide\ncognitive support. However, research on emotional support using such agents is\nlimited. In addition, most of the constructed agents operate in English,\nhighlighting the importance of conducting such studies in China. In this study,\nwe analyze the effectiveness of Emohaa in reducing symptoms of mental distress.\nEmohaa is a conversational agent that provides cognitive support through\nCBT-based exercises and guided conversations. It also emotionally supports\nusers by enabling them to vent their desired emotional problems. The study\nincluded 134 participants, split into three groups: Emohaa (CBT-based), Emohaa\n(Full), and control. Experimental results demonstrated that compared to the\ncontrol group, participants who used Emohaa experienced considerably more\nsignificant improvements in symptoms of mental distress. We also found that\nadding the emotional support agent had a complementary effect on such\nimprovements, mainly depression and insomnia. Based on the obtained results and\nparticipants' satisfaction with the platform, we concluded that Emohaa is a\npractical and effective tool for reducing mental distress.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2209.10183v1",
    "pdf_url": "http://arxiv.org/pdf/2209.10183v1",
    "full_text": "Highlights\n\nChatbots for Mental Health Support: Exploring the Impact of Emohaa on Reducing Mental\nDistress in China\nSahand Sabour,Wen Zhang,Xiyao Xiao,Yuwei Zhang,Yinhe Zheng,Jiaxin Wen,Jialu Zhao,Minlie Huang\n\n• This study analyzes the eﬀectiveness, acceptability, and practicality of Emohaa, a Chinese conversational agent\n\nfor mental health support, in reducing mental health distress.\n\n• Emohaa provides template-based intervention based on Cognitive Behavioral Therapy (CBT) principles. It also\nprovides emotional support by allowing users to discuss their desired topic freely and vent about their problems.\n\n• Experimental results demonstrate that using Emohaa signiﬁcantly reduces symptoms of mental distress, namely\n\ndepression, anxiety, insomnia, and negative aﬀect.\n\n• Our ﬁndings suggest that allowing participants to have open conversations with the agent and receiving emotional\n\nsupport has a complementary eﬀect on the improvements.\n\n• Based on the results, we conclude that Emohaa is a feasible and eﬀective tool for reducing mental distress.\n\n2\n2\n0\n2\n\np\ne\nS\n1\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n3\n8\n1\n0\n1\n.\n9\n0\n2\n2\n:\nv\ni\nX\nr\na\n\n \n \n \n \n \n \n\fChatbots for Mental Health Support: Exploring the Impact of\nEmohaa on Reducing Mental Distress in China⋆\n\nSahand Saboura, Wen Zhangb, Xiyao Xiaoc, Yuwei Zhangc, Yinhe Zhengc, Jiaxin Wena,\nJialu Zhaod,∗ and Minlie Huanga,c,∗\n\naThe CoAI Group, DCST, Institute for Artiﬁcial Intelligence, State Key Lab of Intelligent Technology and Systems, Beijing National Research\nCenter for Information Science and Technology, Tsinghua University, Beijing 100084, China\nbDepartment of Psychology, Beijing Normal University, Beijing 100875, China\ncBeijing Lingxin Intelligent Technology CO., Ltd,, Block D, Yousheng Building, Haidian District, Beijing 100083, China\ndCenter for Counseling and Psychological Development Guidance Center, Tsinghua University, Beijing 100084, China\n\nA R T I C L E I N F O\n\nA B S T R A C T\n\nKeywords:\nChatbot\nEmotional Support\nArtiﬁcial Intelligence\nConversational Agent\nMental Health Support\nCognitive Behavioral Therapy\n\nThe growing demand for mental health support has highlighted the importance of conversational\nagents as human supporters worldwide and in China. These agents could increase availability\nand reduce the relative costs of mental health support. The provided support can be divided into\ntwo main types: cognitive and emotional support. Existing work on this topic mainly focuses\non constructing agents that adopt Cognitive Behavioral Therapy (CBT) principles. Such agents\noperate based on pre-deﬁned templates and exercises to provide cognitive support. However,\nresearch on emotional support using such agents is limited. In addition, most of the constructed\nagents operate in English, highlighting the importance of conducting such studies in China. In\nthis study, we analyze the eﬀectiveness of Emohaa in reducing symptoms of mental distress.\nEmohaa is a conversational agent that provides cognitive support through CBT-based exercises\nand guided conversations. It also emotionally supports users by enabling them to vent their\ndesired emotional problems. The study included 134 participants, split into three groups: Emohaa\n(CBT-based), Emohaa (Full), and control. Experimental results demonstrated that compared to\nthe control group, participants who used Emohaa experienced considerably more signiﬁcant\nimprovements in symptoms of mental distress. We also found that adding the emotional support\nagent had a complementary eﬀect on such improvements, mainly depression and insomnia.\nBased on the obtained results and participants’ satisfaction with the platform, we concluded\nthat Emohaa is a practical and eﬀective tool for reducing mental distress.\n\n1. Introduction\n\nMental health is a prevalent issue in the modern world due to the increasing morbidity of mental diseases\n(WHO, 2022). During the COVID-19 pandemic, depression, anxiety, and other mental health issues have increased\nsigniﬁcantly (Lakhan et al., 2020). Speciﬁcally, a review by Lakhan et al. (2020) highlighted a 20% and 35% rise in\ndepression and anxiety, respectively, for 113,285 individuals across 16 studies. Additionally, an international study\nwith a sample of 22,330 adults showed that about 17.4% of the participants met the criteria for a probable insomnia\ndisorder (Taylor et al., 2011). These mental health issues impact people’s daily lives, leading to social dysfunction\nand risks of self-harm and suicide (Hanna and Strober, 2020). Due to the rapidly increasing demands, mental health\nservices worldwide face challenges regarding lack of professional training and stigmatization of mental illness. These\nchallenges can lead to low diagnosis accuracy and patient treatment delays (Lakhan et al., 2020).\n\nSimilarly, the prevalence of mental health diseases in China is increasing. According to the epidemiological survey\nof mental disorders in China, the lifetime prevalence rate of mental disorders in adults, excluding senile dementia"
  },
  {
    "title": "Supporting Therapeutic Relationships and Communication about Mental\n  Health",
    "authors": [
      "David Coyle",
      "Gavin Doherty"
    ],
    "abstract": "Effective communication and strong therapeutic relationships are critical to\nsuccessful mental health interventions. For example, in 1957 Carl Rogers, a\npioneer of person-centred therapy, proposed that an empowering relationship\ncould, in and of itself, create the necessary and sufficient conditions for\npositive therapeutic outcomes [1]. Whilst modern psychological theories no\nlonger favour an exclusive focus on relationships, positive relationships and\nthe dynamics of client-therapist communication remain cornerstones of mental\nhealth intervention theories. A more recent meta-review concluded that across\nall interventions models, irrespective of the theoretical approach, the quality\nof the relationship between therapists and clients is the second leading\ndeterminant of successful clinical outcomes [2]. Over the past ten years we\n(David Coyle and Gavin Doherty) have designed and evaluated a wide range to\nsystems that provide support for psychological (or talk- based) mental health\ninterventions [3]. Here we briefly consider two recent examples. In each case\nour aim was to enhance communication and reshape clinical practice in a manner\nthat empowers patients. gNats Island is a computer game that supports\nface-to-face interventions for adolescents [4]. MindBalance is an online\ntreatment programme for adults experiencing difficulties with depression [5].",
    "year": 2013,
    "url": "http://arxiv.org/abs/1307.3164v1",
    "pdf_url": "http://arxiv.org/pdf/1307.3164v1",
    "full_text": "Supporting Therapeutic Relationships and \nCommunication about Mental Health\n\nDavid Coyle \n\nGavin Doherty \n\nInteraction and Graphics Group, \n\nSchool of Computer Science      \n\nDept. of Computer Science, \n\nand Statistics, \n\nUniversity of Bristol, \n\nBristol BS8 1UB, UK \n\nTrinity College Dublin, \n\nCollege Green,  \n\ndavid.coyle@bristol.ac.uk  \n\nDublin 2, Ireland \n\ngavin.doherty@cs.tcd.ie  \n\nKeywords \nMental health; client-therapist relationships; \ncommunication; face-to-face and remote interventions \n\nACM Classification Keywords \nH.5.m [Information Interfaces and Presentation]: Miscellaneous – \n\ninterdisciplinary design, mental health \n\nCopyright is held by the author/owner(s).  \nACM CHI 2013 April 28, 2013, Paris, France.  \n\nIntroduction and background \nEffective communication and strong therapeutic \nrelationships are critical to successful mental health \ninterventions. For example, in 1957 Carl Rogers, a \npioneer of person-centred therapy, proposed that an \nempowering relationship could, in and of itself, create \n“the necessary and sufficient conditions” for positive \ntherapeutic outcomes [1]. Whilst modern psychological \ntheories no longer favour an exclusive focus on \nrelationships, positive relationships and the dynamics of \nclient-therapist communication remain cornerstones of \nmental health intervention theories. A more recent \nmeta-review concluded that across all interventions \nmodels, irrespective of the theoretical approach, the \nquality of the relationship between therapists and \nclients is the second leading determinant of successful \nclinical outcomes [2]. \n\nOver the past ten years we (David Coyle and Gavin \nDoherty) have designed and evaluated a wide range to \nsystems that provide support for psychological (or talk-\nbased) mental health interventions [3]. Here we briefly \nconsider two recent examples. In each case our aim \nwas to enhance communication and reshape clinical \npractice in a manner that empowers patients. gNats \nIsland is a computer game that supports face-to-face \ninterventions for adolescents [4]. MindBalance is an \nonline treatment programme for adults experiencing \ndifficulties with depression [5]. \n\n \n \n \n \n \n \n \n \n \n \n \n \n \n\fFace-to-face communication: gNats Island \nAdolescents experiencing mental health difficulties \noften react confrontationally, or not at all, to direct \nconversations with a therapist. When therapists work \nwith younger children, play therapy often provides an \neffective way of engaging, indirectly, in therapeutic \nprocesses. However adolescents can also react \nnegatively to traditional play therapy if they feel they \nare being treated as children. \n\ngNats Island is a desktop computer game that aims to \naddress this imbalance. It implements key aspects of \nCognitive Behavioural Therapy (CBT) and provides an \nage appropriate, face-to-face intervention for \nadolescents aged 10-15. The game provides an overall \nnarrative in which players visit a tropical island and \nmeet a team of wild life explorers. Characters introduce \nmental health concepts using spoken conversation, \nanimations, videos and questions regarding the player’s \nown situation. Concrete metaphors are used to explain \nabstract CBT concepts. For example negative automatic \nthoughts, a key concept in CBT, are presented as little \ncreatures called gNats that can sting people, causing \nnegative thinking. Through a series of in-game \nconversations players learn new strategies for \nidentifying and challenging negative thoughts. \nMetaphors such as catching, trapping and swatting \ngNats are used to describe this process. \n\nIn sessions a therapist and adolescent sit together at a \ncomputer. Rather than talking face-to-face with the \nadolescent, the therapist acts as a partner in their \nexploration of the game world. As such gNats Island \nrepresents a substantial reshaping of the traditional \ntherapeutic interaction. It was intended that \nconversations with game characters would provide a \ncontext for more detailed conversations between the \n\nadolescent and therapist. Further, it was predicted that \nthe game would help to reduce the difficulties many \nadolescents experience with face-to-face interventions \nand assist in creating a client-centred, fun and \nexperiential process. \n\nTherapists who used gNats Island with adolescents \nwere very positive about the way in which the game \nchanged the dynamics of the therapeutic interaction. \nThey highlighted both specific factors (e.g. eye contact) \nand the general role of the game as a mediating factor: \n\n“I thought it was really good from an eye contact point \nof view, he doesn’t like making a lot of eye contact, so \nhaving the screen to focus in on was perfect.”  \n\n“It was almost like a transitional object or an external \nkind of mediating factor, so that I suppose the sessions \nwere less directed, less challenging ... so the child \nfound it easier to engage through the medium of the \ngame.” \n\nClinicians also felt the game had a beneficial impact on \nthe client-th"
  },
  {
    "title": "Heart rate and its variability as an indicator of mental health in male\n  prisoners",
    "authors": [
      "Christian Gold",
      "Jörg Assmus"
    ],
    "abstract": "Heart rate (HR) and its variability (HRV) has been proposed as a marker for\ndepressive symptoms and other aspects of mental health. However, the real\ncorrelation between them is presently uncertain, as previous studies have\ngenerally been conducted on the basis of small samples. In a sample of 113\nadult male prisoners, we analyzed correlations between five measures of HR/HRV\nand five psychological measures of mental health aspects (depression, state and\ntrait anxiety, and social relationships). We used Nadaraya-Watson\nnon-parametric regression in both directions and age-stratified Spearman\ncorrelation to detect possible relations. Despite strong correlations among\nHR/HRV measures and among psychological measures, correlations between HR/HRV\nand psychological measures were low and non-significant for the overall sample.\nHowever, we found an age dependency, suggesting some correlations in younger\npeople (HR with STAI-State, r = 0.39; with HADS-Anxiety, r = 0.52; both p <\n.005). Overall, the general utility of HR/HRV as a marker for mental health\nacross populations remains unclear. Future research should address age and\nother potential confounders more consistently.",
    "year": 2015,
    "url": "http://arxiv.org/abs/1501.05842v1",
    "pdf_url": "http://arxiv.org/pdf/1501.05842v1",
    "full_text": "Heart rate and its variability as an indicator of mental health in \nmale prisoners \n\nHRV and mental health \n\nChristian Gold1,2, Jörg Assmus1,3 \n1 GAMUT, Uni Research Health, Uni Research, Bergen, Norway \n2 Grieg Academy Department of Music, University of Bergen, Norway \n3 Centre for Clinical Research, Haukeland University Hospital, Bergen, Norway \n\nCorrespondence \nChristian Gold \nGAMUT – The Grieg Academy Music Therapy Research Centre \nUni Research Health \nUni Research \nLars Hilles gt. 3 \n5015 Bergen \nNorway \nPhone +47-97501757 \nEmail: christian.gold@uni.no \n\nAbstract \nHeart rate (HR) and its variability (HRV) has been proposed as a marker for depressive \nsymptoms and other aspects of mental health. However, the real correlation between them is \npresently uncertain, as previous studies have generally been conducted on the basis of small \nsamples. In a sample of 113 adult male prisoners, we analyzed correlations between five \nmeasures of HR/HRV and five psychological measures of mental health aspects (depression, \nstate and trait anxiety, and social relationships). We used Nadaraya-Watson non-parametric \nregression in both directions and age-stratified Spearman correlation to detect possible \nrelations. Despite strong correlations among HR/HRV measures and among psychological \nmeasures, correlations between HR/HRV and psychological measures were low and non-\nsignificant for the overall sample. However, we found an age dependency, suggesting some \ncorrelations in younger people (HR with STAI-State, r = 0.39; with HADS-Anxiety, r = 0.52; \nboth p < .005). Overall, the general utility of HR/HRV as a marker for mental health across \npopulations remains unclear. Future research should address age and other potential \nconfounders more consistently.  \n\nKeywords \nbiomarkers, surrogate endpoints, clinical endpoints, depression, anxiety, social relationships, \nheart rate variability, confounding, age \n\ni. Introduction \nIn evidence-based mental health care, it is important, but not always straightforward, to \nchoose the best measures to assess outcomes. Already selecting the right domain can be \nchallenging – for example, one has to choose between ‘positive’ or ‘negative’ outcome \ndomains (e.g., symptoms or functioning), and between proximal (direct) or distal \n(downstream) outcomes, all to reflect best what the intervention can do and what clients and \nproviders need or request (1). In addition, choosing the right data source for a given domain is \nmore than a technicality. A relatively recent challenge in this context is the choice between \ntraditional psychological assessments (i.e., either self-report or assessor-based, often using \n\n1 \n\n \n \n \n \n \n \n \n \n\fHRV and mental health \n\nquestionnaires) versus newer neurophysiological measures. Neurophysiological assessments \nrely on technological tools for measuring some indicator of brain activity. If successful, such \nmeasures may provide a more objective basis for judging someone’s mental health, as they \nare less susceptible to purposeful distortions and biases than traditional psychological \nassessments. In addition, they might also help to understand links between mental and somatic \nprocesses. However, in contrast to questionnaire-based methods, physiological indicators are \nusually ‘found’ rather than developed for the purpose. They are therefore reflective of a \nvariety of factors, including many that may be unrelated to the domain of interest and that will \ncomplicate the use of these measures by acting as noise or confounding variables (2). For \nexample, a recent study showed almost no correlation between encephalographic markers for \ndepression/anxiety and psychological assessments of these domains (3). However, many \nrecent studies have used or suggested physiological indicators of mental health as outcomes, \neither alongside or instead of psychological assessments (4-11). \n\nHeart rate variability (HRV) is one such marker. As a potential biomarker, it is “important not \nso much for what it tells us about the state of the heart as much as it is important for what it \ntells us about the state of the brain” (12). HRV is influenced by various influences from the \nbrain, including both the sympathetic as well as the parasympathetic nervous system. Simply \nput, sympathetic input increases the heart rate (in response to stressors, to facilitate ‘fight or \nflight’ behaviors), and parasympathetic input decreases it (to enable relaxation, to facilitate \n‘rest and digest’ behaviors). High HRV might therefore indicate that both systems work well \nand are in balance; the individual is able to respond and adapt to stressful situations as well as \nto relax. HRV has therefore been suggested as a potential biomarker for numerous aspects of \nmental health: It could be a “marker of stress and health” (12), or of “stress and resilience” (p. \n751). It has also been suggested to reflect the “link between emotional states and dispositions \nsuch as depression, anxiety, anger and hostil"
  },
  {
    "title": "Explainable Multi-class Classification of the CAMH COVID-19 Mental\n  Health Data",
    "authors": [
      "YuanZheng Hu",
      "Marina Sokolova"
    ],
    "abstract": "Application of Machine Learning algorithms to the medical domain is an\nemerging trend that helps to advance medical knowledge. At the same time, there\nis a significant a lack of explainable studies that promote informed,\ntransparent, and interpretable use of Machine Learning algorithms. In this\npaper, we present explainable multi-class classification of the Covid-19 mental\nhealth data. In Machine Learning study, we aim to find the potential factors to\ninfluence a personal mental health during the Covid-19 pandemic. We found that\nRandom Forest (RF) and Gradient Boosting (GB) have scored the highest accuracy\nof 68.08% and 68.19% respectively, with LIME prediction accuracy 65.5% for RF\nand 61.8% for GB. We then compare a Post-hoc system (Local Interpretable\nModel-Agnostic Explanations, or LIME) and an Ante-hoc system (Gini Importance)\nin their ability to explain the obtained Machine Learning results. To the best\nof these authors knowledge, our study is the first explainable Machine Learning\nstudy of the mental health data collected during Covid-19 pandemics.",
    "year": 2021,
    "url": "http://arxiv.org/abs/2105.13430v1",
    "pdf_url": "http://arxiv.org/pdf/2105.13430v1",
    "full_text": "Explainable Multi-class Classification of  \nthe CAMH COVID-19 Mental Health Data  \n\nYuanZheng Hu \nEECS, University of Ottawa \n\nbhu078@uottawa.ca \n\nMarina Sokolova \nIBDA@Dalhousie University and  \nUniversity of Ottawa \nsokolova@uottawa.ca \n\nAbstract  \nApplication of Machine Learning algorithms to the medical domain is an emerging trend that helps to \nadvance medical knowledge.  At the same time, there is a significant a lack of explainable studies that \npromote informed, transparent, and interpretable use of Machine Learning algorithms.   In this paper, \nwe present explainable multi-class classification of the Covid-19 mental health data.  In Machine \nLearning study, we aim to find the potential factors to influence a person’s mental health during the \nCovid-19 pandemic. We found that Random Forest (RF) and Gradient Boosting (GB) have scored the \nhighest accuracy of 68.08% and 68.19% respectively, with LIME prediction accuracy 65.5% for RF and \n61.8% for GB.  We then compare a Post-hoc system (Local Interpretable Model-Agnostic Explanations, or \nLIME) and an Ante-hoc system (Gini Importance) in their ability to explain the obtained Machine \nLearning results.  To the best of these authors’ knowledge, our study is the first explainable Machine \nLearning study of the mental health data collected during Covid-19 pandemics. \n\nIntroduction  \nMachine Learning algorithms applied to the medical domain is an emerging trend that helps to advance \nmedical studies.  Machine Learning (ML) and Deep Learning (DL) algorithms are often deployed to \nanalyse large and diverse data sets when a timely response is essential. Classifications of medical images \nin respect to the COVID-19 diagnosis (Mohamadou et al, 2020), the Covid-19 forecasting model by \nGoogle Cloud and Harvard Global Health Institute help the frontline medicine.  At the same time, \nreported classification accuracy and predicted infections, hospitalizations, expected deaths tell only a \npart of the story if the studies use a black box approach where the algorithms’ internal factors are \ntreated as either unknown or beyond interpretation.   The black box approach impends successful \nimplementation and reproducibility of ML and DL studies that depend on a detailed and systematic \nanalysis of the models, learning functions involved, meta-parameter influence on the obtained results, \namong others. \n\nIn this work, we demonstrate how post-hoc and ante-hoc explanations enrich ML studies.  Multi-class \nclassification of the Covid-19 Mental Health National Survey1 data serves as the ML base of our work.   \nThe dataset is extracted from a series of six surveys conducted in Canada during May – December 2020. \nThe surveys aimed to investigate mental health during the pandemic in Canada.    Our goal is to find out \nthe potential factors to influence a person’s mental health during the Covid-19 pandemic. \n\n1 https://www.camh.ca/en/health-info/mental-health-and-covid-19/covid-19-national-survey \n\n1 \n\n \n \n \n \n\fWe classify the surveys’ participants into one of the six categories, where each category corresponds to \na survey.  The survey questions are the data features; the participant answers are feature values.  We \nuse six algorithms (Gradient Boosting, Random Forest, Decision Tree, SVM, Logistic Regression, Naïve \nBayes).   We apply a post-hoc system LIME (Holzinger et al, 2017) to explain the predictions of the six \nMachine Learning algorithms. After we train our dataset using the six models (Gradient Boosting, \nRandom Forest, Decision Tree, SVM, Logistic Regression, Naïve Bayes), we use an ante-hoc system Gini \nImportance to analyze two Machine Learning models that achieve the best results (Gradient Boosting ad \nRandom Forest).    \n\nWe present a comprehensive analysis of the LIME prediction accuracy for Random Forest and Gradient \nBoosting and compute LIME probability estimates for the top most predictions for the six ML classifiers. \nWe compare LIME and Gini Importance results by using the explainability fact sheet (Sokol and Flach, \n2020). The fact sheet lists functional requirements, operational requirements, usability, safety, and \nvalidation as key aspects of explainability. We show that LIME and Gini Importance are similar in \noperational requirements and differ in functional requirements. \n\nOur explanation results show that consumption of alcohol and use of cannabis have a strong positive \nimpact on determining the periods of the pandemic.  This result helps to get insights into the general \npublic’s mental health during the Covid-19.  At the same time, it delivers an important information to \ndecision makers about usage of the recreational drugs in times of crises.  \n\nTo the best of these authors’ knowledge, our study is the first explainable Machine Learning study of \nmental health data collected during Covid-19 pandemics.   Our study fills the void in post-hoc and ante-\nhoc explanations of multi-class classification of mental health data and comparison of post-hoc "
  },
  {
    "title": "Alexa Depression and Anxiety Self-tests: A Preliminary Analysis of User\n  Experience and Trust",
    "authors": [
      "Juan C. Quiroz",
      "Tristan Bongolan",
      "Kiran Ijaz"
    ],
    "abstract": "Mental health resources available via websites and mobile apps provide\nsupport such as advice, journaling, and elements from cognitive behavioral\ntherapy. The proliferation of spoken conversational agents, such as Alexa,\nSiri, and Google Home, has led to an increasing interest in developing mental\nhealth apps for these devices. We present the pilot study outcomes of an Alexa\nSkill that allows users to conduct depression and anxiety self-tests. Ten\nparticipants were given access to the Alexa Skill for two-weeks, followed by an\nonline evaluation of the Skill's usability and trust. Our preliminary\nevaluation suggests that participants trusted the Skill and scored the\nusability and user experience as average. Usage of the Skill was low, with most\nparticipants using the Skill only once. In view of work-in-progress, we also\npresent a discussion of implementation and study design challenges to guide the\ncurrent literature on designing spoken conversational agents for mental health\napplications.",
    "year": 2020,
    "url": "http://arxiv.org/abs/2008.03892v1",
    "pdf_url": "http://arxiv.org/pdf/2008.03892v1",
    "full_text": "0\n2\n0\n2\n\ng\nu\nA\n0\n1\n\n]\n\nC\nH\n.\ns\nc\n[\n\n1\nv\n2\n9\n8\n3\n0\n.\n8\n0\n0\n2\n:\nv\ni\nX\nr\na\n\nAlexa Depression and Anxiety Self-tests: A Preliminary Analysis\nof User Experience and Trust\n\nJuan C. Quiroz\nCentre for Big Data Research in\nHealth, UNSW\nAustralian Institute of Health\nInnovation, Macquarie University\nSydney, Australia\njuan.quiroz@unsw.edu.au\n\nTristan Bongolan\nMacquarie University\nSydney, Australia\ntbongolan@hotmail.com\n\nKiran Ijaz\nAustralian Institute of Health\nInnovation, Macquarie University\nSydney, Australia\nkiran.ijaz@mq.edu.au\n\nABSTRACT\nMental health resources available via websites and mobile apps\nprovide support such as advice, journaling, and elements from\ncognitive behavioral therapy. The proliferation of spoken conver-\nsational agents, such as Alexa, Siri, and Google Home, has led to\nan increasing interest in developing mental health apps for these\ndevices. We present the pilot study outcomes of an Alexa Skill\nthat allows users to conduct depression and anxiety self-tests. Ten\nparticipants were given access to the Alexa Skill for two-weeks,\nfollowed by an online evaluation of the Skill’s usability and trust.\nOur preliminary evaluation suggests that participants trusted the\nSkill and scored the usability and user experience as average. Usage\nof the Skill was low, with most participants using the Skill only\nonce. In view of work-in-progress, we also present a discussion of\nimplementation and study design challenges to guide the current\nliterature on designing spoken conversational agents for mental\nhealth applications.\n\nCCS CONCEPTS\n• Human-centered computing → Sound-based input / out-\nput.\n\nKEYWORDS\nmental health, conversational agent, depression, anxiety, Alexa\n\nACM Reference Format:\nJuan C. Quiroz, Tristan Bongolan, and Kiran Ijaz. 2020. Alexa Depression\nand Anxiety Self-tests: A Preliminary Analysis of User Experience and Trust.\nIn Adjunct Proceedings of the 2020 ACM International Joint Conference on\nPervasive and Ubiquitous Computing and Proceedings of the 2020 ACM Inter-\nnational Symposium on Wearable Computers (UbiComp/ISWC ’20 Adjunct),\nSeptember 12–16, 2020, Virtual Event, Mexico. ACM, New York, NY, USA,\n3 pages. https://doi.org/10.1145/3410530.3414374\n\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nUbiComp/ISWC ’20 Adjunct, September 12–16, 2020, Virtual Event, Mexico\n© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-8076-8/20/09. . . $15.00\nhttps://doi.org/10.1145/3410530.3414374\n\n1 INTRODUCTION\nMental health problems are a growing global challenge affecting\npeople of all different backgrounds, ages, and socioeconomic sta-\ntus [19]. To tackle this challenge, mental health resources are in-\ncreasingly available online and via mobile apps [8, 12, 14]. The\nproliferation of conversational agents has made them attractive for\nhealth applications [11] and mental health [18]. Notable chatbots\nthat monitor mood and use aspects of CBT to help users deal with\nanxiety and depression include Woebot [17] and TESS [4].\n\nThe advancements and rapid adoption of spoken conversational\nagents, such as Siri and Alexa, make them attractive as a channel\nfor providing mental health resources to users [13]. Spoken conver-\nsational agents interact with users via spoken natural language. For\nmental health applications, this requires users to vocalize responses\nabout their mental health status, which is different than typing\nresponses to a chatbot or on a website. One study explained that\nsome people are more likely to have truthful interactions about\ntheir mental health with technology than wth mental health pro-\nfessionals [16].\n\nThis paper presents work-in-progress findings of an Alexa Skill\nwe developed that performs depression and anxiety self-tests. Cur-\nrent Alexa Skills focus on guiding, educating, and helping users\nmanage mental health issues. Some Alexa Skills examples include\nmanagement for anxiety and stress through advice sessions (Anti\nAnxiety, Anxiety Stress), assisting people with depression by pro-\nviding tasks to boost their mood (Mental Health Day Manager),\nmanagement advice and education for children and teenagers deal-\ning anger, stress, anxiety, and depression (Mental Health Spies),\nand targeted exercises depending on the situation (work, studies,\nlife) causing the user stress (Mindscape). One study used Alexa to\nmonitor a user’s mental health behaviors and symptoms, requiring\nusers to self-report data on sleep, mood, and acti"
  },
  {
    "title": "Participatory Design for Mental Health Data Visualization on a Social\n  Robot",
    "authors": [
      "Raida Karim",
      "Edgar Lopez",
      "Elin A. Björling",
      "Maya Cakmak"
    ],
    "abstract": "The intersection of data visualization and human-robot interaction (HRI) is a\nburgeoning field. Understanding, communicating, and processing different kinds\nof data for creating versatile visualizations can benefit HRI. Conversely,\nexpressing different kinds of data generated from HRI through effective\nvisualizations can provide interesting insights. Our work adds to the\nliterature of this growing domain. In this paper, we present our exploratory\nwork on visualizing mental health data on a social robot. Particularly, we\ndiscuss development of mental health data visualizations using a participatory\ndesign (PD) approach. As a first step with mental health data visualization on\na social robot, this work paves the way for relevant further work and using\nsocial robots as data visualization tools.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2210.06469v1",
    "pdf_url": "http://arxiv.org/pdf/2210.06469v1",
    "full_text": "2\n2\n0\n2\n\ng\nu\nA\n0\n2\n\n]\n\nC\nH\n.\ns\nc\n[\n\n1\nv\n9\n6\n4\n6\n0\n.\n0\n1\n2\n2\n:\nv\ni\nX\nr\na\n\nParticipatory Design for Mental Health Data\nVisualization on a Social Robot\n\nRaida Karim\nUniversity of Washington\nSeattle, Washington, United States\nrk1997@cs.washington.edu\n\nElin A. Bj¨orling\nUniversity of Washington\nSeattle, Washington, United States\nbjorling@uw.edu\n\nEdgar Lopez\nUniversity of Washington\nSeattle, Washington, United States\nlopeze7@uw.edu\n\nMaya Cakmak\nUniversity of Washington\nSeattle, Washington, United States\nmcakmak@cs.washington.edu\n\nAbstract—The intersection of data visualization and human-\nrobot interaction (HRI) is a burgeoning ﬁeld. Understanding,\ncommunicating, and processing different kinds of data for\ncreating versatile visualizations can beneﬁt HRI. Conversely,\nexpressing different kinds of data generated from HRI through\neffective visualizations can provide interesting insights. Our work\nadds to the literature of this growing domain. In this paper, we\npresent our exploratory work on visualizing mental health data\non a social robot. Particularly, we discuss development of mental\nhealth data visualizations using a participatory design (PD)\napproach. As a ﬁrst step with mental health data visualization\non a social robot, this work paves the way for relevant further\nwork and using social robots as data visualization tools.\n\nIndex Terms—Participatory design, mental health, community,\n\ndata visualization, social robots, human-robot interaction\n\nI. INTRODUCTION AND BACKGROUND\nDespite many opportunities for collaborative research in\ndata visualization and HRI, not much work has been con-\ntributed to this intersection [6]. Some existing works of this\narea include visualizing data of children’s touch patterns on\na social robot [5]. Contributing to this promising domain’s\nliterature, we worked on developing visualizations of mental\nhealth data for a social robot. Social robots have been used\nto support mental health in various ways such as to help\nchildren with autism improve on their social skills [1]. They\nhave been used to help older adults by reducing feelings of\nloneliness [3], and other populations. However, existing work\nonly shows support for mental health through social robots by\nresponding interactively to human activity to help them learn\nrelevant skills. No work has shown the use of social robots\nas a means of visualizing mental health data. Therefore, our\nwork is novel or ﬁrst of its kind.\n\nII. A SOCIAL ROBOT & MENTAL HEALTH DATA\nWe detail here the procedure of collecting and visualizing\n\nmental health data in these two respective stages:\n\nA. Data Collection\n\nWe conducted a ﬁve-weekdays HRI study in an American\nuniversity campus with a total of ﬁfty-ﬁve (n=55) participants\nsharing their in-the-moment mood and stress levels with a so-\n\ncial robot. Our previous work [2] showed using an emoji likert\nscale can enhance coherence and accessibility in portraying\ndifferent levels of mood or stress data, which is what we used.\nThe users’ shared data were stored in a secured ﬁrebase 1.\n\nB. Data Visualization\n\nWe developed data visualization software with the updated\nstatic data visualization template from [2] in our social robot’s\nsoftware platform. These visualizations are shown in Fig. 1,\nand were implemented in JavaScript using AnyChart library\n2. When the visualization program is run on the robot,\nmood/stress data from ﬁrebase is sent to visualization software\nand data visualizations are created in real-time.\n\nIII. DISCUSSION\nMental health data visualizations with a social robot can\npotentially improve mental health [2]. To the best of our\nknowledge, this is the ﬁrst work rendering mental health data\nvisualizations on a social robot seeking to alleviate mental\nhealth issues among users. Although this work has been con-\nducted with data collected from people of a university campus,\ncollecting and visualizing other community’s data can inform\nabout distinct mental health needs of each community. Moving\nforward, we plan to expand this work to other community\nspaces such as high school, and public library. As mentioned\nearlier, PD method was used to ﬁnalize design of data visual-\nizations [2]. PD helped us to get inputs from the community\nmembers in designing, developing and reﬁning the features of\nthe robot-rendered data visualizations for mental well-being.\nWe have been using PD in our work for more than two years.\nWe choose to use PD methodology, because PD considers the\nintended users’ and stakeholders’ participation throughout the\ndesign process and can result in well-informed and usability-\ntested features of these data visualizations rendered by a social\nrobot. This can eventually help ensure the success of such\nrobotic technologies in supporting mental health. In [2], we\nused qualitative analysis method to derive common themes in\n\n1Firebase: https://ﬁrebase.google.com/\n2AnyChart: https://www.anychart.com/\n\n \n \n \n \n \n \n\fFig. 1. A line chart visualizing mood data (left) and a color-coded pie chart visualizing "
  },
  {
    "title": "An empirical comparison of machine learning models for student's mental\n  health illness assessment",
    "authors": [
      "Prathamesh Muzumdar",
      "Ganga Prasad Basyal",
      "Piyush Vyas"
    ],
    "abstract": "Student's mental health problems have been explored previously in higher\neducation literature in various contexts including empirical work involving\nquantitative and qualitative methods. Nevertheless, comparatively few research\ncould be found, aiming for computational methods that learn information\ndirectly from data without relying on set parameters for a predetermined\nequation as an analytical method. This study aims to investigate the\nperformance of Machine learning (ML) models used in higher education. ML models\nconsidered are Naive Bayes, Support Vector Machine, K-Nearest Neighbor,\nLogistic regression, Stochastic Gradient Descent, Decision Tree, Random Forest,\nXGBoost (Extreme Gradient Boosting Decision Tree), and NGBoost (Natural)\nalgorithm. Considering the factors of mental health illness among students, we\nfollow three phases of data processing: segmentation, feature extraction, and\nclassification. We evaluate these ML models against classification performance\nmetrics such as accuracy, precision, recall, F1 score, and predicted run time.\nThe empirical analysis includes two contributions: 1. It examines the\nperformance of various ML models on a survey-based educational dataset,\ninferring a significant classification performance by a tree-based XGBoost\nalgorithm; 2. It explores the feature importance [variables] from the datasets\nto infer the significant importance of social support, learning environment,\nand childhood adversities on a student's mental health illness.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2202.13495v1",
    "pdf_url": "http://arxiv.org/pdf/2202.13495v1",
    "full_text": "Asian Journal of Computer and Information Systems (ISSN: 2321 – 5658) \nVolume 10 – Issue 1, February 2022 \n\nAn Empirical Comparison of Machine Learning Models for \nStudent’s Mental Health Illness Assessment \n\nPrathamesh Muzumdar1, Ganga Prasad Basyal2, Piyush Vyas3 \n\n1College of Business, The University of Texas at Arlington, Texas, USA \nEmail: prathameshmegh.muzumdar [AT] mavs.uta.edu \n\n2Business and Natural Sciences Department, College of Business and Natural Sciences  \nBlack Hills State University, Spearfish, South Dakota, USA \nEmail: gangaprasad.basyal [AT] bhsu.edu \n\n3College of Business and Information Systems, Dakota State University \nMadison, South Dakota, USA \nEmail: piyush.vyas [AT] trojans.dsu.edu \n\n_________________________________________________________________________________________________ \n\nABSTRACT---  Student’s  mental  health  problems  have  been  explored  previously  in  higher  education  literature  in \nvarious contexts including empirical work involving quantitative and qualitative methods. Nevertheless, comparatively \nfew  research  could  be  found,  aiming  for  computational  methods  that  learn  information  directly  from  data  without \nrelying  on  set  parameters  for  a  predetermined  equation as  an  analytical method.  This  study  aims  to  investigate  the \nperformance  of  Machine  learning  (ML)  models  used  in  higher  education.  ML  models  considered  are  Naïve  Bayes, \nSupport  Vector  Machine,  K-Nearest  Neighbor,  Logistic  Regression,  Stochastic  Gradient  Descent,  Decision  Tree, \nRandom Forest, XGBoost (Extreme Gradient Boosting Decision Tree), and NGBoost (Natural) algorithm. Considering \nthe factors of mental health illness among students, we follow three phases of data processing: segmentation, feature \nextraction,  and  classification.  We  evaluate  these  ML  models  against  classification  performance  metrics  such  as \naccuracy, precision, recall, F1 score, and predicted run time. The empirical analysis includes two contributions: 1. It \nexamines  the  performance  of  various  ML  models  on  a  survey-based  educational  dataset,  inferring  a  significant \nclassification performance by a tree-based XGBoost algorithm; 2. It explores the feature importance [variables] from \nthe datasets to infer the significant importance of social support, learning environment, and childhood adversities on a \nstudent’s mental health illness. \n\nKeywords--- Student’s mental health illness, Machine learning, Feature importance \n\n1.  INTRODUCTION \n\nThe World Health Organization [WHO] has indicated that mental illness affects nearly half of the population worldwide \n[3]. The ubiquity of mental illness is associated with considerable impairment in cognitive skills [13], with the combination \nof anxiety and affective disorders being the most common forms of disability among sufferers  [20]. Mental illness is as \nprevalent among college students as others, and the illness appears to be increasing in number and severity [24]. When \nresearchers study such illness, college students are the most neglected population, though students are not immune to the \nsufferings and disability associated with such illness. Mental health problems are very common among students and are \nhighly  prevalent  in  college  students  [14].  This  is  mainly  because  attending  college  requires  a  student  to  overcome \nchallenging times,  which is uncommon in settings like community college and high school  [26]. College students start \ncollege  after  completing  high  school,  typically  depend  upon  parents  for  financial  support  for  few  years  till  they  start \nworking part-time [1]. These students not only face stress related to academic load but also have to face the task of taking \non more adult-like responsibilities at a younger age. Mental health problems among college students represent a growing \nconcern as a large number of students enter their adulthood and this stage is considered an important period of life [24]. \nThe  developmentally  challenging  transition  to  adulthood  and  untreated  mental  illness  leads  to  crucial  implications  for \nacademic success, productivity, social and personal relationships, and substance abuse [29]. \n\nCollege tenure represents the time in many people’s lives when their main activities relating to career and social life \nare  integrated  with  their  surroundings.  University  campuses  are  responsible  to  develop,  disseminate,  and  evaluate  best \npractices to ensure a better experience for students [15]. Therefore, colleges offer the best opportunity to address student’s \nmental health problems among late adolescents and young adults [13]. A robust base of research is necessary to deeply \nunderstand this phenomenon and investigate the antecedents of student’s mental health problems. In that regard, machine \nlearning models and data mining techniques are efficient methods in extracting features and classifying educatio"
  },
  {
    "title": "Temperature and Mental Health: Evidence from Helpline Calls",
    "authors": [
      "Benedikt Janzen"
    ],
    "abstract": "This paper studies the short-term effects of ambient temperature on mental\nhealth using data on nearly half a million helpline calls in Germany.\nLeveraging location-based routing of helpline calls and random day-to-day\nweather fluctuations, I find a negative effect of temperature extremes on\nmental health as revealed by an increase in the demand for telephone counseling\nservices. On days with an average temperature above 25{\\deg}C (77{\\deg}F) and\nbelow 0{\\deg}C (32{\\deg}F), call volume is 3.4 and 5.1 percent higher,\nrespectively, than on mid-temperature days. Mechanism analysis reveals\npronounced adverse effects of cold temperatures on social and psychological\nwell-being and of hot temperatures on psychological well-being and violence.\nMore broadly, the findings of this work contribute to our understanding of how\nchanging climatic conditions will affect population mental health and\nassociated social costs in the near future.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2207.04992v2",
    "pdf_url": "http://arxiv.org/pdf/2207.04992v2",
    "full_text": "Temperature and Mental Health: Evidence from\nHelpline Calls∗\n\nBenedikt Janzen†\n\nFirst version: July 2022\nThis version: November 2022\n\nAbstract\n\nThis paper studies the short-term eﬀects of ambient temperature on mental health\n\nusing data on nearly half a million helpline calls in Germany. Leveraging location-\n\nbased routing of helpline calls and random day-to-day weather ﬂuctuations, I ﬁnd a\n\nnegative eﬀect of temperature extremes on mental health as revealed by an increase in\n\nthe demand for telephone counseling services. On days with an average temperature\nabove 25◦C (77◦F) and below 0◦C (32◦F), call volume is 3.4 and 5.1 percent higher,\nrespectively, than on mid-temperature days. Mechanism analysis reveals pronounced\n\nadverse eﬀects of cold temperatures on social and psychological well-being and of hot\n\ntemperatures on psychological well-being and violence. More broadly, the ﬁndings of\n\nthis work contribute to our understanding of how changing climatic conditions will\n\naﬀect population mental health and associated social costs in the near future.\n\nKeywords: Climate Change, Weather, Well-being\n\nJEL Codes: I1, I31, Q5, Q54\n\n2\n2\n0\n2\n\nv\no\nN\n5\n1\n\n]\n\nN\nG\n.\nn\no\nc\ne\n[\n\n2\nv\n2\n9\n9\n4\n0\n.\n7\n0\n2\n2\n:\nv\ni\nX\nr\na\n\n∗I am thankful for helpful comments from Ludovica Gazze, Jamie Mullins, Alessandro Palma, Patrick\nBigler, as well as conference and seminar participants at the AERE Summer Conference, the EAERE Annual\nConference, the ESPE Annual Conference, the IAERE Annual Conference, and the VfS Environmental and\nResource Economics Junior Workshop. I am grateful to my supervisor Doina Radulescu for her excellent\nand continuous guidance. I am particularly indebted to Ludger Storch and TelefonSeelsorge for providing\nthe necessary data. The author has no conﬂict of interest in any part and did not receive any funding for\nthis work. All remaining errors are my own.\n\n†University of Bern, KPM Center for Public Management and OCCR Oeschger Centre for Climate Change\n\nResearch; Email: benedikt.janzen@kpm.unibe.ch\n\n \n \n \n \n \n \n\f1\n\nIntroduction\n\nMental disorders aﬀect nearly one billion people worldwide, accounting for ﬁve percent of\nthe total global burden of disease (Ferrari et al., 2022). The World Health Organization\n(2012) expects that by the end of the decade mental illness will be the leading cause of\ndisease burden worldwide, up from 13th in 1990. For those aﬀected, mental illnesses such as\ndepression are associated with high individual costs, as they reduce labor force participation\nand entail large earning penalties (B¨utikofer et al., 2020; Biasi et al., 2021). Globally, the\nWorld Economic Forum estimates that the socioeconomic cost of mental disorders was $2.5\ntrillion in 2010, and it is expected to more than double by 2030 (Bloom et al., 2011). Because\nof uncertainty in potential risk factors for human health, which include climate variability\nand trends (McMichael et al., 2006), and given an increase in global surface temperatures\nthrough at least mid-century (IPCC, 2021) projected costs are likely to be an underestimate.\n\nDespite their large share of the global burden of disease and in the face of climate change,\nthere is limited causal evidence on the impact of temperature extremes on mental health\n(Berry et al., 2018). Where existing work has explored the causal eﬀects of temperature\non mental distress, it has focused on suicidality (Burke et al., 2018; Carleton, 2017), health\ncare utilization (Mullins & White, 2019), and self-reported mental health (Obradovich et\nal., 2018). However, these measures have limitations that ultimately make it diﬃcult to\ninfer the impact of temperature on mental health from them alone (Romanello et al., 2021;\nObradovich & Minor, 2022) as they either focus on rare and extreme or clinical outcomes1,\nor represent subjective measures of mental health that might suﬀer from systematic bias\n(e.g., Jahedi & M´endez, 2014).\n\nThis paper studies the short-term eﬀects of ambient temperature on mental distress using\nadministrative records from the largest general telephone counseling service in Germany,\nconsisting of 485,274 individual calls received at 55 sites nationwide between November 2018\nand March 2020. The data contains the timestamp, processing location, call topics, and\ncaller characteristics for each call. Telephone helplines provide free, low-threshold, anony-\nmous2 counseling services for people with unmet mental health needs. Although not a\ndirect measure of psychiatric disorders, the use of helpline data oﬀers many advantages in-\n\n1Mental health stigma can discourage people from seeking professional help (Bharadwaj et al., 2017). In\naddition, access to evidence-based treatment remains inadequate even in high-income countries (Demytte-\nnaere et al., 2004; World Health Organization, 2012).\n\n2In Germany, anonymous and unobservable access to telephone counseling services is even guaranteed\nby federal law (§99 Abs. 2 Telecommunications Act (TKG)), which prohibits telecommunication service\nprovi"
  },
  {
    "title": "Exploring Mental Health Communications among Instagram Coaches",
    "authors": [
      "Ehsan-Ul Haq",
      "Lik-Hang Lee",
      "Gareth Tyson",
      "Reza Hadi Mogavi",
      "Tristan Braud",
      "Pan Hui"
    ],
    "abstract": "There has been a significant expansion in the use of online social networks\n(OSNs) to support people experiencing mental health issues. This paper studies\nthe role of Instagram influencers who specialize in coaching people with mental\nhealth issues. Using a dataset of 97k posts, we characterize such users'\nlinguistic and behavioural features. We explore how these observations impact\naudience engagement (as measured by likes). We show that the support provided\nby these accounts varies based on their self-declared professional identities.\nFor instance, Instagram accounts that declare themselves as Authors offer less\nsupport than accounts that label themselves as Coach. We show that increasing\ninformation support in general communication positively affects user\nengagement. However, the effect of vocabulary on engagement is not consistent\nacross the Instagram account types. Our findings shed light on this\nunderstudied topic and guide how mental health practitioners can improve\noutreach.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2211.06013v1",
    "pdf_url": "http://arxiv.org/pdf/2211.06013v1",
    "full_text": "2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)\n\nExploring Mental Health Communications among\nInstagram Coaches\n\nEhsan-Ul Haq∗, Lik-Hang Lee†, Gareth Tyson§, Reza Hadi Mogavi∗, Tristan Braud∗, and Pan Hui∗‡§\n∗Hong Kong University of Science and Technology, HKSAR\n†Korea Advanced Institute of Science and Technology\n‡University of Helsinki, Helsinki\n§Hong Kong University of Science and Technology, Guangzhou\n\nEmail: {euhaq,rhadimogavi}@connect.ust.hk\n\nlikhang.lee@kaist.ac.kr\n\n{gtyson,braudt,panhui}@ust.hk\n\n2\n2\n0\n2\n\nv\no\nN\n1\n1\n\n]\nI\nS\n.\ns\nc\n[\n\n1\nv\n3\n1\n0\n6\n0\n.\n1\n1\n2\n2\n:\nv\ni\nX\nr\na\n\nAbstract—There has been a signiﬁcant expansion in the use\nof online social networks (OSNs) to support people experiencing\nmental health issues. This paper studies the role of Instagram\ninﬂuencers who specialize in coaching people with mental health\nissues. Using a dataset of 97k posts, we characterize such\nusers’ linguistic and behavioural features. We explore how these\nobservations impact audience engagement (as measured by likes).\nWe show that the support provided by these accounts varies\nbased on their self-declared professional identities. For instance,\nInstagram accounts that declare themselves as Authors offer less\nsupport than accounts that label themselves as a Coach. We\nshow that increasing information support in general communi-\ncation positively affects user engagement. However, the effect of\nvocabulary on engagement is not consistent across the Instagram\naccount types. Our ﬁndings shed light on this understudied topic\nand guide how mental health practitioners can improve outreach.\n\nIndex Terms—social networks, mental health, Instagram, in-\n\nﬂuencers\n\nI. INTRODUCTION\n\nThe US government reports that one in ﬁve Americans are\nfacing a mental health problem [1]. Similar statistics have been\nreported in other regions [2]. Mental health issues can have\ndevastating consequences, yet such issues are often considered\ntaboo.1 This can result in a reluctance to seek help from\nprofessionals, especially since some societies do not encourage\ndiscussions on mental health issues. In such cases, the use\nof information and communication technologies (ICT) can\nbe an important asset in helping people. Researchers have\nstudied Online Social Networks’ (OSNs) role in the support\nand prediction of mental health issues [3], [4]. Social media\nhas also led to the emergence of mental health ‘inﬂuencers’,\ni.e., OSN proﬁles that focus on offering mental health advice.\nSuch accounts frequently post advice and interact with their\naudience in an attempt to promote well-being.\n\nDespite this, there is a paucity of (quantiﬁed) knowledge\nabout how these users operate and impact others. Considering\nthe critical role these accounts can play in people’s lives, we\nargue that it is vital to study them. We take two social science\ntheories as motivating factors for our research. First, we look\n\n1https://www.swissre.com/risk-knowledge/risk-perspectives-blog/world-\n\nmental-health-day-preventing-breaking-taboos.html\nIEEE/ACM ASONAM 2022, November 10-13, 2022\n978-1-6654-5661-6/22/$31.00 © 2022 IEEE\n\nat these accounts from the identity perspective. Professional\nidentity helps individuals deﬁne and express their role as a\nprofessional and social entity [5], [6]. Moreover, individuals\nwith professional roles often enjoy trust from the wider\nsociety [7]. This leads us to reason that while the goal of\nthese accounts is to promote mental health, their professional\nidentity can be used to characterize such accounts. Thus,\ntaking this self-declared identity as our comparative scale to\nstudy their communications.\nSecond, we look at\n\nthe psychological characteristics of\nthe language used. The language used for mental health\nsupport has an effect on patient health [8], [9]. The analysis\nof language related to mental health is widely carried out\nusing the psychological characterization of vocabulary and\nquantifying the level of support [10], more particularly in\nthe context of Information and Emotion Support\nthat can\nhave practical outcomes [11]. In our work, we analyze the\ncommunication based on the level of Information and Emotion\nSupport provided by mental health inﬂuencers. We note that\nwhile these online communications largely remain one-way\nin contrast to an actual therapy session, the primary goal of\nhealth inﬂuencers is to promote well-being. Hence, the role of\nlanguage remains important.\n\nThis paper presents the ﬁrst analysis of how mental health\ninﬂuencers use Instagram. We choose Instagram because of\nthe growing anecdotal evidence of the importance it plays in\nthis ﬁeld.2 In addition to the characterization of the language,\nand support provided by these accounts, we further quantify\nthe effect of these attributes on user engagement. Speciﬁcally,\nwe ask two research questions:\n\n• RQ1: Is there any difference in the language across\naccounts based on their identity? More particularly, what\nare the levels of\ninformation and emoti"
  },
  {
    "title": "Quantifying the Effect of Socio-Economic Predictors and Built\n  Environment on Mental Health Events in Little Rock, AR",
    "authors": [
      "Alfieri Ek",
      "Samantha Robinson",
      "Grant Drawve",
      "Jyotishka Datta"
    ],
    "abstract": "Proper allocation of law enforcement resources remains a critical issue in\ncrime prediction and prevention that operates by characterizing spatially\naggregated crime activities and a multitude of predictor variables of interest.\nDespite the critical nature of proper resource allocation for mental health\nincidents, there has been little progress in statistical modeling of the\ngeo-spatial nature of mental health events in Little Rock, Arkansas. In this\narticle, we provide insights into the spatial nature of mental health data from\nLittle Rock, Arkansas between 2015 and 2018, under a supervised spatial\nmodeling framework while extending the popular risk terrain modeling (Caplan et\nal., 2011, 2015; Drawve, 2016) approach. We provide evidence of spatial\nclustering and identify the important features influencing such heterogeneity\nvia a spatially informed hierarchy of generalized linear models, spatial\nregression models and a tree based method, viz., Poisson regression, spatial\nDurbin error model, Manski model and Random Forest. The insights obtained from\nthese different models are presented here along with their relative predictive\nperformances. The inferential tools developed here can be used in a broad\nvariety of spatial modeling contexts and have the potential to aid both law\nenforcement agencies and the city in properly allocating resources.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2212.05486v1",
    "pdf_url": "http://arxiv.org/pdf/2212.05486v1",
    "full_text": "2\n2\n0\n2\n\nc\ne\nD\n1\n1\n\n]\nP\nA\n\n.\nt\na\nt\ns\n[\n\n1\nv\n6\n8\n4\n5\n0\n.\n2\n1\n2\n2\n:\nv\ni\nX\nr\na\n\nQuantifying the Effect of Socio-Economic Predictors and Built\nEnvironment on Mental Health Events in Little Rock, AR *\n\nAlﬁeri Ek\nDepartment of Mathematical Sciences, University of Arkansas - Fayetteville\nand\nSamantha Robinson\nDepartment of Mathematical Sciences, University of Arkansas - Fayetteville\nand\nGrant Drawve\nDepartment of Sociology and Criminology, University of Arkansas - Fayetteville\nand\nJyotishka Datta †\nDepartment of Statistics, Virginia Polytechnic Institute and State University\n\nDecember 13, 2022\n\nAbstract\n\nProper allocation of law enforcement resources remains a critical issue in crime prediction\nand prevention that operates by characterizing spatially aggregated crime activities and a\nmultitude of predictor variables of interest. Despite the critical nature of proper resource\nallocation for mental health incidents, there has been little progress in statistical modeling of the\ngeo-spatial nature of mental health events in Little Rock, Arkansas. In this article, we provide\ninsights into the spatial nature of mental health data from Little Rock, Arkansas between 2015\nand 2018, under a supervised spatial modeling framework while extending the popular risk\nterrain modeling (Caplan et al., 2011, 2015; Drawve, 2016) approach. We provide evidence\nof spatial clustering and identify the important features inﬂuencing such heterogeneity via a\nspatially informed hierarchy of generalized linear models, spatial regression models and a tree\nbased method, viz., Poisson regression, spatial Durbin error model, Manski model and Random\nForest. The insights obtained from these different models are presented here along with their\nrelative predictive performances. The inferential tools developed here can be used in a broad\nvariety of spatial modeling contexts and have the potential to aid both law enforcement agencies\nand the city in properly allocating resources.\n\n1 Introduction\n\nOver the last two decades, law enforcement agencies are relying more and more on statistical tools\nto build an objective criminal justice system, leading to a meteoric rise of “predictive policing”,\nloosely deﬁned as “the application of analytical techniques - particularly quantitative techniques - to\nidentify likely targets for police intervention and prevent crime or solve past crimes by making statistical\n\n*This study is a continuation of work presented in the ﬁrst author’s MS thesis and is a work-in-progress draft.\n†Corresponding author\n\n1\n\n \n \n \n \n \n \n\fpredictions” (Perry et al., 2013). The proposed algorithms and methods attempt to uncover and\nexploit different aspects of crime activities data. For example, Gotway & Stroup (1997) use a spatial\ngeneralized linear model, that has been extended both by considering the temporal pattern as well\nas a non-linear modeling approach using generalized additive modeling in ST-GAM or LST-GAM\n(Wang & Brown, 2012). In a series of papers, Mohler et al. (2011, 2013, 2015) propose a self-exciting\npoint process model that treats near-repeat nature of crimes (Townsley et al., 2000) as aftershocks\nof an earthquake. This is the main driving force behind the popular crime forecasting software\ncalled PredPol (https://predpol.com/) that has been since adopted by many policing agencies\nthroughout the US.\n\nApart from increasing the accuracy of prediction of future crime, it is also important to understand\nwhich geographical factors signiﬁcantly contribute to crime. Such knowledge can inform a plan\nfor allocating resources or making policy changes to either counteract the effect of a ‘risky’ place\nor increase the intensity or presence of a ‘protective’ place. This is also closely related to the goal\nof ensuring that a prediction rule does not suffer from algorithmic or systemic biases. This is\nparticularly important, as with the increase in complexity and use of such data-based tools, there\nis growing concern and additional effort devoted to reducing the racial disparities in predictive\npolicing, while producing dynamic and real-time forecasts and insights about spatio-temporal\ncrime activities. For example, using a combination of demographically representative synthetic\ndata and survey data on drug use, Lum & Isaac (2016) point out that predictive policing estimates\nbased on biased policing records often accentuate the racial bias instead of removing it. A natural\nsolution seems to be the risk terrain modeling (RTM) framework of Caplan et al. (2011), that uses a\nsimple but interpretable approach. In RTM, a separate map layer is created for each predictor, that\nare then combined to produce a composite map where contribution or importance of each factor\ncan be evaluated in a model-based way.\n\nWe start with a brief review of the existing statistical methodology behind the most common crime\nforecasting tools.\n\n1.1 Literature Review\n\nSelf-exciting Point Process: One of the popular statistical approaches to modeling criminal activi-\nties "
  },
  {
    "title": "Exploring Hybrid and Ensemble Models for Multiclass Prediction of Mental\n  Health Status on Social Media",
    "authors": [
      "Sourabh Zanwar",
      "Daniel Wiechmann",
      "Yu Qiao",
      "Elma Kerz"
    ],
    "abstract": "In recent years, there has been a surge of interest in research on automatic\nmental health detection (MHD) from social media data leveraging advances in\nnatural language processing and machine learning techniques. While significant\nprogress has been achieved in this interdisciplinary research area, the vast\nmajority of work has treated MHD as a binary classification task. The\nmulticlass classification setup is, however, essential if we are to uncover the\nsubtle differences among the statistical patterns of language use associated\nwith particular mental health conditions. Here, we report on experiments aimed\nat predicting six conditions (anxiety, attention deficit hyperactivity\ndisorder, bipolar disorder, post-traumatic stress disorder, depression, and\npsychological stress) from Reddit social media posts. We explore and compare\nthe performance of hybrid and ensemble models leveraging transformer-based\narchitectures (BERT and RoBERTa) and BiLSTM neural networks trained on\nwithin-text distributions of a diverse set of linguistic features. This set\nencompasses measures of syntactic complexity, lexical sophistication and\ndiversity, readability, and register-specific ngram frequencies, as well as\nsentiment and emotion lexicons. In addition, we conduct feature ablation\nexperiments to investigate which types of features are most indicative of\nparticular mental health conditions.",
    "year": 2022,
    "url": "http://arxiv.org/abs/2212.09839v1",
    "pdf_url": "http://arxiv.org/pdf/2212.09839v1",
    "full_text": "Exploring Hybrid and Ensemble Models for Multiclass Prediction of\nMental Health Status on Social Media\n\nSourabh Zanwar\nRWTH Aachen University\nsourabh.zanwar@rwth-aachen.de\n\nDaniel Wiechmann\nUniversity of Amsterdam\nd.wiechmann@uva.nl\n\nYu Qiao\nRWTH Aachen University\nyu.qiao@rwth-aachen.de\n\nElma Kerz\nRWTH Aachen University\nelma.kerz@ifaar.rwth-aachen.de\n\nAbstract\n\nIn recent years, there has been a surge of in-\nterest in research on automatic mental health\ndetection (MHD) from social media data lever-\naging advances in natural language processing\nand machine learning techniques. While sig-\nniﬁcant progress has been achieved in this in-\nterdisciplinary research area, the vast major-\nity of work has treated MHD as a binary clas-\nsiﬁcation task. The multiclass classiﬁcation\nsetup is, however, essential if we are to un-\ncover the subtle differences among the statis-\ntical patterns of language use associated with\nparticular mental health conditions. Here, we\nreport on experiments aimed at predicting six\nconditions (anxiety, attention deﬁcit hyperac-\ntivity disorder, bipolar disorder, post-traumatic\nstress disorder, depression, and psychological\nstress) from Reddit social media posts. We ex-\nplore and compare the performance of hybrid\nand ensemble models leveraging transformer-\nbased architectures (BERT and RoBERTa) and\nBiLSTM neural networks trained on within-\ntext distributions of a diverse set of linguis-\ntic features. This set encompasses measures\nof syntactic complexity, lexical sophistication\nand diversity, readability, and register-speciﬁc\nngram frequencies, as well as sentiment and\nemotion lexicons. In addition, we conduct fea-\nture ablation experiments to investigate which\ntypes of features are most indicative of partic-\nular mental health conditions.\n\n1\n\nIntroduction\n\nMental health is a major challenge in healthcare\nand in our modern societies at large, as evidenced\nby the topic’s inclusion in the United Nations’ 17\nSustainable Development Goals. The World Health\nOrganization estimates that 970 million people\nworldwide suffer from mental health issues, the\nmost common being anxiety and depressive disor-\nders1. The problem is compounded by the fact that\n\n1https://www.who.int/news-room/fact-sheets/\n\ndetail/mental-disorders\n\nthe rate of undiagnosed mental disorders has been\nestimated to be as high as 45% (La Vonne et al.,\n2012). The societal impact of mental health disor-\nders requires prevention and intervention strategies\nfocused primarily on screening and early diagnosis.\nIn keeping with the WHO Mental Health Action\nPlan (Saxena et al., 2013), natural language pro-\ncessing and machine learning can make an impor-\ntant contribution to gathering more comprehensive\ninformation and knowledge about mental illness.\nIn particular, an increasing use of social media plat-\nforms by individuals is generating large amounts\nof high-quality behavioral and textual data that can\nsupport the development of computational solu-\ntions for the study of mental disorders. An emerg-\ning, interdisciplinary ﬁeld of research at the in-\ntersections of computational linguistics, health in-\nformatics and artiﬁcial intelligence now leverages\nnatural language processing techniques to analyze\nsuch data to develop models for early detection of\nvarious mental health conditions.\n\nSystematic reviews of this research show that\nthe vast majority of the existing work has focused\nprimarily on automatic identiﬁcation of speciﬁc\ndisorders, with depression and anxiety being the\nmost commonly studied target conditions (Calvo\net al., 2017; Chancellor and De Choudhury, 2020;\nZhang et al., 2022). As a result, existing work has\nfocused on developing binary classiﬁers that aim\nto distinguish between individuals with a particular\nmental illness and control users.\n\nThe current work addresses the more complex\nproblem of distinguishing between multiple men-\ntal states, which is essential if we are to uncover\nthe subtle differences among the statistical pat-\nterns of language use associated with particular\ndisorders. Speciﬁcally, in this paper we make the\nfollowing contributions to the existing literature\non health text mining based on social media data:\n(1) We frame the MHC detection tasks as a multi-\nclass prediction task aimed to determine to what\n\n2\n2\n0\n2\nc\ne\nD\n9\n1\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n9\n3\n8\n9\n0\n.\n2\n1\n2\n2\n:\nv\ni\nX\nr\na\n\n \n \n \n \n \n \n\fextent six mental health conditions (anxiety, atten-\ntion deﬁcit hyperactivity disorder, bipolar disorder,\npost-traumatic stress disorder, depression, and psy-\nchological stress) can be predicted on the basis of\nsocial media posts from Reddit. (2) We explore\nand compare the performance of hybrid and ensem-\nble models leveraging transformer-based architec-\ntures (BERT and RoBERTa) and BiLSTM neural\nnetworks trained on within-text distributions of a\ndiverse set of linguistic features. (3) We conduct\nfeature ablation experiments to investigate which\ntypes of features are most indicative of particular\nmental health conditions.\n\nThis pap"
  },
  {
    "title": "Deep Learning Mental Health Dialogue System",
    "authors": [
      "Lennart Brocki",
      "George C. Dyer",
      "Anna Gładka",
      "Neo Christopher Chung"
    ],
    "abstract": "Mental health counseling remains a major challenge in modern society due to\ncost, stigma, fear, and unavailability. We posit that generative artificial\nintelligence (AI) models designed for mental health counseling could help\nimprove outcomes by lowering barriers to access. To this end, we have developed\na deep learning (DL) dialogue system called Serena. The system consists of a\ncore generative model and post-processing algorithms. The core generative model\nis a 2.7 billion parameter Seq2Seq Transformer fine-tuned on thousands of\ntranscripts of person-centered-therapy (PCT) sessions. The series of\npost-processing algorithms detects contradictions, improves coherency, and\nremoves repetitive answers. Serena is implemented and deployed on\n\\url{https://serena.chat}, which currently offers limited free services. While\nthe dialogue system is capable of responding in a qualitatively empathetic and\nengaging manner, occasionally it displays hallucination and long-term\nincoherence. Overall, we demonstrate that a deep learning mental health\ndialogue system has the potential to provide a low-cost and effective\ncomplement to traditional human counselors with less barriers to access.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2301.09412v1",
    "pdf_url": "http://arxiv.org/pdf/2301.09412v1",
    "full_text": "6th International Workshop on Dialog Systems (IWDS)\n10th IEEE International Conference on Big Data and Smart Computing (BigComp)\n\nDeep Learning Mental Health Dialogue System\n\nLennart Brocki\nInstitute of Informatics\nUniversity of Warsaw\nWarsaw, Poland\nbrocki.lennart@gmail.com\n\nGeorge C. Dyer\nDemiteris\nWrocław, Poland\ngeorgecdyer@gmail.com\n\nAnna Gładka\nPsychiatry Department\nWrocław Medical University\nWrocław, Poland\nagladka@gmail.com\n\nNeo Christopher Chung\nInstitute of Informatics\nUniversity of Warsaw\nWarsaw, Poland\nnchchung@gmail.com\n\n3\n2\n0\n2\n\nn\na\nJ\n\n3\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n2\n1\n4\n9\n0\n.\n1\n0\n3\n2\n:\nv\ni\nX\nr\na\n\nAbstract—Mental health counseling remains a major challenge\nin modern society due to cost, stigma, fear, and unavailability. We\nposit that generative artiﬁcial intelligence (AI) models designed\nfor mental health counseling could help improve outcomes by\nlowering barriers to access. To this end, we have developed a\ndeep learning (DL) dialogue system called Serena. The system\nconsists of a core generative model and post-processing algo-\nrithms. The core generative model is a 2.7 billion parameter\nSeq2Seq Transformer [26] ﬁne-tuned on thousands of transcripts\nof person-centered-therapy (PCT) sessions. The series of post-\nprocessing algorithms detects contradictions, improves coherency,\nand removes repetitive answers. Serena is implemented and\ndeployed on https://serena.chat, which currently offers limited\nfree services. While the dialogue system is capable of responding\nin a qualitatively empathetic and engaging manner, occasionally\nit displays hallucination and long-term incoherence. Overall, we\ndemonstrate that a deep learning mental health dialogue system\nhas the potential to provide a low-cost and effective complement\nto traditional human counselors with less barriers to access.\n\nIndex Terms—Deep Learning, Artiﬁcial Intelligence, Trans-\n\nformers, Mental Health, Chatbot, Dialogue System\n\nI. INTRODUCTION\n\nThe lack of widespread access to mental health counseling\nremains one of the biggest challenges in the world. It\nis\nestimated that 658 million people in the world suffer from\nsome form of psychological distress and this number grew by\n50% in the last 30 years [4]. Yet only 35% percent of people\nwith mental health disorders receive mental health treatment\n[3], and less than 25% percent have ever “seen someone” [7].\nPsychological counseling and therapy are helpful in treating\nanxiety, depression, obsessive compulsive disorder, personality\ndisorders, eating disorders and a plethora of other conditions\n[14]. Around 48% of people experiencing a mental health\ncrisis reported that talking with friends was helpful, however\n56% of them ended up handling their problems alone [6].\nWe propose that a virtual mental health counselor based on\ngenerative deep learning models could substantially improve\nmental health outcomes for many user proﬁles. In this paper\nwe will present our design and implementation of a deep\nlearning dialogue system for psychological counseling.\n\nGenerative deep learning (DL) models may provide an\nanswer to a simple yet\ntenacious question: how can we\nmake mental health counseling more accessible? To effectively\ntackle the problem, we ﬁrst need to consider why most people\ncannot or do not want to access mental health counseling.\nThe most obvious cause is the prohibitive cost of the type\n\nFig. 1. Overview of the Serena dialogue system. A large generative model\noutputs candidate responses conditioned on a user prompt and three smaller,\nmore specialized NLP models are used to reject unsuitable responses.\n\nof regular, in-person counseling that is proven to be the most\nbeneﬁcial [11]. A similar obstacle is time. Those people who\nearn enough money to afford quality counseling may not,\nas a result, have enough time to dedicate to the process,\nwhich in addition to the actual sessions, requires scheduling,\ncommuting, arranging for the care of children, etc. Finally, we\nhave fear of counseling and perceived stigma [22].\n\nWe designed such a DL-based dialogue system called Ser-\nena as a system that addresses as many of these factors as pos-\nsible, with an emphasis on ﬁlling the gaps left by traditional,\nin-person counseling. Stated differently, the proposed system is\nnot designed as a replacement for traditional therapy. Rather,\nwe conceive it as: 1) a fallback for those who are strictly\nunable to engage in traditional therapy because of money or\ntime; 2) a catalyst for helping people warm up to the idea of\nsharing their thoughts through the process of dialogue, which\nmay result in them in setting up in-person sessions; 3) a tool\nfor identifying therapy needs and measuring engagement with\na virtual counseling model across a wide demographic, with\nthe goal of improving quality and access to mental health\nresources globally.\n\nII. RELATED WORK\n\nBroadly speaking, dialogue systems (a.k.a. chatbots) can\nbe divided into two groups: those that primarily use artiﬁcial\nintelligence or generative processes on the one han"
  },
  {
    "title": "Curriculum-guided Abstractive Summarization for Mental Health Online\n  Posts",
    "authors": [
      "Sajad Sotudeh",
      "Nazli Goharian",
      "Hanieh Deilamsalehy",
      "Franck Dernoncourt"
    ],
    "abstract": "Automatically generating short summaries from users' online mental health\nposts could save counselors' reading time and reduce their fatigue so that they\ncan provide timely responses to those seeking help for improving their mental\nstate. Recent Transformers-based summarization models have presented a\npromising approach to abstractive summarization. They go beyond sentence\nselection and extractive strategies to deal with more complicated tasks such as\nnovel word generation and sentence paraphrasing. Nonetheless, these models have\na prominent shortcoming; their training strategy is not quite efficient, which\nrestricts the model's performance. In this paper, we include a curriculum\nlearning approach to reweigh the training samples, bringing about an efficient\nlearning procedure. We apply our model on extreme summarization dataset of\nMentSum posts -- a dataset of mental health related posts from Reddit social\nmedia. Compared to the state-of-the-art model, our proposed method makes\nsubstantial gains in terms of Rouge and Bertscore evaluation metrics, yielding\n3.5% (Rouge-1), 10.4% (Rouge-2), and 4.7% (Rouge-L), 1.5% (Bertscore) relative\nimprovements.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2302.00954v1",
    "pdf_url": "http://arxiv.org/pdf/2302.00954v1",
    "full_text": "Curriculum-guided Abstractive Summarization\nfor Mental Health Online Posts\n\nSajad Sotudeh 1*, Nazli Goharian1, Hanieh Deilamsalehy2, and Franck Dernoncourt2\n\n1IRLab, Georgetown University\n{sajad,nazli}@ir.cs.georgetown.edu\n2Adobe Research\n{deilamsa,franck.dernoncourt}@adobe.com\n\nAbstract\n\nAutomatically generating short summaries\nfrom users’ online mental health posts could\nsave counselors’ reading time and reduce their\nfatigue so that they can provide timely re-\nsponses to those seeking help for improv-\ning their mental state. Recent Transformers-\nbased summarization models have presented\na promising approach to abstractive summa-\nrization. They go beyond sentence selection\nand extractive strategies to deal with more\ncomplicated tasks such as novel word gener-\nation and sentence paraphrasing. Nonethe-\nless, these models have a prominent shortcom-\ning;\ntheir training strategy is not quite efﬁ-\ncient, which restricts the model’s performance.\nIn this paper, we include a curriculum learn-\ning approach to reweigh the training samples,\nbringing about an efﬁcient learning procedure.\nWe apply our model on extreme summariza-\ntion dataset of MENTSUM posts —a dataset\nof mental health related posts from Reddit so-\ncial media. Compared to the state-of-the-art\nmodel, our proposed method makes substan-\ntial gains in terms of ROUGE and BERTSCORE\nevaluation metrics, yielding 3.5% (ROUGE-\n1), 10.4% (ROUGE-2), and 4.7% (ROUGE-L),\n1.5% (BERTSCORE) relative improvements.\n\n1\n\nIntroduction\n\nSummarization of mental health online posts is an\nemerging task that aims to summarize users’ posts\nwho are seeking help to enhance their mental state\nin online networks such as Reddit 1 and Reachout 2.\nThe post might address several issues of the user’s\nconcerns or simply be an elaboration on the user’s\nmental and emotional situation. With user prefer-\nence, each user-written post can be accompanied\nby a succinct summary (known as TL;DR 3), con-\n\n* Work partially done during the internship at Adobe\n\nResearch.\n\n1https://www.reddit.com/\n2https://au.reachout.com/\n3 TL;DR is the abbreviation of “Too Long, Didn’t Read”.\nWe use “TL;DR” and “summary” exchangeably in this paper.\n\ndensing major points of the user post. This TL;DR\nsummary is deemed to urge the counselors for a\nfaster read of the user’s posted content before read-\ning the post in its entirety; hence, counsellors can\nprovide responses promptly. Herein, we aim to im-\nprove state-of-the-art results reported in (Sotudeh,\nGoharian, and Young, 2022) for this task.\n\nLarge-scale deep neural models are often hard\nleaning on intricate heuristic set-ups,\nto train,\nwhich can be time-consuming and expensive to\ntune (Gong et al., 2019; Chen et al., 2021). This is\nespecially the case for the Transformers-based sum-\nmarizers, which have been shown to consistently\noutperform the RNN networks when rigorously\ntuned (Popel and Bojar, 2018), but also require\nheuristics such as specialized learning rates and\nlarge-batch training (Platanios et al., 2019). In this\npaper, we attempt to overcome the mentioned prob-\nlem on BART (Lewis et al., 2020) Transformers-\nbased summarizer by introducing a Curriculum\nLearning (CL) strategy (Bengio et al., 2009) for\ntraining the summarization model, leading to im-\nproved convergence time, and performance.\n\nInspired by humans’ teaching style, curriculum\nlearning suggests moving the teaching process\nfrom easier samples to more difﬁcult ones and dates\nback to the nineties (Elman, 1993). The driving\nidea behind this approach is that networks can ac-\ncomplish better task learning when the training\ninstances are exposed to the network in a speciﬁc\nand certain order, from easier samples to more dif-\nﬁcult ones (Chang et al., 2021). In the context of\nneural networks, this process can be thought of as a\ntechnique that makes the network robust to getting\nstuck at local optima, which is more likely in the\nearly stages of the training process. Given the men-\ntioned challenge of summarization networks, we\nutilize the SUPERLOSS (Castells et al., 2020) func-\ntion that falls into the family of conﬁdence-aware\ncurriculum learning techniques, introducing a new\nparameter called conﬁdence (i.e., σ) to the network.\n\n3\n2\n0\n2\n\nb\ne\nF\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n4\n5\n9\n0\n0\n.\n2\n0\n3\n2\n:\nv\ni\nX\nr\na\n\n \n \n \n \n \n \n\fWe validate our model on MENTSUM (Sotudeh,\nGoharian, and Young, 2022) dataset, containing\nover 24k instances mined from 43 mental health\nrelated communities on Reddit social media. Our\nexperimental results show the efﬁcacy of applying\ncurriculum learning objectives on BART summa-\nrizer, achieving a new state-of-the-art performance.\n\n2 Related Work\n\nWhile majority of works in mental health research\nhave focused on studying users’ behavioral patterns\nthrough classiﬁcation and prediction tasks (Choud-\nhury et al., 2013; Resnik et al., 2013; Coppersmith\net al., 2014; Yates et al., 2017; Cohan et al., 2017,\n2018; MacAvaney et al., 2018), summarization of\nonline mental health posts has been recently made\nvia"
  },
  {
    "title": "Evaluation of ChatGPT for NLP-based Mental Health Applications",
    "authors": [
      "Bishal Lamichhane"
    ],
    "abstract": "Large language models (LLM) have been successful in several natural language\nunderstanding tasks and could be relevant for natural language processing\n(NLP)-based mental health application research. In this work, we report the\nperformance of LLM-based ChatGPT (with gpt-3.5-turbo backend) in three\ntext-based mental health classification tasks: stress detection (2-class\nclassification), depression detection (2-class classification), and suicidality\ndetection (5-class classification). We obtained annotated social media posts\nfor the three classification tasks from public datasets. Then ChatGPT API\nclassified the social media posts with an input prompt for classification. We\nobtained F1 scores of 0.73, 0.86, and 0.37 for stress detection, depression\ndetection, and suicidality detection, respectively. A baseline model that\nalways predicted the dominant class resulted in F1 scores of 0.35, 0.60, and\n0.19. The zero-shot classification accuracy obtained with ChatGPT indicates a\npotential use of language models for mental health classification tasks.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2303.15727v1",
    "pdf_url": "http://arxiv.org/pdf/2303.15727v1",
    "full_text": "Evaluation of ChatGPT for NLP-based Mental\nHealth Applications\n\nBishal Lamichhane,\nlamichhane.bishal@gmail.com\n\n1\n\n3\n2\n0\n2\n\nr\na\n\nM\n8\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n7\n2\n7\n5\n1\n.\n3\n0\n3\n2\n:\nv\ni\nX\nr\na\n\nAbstract—Large language models (LLM) have been successful\nin several natural language understanding tasks and could be rel-\nevant for natural language processing (NLP)-based mental health\napplication research. In this work, we report the performance\nof LLM-based ChatGPT (with gpt-3.5-turbo backend) in three\ntext-based mental health classiﬁcation tasks: stress detection (2-\nclass classiﬁcation), depression detection (2-class classiﬁcation),\nand suicidality detection (5-class classiﬁcation). We obtained\nannotated social media posts for the three classiﬁcation tasks\nfrom public datasets. Then ChatGPT API classiﬁed the social\nmedia posts with an input prompt for classiﬁcation. We obtained\nF1 scores of 0.73, 0.86, and 0.37 for stress detection, depression\ndetection, and suicidality detection, respectively. A baseline model\nthat always predicted the dominant class resulted in F1 scores\nof 0.35, 0.60, and 0.19. The zero-shot classiﬁcation accuracy\nobtained with ChatGPT indicates a potential use of language\nmodels for mental health classiﬁcation tasks.\n\nIndex Terms—ChatGPT, mental health, natural language pro-\n\ncessing, stress, depression, suicidality\n\nI. INTRODUCTION\n\nMental health illnesses are widely prevalent. More than one\nbillion people worldwide are estimated to be suffering from\nmental illnesses [1]. In the US, one in ﬁve individuals has men-\ntal health issues every year [2]. Proper management of mental\nhealth with timely diagnosis,\nintervention, and monitoring\nrequires measuring mental health. Since most mental health ill-\nnesses have bio-psycho-social origins, research on measuring\nmental health has considered obtaining bio-behavioral signals\nto detect the mental health state of the individual. Social media\nposts could be a source to detect the mental health state of an\nindividual. One’s mental health state could be reﬂected in the\nsentiments or linguistic contents of their social media posts.\nAccordingly, previous works have demonstrated mental health\nstate detection based on the analysis of users’ social media\nposts [3], [4], [5].\n\nMental health state detection from texts such as social\nmedia posts requires natural language processing (NLP) to\ninfer the sentiment and content shared in the text. Recently,\nlarge language models (LLM) have shown unprecedented\nsuccess in natural language understanding. LLMs are neural\nnetworks based on the transformer architecture [6] trained in\na self-supervised setting with a large text corpus, followed by\nﬁne-tuning in supervised and reinforcement learning settings.\nChatGPT is a popular LLM-based chat application/assistant\nthat has been receiving a lot of public attention. ChatGPT as\na conversation agent demonstrates its capability to understand\nthe text and respond accordingly. Though several limitations\nof ChatGPT and LLMs, in general, are acknowledged, these\n\nmodels have shown to be good generalized models across\ndifferent applications. The applications of the GPT-4 model,\nthe latest LLM model from OpenAI, in several areas such\nas programming and mathematics were demonstrated by the\nauthors in [7]. Similarly, the authors in [8] demonstrated\nGPT-4’s capability in the medical domain for answering\nUSMLE (United States Medical Licensing Examination) and\nMultMedQA dataset [9] questions.\n\nOne application area for LLM could be in mental health,\ngiven the model’s capability for language understanding. Dif-\nferent application scenarios could arise for LLM’s use in a\nmental health context. As a user interacts more with LLMs,\nthe\nsometimes even sharing their thoughts and concerns,\nposts shared with LLMs could provide a better view of the\nperson’s mental health compared to social media posts. The\nLLMs could adapt to respond based on the person’s mental\nhealth state or even provide interventions, e.g., by suggesting\nto seek medical care. LLM’s language understanding could\nalso be used as a backend in many front-end mental health\napplications. Much effort today is focused on building custom\nmachine-learning models for mental health detection tasks\nbased on texts and other modalities. As the LLMs get more\nintelligent, it is not inconceivable that these LLMs become a\ndefacto backend for all language understanding tasks such as\nin mental health applications\n\nGiven the current capability of ChatGPT as one of the most\npopular LLM-based chat applications, in this work, we evalu-\nated ChatGPT’s zero-shot classiﬁcation performance in three\nmental health application tasks: stress detection, depression\ndetection, and suicidality detection tasks based on user’s social\nmedia posts. We used publicly available labeled datasets for\nour evaluations.\n\nA. Dataset\n\nII. METHOD\n\n1) Stress Detection Dataset: We evaluated ChatGPT’s abil-\nity to detect stressed states using the labeled stress detection\ndataset available "
  },
  {
    "title": "Demo Alleviate: Demonstrating Artificial Intelligence Enabled Virtual\n  Assistance for Telehealth: The Mental Health Case",
    "authors": [
      "Kaushik Roy",
      "Vedant Khandelwal",
      "Raxit Goswami",
      "Nathan Dolbir",
      "Jinendra Malekar",
      "Amit Sheth"
    ],
    "abstract": "After the pandemic, artificial intelligence (AI) powered support for mental\nhealth care has become increasingly important. The breadth and complexity of\nsignificant challenges required to provide adequate care involve: (a)\nPersonalized patient understanding, (b) Safety-constrained and medically\nvalidated chatbot patient interactions, and (c) Support for continued\nfeedback-based refinements in design using chatbot-patient interactions. We\npropose Alleviate, a chatbot designed to assist patients suffering from mental\nhealth challenges with personalized care and assist clinicians with\nunderstanding their patients better. Alleviate draws from an array of publicly\navailable clinically valid mental-health texts and databases, allowing\nAlleviate to make medically sound and informed decisions. In addition,\nAlleviate's modular design and explainable decision-making lends itself to\nrobust and continued feedback-based refinements to its design. In this paper,\nwe explain the different modules of Alleviate and submit a short video\ndemonstrating Alleviate's capabilities to help patients and clinicians\nunderstand each other better to facilitate optimal care strategies.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2304.00025v1",
    "pdf_url": "http://arxiv.org/pdf/2304.00025v1",
    "full_text": "3\n2\n0\n2\n\nr\na\n\nM\n1\n3\n\n]\nL\nC\n.\ns\nc\n[\n\n1\nv\n5\n2\n0\n0\n0\n.\n4\n0\n3\n2\n:\nv\ni\nX\nr\na\n\nDemo Alleviate: Demonstrating Artiﬁcial Intelligence Enabled Virtual Assistance\nfor Telehealth: The Mental Health Case\n\nKaushik Roy, Vedant Khandelwal, Raxit Goswami, Nathan Dolbir, Jinendra Malekar, Amit Sheth\nArtiﬁcial Intelligence Institute, University of South Carolina\nColumbia, South Carolina (Zip - 29208)\n{kaushikr, vedant, rgoswami, ndolbir}@email.sc.edu, jmalekar@mailbox.sc.edu, amit@sc.edu\n\nAbstract\n\nAfter the pandemic, artiﬁcial intelligence (AI) powered sup-\nport for mental health care has become increasingly im-\nportant. The breadth and complexity of signiﬁcant chal-\nlenges required to provide adequate care involve: (a) Per-\nsonalized patient understanding, (b) Safety-constrained and\nmedically validated chatbot patient interactions, and (c) Sup-\nport for continued feedback-based reﬁnements in design us-\ning chatbot-patient interactions. We propose Alleviate, a chat-\nbot designed to assist patients suffering from mental health\nchallenges with personalized care and assist clinicians with\nunderstanding their patients better. Alleviate draws from an\narray of publicly available clinically valid mental-health texts\nand databases, allowing Alleviate to make medically sound\nand informed decisions. In addition, Alleviate’s modular de-\nsign and explainable decision-making lends itself to robust\nand continued feedback-based reﬁnements to its design. In\nthis paper, we explain the different modules of Alleviate and\nsubmit a short video demonstrating Alleviate’s capabilities to\nhelp patients and clinicians understand each other better to\nfacilitate optimal care strategies.\n\nIntroduction\nThe current pandemic has over-extended mental healthcare\nsystems and caused striking increases in mental health clin-\nical services(WHO 2022; WCVB 2020). With the severe\nshortage of mental health clinicians coupled with a decrease\nin in-person visits at health care facilities, AI-powered chat-\nbots offer a promising solution in helping patients miti-\ngate mental health symptoms early on through active self-\ncare for effective prevention and intervention. The current\nstandard of chatbots provides script-based screening tasks\n(e.g., reminding, scheduling) that assist patients with mental\nhealth self-management through chatbot-patient interactions\nfor their daily self-care(Jaimini et al. 2018).\n\nEnabling more advanced capabilities in chatbots raises\nchallenging core algorithmic issues on: (a) Personalized\npatient understanding, (b) Safety-constrained and medi-\ncally validated chatbot-patient interactions, and (c) support\nfor continued feedback-based reﬁnements in design using\nchatbot-patient and chatbot-clinician interactions.\n\nWe propose Alleviate, a chatbot designed to assist patients\nsuffering from mental health challenges with personalized\n\nCopyright © 2023, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\n\ncare. Alleviate represents personalized patient knowledge as\na graph that integrates knowledge from an array of clinically\nvalid mental-health texts and databases with patient-speciﬁc\ninformation derived from provider notes and patient-chatbot\ninteractions (see Figure 1 (a))(Cameron et al. 2015; Roy\net al. 2021a; Rawte et al. 2022; Lokala et al. 2021; Gaur\net al. 2021). Furthermore, alleviate operates in strict confor-\nmance with medically established guidelines ensuring safe\ninteractions with the patient. The breadth and depth of med-\nical knowledge consolidated in the knowledge graph enable\nAlleviate to make medically sound and informed decisions\n(see Figure 1 (b))(Roy et al. 2022; Sheth et al. 2022; Gupta\net al. 2022). In addition, Alleviate’s modular design and ex-\nplainable reinforcement learning algorithms allow continued\ndevelopment and reﬁnement using user and clinician feed-\nback (see Figure 1 (c))(Roy et al. 2021b). We explain the\ninner workings of the Alleviate functions:\n\n• Safe\n\nand Explainable Medication Reminder\n\nand\n\nTroubleshooting.\n• Patient Appraisal\nRecommendations.\n\non Adherence\n\nto Medical\n\n• Behavior Detection Requiring Emergency Human\n\nIntervention.\n\n. The functions cover Alleviate’s aim to assist care providers\nwith safe and explainable personalized patient care.\n\nSafe and Explainable Medication Reminder\nand Troubleshooting\nAlleviate extracts personalized patient information from\nprovider notes and past patient interactions using ¡sub-\nject, predicate, object¿ triple extraction techniques to boot-\nstrap the patient knowledge graph. Further, Alleviate inte-\ngrates patient information with mental health information\nfrom knowledge bases by connecting the entities and re-\nlationships in the initialized patient knowledge graph with\nsimilar entities in the knowledge bases. Computing dense\nrepresentation-based distances are used to determine simi-\nlar entities. Finally, alleviate resolves connection conﬂicts\nduring integration using clinician-speciﬁed guidelines for\nconﬂict resolution. Fi"
  },
  {
    "title": "Amity -- A Hybrid Mental Health Application",
    "authors": [
      "Srija Santhanam",
      "Kavipriya P",
      "Balamurugan MS",
      "Manoj Kumar Rajagopal"
    ],
    "abstract": "Wellness in trivial terms combines physical, social, and mental wellbeing.\nWhile mental health is neglected, long-term success in a person life is mostly\ndetermined by his psychological health and contentment. For a person in\ndistress, professional mental health services are quite expensive, unpopular,\nand invite a lot of hesitation. Hence, it would be effective to use an Android\napplication that can offer day to day therapeutic assistance, meditation\nsessions, and guidance since it can cater to a massive community instantly. In\nthis paper, we propose a mobile and web application AMITY with a chat group and\nchatbot created using a machine learning approach. We have also built a dataset\nto train the chatbot model that we propose in this paper. We briefly introduce\nthe dataset and the machine learning model in section 3. In section 4, we\ninclude the architecture and the development details of the Hybrid application.\nNext, we present our results on usability and the efficiency of the idea we\npropose.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2305.11871v1",
    "pdf_url": "http://arxiv.org/pdf/2305.11871v1",
    "full_text": "AMITY - A HYBRID MENTAL HEALTH APPLICATION\n\nSrija Santhanam , Kavipriya P , Balamurugan MS\n\nSchool of Electronics Engineering , Vellore Institute of Technology , Chennai , India\n\nABSTRACT.\n\nWellness in trivial terms combines physical, social, and mental well-being. While mental health\nis generally neglected,\nlong-term success in a person’s life is mostly determined by his\npsychological health and contentment. For a person in distress, professional mental health\nservices are quite expensive, unpopular, and invite a lot of hesitation. Hence, It would be\neffective to use an Android application that can offer day-to-day therapeutic assistance,\nmeditation sessions, and guidance since it can cater to a massive community instantly. In this\npaper, we propose a mobile and web application-AMITY with a chat group and chatbot created\nusing a machine learning approach. We have also built a dataset to train the chatbot model that\nwe propose in this paper. We briefly introduce the dataset and the machine learning model in\nsection 3. In section 4, we include the architecture and the development details of the Hybrid\napplication. Next, we present our results on usability and the efficiency of the idea we propose.\n\nINTRODUCTION\n\nEmotional well-being stands equal to physical well-being and plays a vital role in creating\npositive relationships, giving back to the community, and feeling accepted in groups. Positive\nmental health can help us deal with stress, adapt to changes, make difficult decisions, and\nmanage emotions.\n\nMental health has become a rising concern over the past decade, especially after a pandemic\nthat scaled worldwide and terrorized lakhs of people in their homes. In 2020, the Centers for\nDisease Control and Prevention in the United States found that there was a 31% increase in the\nnumber of people with mental health disorders from the previous year due to COVID-19.\nAlarmingly, about 381 suicides happen every day in India according to National Crime Records\nBureau(2019).\n\nAround 10% of the population of India in 2015-2016 was found to need Counseling services out\nof which only 28% received treatment. Also, mental health issues are shunned and ostracized\nsince there is not much awareness propagated. There is an inadequacy in the number of mental\nhealth professionals and the percentage of funds allocated by the Government of India is\nminimal. Consequently, psychological therapy is expensive in India and people in turn solicit\nhelp from conventional\nInstitutions such as religious establishments, cultural practices, or\nimmediate friends and family.\n\nThe vast majority do not\ntreat mental health problems until their effects become severe.\nProfessional help is not immediate. A significant fraction might also find it difficult to share their\n\n\fproblems with another individual face to face. It is said that 1 in 4 people have mental health\nproblems in their lifetime. Supply does not meet the demands here. Hence, a vast platform such\nas an Android application surely is a benefit. A multitude of mental health applications exist\noffering breathing and meditation practices, sleep stories, and mindfulness exercises. There is\nthis app called ‘WoeBot’ offering cognitive behavioral therapy exercises to induce sleep. Another\napplication ‘BetterHelp’ connects users with therapists online and the MoodFit app tracks the\nmood of the user on a day-to-day basis with which required exercises are suggested. Generally,\npeople need to talk or let out their emotions to someone on an immediate basis to relieve stress,\nanxiety, or frustration. The problem is that there would not be many that may listen and\nempathize. Our solution involves a group chat feature that helps people with similar problems\nconnect, talk and help each other out anytime and anywhere which is lacking in the majority of\nthe apps out there.\n\nEmotional Artificial Intelligence uses machine learning to detect and respond to the emotions of\nhumans with technologies such as Computer Vision and Natural Language Processing. Facial\nRecognition algorithms are used for detecting expressions, while chatbots enable conversations\nwith users based on their mood that could be tracked from their messages. Hence, helping\npeople who are depressed will be made easier and cheaper with Artificial Intelligence. We\ninclude an NLP-based chatbot in our application that offers quick therapeutic assistance to the\nusers based on their input. We also suggest diet and exercise plans as an additional feature.\nUsers would also be able to call therapists if they need a professional to talk to.\n\n2.RELATED WORKS\n\nThere are a few psychotherapeutic approaches used for mental wellness. Cognitive Behavioral\nTherapy (CBT). Dialectical Behavior Therapy (DBT), Acceptance and Commitment Therapy\n(ACT), Psychodynamic Therapy, Interpersonal Therapy (IPT), Eye Movement Desensitization\nand Reprocessing (EMDR), and Mindfulness-Based Therapies, are some of\nthe major\npsychotherapeutic approaches used. Among the above ther"
  },
  {
    "title": "Rethinking Large Language Models in Mental Health Applications",
    "authors": [
      "Shaoxiong Ji",
      "Tianlin Zhang",
      "Kailai Yang",
      "Sophia Ananiadou",
      "Erik Cambria"
    ],
    "abstract": "Large Language Models (LLMs) have become valuable assets in mental health,\nshowing promise in both classification tasks and counseling applications. This\npaper offers a perspective on using LLMs in mental health applications. It\ndiscusses the instability of generative models for prediction and the potential\nfor generating hallucinatory outputs, underscoring the need for ongoing audits\nand evaluations to maintain their reliability and dependability. The paper also\ndistinguishes between the often interchangeable terms ``explainability'' and\n``interpretability'', advocating for developing inherently interpretable\nmethods instead of relying on potentially hallucinated self-explanations\ngenerated by LLMs. Despite the advancements in LLMs, human counselors'\nempathetic understanding, nuanced interpretation, and contextual awareness\nremain irreplaceable in the sensitive and complex realm of mental health\ncounseling. The use of LLMs should be approached with a judicious and\nconsiderate mindset, viewing them as tools that complement human expertise\nrather than seeking to replace it.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2311.11267v2",
    "pdf_url": "http://arxiv.org/pdf/2311.11267v2",
    "full_text": "3\n2\n0\n2\nc\ne\nD\n7\n1\n\n]\nL\nC\n.\ns\nc\n[\n\n2\nv\n7\n6\n2\n1\n1\n.\n1\n1\n3\n2\n:\nv\ni\nX\nr\na\n\nRethinking Large Language Models\nin Mental Health Applications\n\nShaoxiong Ji †, Tianlin Zhang ⋆, Kailai Yang ⋆, Sophia Ananiadou ⋆, and Erik\nCambria α\n\n†\n\nUniversity of Helsinki, Finland\n⋆ The University of Manchester, UK\nαNanyang Technological University, Singapore\nEmail: shaoxiong.ji@helsinki.fi; {kailai.yang,tianlin.zhang}@postgrad.manchester.ac.uk;,\nsophia.ananiadou@manchester.ac.uk, cambria@ntu.edu.sg\n\nAbstract\n\nLarge Language Models (LLMs) have become valuable assets in mental health, showing promise\nin both classification tasks and counseling applications. This paper offers a perspective on using\nLLMs in mental health applications. It discusses the instability of generative models for predic-\ntion and the potential for generating hallucinatory outputs, underscoring the need for ongoing au-\ndits and evaluations to maintain their reliability and dependability. The paper also distinguishes\nbetween the often interchangeable terms “explainability” and “interpretability”, advocating for\ndeveloping inherently interpretable methods instead of relying on potentially hallucinated self-\nexplanations generated by LLMs. Despite the advancements in LLMs, human counselors’ em-\npathetic understanding, nuanced interpretation, and contextual awareness remain irreplaceable\nin the sensitive and complex realm of mental health counseling. The use of LLMs should be ap-\nproached with a judicious and considerate mindset, viewing them as tools that complement human\nexpertise rather than seeking to replace it.\n\n1 Introduction\n\nMental health is important and has been studied by natural language processing (NLP) using text\n(e.g., social posts and doctor-patient conversations) as the data sources, leading to the development\nof automatic methods for various applications, including early detection of mental disorders [49]\nand mental health counseling [1]. Researchers have employed techniques, ranging from traditional\nfeature engineering to automatic feature learning, such as convolutional neural networks, recurrent\nneural networks, and transformer networks, for mental illness detection and classification [49]. Re-\ncent advances utilize pretrained language models (PLMs). PLMs trained with the masked language\nmodeling objective have become popular for training classification models in this domain. Domain-\nspecific continual pre-training has also undergone intensive development to acquire domain knowl-\nedge with representative discriminative models including PsychBERT [41], MentalBERT [18], PHS-\nBERT [31], and MentalLongformer [19]. A recent shift as in Figure 1 has occurred towards prompt\nlearning, where generative large language models (LLMs) such as SmileChat [33], Psy-LLM [22],\nMental-LLM [46], MentalLLaMA [48], ChatCounselor [26], and MindWatch [4], are used to gen-\nerate predictions or counseling based on input prompts related to mental health conditions. This\nshift signifies a growing interest in leveraging generative LLMs and prompt learning for mental\nhealth-related tasks. However, one question looms large: is this a mere hype? This paper delves into\nthe recent developments and concerns surrounding the use of LLMs for early prediction of mental\nhealth conditions, generating explanations for mental health conditions, and generating responses\nin mental health counseling.\n\nThe landscape of large language models has undergone substantial transformation in recent\nyears. Current LLMs boast hundreds of billions of parameters, a stark contrast to the relatively\nmodest sizes seen in the early 2010s, typically ranging from millions to tens of millions of pa-\nrameters. Notably, models such as BERT, with 110 million parameters, and GPT-2, with 1.5 billion\n\n1\n\n \n \n \n \n \n \n\fFigure 1: A paradigm shift in NLP for mental health applications from masked language models\nsuch as BERT to generative language models such as GPT and LLaMA. Images of BERT, GPT, LLaMA\nare generated by Midjourney AI Art Generator.\n\nparameters, which were once considered large, now fall into the category of medium-sized language\nmodels by standards at the time of writing. It is important to note that the size of language models is\nnot the only factor determining their performance. Other factors, such as model architecture, train-\ning data, and fine-tuning, also play significant roles in their capabilities. This growth in model size\nreflects the ongoing evolution of AI language models. This paper focuses on the recent use of gen-\nerative LLMs in mental health applications. For the purpose of this paper, the term “LLMs” refers\nto generative models trained with the causal language modeling objective, often called next-word\nprediction in a simpler term.\n\nOur paper offers perspectives on rethinking large language models in the context of mental\nhealthcare. When using generation to predict mental health conditions based on a prompt and\npost, it is worth noting that the generation-as-prediction process can "
  },
  {
    "title": "PsyChat: A Client-Centric Dialogue System for Mental Health Support",
    "authors": [
      "Huachuan Qiu",
      "Anqi Li",
      "Lizhi Ma",
      "Zhenzhong Lan"
    ],
    "abstract": "Dialogue systems are increasingly integrated into mental health support to\nhelp clients facilitate exploration, gain insight, take action, and ultimately\nheal themselves. A practical and user-friendly dialogue system should be\nclient-centric, focusing on the client's behaviors. However, existing dialogue\nsystems publicly available for mental health support often concentrate solely\non the counselor's strategies rather than the behaviors expressed by clients.\nThis can lead to unreasonable or inappropriate counseling strategies and\ncorresponding responses generated by the dialogue system. To address this\nissue, we propose PsyChat, a client-centric dialogue system that provides\npsychological support through online chat. The client-centric dialogue system\ncomprises five modules: client behavior recognition, counselor strategy\nselection, input packer, response generator, and response selection. Both\nautomatic and human evaluations demonstrate the effectiveness and practicality\nof our proposed dialogue system for real-life mental health support.\nFurthermore, the case study demonstrates that the dialogue system can predict\nthe client's behaviors, select appropriate counselor strategies, and generate\naccurate and suitable responses.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2312.04262v2",
    "pdf_url": "http://arxiv.org/pdf/2312.04262v2",
    "full_text": "PsyChat: A Client-Centric Dialogue System for\nMental Health Support\n\nHuachuan Qiu1,2, Anqi Li1,2, Lizhi Ma2, Zhenzhong Lan2,†\n1Zhejiang University, Hangzhou, China\n2School of Engineering, Westlake University, Hangzhou, China\n{qiuhuachuan, lanzhenzhong}@westlake.edu.cn\n\n4\n2\n0\n2\n\nr\na\n\nM\n0\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n2\nv\n2\n6\n2\n4\n0\n.\n2\n1\n3\n2\n:\nv\ni\nX\nr\na\n\nAbstract—Dialogue systems are increasingly integrated into\nmental health support\nto help clients facilitate exploration,\ngain insight, take action, and ultimately heal themselves. A\npractical and user-friendly dialogue system should be client-\ncentric, focusing on the client’s behaviors. However, existing\ndialogue systems publicly available for mental health support\noften concentrate solely on the counselor’s strategies rather than\nthe behaviors expressed by clients. This can lead to unreason-\nable or inappropriate counseling strategies and corresponding\nresponses generated by the dialogue system. To address this\nissue, we propose PsyChat, a client-centric dialogue system that\nprovides psychological support through online chat. The client-\ncentric dialogue system comprises five modules: client behavior\nrecognition, counselor strategy selection, input packer, response\ngenerator, and response selection. Both automatic and human\nevaluations demonstrate the effectiveness and practicality of our\nproposed dialogue system for real-life mental health support. Fur-\nthermore, the case study demonstrates that the dialogue system\ncan predict the client’s behaviors, select appropriate counselor\nstrategies, and generate accurate and suitable responses.\n\nIndex Terms—dialogue system, client-centric, mental health\nsupport, client behavior recognition, counselor strategy selection\n\nI. INTRODUCTION\n\nMental health [1] is a growing concern in our fast-paced and\ndigitally connected world. However, traditional mental health\nsupport services often face challenges related to accessibility,\naffordability, and stigma. Additionally, face-to-face interviews\nwith counselors are constrained by time and space. Therefore,\nmany individuals are hesitant to seek help due to these barriers,\nleaving their mental well-being at risk. With the increasing\ndemand for mental health support, there is a pressing need for\ninnovative approaches to effectively meet this demand.\n\nDialogue systems are increasingly integrated into mental\nhealth support to assist clients in exploring, gaining insight,\ntaking action, and ultimately facilitating self-healing [2]. A\npractical and user-friendly dialogue system should be client-\ncentric, focusing on clients’ behaviors. However, existing\ndialogue systems [3]–[5] for mental health support often\nconcentrate solely on counselors’ strategies, frequently over-\nlooking the behaviors expressed by clients. This tendency\nleads to unreasonable or inappropriate counseling strategies\nand corresponding responses produced by the dialogue system.\nMore specifically, a practical and user-friendly dialogue sys-\ntem should prioritize considering clients’ states. Therefore, it\n\nFig. 1. An illustration depicting how a counselor tailors strategies in response\nto the behaviors exhibited by the client.\n\nshould adjust its strategies based on clients’ current behaviors,\nmimicking human counselors, as illustrated in Figure 1.\n\nIn light of this, we introduce PsyChat, a client-centric\ndialogue system designed to provide psychological support\nthrough online chat. The client-centric dialogue system con-\nsists of five modules: client behavior recognition, counselor\nstrategy selection, input packer, response generator, and re-\nsponse selection. The response generation module is intention-\nally fine-tuned using synthetic and real-life dialogue datasets.\nThe primary contributions of this paper are as follows:\n\n• To the best of our knowledge, we are the first to propose a\nclient-centric dialogue system for mental health support,\nwith a priority on considering the client’s behaviors.\n• We optimize collaboration among modules by conducting\nextensive experiments to identify the optimal model for\neach. These selected models are then integrated to form\na cohesive dialogue system dedicated to mental health.\n• Automatic and human evaluations demonstrate the ef-\nfectiveness and practicality of our developed dialogue\nsystem. Finally, we release our code and model1 to\nfacilitate research in mental health support.\n\nII. RELATED WORK\n\nWhile the development of integrated dialogue systems for\nmental health support remains unexplored, we offer a summary\n\n† Corresponding Author.\n\n1https://github.com/qiuhuachuan/PsyChat\n\n( Negative – Sarcastic Answer )You always provide me with encouragement and support, and it feels a bit like you're just going through the motions. Any practical advice you can offer?Counselor( Supporting – Restatement )You mentioned struggling with procrastination.( Supporting – Affirmation and Reassurance )It's impressive that you're aware of this tendency.( Positive – Confirming )I really appreciate your underst"
  },
  {
    "title": "The Role of Likes: How Online Feedback Impacts Users' Mental Health",
    "authors": [
      "Angelina Voggenreiter",
      "Sophie Brandt",
      "Fabian Putterer",
      "Andreas Frings",
      "Juergen Pfeffer"
    ],
    "abstract": "Social media usage has been shown to have both positive and negative\nconsequences for users' mental health. Several studies indicated that peer\nfeedback plays an important role in the relationship between social media use\nand mental health. In this research, we analyse the impact of receiving online\nfeedback on users' emotional experience, social connectedness and self-esteem.\nIn an experimental study, we let users interact with others on a Facebook-like\nsystem over the course of a week while controlling for the amount of positive\nreactions they receive from their peers. We find that experiencing little to no\nreaction from others does not only elicit negative emotions and stress amongst\nusers, but also induces low levels of self-esteem. In contrast, receiving much\npositive online feedback, evokes feelings of social connectedness and reduces\noverall loneliness. On a societal level, our study can help to better\nunderstand the mechanisms through which social media use impacts mental health\nin a positive or negative way. On a methodological level, we provide a new\nopen-source tool for designing and conducting social media experiments.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2312.11914v1",
    "pdf_url": "http://arxiv.org/pdf/2312.11914v1",
    "full_text": "3\n2\n0\n2\nc\ne\nD\n9\n1\n\n]\n\nY\nC\n.\ns\nc\n[\n\n1\nv\n4\n1\n9\n1\n1\n.\n2\n1\n3\n2\n:\nv\ni\nX\nr\na\n\nThe Role of Likes: How Online Feedback Impacts Users’ Mental\nHealth\n\nAngelina Voggenreiter*1\n0000-0001-6597-3514\n\nSophie Brandt*\n0009-0003-6999-5106\n\nFabian Putterer*\n0009-0009-9310-3634\n\nAndreas Frings*\n0009-0009-4993-0384\n\nJ¨urgen Pfeffer*\n0000-0002-1677-150X\n\n*School of Social Sciences and Technology, Technical University of Munich\n1angelina.voggenreiter@tum.de\n\nAbstract\n\n1\n\nIntroduction\n\nSocial media usage has been shown to have both\npositive and negative consequences for users’ mental\nhealth. Several studies indicated that peer feedback\nplays an important role in the relationship between\nsocial media use and mental health. In this research,\nwe analyse the impact of receiving online feedback\non users’ emotional experience, social connectedness\nand self-esteem.\nIn an experimental study, we let\nusers interact with others on a Facebook-like system\nover the course of a week while controlling for the\namount of positive reactions they receive from their\npeers. We find that experiencing little to no reaction\nfrom others does not only elicit negative emotions and\nstress amongst users, but also induces low levels of\nself-esteem. In contrast, receiving much positive on-\nline feedback, evokes feelings of social connectedness\nand reduces overall loneliness. On a societal level,\nour study can help to better understand the mecha-\nnisms through which social media use impacts mental\nhealth in a positive or negative way. On a method-\nological level, we provide a new open-source tool for\ndesigning and conducting social media experiments.\n\nKeywords\nself-\nsocial media, Facebook,\nesteem, social status, ostracism, rejection, exclusion\n\nlikes,\n\nWorldwide, more than 4.5 billion people use social\nmedia platforms, such as Facebook, Twitter or In-\nstagram. This number is expected to rise in the fol-\nlowing years, with an estimated 5.85 billion users by\n2027 [6]. Based on the sheer amount of people ac-\ntively participating in such online spaces, it is impor-\ntant to understand the impact social media can have\non their users.\n\nOn the one hand, social media offers tremendous\npossibilities to improve people’s mental health: So-\ncial media has been shown to provide distinct social\nsupport and connectedness, which can be associated\nwith better mental health outcomes [15].\n\nEspecially when looking at marginalized groups\nsuch as the LGBTQIA+ community, social media\ncan serve as a place to find friends and social sup-\nport. For example, LGBTQIA+ youth is more likely\nthan non-LGBTQIA+ youth to report having friends\nexclusively known online, who are further described\nas more supportive than their in-person friendships,\nproving how the internet can serve as a safe space for\nreceiving both social and emotional encouragement\n[21]. By investigating the online behaviour of uni-\nversity students an overall positive indirect impact\nof social media use on psychological well-being was\n\n1\n\n \n \n \n \n \n \n\ffound. The effect was mainly derived from its posi-\ntive effect on bonding and bridging social capital, im-\nplying that the use of social media allows students to\ncontinue their close relationships during events such\nas a pandemic. Further, social media was shown to\nimprove trust and promote the establishing of social\nconnections. Finally, it was found that students can\nuse social media platforms to receive emotional sup-\nport and increase their potential to mobilize others or\nbuild social networks, leading to social belongingness\n[11].\n\nOn the other hand, social media use has also\nbeen associated with numerous mental health issues,\nsuch as anxiety, depression, loneliness, poor quality\nof sleep, thoughts of self-harm and suicide, and in-\ncreased levels of psychological distress [14].\n\nCoyne et al.\n\n[2] performed an eight-year longi-\ntudinal study to analyse the effects of social media\nuse on adolescents’ mental health. Based on an-\nnual surveys, they found that, although there were\nno within-subjects relationships between social me-\ndia usage time and mental health consequences, par-\nticipants who spent more time on social media had a\nhigher chance of experiencing anxiety and depression,\ncompared to others [2].\n\nFurther investigation into social networks and their\nrelationship to student mental health showed that\nsymptoms of poor mental health, especially depres-\nsion, increased with a roll-out of Facebook at the col-\nlege. For students predicted to be most susceptible to\nmental illness, the introduction of Facebook led to an\nincreased uptake of mental healthcare services. Addi-\ntionally, the likelihood to report a negative impact of\npoor mental health on their academic performance\nincreased [1]. Another study looking specifically at\nadolescents showed higher usage of social media and\nhigher emotional investment in social media leads to\na poorer quality of sleep, higher levels of anxiety and\ndepression, and lower self-esteem [20].\n\nHowever, the mechanisms in which social media\nmigh"
  },
  {
    "title": "Mental Workload Estimation with Electroencephalogram Signals by\n  Combining Multi-Space Deep Models",
    "authors": [
      "Hong-Hai Nguyen",
      "Ngumimi Karen Iyortsuun",
      "Seungwon Kim",
      "Hyung-Jeong Yang",
      "Soo-Hyung Kim"
    ],
    "abstract": "The human brain remains continuously active, whether an individual is working\nor at rest. Mental activity is a daily process, and if the brain becomes\nexcessively active, known as overload, it can adversely affect human health.\nRecently, advancements in early prediction of mental health conditions have\nemerged, aiming to prevent serious consequences and enhance the overall quality\nof life. Consequently, the estimation of mental status has garnered significant\nattention from diverse researchers due to its potential benefits. While various\nsignals are employed to assess mental state, the electroencephalogram,\ncontaining extensive information about the brain, is widely utilized by\nresearchers. In this paper, we categorize mental workload into three states\n(low, middle, and high) and estimate a continuum of mental workload levels. Our\nmethod leverages information from multiple spatial dimensions to achieve\noptimal results in mental estimation. For the time domain approach, we employ\nTemporal Convolutional Networks. In the frequency domain, we introduce a novel\narchitecture based on combining residual blocks, termed the Multi-Dimensional\nResidual Block. The integration of these two domains yields significant results\ncompared to individual estimates in each domain. Our approach achieved a 74.98%\naccuracy in the three-class classification, surpassing the provided data\nresults at 69.00%. Specially, our method demonstrates efficacy in estimating\ncontinuous levels, evidenced by a corresponding Concordance Correlation\nCoefficient (CCC) result of 0.629. The combination of time and frequency domain\nanalysis in our approach highlights the exciting potential to improve\nhealthcare applications in the future.",
    "year": 2023,
    "url": "http://arxiv.org/abs/2308.02409v2",
    "pdf_url": "http://arxiv.org/pdf/2308.02409v2",
    "full_text": "4\n2\n0\n2\n\nr\na\n\nM\n2\n1\n\n]\nP\nS\n.\ns\ns\ne\ne\n[\n\n2\nv\n9\n0\n4\n2\n0\n.\n8\n0\n3\n2\n:\nv\ni\nX\nr\na\n\nMENTAL WORKLOAD ESTIMATION WITH\n\nELECTROENCEPHALOGRAM SIGNALS BY COMBINING\n\nMULTI-SPACE DEEP MODELS\n\nHong-Hai Nguyen, Ngumimi Karen Iyortsuun, Seungwon Kim, Hyung-Jeong Yang, and Soo-Hyung Kim ∗\n\nArtificial Intelligence Convergence, Chonnam National University, Gwangju, 61186, South Korea\n\nhonghaik14@gmail.com; kareniyortsuun@gmail.com; Seungwon.Kim@jnu.ac.kr; hjyang@jnu.ac.kr; shkim@jnu.ac.kr.\n\nABSTRACT\n\nThe human brain remains continuously active, whether an individual is working or at rest. Mental\n\nactivity is a daily process, and if the brain becomes excessively active, known as overload, it\n\ncan adversely affect human health. Recently, advancements in early prediction of mental health\n\nconditions have emerged, aiming to prevent serious consequences and enhance the overall quality of\n\nlife. Consequently, the estimation of mental status has garnered significant attention from diverse\n\nresearchers due to its potential benefits. While various signals are employed to assess mental state,\n\nthe electroencephalogram, containing extensive information about the brain, is widely utilized by\n\nresearchers. In this paper, we categorize mental workload into three states (low, middle, and high) and\n\nestimate a continuum of mental workload levels. Our method leverages information from multiple\n\nspatial dimensions to achieve optimal results in mental estimation. For the time domain approach,\n\nwe employ Temporal Convolutional Networks. In the frequency domain, we introduce a novel\n\narchitecture based on combining residual blocks, termed the Multi-Dimensional Residual Block. The\n\nintegration of these two domains yields significant results compared to individual estimates in each\n\ndomain. Our approach achieved a 74.98% accuracy in the three-class classification, surpassing the\n\nprovided data results at 69.00%. Specially, our method demonstrates efficacy in estimating continuous\n\nlevels, evidenced by a corresponding Concordance Correlation Coefficient (CCC) result of 0.629.\n\nThe combination of time and frequency domain analysis in our approach highlights the exciting\n\npotential to improve healthcare applications in the future.\n\nKeywords Electroencephalogram · Mental Workload · Temporal Convolutional Networks · Time-Frequency domains\n\n∗Corresponding author: Soo-Hyung Kim\n\n \n \n \n \n \n \n\fMental Workload Estimation with Electroencephalogram Signals by Combining Multi-Space Deep Models\n\n1\n\nIntroduction\n\nMental workload (MWL) refers to brain activities, which are the number of resources in the human brain. The level\n\nof the resource can be changed when the human is thinking or performing a task [1]. Because the mental workload\n\nresource of a person is limited, the ability to process a lot of information at once will be limited [2, 3]. Humans will be\n\nbored if they do easy work when their MWL is low and their MWL is high when they do complicated tasks. However, a\n\nhigh MWL is not suitable for their health [4] and can impair their abilities for memory, communication, activity, etc. For\n\njobs with high MWL, such as doctors, soldiers and pilots, the brain sometimes has serious accidents [5]. Furthermore,\n\nunderstanding how the human brain works in daily activities and tasks is an essential area of neuroergonomics research.\n\nTherefore, the MWL estimation helps to observe and help people at work and evaluate their work system, which can\n\nbe improved in the future [6]. Because the EEG signal is a recording of the biological activities of individual brain\n\ncells or a subset of brain cells transmitted directly or indirectly through the cerebral cortex and scalp. EEG signals that\n\nrecord brain activities reflect physiological and pathological functions of the hemisphere or of the whole brain related\n\nto clinical symptoms, supplementing diagnosis and monitoring treatment, called a clinical electroencephalogram. By\n\nproviding a reliable EEG can contribute to predicting and preventing work-related risks. Diagnostic applications in\n\nMWL estimation can be created to address various real-world issues in healthcare, education, and smart traffic, among\n\nothers [7, 8].\n\nThree metrics were used to measure MWL, namely subject, performance, and physiological measures [6, 9–11]. The\n\ntraditional method to measure the context is through a set of various questions, such as the Aeronautics and Space\n\nAdministration Task Load Index (NASA-TLX) [12] or Assessment Technique (SWAT) [13]. Performance measurement\n\ninvolves measuring the person’s performance during the task with an increasing workload. Both subject and performance\n\nmeasures are taken after the task is completed, making them prone to bias. On the contrary, physiological measurements\n\ncan continuously record information about the workload and do not affect the performance of the main task. Therefore,\n\nphysiological signals can be used to evaluate the effectiveness of mental workload.\n\nPhysiological measurement uses a variet"
  },
  {
    "title": "Engagement Patterns of Peer-to-Peer Interactions on Mental Health\n  Platforms",
    "authors": [
      "Ashish Sharma",
      "Monojit Choudhury",
      "Tim Althoff",
      "Amit Sharma"
    ],
    "abstract": "Mental illness is a global health problem, but access to mental healthcare\nresources remain poor worldwide. Online peer-to-peer support platforms attempt\nto alleviate this fundamental gap by enabling those who struggle with mental\nillness to provide and receive social support from their peers. However,\nsuccessful social support requires users to engage with each other and failures\nmay have serious consequences for users in need. Our understanding of\nengagement patterns on mental health platforms is limited but critical to\ninform the role, limitations, and design of these platforms. Here, we present a\nlarge-scale analysis of engagement patterns of 35 million posts on two popular\nonline mental health platforms, TalkLife and Reddit. Leveraging communication\nmodels in human-computer interaction and communication theory, we\noperationalize a set of four engagement indicators based on attention and\ninteraction. We then propose a generative model to jointly model these\nindicators of engagement, the output of which is synthesized into a novel set\nof eleven distinct, interpretable patterns. We demonstrate that this framework\nof engagement patterns enables informative evaluations and analysis of online\nsupport platforms. Specifically, we find that mutual back-and-forth\ninteractions are associated with significantly higher user retention rates on\nTalkLife. Such back-and-forth interactions, in turn, are associated with early\nresponse times and the sentiment of posts.",
    "year": 2020,
    "url": "http://arxiv.org/abs/2004.04999v1",
    "pdf_url": "http://arxiv.org/pdf/2004.04999v1",
    "full_text": "Engagement Patterns of Peer-to-Peer Interactions on Mental Health Platforms\n\nAshish Sharma1∗ Monojit Choudhury2 Tim Althoff1 Amit Sharma2\n1Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, USA\n2Microsoft Research, Bangalore, India\n1{ashshar,althoff}@cs.washington.edu 2{monojitc,amshar}@microsoft.com\n\n0\n2\n0\n2\n\nr\np\nA\n0\n1\n\n]\nI\nS\n.\ns\nc\n[\n\n1\nv\n9\n9\n9\n4\n0\n.\n4\n0\n0\n2\n:\nv\ni\nX\nr\na\n\nAbstract\n\nMental illness is a global health problem, but access to men-\ntal healthcare resources remain poor worldwide. Online peer-\nto-peer support platforms attempt to alleviate this fundamen-\ntal gap by enabling those who struggle with mental illness\nto provide and receive social support from their peers. How-\never, successful social support requires users to engage with\neach other and failures may have serious consequences for\nusers in need. Our understanding of engagement patterns on\nmental health platforms is limited but critical to inform the\nrole, limitations, and design of these platforms. Here, we\npresent a large-scale analysis of engagement patterns of 35\nmillion posts on two popular online mental health platforms,\nTALKLIFE and REDDIT. Leveraging communication models\nin human-computer interaction and communication theory,\nwe operationalize a set of four engagement indicators based\non attention and interaction. We then propose a generative\nmodel to jointly model these indicators of engagement, the\noutput of which is synthesized into a novel set of eleven dis-\ntinct, interpretable patterns. We demonstrate that this frame-\nwork of engagement patterns enables informative evaluations\nand analysis of online support platforms. Speciﬁcally, we ﬁnd\nthat mutual back-and-forth interactions are associated with\nsigniﬁcantly higher user retention rates on TALKLIFE. Such\nback-and-forth interactions, in turn, are associated with early\nresponse times and the sentiment of posts.\n\n1\n\nIntroduction\n\nMental illness is an alarming global health issue with ad-\nverse social and economic consequences. Mental illness\nand related behavioral health problems contribute 13% to\nthe global burden of disease, more than cardiovascular dis-\neases and cancer (Collins et al. 2011). Still, access to men-\ntal health care is poor worldwide. Most low-income and\nmiddle-income countries have less than one psychiatrist per\n100,000 individuals (Rathod et al. 2017). Even in high-\nincome countries like the United States, 60% of counties do\nnot have a single psychiatrist (New-American-Economy Re-\nsearch, 2019).\n\n∗This work was done when the author was a Research Fellow\n\nat Microsoft Research, India.\nCopyright c(cid:13) 2020, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\n\nResearch suggests that for people in distress, connecting\nand interacting with peers can be helpful in coping with\nmental illness, enhancing mental well-being and developing\nsocial integration (Davidson et al. 1999). This form of so-\ncial support (Kaplan, Cassel, and Gore 1977) through peers\ncan be provided online which has stimulated the design and\ndevelopment of online mental health support platforms.\n\nIn recent years, several low-cost and easy-to-access peer-\nto-peer support platforms, such as TALKLIFE & 7Cups1,\nhave provided new pathways for seeking social support and\ndealing with mental health challenges. These platforms al-\nlow interactions between support seekers and peers in a\nthread-like setting; it starts with a user writing a support\nseeking post which elicits responses from peers and subse-\nquent interactions between the users. Online platforms have\nmultiple advantages over traditional face-to-face supportive\nmethods: they enable asynchronous conversations by de-\nsign; they are unrestricted by time, space and geographic\nboundaries; and they facilitate anonymous disclosures which\ncan be helpful in dealing with the major challenge of stigma\nassociated with mental illness (White and Dorman 2001).\n\nHowever, for these platforms to be successful at facili-\ntating peer-to-peer support, users need to interact and en-\ngage. A user who wants to seek support on the platform\n(henceforth referred to as seeker) needs to interact with a\npeer who is willing to provide support (henceforth referred\nas peer-supporter). For example, on TALKLIFE, one third\nof support-seeking posts by users do not receive any re-\nsponses at all. Receiving no response or having limited en-\ngagement with peers can have serious consequences on a\nmental health platform with vulnerable users, a number of\nwhom are at risk for self-harm or suicide. Also, as indi-\ncated in prior literature, engagement between users is key\nfor ensuring favorable outcomes on these platforms (Van\nUden-Kraan et al. 2011), including overcoming cognitive\ndistortion, effective distraction, and empathy (Taylor 2011;\nMayshak et al. 2017).\n\nPrior work on engagement between users on support plat-\nforms have focused on ﬁnding its correlations with several\nuser and platform related char"
  }
]